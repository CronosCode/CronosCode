
# A FIRST COURSE IN PROBABILITY


_This page intentionally left blank_


# A FIRST COURSE IN PROBABILITY

## Eighth Edition

## Sheldon Ross

_University of Southern California_

_Upper Saddle River, New Jersey 07458_


**Library of Congress Cataloging-in-Publication Data**
Ross, Sheldon M.
A first course in probability / Sheldon Ross. — 8th ed.
p. cm.
Includes bibliographical references and index.
ISBN-13: 978-0-13-603313-
ISBN-10: 0-13-603313-X

1. Probabilities—Textbooks. I. Title.
QA273.R83 2010
519.2—dc
    2008033720

Editor in Chief, Mathematics and Statistics: _Deirdre Lynch_
Senior Project Editor: _Rachel S. Reeve_
Assistant Editor: _Christina Lepre_
Editorial Assistant: _Dana Jones_
Project Manager: _Robert S. Merenoff_
Associate Managing Editor: _Bayani Mendoza de Leon_
Senior Managing Editor: _Linda Mihatov Behrens_
Senior Operations Supervisor: _Diane Peirano_
Marketing Assistant: _Kathleen DeChavez_
Creative Director: _Jayne Conte_
Art Director/Designer: _Bruce Kenselaar_
AV Project Manager: _Thomas Benfatti_
Compositor: _Integra Software Services Pvt. Ltd, Pondicherry, India_
Cover Image Credit: _Getty Images, Inc._

##### ©2010, 2006, 2002, 1998, 1994, 1988,

```
1984, 1976 by Pearson Education, Inc.,
Pearson Prentice Hall
Pearson Education, Inc.
Upper Saddle River, NJ 07458
```
All rights reserved. No part of this book may be reproduced, in any
form or by any means, without permission in writing from the publisher.

Pearson Prentice Hall™is a trademark of Pearson Education, Inc.

Printed in the United States of America

10987654321

ISBN-13: 978-0-13-603313-
ISBN-10: 0-13-603313-X

Pearson Education, Ltd., _London_
Pearson Education Australia PTY. Limited, _Sydney_
Pearson Education _Singapore_ , Pte. Ltd
Pearson Education North Asia Ltd, _Hong Kong_
Pearson Education Canada, Ltd., _Toronto_
Pearson Educacion de Mexico, S.A. de C.V. ́
Pearson Education – Japan, _Tokyo_
Pearson Education Malaysia, Pte. Ltd
Pearson Education _Upper Saddle River_ , New Jersey


_For Rebecca_


_This page intentionally left blank_


## Contents



8.6 Bounding the Error Probability When Approximating a Sum of


- 1 Combinatorial Analysis Preface xi
   - 1.1 Introduction
   - 1.2 The Basic Principle of Counting
   - 1.3 Permutations.................................
   - 1.4 Combinations
   - 1.5 Multinomial Coefficients
   - 1.6 The Number of Integer Solutions of Equations
      - Summary
      - Problems...................................
      - Theoretical Exercises
      - Self-Test Problems and Exercises
- 2 Axioms of Probability
   - 2.1 Introduction
   - 2.2 SampleSpaceandEvents..........................
   - 2.3 Axioms of Probability
   - 2.4 Some Simple Propositions
   - 2.5 Sample Spaces Having Equally Likely Outcomes
   - 2.6 Probability as a Continuous Set Function
   - 2.7 Probability as a Measure of Belief
      - Summary
      - Problems...................................
      - Theoretical Exercises
      - Self-Test Problems and Exercises
- 3 Conditional Probability and Independence
   - 3.1 Introduction
   - 3.2 Conditional Probabilities
   - 3.3 Bayes’s Formula
   - 3.4 IndependentEvents.............................
   - 3.5 P (·| F ) Is a Probability
      - Summary
      - Problems...................................
      - Theoretical Exercises
      - Self-Test Problems and Exercises
- 4 Random Variables
   - 4.1 Random Variables..............................
   - 4.2 Discrete Random Variables
   - 4.3 ExpectedValue
   - 4.4 Expectation of a Function of a Random Variable
   - 4.5 Variance
   - 4.6 The Bernoulli and Binomial Random Variables
      - 4.6.1 Properties of Binomial Random Variables............
      - 4.6.2 Computing the Binomial Distribution Function
   - 4.7 The Poisson Random Variable....................... viii Contents
      - 4.7.1 Computing the Poisson Distribution Function
   - 4.8 Other Discrete Probability Distributions
      - 4.8.1 The Geometric Random Variable
      - 4.8.2 The Negative Binomial Random Variable
      - 4.8.3 The Hypergeometric Random Variable
      - 4.8.4 TheZeta(orZipf)Distribution..................
   - 4.9 Expected Value of Sums of Random Variables
   - 4.10 Properties of the Cumulative Distribution Function
      - Summary
      - Problems...................................
      - Theoretical Exercises
      - Self-Test Problems and Exercises
- 5 Continuous Random Variables
   - 5.1 Introduction
   - 5.2 Expectation and Variance of Continuous Random Variables
   - 5.3 The Uniform Random Variable
   - 5.4 Normal Random Variables
      - 5.4.1 The Normal Approximation to the Binomial Distribution
   - 5.5 Exponential Random Variables
      - 5.5.1 Hazard Rate Functions.......................
   - 5.6 Other Continuous Distributions
      - 5.6.1 TheGammaDistribution
      - 5.6.2 TheWeibullDistribution
      - 5.6.3 TheCauchyDistribution......................
      - 5.6.4 TheBetaDistribution
   - 5.7 The Distribution of a Function of a Random Variable
      - Summary
      - Problems...................................
      - Theoretical Exercises
      - Self-Test Problems and Exercises
- 6 Jointly Distributed Random Variables
   - 6.1 JointDistributionFunctions
   - 6.2 Independent Random Variables
   - 6.3 Sums of Independent Random Variables
      - 6.3.1 Identically Distributed Uniform Random Variables
      - 6.3.2 Gamma Random Variables
      - 6.3.3 Normal Random Variables
      - 6.3.4 Poisson and Binomial Random Variables
      - 6.3.5 Geometric Random Variables...................
   - 6.4 Conditional Distributions: Discrete Case
   - 6.5 Conditional Distributions: Continuous Case
   - 6.6 OrderStatistics
   - 6.7 Joint Probability Distribution of Functions of Random Variables
   - 6.8 Exchangeable Random Variables
      - Summary
      - Problems...................................
      - Theoretical Exercises
      - Self-Test Problems and Exercises
- 7 Properties of Expectation Contents ix
   - 7.1 Introduction
   - 7.2 Expectation of Sums of Random Variables
         - via the Probabilistic Method 7.2.1 Obtaining Bounds from Expectations
      - 7.2.2 The Maximum–Minimums Identity
   - 7.3 Moments of the Number of Events that Occur
   - 7.4 Covariance, Variance of Sums, and Correlations
   - 7.5 Conditional Expectation
      - 7.5.1 Definitions..............................
      - 7.5.2 Computing Expectations by Conditioning
      - 7.5.3 Computing Probabilities by Conditioning
      - 7.5.4 Conditional Variance
   - 7.6 Conditional Expectation and Prediction
   - 7.7 Moment Generating Functions.......................
      - 7.7.1 Joint Moment Generating Functions
   - 7.8 Additional Properties of Normal Random Variables
      - 7.8.1 The Multivariate Normal Distribution
         - and Sample Variance 7.8.2 The Joint Distribution of the Sample Mean
   - 7.9 General Definition of Expectation
      - Summary
      - Problems...................................
      - Theoretical Exercises
      - Self-Test Problems and Exercises
- 8 Limit Theorems
   - 8.1 Introduction
      - Numbers 8.2 Chebyshev’s Inequality and the Weak Law of Large
   - 8.3 TheCentralLimitTheorem
   - 8.4 The Strong Law of Large Numbers
   - 8.5 Other Inequalities
      - Random Variable Independent Bernoulli Random Variables by a Poisson
      - Summary
      - Problems...................................
      - Theoretical Exercises
      - Self-Test Problems and Exercises
- 9 Additional Topics in Probability
   - 9.1 The Poisson Process
   - 9.2 MarkovChains................................
   - 9.3 Surprise, Uncertainty, and Entropy
   - 9.4 Coding Theory and Entropy
      - Summary
      - Problems and Theoretical Exercises
      - Self-Test Problems and Exercises
      - References
- 10 Simulation x Contents
   - 10.1 Introduction
   - 10.2 General Techniques for Simulating Continuous Random Variables
      - 10.2.1 The Inverse Transformation Method
      - 10.2.2 The Rejection Method
   - 10.3 Simulating from Discrete Distributions
   - 10.4 Variance Reduction Techniques
      - 10.4.1 Use of Antithetic Variables
      - 10.4.2 Variance Reduction by Conditioning
      - 10.4.3 Control Variates
      - Summary
      - Problems...................................
      - Self-Test Problems and Exercises
      - Reference
   - Answers to Selected Problems
   - Solutions to Self-Test Problems and Exercises
   - Index


# Preface

```
“We see that the theory of probability is at bottom only common sense reduced
to calculation; it makes us appreciate with exactitude what reasonable minds feel
by a sort of instinct, often without being able to account for it....It is remarkable
that this science, which originated in the consideration of games of chance, should
have become the most important object of human knowledge....The most important
questions of life are, for the most part, really only problems of probability.” So said
the famous French mathematician and astronomer (the “Newton of France”) Pierre-
Simon, Marquis de Laplace. Although many people feel that the famous marquis,
who was also one of the great contributors to the development of probability, might
have exaggerated somewhat, it is nevertheless true that probability theory has become
a tool of fundamental importance to nearly all scientists, engineers, medical practi-
tioners, jurists, and industrialists. In fact, the enlightened individual had learned to
ask not “Is it so?” but rather “What is the probability that it is so?”
This book is intended as an elementary introduction to the theory of probability
for students in mathematics, statistics, engineering, and the sciences (including com-
puter science, biology, the social sciences, and management science) who possess the
prerequisite knowledge of elementary calculus. It attempts to present not only the
mathematics of probability theory, but also, through numerous examples, the many
diverse possible applications of this subject.
Chapter 1 presents the basic principles of combinatorial analysis, which are most
useful in computing probabilities.
Chapter 2 handles the axioms of probability theory and shows how they can be
applied to compute various probabilities of interest.
Chapter 3 deals with the extremely important subjects of conditional probability
and independence of events. By a series of examples, we illustrate how conditional
probabilities come into play not only when some partial information is available,
but also as a tool to enable us to compute probabilities more easily, even when
no partial information is present. This extremely important technique of obtaining
probabilities by “conditioning” reappears in Chapter 7, where we use it to obtain
expectations.
The concept of random variables is introduced in Chapters 4, 5, and 6. Discrete
random variables are dealt with in Chapter 4, continuous random variables in
Chapter 5, and jointly distributed random variables in Chapter 6. The important con-
cepts of the expected value and the variance of a random variable are introduced in
Chapters 4 and 5, and these quantities are then determined for many of the common
types of random variables.
Additional properties of the expected value are considered in Chapter 7. Many
examples illustrating the usefulness of the result that the expected value of a sum of
random variables is equal to the sum of their expected values are presented. Sections
on conditional expectation, including its use in prediction, and on moment-generating
functions are contained in this chapter. In addition, the final section introduces the
multivariate normal distribution and presents a simple proof concerning the joint
distribution of the sample mean and sample variance of a sample from a normal
distribution.
```
```
xi
```

**xii** Preface

```
Chapter 8 presents the major theoretical results of probability theory. In partic-
ular, we prove the strong law of large numbers and the central limit theorem. Our
proof of the strong law is a relatively simple one which assumes that the random vari-
ables have a finite fourth moment, and our proof of the central limit theorem assumes
Levy’s continuity theorem. This chapter also presents such probability inequalities as
Markov’s inequality, Chebyshev’s inequality, and Chernoff bounds. The final section
of Chapter 8 gives a bound on the error involved when a probability concerning
a sum of independent Bernoulli random variables is approximated by the corre-
sponding probability of a Poisson random variable having the same expected
value.
Chapter 9 presents some additional topics, such as Markov chains, the Poisson pro-
cess, and an introduction to information and coding theory, and Chapter 10 considers
simulation.
As in the previous edition, three sets of exercises are given at the end of each
chapter. They are designated as Problems, Theoretical Exercises ,and Self-Test Prob-
lems and Exercises. This last set of exercises, for which complete solutions appear in
Solutions to Self-Test Problems and Exercises, is designed to help students test their
comprehension and study for exams.
```
##### CHANGES IN THE NEW EDITION

```
The eighth edition continues the evolution and fine tuning of the text. It includes
new problems, exercises, and text material chosen both for its inherent interest and
for its use in building student intuition about probability. Illustrative of these goals
are Example 5d of Chapter 1 on knockout tournaments, and Examples 4k and 5i of
Chapter 7 on multiple player gambler’s ruin problems.
A key change in the current edition is that the important result that the expectation
of a sum of random variables is equal to the sum of the expectations is now first
presented in Chapter 4 (rather than Chapter 7 as in previous editions). A new and
elementary proof of this result when the sample space of the probability experiment
is finite is given in this chapter.
Another change is the expansion of Section 6.3, which deals with the sum of inde-
pendent random variables. Section 6.3.1 is a new section in which we derive the
distribution of the sum of independent and identically distributed uniform random
variables, and then use our results to show that the expected number of random num-
bers that needs to be added for their sum to exceed 1 is equal to e. Section 6.3.5 is a
new section in which we derive the distribution of the sum of independent geometric
random variables with different means.
```
##### ACKNOWLEDGMENTS

```
I am grateful for the careful work of Hossein Hamedani in checking the text for accu-
racy. I also appreciate the thoughtfulness of the following people that have taken the
time to contact me with comments for improving the text: Amir Ardestani, Polytech-
nic University of Teheran; Joe Blitzstein, Harvard University; Peter Nuesch, Univer-
sity of Lausaunne; Joseph Mitchell, SUNY, Stony Brook; Alan Chambless, actuary;
Robert Kriner; Israel David, Ben-Gurion University; T. Lim, George Mason Univer-
sity; Wei Chen, Rutgers; D. Monrad, University of Illinois; W. Rosenberger, George
Mason University; E. Ionides, University of Michigan; J. Corvino, Lafayette College;
T. Seppalainen, University of Wisconsin.
Finally, I would like to thank the following reviewers for their many helpful com-
ments. Reviewers of the eighth edition are marked with an asterisk.
```

```
Acknowledgments xiii
```
K. B. Athreya, _Iowa State University_
Richard Bass, _University of Connecticut_
Robert Bauer, _University of Illinois at
Urbana-Champaign_
Phillip Beckwith, _Michigan Tech_
Arthur Benjamin, _Harvey Mudd College_
Geoffrey Berresford, _Long Island University_
Baidurya Bhattacharya, _University of Delaware_
Howard Bird, _St. Cloud State University_
Shahar Boneh, _Metropolitan State College of
Denver_
Jean Cadet, _State University of New York at
Stony Brook_
Steven Chiappari, _Santa Clara University_
Nicolas Christou, _University of California, Los
Angeles_
James Clay, _University of Arizona at Tucson_
Francis Conlan, _University of Santa Clara_
*Justin Corvino, _Lafayette College_
Jay DeVore, _California Polytechnic University,
San Luis Obispo_
Scott Emerson, _University of Washington_
Thomas R. Fischer, _Texas A & M University_
Anant Godbole, _Michigan Technical
University_
Zakkula Govindarajulu, _University of Kentucky_
Richard Groeneveld, _Iowa State University_
Mike Hardy, _Massachusetts Institute of
Technology_
Bernard Harris, _University of Wisconsin_
Larry Harris, _University of Kentucky_
David Heath, _Cornell University_
Stephen Herschkorn, _Rutgers University_
Julia L. Higle, _University of Arizona_
Mark Huber, _Duke University_

```
*Edward Ionides, University of Michigan
Anastasia Ivanova, University of North Carolina
Hamid Jafarkhani, University of California,
Irvine
Chuanshu Ji, University of North Carolina,
Chapel Hill
Robert Keener, University of Michigan
Fred Leysieffer, Florida State University
Thomas Liggett, University of California, Los
Angeles
Helmut Mayer, University of Georgia
Bill McCormick, University of Georgia
Ian McKeague, Florida State University
R. Miller, Stanford University
*Ditlev Monrad, University of Illinois
Robb J. Muirhead, University of Michigan
Joe Naus, Rutgers University
Nhu Nguyen, New Mexico State University
Ellen O’Brien, George Mason University
N. U. Prabhu, Cornell University
Kathryn Prewitt, Arizona State University
Jim Propp, University of Wisconsin
*William F. Rosenberger, George Mason
University
Myra Samuels, Purdue University
I. R. Savage, Yale University
Art Schwartz, University of Michigan at Ann
Arbor
Therese Shelton, Southwestern University
Malcolm Sherman, State University of New York
at Albany
Murad Taqqu, Boston University
Eli Upfal, Brown University
Ed Wheeler, University of Tennessee
Allen Webster, Bradley University
```
```
S. R.
smross@usc.edu
```

_This page intentionally left blank_


## CHAPTER 1

# Combinatorial Analysis

### 1.1 Introduction

### 1.2 The Basic Principle of Counting

**1.3 PERMUTATIONS
1.4 COMBINATIONS
1.5 MULTINOMIAL COEFFICIENTS
1.6 THE NUMBER OF INTEGER SOLUTIONS OF EQUATIONS**

##### 1.1 INTRODUCTION

```
Here is a typical problem of interest involving probability: A communication system
is to consist of n seemingly identical antennas that are to be lined up in a linear order.
The resulting system will then be able to receive all incoming signals—and will be
called functional —as long as no two consecutive antennas are defective. If it turns
out that exactly m of the n antennas are defective, what is the probability that the
resulting system will be functional? For instance, in the special case where n =4and
m =2, there are 6 possible system configurations, namely,
```
```
0110
0101
1010
0011
1001
1100
```
```
where 1 means that the antenna is working and 0 that it is defective. Because the
resulting system will be functional in the first 3 arrangements and not functional in
the remaining 3, it seems reasonable to take^36 =^12 as the desired probability. In
the case of general n and m , we could compute the probability that the system is
functional in a similar fashion. That is, we could count the number of configurations
that result in the system’s being functional and then divide by the total number of all
possible configurations.
From the preceding discussion, we see that it would be useful to have an effective
method for counting the number of ways that things can occur. In fact, many prob-
lems in probability theory can be solved simply by counting the number of different
ways that a certain event can occur. The mathematical theory of counting is formally
known as combinatorial analysis.
```
**1.2 THE BASIC PRINCIPLE OF COUNTING**

```
The basic principle of counting will be fundamental to all our work. Loosely put, it
states that if one experiment can result in any of m possible outcomes and if another
experiment can result in any of n possible outcomes, then there are mn possible out-
comes of the two experiments.
```
```
1
```

**2** Chapter 1 Combinatorial Analysis

```
The basic principle of counting
```
```
Suppose that two experiments are to be performed. Then if experiment 1 can result
in any one of m possible outcomes and if, for each outcome of experiment 1, there
are n possible outcomes of experiment 2, then together there are mn possible out-
comes of the two experiments.
```
```
Proof of the Basic Principle: The basic principle may be proven by enumerating all
the possible outcomes of the two experiments; that is,
```
```
(1, 1),(1, 2), ...,(1, n )
(2, 1),(2, 2), ...,(2, n )
```
```
#
#
#
( m ,1),( m ,2),...,( m , n )
```
```
where we say that the outcome is ( i , j ) if experiment 1 results in its i th possible out-
come and experiment 2 then results in its j th possible outcome. Hence, the set of
possible outcomes consists of m rows, each containing n elements. This proves the
result.
```
```
EXAMPLE 2a
A small community consists of 10 women, each of whom has 3 children. If one woman
and one of her children are to be chosen as mother and child of the year, how many
different choices are possible?
```
```
Solution. By regarding the choice of the woman as the outcome of the first experi-
ment and the subsequent choice of one of her children as the outcome of the second
experiment, we see from the basic principle that there are 10 * 3 = 30 possible
choices..
```
```
When there are more than two experiments to be performed, the basic principle
can be generalized.
```
```
The generalized basic principle of counting
```
```
If r experiments that are to be performed are such that the first one may result in
any of n 1 possible outcomes; and if, for each of these n 1 possible outcomes, there
are n 2 possible outcomes of the second experiment; and if, for each of the possible
outcomes of the first two experiments, there are n 3 possible outcomes of the third
experiment; and if...,thenthereisatotalof n 1 · n 2 ··· nr possible outcomes of the
r experiments.
```
```
EXAMPLE 2b
A college planning committee consists of 3 freshmen, 4 sophomores, 5 juniors, and 2
seniors. A subcommittee of 4, consisting of 1 person from each class, is to be chosen.
How many different subcommittees are possible?
```

```
Section 1.3 Permutations 3
```
```
Solution. We may regard the choice of a subcommittee as the combined outcome of
the four separate experiments of choosing a single representative from each of the
classes. It then follows from the generalized version of the basic principle that there
are 3 * 4 * 5 * 2 =120 possible subcommittees..
```
```
EXAMPLE 2c
How many different 7-place license plates are possible if the first 3 places are to be
occupied by letters and the final 4 by numbers?
```
```
Solution. By the generalized version of the basic principle, the answer is 26· 26 ·
26 · 10 · 10 · 10 · 10 =175,760,000..
```
```
EXAMPLE 2d
How many functions defined on n points are possible if each functional value is either
0or1?
```
```
Solution. Let the points be 1, 2,..., n. Since f ( i )must be either 0 or 1 for each i =
1, 2,..., n , it follows that there are 2 n possible functions..
```
```
EXAMPLE 2e
In Example 2c, how many license plates would be possible if repetition among letters
or numbers were prohibited?
```
```
Solution. In this case, there would be 26 · 25 · 24 · 10 · 9 · 8 · 7 =78,624,
possible license plates..
```
### 1.3 Permutations.................................

```
How many different ordered arrangements of the letters a , b ,and c are possible? By
direct enumeration we see that there are 6, namely, abc, acb, bac, bca, cab ,and cba.
Each arrangement is known as a permutation. Thus, there are 6 possible permutations
of a set of 3 objects. This result could also have been obtained from the basic principle,
since the first object in the permutation can be any of the 3, the second object in the
permutation can then be chosen from any of the remaining 2, and the third object
in the permutation is then the remaining 1. Thus, there are 3· 2 · 1 =6 possible
permutations.
Suppose now that we have n objects. Reasoning similar to that we have just used
for the 3 letters then shows that there are
```
```
n ( n − 1 )( n − 2 )··· 3 · 2 · 1 = n!
```
```
different permutations of the n objects.
```
```
EXAMPLE 3a
How many different batting orders are possible for a baseball team consisting of 9
players?
```
```
Solution. There are 9!=362,880 possible batting orders..
```

**4** Chapter 1 Combinatorial Analysis

```
EXAMPLE 3b
A class in probability theory consists of 6 men and 4 women. An examination is given,
and the students are ranked according to their performance. Assume that no two
students obtain the same score.
(a) How many different rankings are possible?
(b) If the men are ranked just among themselves and the women just among them-
selves, how many different rankings are possible?
```
```
Solution. (a) Because each ranking corresponds to a particular ordered arrangement
of the 10 people, the answer to this part is 10!=3,628,800.
(b) Since there are 6! possible rankings of the men among themselves and 4! possi-
ble rankings of the women among themselves, it follows from the basic principle that
there are(6!)(4!)=( 720 )( 24 )=17,280 possible rankings in this case..
```
```
EXAMPLE 3c
Ms. Jones has 10 books that she is going to put on her bookshelf. Of these, 4 are
mathematics books, 3 are chemistry books, 2 are history books, and 1 is a language
book. Ms. Jones wants to arrange her books so that all the books dealing with the
same subject are together on the shelf. How many different arrangements are
possible?
```
```
Solution. There are 4! 3! 2! 1! arrangements such that the mathematics books are
first in line, then the chemistry books, then the history books, and then the language
book. Similarly, for each possible ordering of the subjects, there are 4! 3! 2! 1! possible
arrangements. Hence, as there are 4! possible orderings of the subjects, the desired
answer is 4! 4! 3! 2! 1!=6912..
```
```
We shall now determine the number of permutations of a set of n objects when cer-
tain of the objects are indistinguishable from each other. To set this situation straight
in our minds, consider the following example.
```
```
EXAMPLE 3d
How many different letter arrangements can be formed from the letters PEPPER?
```
```
Solution. We first note that there are 6! permutations of the letters P 1 E 1 P 2 P 3 E 2 R
when the 3 P ’s and the 2 E ’s are distinguished from each other. However, consider
any one of these permutations—for instance, P 1 P 2 E 1 P 3 E 2 R. If we now permute the
P ’s among themselves and the E ’s among themselves, then the resultant arrangement
would still be of the form PPEPER. That is, all 3! 2! permutations
```
##### P 1 P 2 E 1 P 3 E 2 RP 1 P 2 E 2 P 3 E 1 R

##### P 1 P 3 E 1 P 2 E 2 RP 1 P 3 E 2 P 2 E 1 R

##### P 2 P 1 E 1 P 3 E 2 RP 2 P 1 E 2 P 3 E 1 R

##### P 2 P 3 E 1 P 1 E 2 RP 2 P 3 E 2 P 1 E 1 R

##### P 3 P 1 E 1 P 2 E 2 RP 3 P 1 E 2 P 2 E 1 R

##### P 3 P 2 E 1 P 1 E 2 RP 3 P 2 E 2 P 1 E 1 R

```
are of the form PPEPER. Hence, there are 6!/(3! 2!)=60 possible letter arrange-
ments of the letters PEPPER..
```

```
Section 1.4 Combinations 5
```
```
In general, the same reasoning as that used in Example 3d shows that there are
```
```
n!
n 1! n 2 !··· nr!
```
```
different permutations of n objects, of which n 1 are alike, n 2 are alike,..., nr are
alike.
```
```
EXAMPLE 3e
A chess tournament has 10 competitors, of which 4 are Russian, 3 are from the United
States, 2 are from Great Britain, and 1 is from Brazil. If the tournament result lists just
the nationalities of the players in the order in which they placed, how many outcomes
are possible?
```
```
Solution. There are
10!
4! 3! 2! 1!
```
##### =12,

```
possible outcomes..
```
```
EXAMPLE 3f
How many different signals, each consisting of 9 flags hung in a line, can be made
from a set of 4 white flags, 3 red flags, and 2 blue flags if all flags of the same color are
identical?
```
```
Solution. There are
9!
4! 3! 2!
```
##### = 1260

```
different signals..
```
### 1.4 Combinations

```
We are often interested in determining the number of different groups of r objects
that could be formed from a total of n objects. For instance, how many different
groups of 3 could be selected from the 5 items A , B , C , D ,and E? To answer this
question, reason as follows: Since there are 5 ways to select the initial item, 4 ways to
then select the next item, and 3 ways to select the final item, there are thus 5· 4 · 3
ways of selecting the group of 3 when the order in which the items are selected is
relevant. However, since every group of 3—say, the group consisting of items A , B ,
and C —will be counted 6 times (that is, all of the permutations ABC, ACB, BAC,
BCA, CAB ,and CBA will be counted when the order of selection is relevant), it
follows that the total number of groups that can be formed is
```
```
5 · 4 · 3
3 · 2 · 1
```
##### = 10

```
In general, as n ( n − 1 )···( n − r + 1 )represents the number of different ways that a
group of r items could be selected from n items when the order of selection is relevant,
and as each group of r items will be counted r! times in this count, it follows that the
number of different groups of r items that could be formed from a set of n items is
```
```
n ( n − 1 )···( n − r + 1 )
r!
```
##### =

```
n!
( n − r )! r!
```

**6** Chapter 1 Combinatorial Analysis

```
Notation and terminology
```
```
We define
```
##### (

```
n
r
```
##### )

```
,for r ... n ,by
```
```
(
n
r
```
##### )

##### =

```
n!
( n − r )! r!
```
```
and say that
```
##### (

```
n
r
```
##### )

```
represents the number of possible combinations of n objects
```
```
taken r at a time.†
```
```
Thus,
```
##### (

```
n
r
```
##### )

```
represents the number of different groups of size r that could be
selected from a set of n objects when the order of selection is not considered relevant.
```
```
EXAMPLE 4a
A committee of 3 is to be formed from a group of 20 people. How many different
committees are possible?
```
```
Solution. There are
```
##### (

##### 20

##### 3

##### )

##### =

##### 20 · 19 · 18

##### 3 · 2 · 1

```
=1140 possible committees..
```
```
EXAMPLE 4b
From a group of 5 women and 7 men, how many different committees consisting of
2 women and 3 men can be formed? What if 2 of the men are feuding and refuse to
serve on the committee together?
```
```
Solution. As there are
```
##### (

##### 5

##### 2

##### )

```
possible groups of 2 women, and
```
##### (

##### 7

##### 3

##### )

```
possible
```
```
groups of 3 men, it follows from the basic principle that there are
```
##### (

##### 5

##### 2

##### )(

##### 7

##### 3

##### )

##### =

##### (

##### 5 · 4

##### 2 · 1

##### )

##### 7 · 6 · 5

##### 3 · 2 · 1

```
=350 possible committees consisting of 2 women and 3 men.
```
```
(Now suppose that 2 of the men refuse to serve together. Because a total of
2
2
```
##### )(

##### 5

##### 1

##### )

```
=5 out of the
```
##### (

##### 7

##### 3

##### )

```
=35 possible groups of 3 men contain both of
the feuding men, it follows that there are 35− 5 =30 groups that do not contain
both of the feuding men. Because there are still
```
##### (

##### 5

##### 2

##### )

```
=10 ways to choose the 2
women, there are 30 · 10 =300 possible committees in this case..
```
```
†By convention, 0! is defined to be 1. Thus,
```
```
(
n
0
```
```
)
=
```
```
(
n
n
```
```
)
=1. We also take
```
```
(
n
i
```
```
)
to be equal
to 0 when either i <0or i > n.
```

```
Section 1.4 Combinations 7
```
**_EXAMPLE 4c_**

Consider a set of _n_ antennas of which _m_ are defective and _n_ − _m_ are functional
and assume that all of the defectives and all of the functionals are considered indis-
tinguishable. How many linear orderings are there in which no two defectives are
consecutive?

**_Solution._** Imagine that the _n_ − _m_ functional antennas are lined up among them-
selves. Now, if no two defectives are to be consecutive, then the spaces between the
functional antennas must each contain at most one defective antenna. That is, in the
_n_ − _m_ + 1 possible positions—represented in Figure 1.1 by carets—between the
_n_ − _m_ functional antennas, we must select _m_ of these in which to put the defective

antennas. Hence, there are

##### (

```
n − m + 1
m
```
##### )

```
possible orderings in which there is at
```
least one functional antenna between any two defective ones..

```
^^1 ^^1 ^ 1... ^^1 ^^1 ^
1  functional
```
```
^  place for at most one defective
```
```
FIGURE 1.1: No consecutive defectives
```
```
A useful combinatorial identity is
(
n
r
```
##### )

##### =

##### (

```
n − 1
r − 1
```
##### )

##### +

##### (

```
n − 1
r
```
##### )

```
1 ... r ... n (4.1)
```
Equation (4.1) may be proved analytically or by the following combinatorial argu-
ment: Consider a group of _n_ objects, and fix attention on some particular one of these

objects—call it object 1. Now, there are

##### (

```
n − 1
r − 1
```
##### )

```
groups of size r that contain object
```
1 (since each such group is formed by selecting _r_ −1 from the remaining _n_ − 1

objects). Also, there are

##### (

```
n − 1
r
```
##### )

```
groups of size r that do not contain object 1. As
```
there is a total of

##### (

```
n
r
```
##### )

```
groups of size r , Equation (4.1) follows.
```
```
The values
```
##### (

```
n
r
```
##### )

```
are often referred to as binomial coefficients because of their
```
prominence in the binomial theorem.

```
The binomial theorem
```
```
( x + y ) n =
```
```
∑ n
```
```
k = 0
```
##### (

```
n
k
```
##### )

```
xkyn − k (4.2)
```
We shall present two proofs of the binomial theorem. The first is a proof by math-
ematical induction, and the second is a proof based on combinatorial considerations.


**8** Chapter 1 Combinatorial Analysis

```
Proof of the Binomial Theorem by Induction: When n =1, Equation (4.2) reduces to
```
```
x + y =
```
##### (

##### 1

##### 0

##### )

```
x^0 y^1 +
```
##### (

##### 1

##### 1

##### )

```
x^1 y^0 = y + x
```
```
Assume Equation (4.2) for n −1. Now,
```
```
( x + y ) n =( x + y )( x + y ) n −^1
```
```
=( x + y )
```
```
n ∑− 1
```
```
k = 0
```
##### (

```
n − 1
k
```
##### )

```
xkyn −^1 − k
```
##### =

```
n ∑− 1
```
```
k = 0
```
##### (

```
n − 1
k
```
##### )

```
xk +^1 yn −^1 − k +
```
```
n ∑− 1
```
```
k = 0
```
##### (

```
n − 1
k
```
##### )

```
xkyn − k
```
```
Letting i = k +1inthefirstsumand i = k in the second sum, we find that
```
```
( x + y ) n =
```
```
∑ n
```
```
i = 1
```
##### (

```
n − 1
i − 1
```
##### )

```
xiyn − i +
```
```
n ∑− 1
```
```
i = 0
```
##### (

```
n − 1
i
```
##### )

```
xiyn − i
```
```
= xn +
```
```
n ∑− 1
```
```
i = 1
```
##### [(

```
n − 1
i − 1
```
##### )

##### +

##### (

```
n − 1
i
```
##### )]

```
xiyn − i + yn
```
```
= xn +
```
```
∑ n − i
```
```
i = 1
```
##### (

```
n
i
```
##### )

```
xiyn − i + yn
```
##### =

```
∑ n
```
```
i = 0
```
##### (

```
n
i
```
##### )

```
xiyn − i
```
```
where the next-to-last equality follows by Equation (4.1). By induction, the theorem
is now proved.
```
```
Combinatorial Proof of the Binomial Theorem: Consider the product
```
```
( x 1 + y 1 )( x 2 + y 2 )···( xn + yn )
```
```
Its expansion consists of the sum of 2 n terms, each term being the product of n factors.
Furthermore, each of the 2 n terms in the sum will contain as a factor either xi or yi
for each i =1, 2,..., n. For example,
```
```
( x 1 + y 1 )( x 2 + y 2 )= x 1 x 2 + x 1 y 2 + y 1 x 2 + y 1 y 2
```
```
Now, how many of the 2 n terms in the sum will have k of the xi ’s and( n − k )of the yi ’s
as factors? As each term consisting of k of the xi ’s and( n − k )of the yi ’s corresponds
to a choice of a group of k from the n values x 1 , x 2 ,..., xn , there are
```
##### (

```
n
k
```
##### )

```
such terms.
Thus, letting xi = x , yi = y , i =1,..., n , we see that
```
```
( x + y ) n =
```
```
∑ n
```
```
k = 0
```
##### (

```
n
k
```
##### )

```
xkyn − k
```

```
Section 1.5 Multinomial Coefficients 9
```
```
EXAMPLE 4d
Expand( x + y )^3.
```
```
Solution.
```
```
( x + y )^3 =
```
##### (

##### 3

##### 0

##### )

```
x^0 y^3 +
```
##### (

##### 3

##### 1

##### )

```
x^1 y^2 +
```
##### (

##### 3

##### 2

##### )

```
x^2 y +
```
##### (

##### 3

##### 3

##### )

```
x^3 y^0
```
```
= y^3 + 3 xy^2 + 3 x^2 y + x^3.
```
```
EXAMPLE 4e
How many subsets are there of a set consisting of n elements?
```
```
Solution. Since there are
```
##### (

```
n
k
```
##### )

```
subsets of size k , the desired answer is
```
```
∑ n
```
```
k = 0
```
##### (

```
n
k
```
##### )

```
=( 1 + 1 ) n = 2 n
```
```
This result could also have been obtained by assigning either the number 0 or the
number 1 to each element in the set. To each assignment of numbers, there corre-
sponds, in a one-to-one fashion, a subset, namely, that subset consisting of all ele-
ments that were assigned the value 1. As there are 2 n possible assignments, the result
follows.
Note that we have included the set consisting of 0 elements (that is, the null set)
as a subset of the original set. Hence, the number of subsets that contain at least one
element is 2 n −1..
```
### 1.5 Multinomial Coefficients

```
In this section, we consider the following problem: A set of n distinct items is to be
divided into r distinct groups of respective sizes n 1 , n 2 ,..., nr , where
```
```
∑ r
i = 1 ni = n.
How many different divisions are possible? To answer this question, we note that
there are
```
##### (

```
n
n 1
```
##### )

```
possible choices for the first group; for each choice of the first group,
```
```
there are
```
##### (

```
n − n 1
n 2
```
##### )

```
possible choices for the second group; for each choice of the
```
```
first two groups, there are
```
##### (

```
n − n 1 − n 2
n 3
```
##### )

```
possible choices for the third group; and
so on. It then follows from the generalized version of the basic counting principle that
there are
(
n
n 1
```
##### )(

```
n − n 1
n 2
```
##### )

##### ···

##### (

```
n − n 1 − n 2 − ··· − nr − 1
nr
```
##### )

##### =

```
n!
( n − n 1 )! n 1!
```
```
( n − n 1 )!
( n − n 1 − n 2 )! n 2!
```
##### ···

```
( n − n 1 − n 2 − ··· − nr − 1 )!
0! nr!
```
```
=
```
```
n!
n 1! n 2 !··· nr!
```
```
possible divisions.
```

**10** Chapter 1 Combinatorial Analysis

```
Another way to see this result is to consider the n values 1, 1,...,1,2,...,2,...,
r ,..., r , where i appears ni times, for i =1,..., r .Every permutation of these values
corresponds to a division of the n items into the r groups in the following manner:
Let the permutation i 1 , i 2 ,..., in correspond to assigning item 1 to group i 1 , item 2 to
group i 2 , and so on. For instance, if n =8andif n 1 =4, n 2 =3, and n 3 =1, then
the permutation 1, 1, 2, 3, 2, 1, 2, 1 corresponds to assigning items 1, 2, 6, 8 to the first
group, items 3, 5, 7 to the second group, and item 4 to the third group. Because every
permutation yields a division of the items and every possible division results from
some permutation, it follows that the number of divisions of n items into r distinct
groups of sizes n 1 , n 2 ,..., nr is the same as the number of permutations of n items of
which n 1 are alike, and n 2 are alike,...,and nr are alike, which was shown in Section
1 .3toequal
```
```
n!
n 1! n 2 !··· nr!
```
##### .

```
Notation
```
```
If n 1 + n 2 + ··· + nr = n , we define
```
##### (

```
n
n 1 , n 2 ,..., nr
```
##### )

```
by
```
##### (

```
n
n 1 , n 2 ,..., nr
```
##### )

##### =

```
n!
n 1! n 2 !··· nr!
```
```
Thus,
```
##### (

```
n
n 1 , n 2 ,..., nr
```
##### )

```
represents the number of possible divisions of n distinct
objects into r distinct groups of respective sizes n 1 , n 2 ,..., nr.
```
```
EXAMPLE 5a
A police department in a small city consists of 10 officers. If the department policy is
to have 5 of the officers patrolling the streets, 2 of the officers working full time at the
station, and 3 of the officers on reserve at the station, how many different divisions of
the 10 officers into the 3 groups are possible?
```
```
Solution. There are
```
##### 10!

##### 5! 2! 3!

```
=2520 possible divisions..
```
```
EXAMPLE 5b
Ten children are to be divided into an A team and a B team of 5 each. The A team
will play in one league and the B team in another. How many different divisions are
possible?
```
```
Solution. There are
```
##### 10!

##### 5! 5!

```
=252 possible divisions..
```
```
EXAMPLE 5c
In order to play a game of basketball, 10 children at a playground divide themselves
into two teams of 5 each. How many different divisions are possible?
```

```
Section 1.5 Multinomial Coefficients 11
```
**_Solution._** Note that this example is different from Example 5b because now the order
of the two teams is irrelevant. That is, there is no _A_ and _B_ team, but just a division
consisting of 2 groups of 5 each. Hence, the desired answer is

```
10!/(5! 5!)
2!
```
##### = 126.

The proof of the following theorem, which generalizes the binomial theorem, is
left as an exercise.

```
The multinomial theorem
```
```
( x 1 + x 2 + ··· + xr ) n =
```
##### ∑

```
( n 1 ,..., nr ):
n 1 + ··· + nr = n
```
##### (

```
n
n 1 , n 2 ,..., nr
```
##### )

```
xn 11 xn 22 ··· xnrr
```
```
That is, the sum is over all nonnegative integer-valued vectors( n 1 , n 2 ,..., nr )such
that n 1 + n 2 + ··· + nr = n.
```
```
The numbers
```
##### (

```
n
n 1 , n 2 ,..., nr
```
##### )

```
are known as multinomial coefficients.
```
**_EXAMPLE 5d_**

In the first round of a knockout tournament involving _n_ = 2 _m_ players, the _n_ players
are divided into _n_ /2 pairs, with each of these pairs then playing a game. The losers
of the games are eliminated while the winners go on to the next round, where the
process is repeated until only a single player remains. Suppose we have a knockout
tournament of 8 players.

```
(a) How many possible outcomes are there for the initial round? (For instance, one
outcome is that 1 beats 2, 3 beats 4, 5 beats 6, and 7 beats 8. )
(b) How many outcomes of the tournament are possible, where an outcome gives
complete information for all rounds?
```
**_Solution._** One way to determine the number of possible outcomes for the initial
round is to first determine the number of possible pairings for that round. To do
so, note that the number of ways to divide the 8 players into a _first_ pair, a _second_ pair,

a _third_ pair, and a _fourth_ pair is

##### (

##### 8

##### 2, 2, 2, 2

##### )

##### =

##### 8!

##### 24

```
.Thus, the number of possible pair-
```
ings when there is no ordering of the 4 pairs is

##### 8!

##### 24 4!

```
.For each such pairing, there are
```
2 possible choices from each pair as to the winner of that game, showing that there

are

##### 8!2^4

##### 24 4!

##### =

##### 8!

##### 4!

```
possible results of round 1. (Another way to see this is to note that
```
there are

##### (

##### 8

##### 4

##### )

```
possible choices of the 4 winners and, for each such choice, there are
```
4! ways to pair the 4 winners with the 4 losers, showing that there are 4!

##### (

##### 8

##### 4

##### )

##### =

##### 8!

##### 4!

possible results for the first round.)


```
12 Chapter 1 Combinatorial Analysis
```
```
Similarly, for each result of round 1, there are
```
##### 4!

##### 2!

```
possible outcomes of round 2,
```
```
and for each of the outcomes of the first two rounds, there are
```
##### 2!

##### 1!

```
possible outcomes
of round 3.Consequently, by the generalized basic principle of counting, there are
8!
4!
```
##### 4!

##### 2!

##### 2!

##### 1!

```
= 8! possible outcomes of the tournament. Indeed, the same argument
can be used to show that a knockout tournament of n = 2 m players has n! possible
outcomes.
Knowing the preceding result, it is not difficult to come up with a more direct
argument by showing that there is a one-to-one correspondence between the set of
possible tournament results and the set of permutations of 1,..., n. To obtain such
a correspondence, rank the players as follows for any tournament result: Give the
tournament winner rank 1, and give the final-round loser rank 2. For the two play-
ers who lost in the next-to-last round, give rank 3 to the one who lost to the player
ranked 1 and give rank 4 to the one who lost to the player ranked 2. For the four
players who lost in the second-to-last round, give rank 5 to the one who lost to player
ranked 1, rank 6 to the one who lost to the player ranked 2, rank 7 to the one who
lost to the player ranked 3, and rank 8 to the one who lost to the player ranked 4.
Continuing on in this manner gives a rank to each player. (A more succinct descrip-
tion is to give the winner of the tournament rank 1 and let the rank of a player who
lost in a round having 2 k matches be 2 k plus the rank of the player who beat him, for
k =0,..., m −1.) In this manner, the result of the tournament can be represented
by a permutation i 1 , i 2 ,..., in , where ij is the player who was given rank j. Because
different tournament results give rise to different permutations, and because there is
a tournament result for each permutation, it follows that there are the same number
of possible tournament results as there are permutations of 1,..., n..
```
```
EXAMPLE 5e
```
```
( x 1 + x 2 + x 3 )^2 =
```
##### (

##### 2

##### 2, 0, 0

##### )

```
x^21 x^02 x^03 +
```
##### (

##### 2

##### 0, 2, 0

##### )

```
x^01 x^22 x^03
```
##### +

##### (

##### 2

##### 0, 0, 2

##### )

```
x^01 x^02 x^23 +
```
##### (

##### 2

##### 1, 1, 0

##### )

```
x^11 x^12 x^03
```
##### +

##### (

##### 2

##### 1, 0, 1

##### )

```
x^11 x^02 x^13 +
```
##### (

##### 2

##### 0, 1, 1

##### )

```
x^01 x^12 x^13
```
```
= x^21 + x^22 + x^23 + 2 x 1 x 2 + 2 x 1 x 3 + 2 x 2 x 3.
```
∗ **1.6 THE NUMBER OF INTEGER SOLUTIONS OF EQUATIONS**

```
There are rn possible outcomes when n distinguishable balls are to be distributed into
r distinguishable urns. This result follows because each ball may be distributed into
any of r possible urns. Let us now, however, suppose that the n balls are indistinguish-
able from each other. In this case, how many different outcomes are possible? As the
balls are indistinguishable, it follows that the outcome of the experiment of distribut-
ing the n balls into r urns can be described by a vector( x 1 , x 2 ,..., xr ), where xi denotes
the number of balls that are distributed into the i th urn. Hence, the problem reduces
to finding the number of distinct nonnegative integer-valued vectors( x 1 , x 2 ,..., xr )
such that
x 1 + x 2 + ··· + xr = n
∗Asterisks denote material that is optional.
```

```
Section 1.6 The Number of Integer Solutions of Equations 13
```
To compute this number, let us start by considering the number of positive integer-
valued solutions. Toward that end, imagine that we have _n_ indistinguishable objects
lined up and that we want to divide them into _r_ nonempty groups. To do so, we can
select _r_ −1ofthe _n_ −1 spaces between adjacent objects as our dividing points. (See
Figure 1.2.) For instance, if we have _n_ =8and _r_ =3 and we choose the 2 divisors so
as to obtain
ooo|ooo|oo

(^0) ^ (^0) ^ (^0) ^... ^ (^0) ^ 0
_n_ objects 0
Choose _r_  1 of the spaces ^.
**FIGURE 1.2:** Number of positive solutions
then the resulting vector is _x_ 1 =3, _x_ 2 =3, _x_ 3 =2. As there are

##### (

```
n − 1
r − 1
```
##### )

```
possible
```
selections, we have the following proposition.

**Proposition 6.1.** There are

##### (

```
n − 1
r − 1
```
##### )

```
distinct positive integer-valued vectors( x 1 ,
```
_x_ 2 ,..., _xr_ )satisfying the equation

```
x 1 + x 2 + ··· + xr = nxi >0, i =1,..., r
```
To obtain the number of nonnegative (as opposed to positive) solutions, note
that the number of nonnegative solutions of _x_ 1 + _x_ 2 + ··· + _xr_ = _n_ is the same
as the number of positive solutions of _y_ 1 + ··· + _yr_ = _n_ + _r_ (seen by letting
_yi_ = _xi_ + 1, _i_ = 1,..., _r_ ). Hence, from Proposition 6.1, we obtain the following
proposition.

**Proposition 6.2.** There are

##### (

```
n + r − 1
r − 1
```
##### )

```
distinct nonnegative integer-valued vec-
```
tors( _x_ 1 , _x_ 2 ,..., _xr_ )satisfying the equation

```
x 1 + x 2 + ··· + xr = n (6.1)
```
**_EXAMPLE 6a_**

How many distinct nonnegative integer-valued solutions of _x_ 1 + _x_ 2 =3 are possible?

**_Solution._** There are

##### (

##### 3 + 2 − 1

##### 2 − 1

##### )

```
=4 such solutions: (0, 3), (1, 2), (2, 1), (3, 0)..
```
**_EXAMPLE 6b_**

An investor has 20 thousand dollars to invest among 4 possible investments. Each
investment must be in units of a thousand dollars. If the total 20 thousand is to be


**14** Chapter 1 Combinatorial Analysis

```
invested, how many different investment strategies are possible? What if not all the
money need be invested?
```
```
Solution. If we let xi , i = 1, 2, 3, 4, denote the number of thousands invested in
investment i , then, when all is to be invested, x 1 , x 2 , x 3 , x 4 are integers satisfying the
equation
```
```
x 1 + x 2 + x 3 + x 4 = 20 xi Ú 0
```
```
Hence, by Proposition 6.2, there are
```
##### (

##### 23

##### 3

##### )

```
=1771 possible investment strategies. If
not all of the money need be invested, then if we let x 5 denote the amount kept in
reserve, a strategy is a nonnegative integer-valued vector( x 1 , x 2 , x 3 , x 4 , x 5 )satisfying
the equation
```
```
x 1 + x 2 + x 3 + x 4 + x 5 = 20
```
```
Hence, by Proposition 6.2, there are now
```
##### (

##### 24

##### 4

##### )

```
=10,626 possible strategies..
```
```
EXAMPLE 6c
How many terms are there in the multinomial expansion of( x 1 + x 2 + ··· + xr ) n?
```
```
Solution.
```
```
( x 1 + x 2 + ··· + xr ) n =
```
```
∑( n
n 1 ,..., nr
```
##### )

```
x
n 1
1 ··· x
```
```
nr
r
```
```
where the sum is over all nonnegative integer-valued( n 1 ,..., nr )such that n 1 + ···+
nr = n. Hence, by Proposition 6.2, there are
```
##### (

```
n + r − 1
r − 1
```
##### )

```
such terms..
```
```
EXAMPLE 6d
Let us consider again Example 4c, in which we have a set of n items, of which m are
(indistinguishable and) defective and the remaining n − m are (also indistinguishable
and) functional. Our objective is to determine the number of linear orderings in which
no two defectives are next to each other. To determine this number, let us imagine
that the defective items are lined up among themselves and the functional ones are
now to be put in position. Let us denote x 1 as the number of functional items to the
left of the first defective, x 2 as the number of functional items between the first two
defectives, and so on. That is, schematically, we have
```
```
x 10 x 20 ··· xm 0 xm + 1
```
```
Now, there will be at least one functional item between any pair of defectives as long
as xi >0, i =2,..., m. Hence, the number of outcomes satisfying the condition is the
number of vectors x 1 ,..., xm + 1 that satisfy the equation
```
```
x 1 + ··· + xm + 1 = n − mx 1 Ú0, xm + 1 Ú0, xi >0, i =2,..., m
```

```
Summary 15
```
But, on letting _y_ 1 = _x_ 1 + 1, _yi_ = _xi_ , _i_ =2,..., _m_ , _ym_ + 1 = _xm_ + 1 + 1, we see that
this number is equal to the number of positive vectors( _y_ 1 ,..., _ym_ + 1 )that satisfy the
equation
_y_ 1 + _y_ 2 + ··· + _ym_ + 1 = _n_ − _m_ + 2

Hence, by Proposition 6.1, there are

##### (

```
n − m + 1
m
```
##### )

```
such outcomes, in agreement
```
with the results of Example 4c.
Suppose now that we are interested in the number of outcomes in which each pair
of defective items is separated by at least 2 functional items. By the same reason-
ing as that applied previously, this would equal the number of vectors satisfying the
equation

```
x 1 + ··· + xm + 1 = n − mx 1 Ú0, xm + 1 Ú0, xi Ú2, i =2,..., m
```
Upon letting _y_ 1 = _x_ 1 +1, _yi_ = _xi_ −1, _i_ =2,..., _m_ , _ym_ + 1 = _xm_ + 1 +1, we see that
this is the same as the number of positive solutions of the equation

```
y 1 + ··· + ym + 1 = n − 2 m + 3
```
Hence, from Proposition 6.1, there are

##### (

```
n − 2 m + 2
m
```
##### )

```
such outcomes..
```
#### Summary

The basic principle of counting states that if an experiment consisting of two phases is
such that there are _n_ possible outcomes of phase 1 and, for each of these _n_ outcomes,
there are _m_ possible outcomes of phase 2, then there are _nm_ possible outcomes of the
experiment.
There are _n_! = _n_ ( _n_ − 1 )··· 3 · 2 ·1 possible linear orderings of _n_ items. The
quantity 0! is defined to equal 1.
Let (
_n
i_

##### )

##### =

```
n!
( n − i )! i!
```
when 0 ... _i_ ... _n_ , and let it equal 0 otherwise. This quantity represents the number
of different subgroups of size _i_ that can be chosen from a set of size _n_. It is often
called a _binomial coefficient_ because of its prominence in the binomial theorem, which
states that

```
( x + y ) n =
```
```
∑ n
```
```
i = 0
```
##### (

```
n
i
```
##### )

```
xiyn − i
```
For nonnegative integers _n_ 1 ,..., _nr_ summing to _n_ ,

```
(
n
n 1 , n 2 ,..., nr
```
##### )

##### =

```
n!
n 1! n 2 !··· nr!
```
is the number of divisions of _n_ items into _r_ distinct nonoverlapping subgroups of sizes
_n_ 1 , _n_ 2 ,..., _nr_.


**16** Chapter 1 Combinatorial Analysis

#### Problems...................................

**1. (a)** How many different 7-place license plates are
    possible if the first 2 places are for letters and
    the other 5 for numbers?
**(b)** Repeat part (a) under the assumption that no
letter or number can be repeated in a single
license plate.
**2.** How many outcome sequences are possible when a
    die is rolled four times, where we say, for instance,
    that the outcome is 3, 4, 3, 1 if the first roll landed
    on 3, the second on 4, the third on 3, and the fourth
    on 1?
**3.** Twenty workers are to be assigned to 20 different
    jobs, one to each job. How many different assign-
    ments are possible?
**4.** John, Jim, Jay, and Jack have formed a band con-
    sisting of 4 instruments. If each of the boys can play
    all 4 instruments, how many different arrange-
    ments are possible? What if John and Jim can play
    all 4 instruments, but Jay and Jack can each play
    only piano and drums?
**5.** For years, telephone area codes in the United
    States and Canada consisted of a sequence of three
    digits. The first digit was an integer between 2 and
    9, the second digit was either 0 or 1, and the third
    digit was any integer from 1 to 9. How many area
    codes were possible? How many area codes start-
    ing with a 4 were possible?
**6.** A well-known nursery rhyme starts as follows:
    “As I was going to St. Ives
    I met a man with 7 wives.
    Each wife had 7 sacks.
    Each sack had 7 cats.
    Each cat had 7 kittens...”
    How many kittens did the traveler meet?
**7. (a)** In how many ways can 3 boys and 3 girls sit in
    arow?
    **(b)** In how many ways can 3 boys and 3 girls sit in
       a row if the boys and the girls are each to sit
       together?
    **(c)** In how many ways if only the boys must sit
       together?
    **(d)** In how many ways if no two people of the
       same sex are allowed to sit together?
**8.** How many different letter arrangements can be
    made from the letters
    **(a)** Fluke?
    **(b)** Propose?
    **(c)** Mississippi?
    **(d)** Arrange?
**9.** A child has 12 blocks, of which 6 are black, 4 are
    red, 1 is white, and 1 is blue. If the child puts the
    blocks in a line, how many arrangements are pos-
    sible?
       **10.** In how many ways can 8 people be seated in a
          row if
          **(a)** there are no restrictions on the seating
             arrangement?
          **(b)** persons _A_ and _B_ must sit next to each other?
          **(c)** there are 4 men and 4 women and no 2 men
             or 2 women can sit next to each other?
          **(d)** there are 5 men and they must sit next to each
             other?
          **(e)** there are 4 married couples and each couple
             must sit together?
       **11.** In how many ways can 3 novels, 2 mathematics
          books, and 1 chemistry book be arranged on a
          bookshelf if
          **(a)** the books can be arranged in any order?
          **(b)** the mathematics books must be together and
             the novels must be together?
          **(c)** the novels must be together, but the other
             books can be arranged in any order?
       **12.** Five separate awards (best scholarship, best lead-
          ership qualities, and so on) are to be presented to
          selected students from a class of 30. How many dif-
          ferent outcomes are possible if
          **(a)** a student can receive any number of awards?
          **(b)** each student can receive at most 1 award?
       **13.** Consider a group of 20 people. If everyone shakes
          hands with everyone else, how many handshakes
          take place?
       **14.** How many 5-card poker hands are there?
       **15.** A dance class consists of 22 students, of which 10
          are women and 12 are men. If 5 men and 5 women
          are to be chosen and then paired off, how many
          results are possible?
       **16.** A student has to sell 2 books from a collection of
          6 math, 7 science, and 4 economics books. How
          many choices are possible if
          **(a)** both books are to be on the same subject?
          **(b)** the books are to be on different subjects?
       **17.** Seven different gifts are to be distributed among
          10 children. How many distinct results are possible
          if no child is to receive more than one gift?
       **18.** A committee of 7, consisting of 2 Republicans,
          2 Democrats, and 3 Independents, is to be cho-
          sen from a group of 5 Republicans, 6 Democrats,
          and 4 Independents. How many committees are
          possible?
       **19.** From a group of 8 women and 6 men, a committee
          consisting of 3 men and 3 women is to be formed.
          How many different committees are possible if
          **(a)** 2 of the men refuse to serve together?
          **(b)** 2 of the women refuse to serve together?
          **(c)** 1 man and 1 woman refuse to serve together?


```
Problems 17
```
**20.** A person has 8 friends, of whom 5 will be invited
    to a party.
    **(a)** How many choices are there if 2 of the friends
       are feuding and will not attend together?
    **(b)** How many choices if 2 of the friends will only
       attend together?
**21.** Consider the grid of points shown here. Suppose
    that, starting at the point labeled _A_ , you can go one
    step up or one step to the right at each move. This
    procedure is continued until the point labeled _B_ is
    reached. How many different paths from _A_ to _B_
    are possible?
    _Hint_ : Note that to reach _B_ from _A_ , you must take
    4 steps to the right and 3 steps upward.

```
B
```
_A_

**22.** In Problem 21, how many different paths are there
    from _A_ to _B_ that go through the point circled in
    the following lattice?

```
B
```
_A_

**23.** A psychology laboratory conducting dream
    research contains 3 rooms, with 2 beds in each
    room. If 3 sets of identical twins are to be assigned
    to these 6 beds so that each set of twins sleeps

```
in different beds in the same room, how many
assignments are possible?
```
**24.** Expand( 3 _x_^2 + _y_ )^5.
**25.** The game of bridge is played by 4 players, each of
    whom is dealt 13 cards. How many bridge deals are
    possible?
**26.** Expand( _x_ 1 + 2 _x_ 2 + 3 _x_ 3 )^4.
**27.** If 12 people are to be divided into 3 committees of
    respective sizes 3, 4, and 5, how many divisions are
    possible?
**28.** If 8 new teachers are to be divided among 4
    schools, how many divisions are possible? What if
    each school must receive 2 teachers?
**29.** Ten weight lifters are competing in a team weight-
    lifting contest. Of the lifters, 3 are from the United
    States, 4 are from Russia, 2 are from China, and 1
    is from Canada. If the scoring takes account of the
    countries that the lifters represent, but not their
    individual identities, how many different outcomes
    are possible from the point of view of scores? How
    many different outcomes correspond to results in
    which the United States has 1 competitor in the
    top three and 2 in the bottom three?
**30.** Delegates from 10 countries, including Russia,
    France, England, and the United States, are to
    be seated in a row. How many different seat-
    ing arrangements are possible if the French and
    English delegates are to be seated next to each
    other and the Russian and U.S. delegates are not
    to be next to each other?
∗ **31.** If 8 identical blackboards are to be divided among
4 schools, how many divisions are possible? How
many if each school must receive at least 1 black-
board?
∗ **32.** An elevator starts at the basement with 8 peo-
ple (not including the elevator operator) and dis-
charges them all by the time it reaches the top
floor, number 6. In how many ways could the oper-
ator have perceived the people leaving the eleva-
tor if all people look alike to him? What if the 8
people consisted of 5 men and 3 women and the
operator could tell a man from a woman?
∗ **33.** We have 20 thousand dollars that must be invested
among 4 possible opportunities. Each investment
must be integral in units of 1 thousand dollars,
and there are minimal investments that need to be
made if one is to invest in these opportunities. The
minimal investments are 2, 2, 3, and 4 thousand
dollars. How many different investment strategies
are available if
**(a)** an investment must be made in each opportu-
nity?
**(b)** investments must be made in at least 3 of the
4 opportunities?


**18** Chapter 1 Combinatorial Analysis

#### Theoretical Exercises

**1.** Prove the generalized version of the basic counting
    principle.
**2.** Two experiments are to be performed. The first
    can result in any one of _m_ possible outcomes. If
    the first experiment results in outcome _i_ , then the
    second experiment can result in any of _ni_ possible
    outcomes, _i_ =1, 2,..., _m_. What is the number of
    possible outcomes of the two experiments?
**3.** In how many ways can _r_ objects be selected from a
    set of _n_ objects if the order of selection is consid-
    ered relevant?
**4.** There are

```
(
n
r
```
```
)
different linear arrangements of n
balls of which r are black and n − r are white. Give
a combinatorial explanation of this fact.
```
**5.** Determine the number of vectors( _x_ 1 ,..., _xn_ ),such
    that each _xi_ is either 0 or 1 and

```
∑ n
```
```
i = 1
```
```
xi Ú k
```
**6.** How many vectors _x_ 1 ,..., _xk_ are there for which
    each _xi_ is a positive integer such that 1... _xi_ ... _n_
    and _x_ 1 < _x_ 2 <···< _xk_?
**7.** Give an analytic proof of Equation (4.1).
**8.** Prove that
    (
       _n_ + _m_
          _r_

```
)
=
```
```
(
n
0
```
```
)(
m
r
```
```
)
+
```
```
(
n
1
```
```
)(
m
r − 1
```
```
)
```
```
+··· +
```
```
(
n
r
```
```
)(
m
0
```
```
)
```
```
Hint : Consider a group of n men and m women.
How many groups of size r are possible?
```
**9.** Use Theoretical Exercise 8 to prove that

```
(
2 n
n
```
```
)
=
```
```
∑ n
```
```
k = 0
```
```
(
n
k
```
```
) 2
```
**10.** From a group of _n_ people, suppose that we want to
    choose a committee of _k_ , _k_ ... _n_ , one of whom is to
    be designated as chairperson.
    **(a)** By focusing first on the choice of the commit-
       tee and then on the choice of the chair, argue
       that there are

```
(
n
k
```
```
)
k possible choices.
(b) By focusing first on the choice of the
nonchair committee members and then on
```
```
the choice of the chair, argue that there are(
n
k − 1
```
```
)
( n − k + 1 )possible choices.
(c) By focusing first on the choice of the chair
and then on the choice of the other committee
members, argue that there are n
```
```
(
n − 1
k − 1
```
```
)
```
```
possible choices.
(d) Conclude from parts (a), (b), and (c) that
```
```
k
```
```
(
n
k
```
```
)
=( n − k + 1 )
```
```
(
n
k − 1
```
```
)
= n
```
```
(
n − 1
k − 1
```
```
)
```
```
(e) Use the factorial definition of
```
```
(
m
r
```
```
)
to verify
the identity in part (d).
```
**11.** The following identity is known as Fermat’s com-
    binatorial identity:

```
(
n
k
```
```
)
=
```
```
∑ n
```
```
i = k
```
```
(
i − 1
k − 1
```
```
)
n Ú k
```
```
Give a combinatorial argument (no computations
are needed) to establish this identity.
Hint : Consider the set of numbers 1 through n.
How many subsets of size k have i as their highest-
numbered member?
```
**12.** Consider the following combinatorial identity:

```
∑ n
```
```
k = 1
```
```
k
```
```
(
n
k
```
```
)
= n · 2 n −^1
```
```
(a) Present a combinatorial argument for this
identity by considering a set of n people and
determining, in two ways, the number of pos-
sible selections of a committee of any size and
a chairperson for the committee.
Hint :
(i) How many possible selections are there
ofacommitteeofsize k and its chairper-
son?
(ii) How many possible selections are there
of a chairperson and the other commit-
tee members?
(b) Verify the following identity for n =
1, 2, 3, 4, 5:
```
```
∑ n
```
```
k = 1
```
```
(
n
k
```
```
)
k^2 = 2 n −^2 n ( n + 1 )
```

```
Theoretical Exercises 19
```
```
For a combinatorial proof of the preceding,
consider a set of n people and argue that both
sides of the identity represent the number of
different selections of a committee, its chair-
person, and its secretary (possibly the same as
the chairperson).
Hint :
(i) How many different selections result in
the committee containing exactly k peo-
ple?
(ii) How many different selections are there
in which the chairperson and the secre-
tary are the same? (ANSWER: n 2 n −^1 .)
(iii) How many different selections result in
the chairperson and the secretary being
different?
(c) Now argue that
```
```
∑ n
```
```
k = 1
```
```
(
n
k
```
```
)
k^3 = 2 n −^3 n^2 ( n + 3 )
```
**13.** Show that, for _n_ > 0,

```
∑ n
```
```
i = 0
```
```
(− 1 ) i
```
```
(
n
i
```
```
)
= 0
```
```
Hint : Use the binomial theorem.
```
**14.** From a set of _n_ people, a committee of size _j_ is to be
    chosen, and from this committee, a subcommittee
    of size _i_ , _i_ ... _j_ , is also to be chosen.
    **(a)** Derive a combinatorial identity by comput-
       ing, in two ways, the number of possible
       choices of the committee and subcommittee—
       first by supposing that the committee is
       chosen first and then the subcommittee is
       chosen, and second by supposing that the
       subcommittee is chosen first and then the
       remaining members of the committee are
       chosen.
    **(b)** Use part (a) to prove the following combina-
       torial identity:

```
∑ n
```
```
j = i
```
```
(
n
j
```
```
)(
j
i
```
```
)
=
```
```
(
n
i
```
```
)
2 n − i i ... n
```
```
(c) Use part (a) and Theoretical Exercise 13 to
show that
```
```
∑ n
```
```
j = i
```
```
(
n
j
```
```
)(
j
i
```
```
)
(− 1 ) n − j = 0 i < n
```
**15.** Let _Hk_ ( _n_ )be the number of vectors _x_ 1 ,..., _xk_ for
    which each _xi_ is a positive integer satisfying 1 ...
    _xi_ ... _n_ and _x_ 1 ... _x_ 2 ...···... _xk_.
    **(a)** Without any computations, argue that

```
H 1 ( n )= n
```
```
Hk ( n )=
```
```
∑ n
```
```
j = 1
```
```
Hk − 1 ( j ) k > 1
```
```
Hint : How many vectors are there in which
xk = j?
(b) Use the preceding recursion to compute
H 3 ( 5 ).
Hint : First compute H 2 ( n )for n =1, 2, 3, 4, 5.
```
**16.** Consider a tournament of _n_ contestants in which
    the outcome is an ordering of these contestants,
    with ties allowed. That is, the outcome partitions
    the players into groups, with the first group consist-
    ing of the players that tied for first place, the next
    group being those that tied for the next-best posi-
    tion, and so on. Let _N_ ( _n_ )denote the number of dif-
    ferent possible outcomes. For instance, _N_ ( 2 )=3,
    since, in a tournament with 2 contestants, player 1
    could be uniquely first, player 2 could be uniquely
    first, or they could tie for first.
    **(a)** List all the possible outcomes when _n_ =3.
    **(b)** With _N_ (0) defined to equal 1, argue, without
       any computations, that

```
N ( n )=
```
```
∑ n
```
```
i = 1
```
```
(
n
i
```
```
)
N ( n − i )
```
```
Hint : How many outcomes are there in
which i players tie for last place?
(c) Show that the formula of part (b) is equivalent
to the following:
```
```
N ( n )=
```
```
n ∑− 1
```
```
i = 0
```
```
(
n
i
```
```
)
N ( i )
```
```
(d) Use the recursion to find N (3) and N (4).
```
**17.** Present a combinatorial explanation of why(
    _n_
    _r_

```
)
=
```
```
(
n
r , n − r
```
```
)
.
```

**20** Chapter 1 Combinatorial Analysis

**18.** Argue that
    (
       _n
n_ 1 , _n_ 2 ,..., _nr_

```
)
=
```
```
(
n − 1
n 1 −1, n 2 ,..., nr
```
```
)
```
```
+
```
```
(
n − 1
n 1 , n 2 −1,..., nr
```
```
)
+ ···
```
```
+
```
```
(
n − 1
n 1 , n 2 ,..., nr − 1
```
```
)
```
```
Hint : Use an argument similar to the one used to
establish Equation (4.1).
```
**19.** Prove the multinomial theorem.
∗ **20.** In how many ways can _n_ identical balls be dis-
tributed into _r_ urns so that the _i_ th urn contains at
least _mi_ balls, for each _i_ =1,..., _r_? Assume that
_n_ Ú

```
∑ r
i = 1 mi.
```
```
∗ 21. Argue that there are exactly
```
```
(
r
k
```
```
)(
n − 1
n − r + k
```
```
)
```
```
solutions of
```
```
x 1 + x 2 + ··· + xr = n
```
```
for which exactly k of the xi are equal to 0.
∗ 22. Consider a function f ( x 1 ,..., xn )of n variables.
How many different partial derivatives of order r
does f possess?
∗ 23. Determine the number of vectors( x 1 ,..., xn )such
that each xi is a nonnegative integer and
```
```
∑ n
```
```
i = 1
```
```
xi ... k
```
#### Self-Test Problems and Exercises

**1.** How many different linear arrangements are there
    of the letters A, B, C, D, E, F for which
    **(a)** A and B are next to each other?
    **(b)** AisbeforeB?
    **(c)** A is before B and B is before C?
    **(d)** A is before B and C is before D?
    **(e)** A and B are next to each other and C and D
       are also next to each other?
    **(f)** E is not last in line?
**2.** If 4 Americans, 3 French people, and 3 British
    people are to be seated in a row, how many seat-
    ing arrangements are possible when people of the
    same nationality must sit next to each other?
**3.** A president, treasurer, and secretary, all different,
    are to be chosen from a club consisting of 10 peo-
    ple. How many different choices of officers are
    possible if
    **(a)** there are no restrictions?
    **(b)** _A_ and _B_ will not serve together?
    **(c)** _C_ and _D_ will serve together or not at all?
    **(d)** _E_ must be an officer?
    **(e)** _F_ will serve only if he is president?
**4.** A student is to answer 7 out of 10 questions in
    an examination. How many choices has she? How
    many if she must answer at least 3 of the first 5
    questions?
**5.** In how many ways can a man divide 7 gifts among
    his 3 children if the eldest is to receive 3 gifts and
    the others 2 each?
**6.** How many different 7-place license plates are pos-
    sible when 3 of the entries are letters and 4 are
    digits? Assume that repetition of letters and num-
    bers is allowed and that there is no restriction on
    where the letters or numbers can be placed.
       **7.** Give a combinatorial explanation of the identity
          (
             _n_
             _r_

```
)
=
```
```
(
n
n − r
```
```
)
```
**8.** Consider _n_ -digit numbers where each digit is one
    of the 10 integers 0, 1,..., 9. How many such num-
    bers are there for which
    **(a)** no two consecutive digits are equal?
    **(b)** 0 appears as a digit a total of _i_ times, _i_ =
       0,..., _n_?
**9.** Consider three classes, each consisting of _n_ stu-
    dents. From this group of 3 _n_ students, a group of 3
    students is to be chosen.
    **(a)** How many choices are possible?
    **(b)** How many choices are there in which all 3 stu-
       dents are in the same class?
    **(c)** How many choices are there in which 2 of the
       3 students are in the same class and the other
       student is in a different class?
    **(d)** How many choices are there in which all 3 stu-
       dents are in different classes?
    **(e)** Using the results of parts (a) through (d),
       write a combinatorial identity.
**10.** How many 5-digit numbers can be formed from
the integers 1, 2,..., 9 if no digit can appear more
than twice? (For instance, 41434 is not allowed.)
**11.** From 10 married couples, we want to select a
group of 6 people that is not allowed to contain
a married couple.
**(a)** How many choices are there?
**(b)** How many choices are there if the group must
also consist of 3 men and 3 women?


```
Self-Test Problems and Exercises 21
```
**12.** A committee of 6 people is to be chosen from a
    group consisting of 7 men and 8 women. If the
    committee must consist of at least 3 women and
    at least 2 men, how many different committees are
    possible?
∗ **13.** An art collection on auction consisted of 4 Dalis, 5

van Goghs, and 6 Picassos. At the auction were 5
art collectors. If a reporter noted only the number
of Dalis, van Goghs, and Picassos acquired by each
collector, how many different results could have
been recorded if all of the works were sold?
∗ **14.** Determine the number of vectors( _x_ 1 ,..., _xn_ )such

```
that each xi is a positive integer and
```
```
∑ n
```
```
i = 1
```
```
xi ... k
```
```
where k Ú n.
```
**15.** A total of _n_ students are enrolled in a review
    course for the actuarial examination in probability.
    The posted results of the examination will list the
    names of those who passed, in decreasing order of
    their scores. For instance, the posted result will be
    “Brown, Cho” if Brown and Cho are the only ones
    to pass, with Brown receiving the higher score.

```
Assuming that all scores are distinct (no ties), how
many posted results are possible?
```
**16.** Howmanysubsetsofsize4oftheset _S_ =
    {1, 2,...,20}contain at least one of the elements
    1, 2, 3, 4, 5?
**17.** Give an analytic verification of
    (
       _n_
       2

```
)
=
```
```
(
k
2
```
```
)
+ k ( n − k )+
```
```
(
n − k
2
```
```
)
,1... k ... n
```
```
Now, give a combinatorial argument for this
identity.
```
**18.** In a certain community, there are 3 families con-
    sisting of a single parent and 1 child, 3 families
    consisting of a single parent and 2 children, 5 fam-
    ilies consisting of 2 parents and a single child, 7
    families consisting of 2 parents and 2 children, and
    6 families consisting of 2 parents and 3 children. If
    a parent and child from the same family are to be
    chosen, how many possible choices are there?
**19.** If there are no restrictions on where the digits and
    letters are placed, how many 8-place license plates
    consisting of 5 letters and 3 digits are possible if no
    repetitions of letters or digits are allowed. What if
    the 3 digits must be consecutive?


## CHAPTER 2

# Axioms of Probability

### 2.1 Introduction

### 2.2 SampleSpaceandEvents..........................

**2.3 AXIOMS OF PROBABILITY
2.4 SOME SIMPLE PROPOSITIONS
2.5 SAMPLE SPACES HAVING EQUALLY LIKELY OUTCOMES**

### 2.6 Probability as a Continuous Set Function

**2.7 PROBABILITY AS A MEASURE OF BELIEF**

##### 2.1 INTRODUCTION

```
In this chapter, we introduce the concept of the probability of an event and then show
how probabilities can be computed in certain situations. As a preliminary, however,
we need the concept of the sample space and the events of an experiment.
```
##### 2.2 SAMPLE SPACE AND EVENTS

```
Consider an experiment whose outcome is not predictable with certainty. However,
although the outcome of the experiment will not be known in advance, let us suppose
that the set of all possible outcomes is known. This set of all possible outcomes of
an experiment is known as the sample space of the experiment and is denoted by S.
Following are some examples:
```
1. If the outcome of an experiment consists in the determination of the sex of a
    newborn child, then
       _S_ ={ _g_ , _b_ }

```
where the outcome g means that the child is a girl and b that it is a boy.
```
2. If the outcome of an experiment is the order of finish in a race among the 7
    horses having post positions 1, 2, 3, 4, 5, 6, and 7, then

```
S ={all 7! permutations of(1, 2, 3, 4, 5, 6, 7)}
```
```
The outcome (2, 3, 1, 6, 5, 4, 7) means, for instance, that the number 2 horse
comes in first, then the number 3 horse, then the number 1 horse, and so on.
```
3. If the experiment consists of flipping two coins, then the sample space consists
    of the following four points:

```
S ={( H , H ),( H , T ),( T , H ),( T , T )}
```
```
The outcome will be ( H , H ) if both coins are heads, ( H , T ) if the first coin is
heads and the second tails, ( T , H ) if the first is tails and the second heads, and
( T , T ) if both coins are tails.
```
**22**


```
Section 2.2 Sample Space and Events 23
```
4. If the experiment consists of tossing two dice, then the sample space consists of
    the 36 points
       _S_ ={( _i_ , _j_ ): _i_ , _j_ =1, 2, 3, 4, 5, 6}

```
where the outcome ( i , j ) is said to occur if i appears on the leftmost die and j on
the other die.
```
5. If the experiment consists of measuring (in hours) the lifetime of a transistor,
    then the sample space consists of all nonnegative real numbers; that is,

```
S ={ x :0... x <q}
```
Any subset _E_ of the sample space is known as an _event_. In other words, an event is
a set consisting of possible outcomes of the experiment. If the outcome of the experi-
ment is contained in _E_ , then we say that _E_ has occurred. Following are some examples
of events.
In the preceding Example 1, if _E_ ={ _g_ },then _E_ is the event that the child is a girl.
Similarly, if _F_ ={ _b_ },then _F_ is the event that the child is a boy.
In Example 2, if

```
E ={all outcomes in S starting with a 3}
```
then _E_ is the event that horse 3 wins the race.
In Example 3, if _E_ ={( _H_ , _H_ ),( _H_ , _T_ )},then _E_ is the event that a head appears on
the first coin.
In Example 4, if _E_ ={(1, 6),(2, 5),(3, 4),(4, 3),(5, 2),(6, 1)},then _E_ is the event that
the sum of the dice equals 7.
In Example 5, if _E_ ={ _x_ :0... _x_ ... 5 },then _E_ is the event that the transistor does
not last longer than 5 hours.
For any two events _E_ and _F_ of a sample space _S_ , we define the new event _E_ ∪ _F_
to consist of all outcomes that are either in _E_ or in _F_ or in both _E_ and _F_. That is, the
event _E_ ∪ _F_ will occur if _either E_ or _F_ occurs. For instance, in Example 1, if event
_E_ ={ _g_ }and _F_ ={ _b_ },then

```
E ∪ F ={ g , b }
```
That is, _E_ ∪ _F_ is the whole sample space _S_. In Example 3, if _E_ ={( _H_ , _H_ ),( _H_ , _T_ )}and
_F_ ={( _T_ , _H_ )},then

```
E ∪ F ={( H , H ),( H , T ),( T , H )}
```
Thus, _E_ ∪ _F_ would occur if a head appeared on either coin.
The event _E_ ∪ _F_ is called the _union_ of the event _E_ and the event _F_.
Similarly, for any two events _E_ and _F_ , we may also define the new event _EF_ , called
the _intersection_ of _E_ and _F_ , to consist of all outcomes that are both in _E_ and in _F_.
That is, the event _EF_ (sometimes written _E_ ∩ _F_ ) will occur only if both _E_ and _F_
occur. For instance, in Example 3, if _E_ ={( _H_ , _H_ ),( _H_ , _T_ ),( _T_ , _H_ )}is the event that at
least 1 head occurs and _F_ ={( _H_ , _T_ ),( _T_ , _H_ ),( _T_ , _T_ )}is the event that at least 1 tail
occurs, then

```
EF ={( H , T ),( T , H )}
```
is the event that exactly 1 head and 1 tail occur. In example 4, if _E_ ={(1, 6),(2, 5),
(3, 4),(4, 3),(5, 2),(6, 1)}is the event that the sum of the dice is 7 and _F_ ={(1, 5),(2, 4),
(3, 3),(4, 2),(5, 1)}is the event that the sum is 6, then the event _EF_ does not contain


**24** Chapter 2 Axioms of Probability

```
any outcomes and hence could not occur. To give such an event a name, we shall refer
to it as the null event and denote it by Ø. (That is, Ø refers to the event consisting of
no outcomes.) If EF =Ø, then E and F are said to be mutually exclusive.
We define unions and intersections of more than two events in a similar manner.
If E 1 , E 2 ,...are events, then the union of these events, denoted by
```
```
⋃q
n = 1
```
```
En , is defined
```
```
to be that event which consists of all outcomes that are in En for at least one value
of n = 1, 2,.... Similarly, the intersection of the events En , denoted by
```
```
⋂q
n = 1
```
```
En ,is
```
```
defined to be the event consisting of those outcomes which are in all of the events
En , n =1, 2,....
Finally, for any event E , we define the new event Ec , referred to as the com-
plement of E , to consist of all outcomes in the sample space S that are not in E.
That is, Ec will occur if and only if E does not occur. In Example 4, if event E =
{(1, 6),(2, 5),(3, 4),(4, 3),(5, 2),(6, 1)},then Ec will occur when the sum of the dice
does not equal 7. Note that because the experiment must result in some outcome, it
follows that Sc =Ø.
For any two events E and F , if all of the outcomes in E are also in F , then we say
that E is contained in F ,or E is a subset of F , and write E ( F (or equivalently, F ) E ,
which we sometimes say as F is a superset of E ). Thus, if E ( F , then the occurrence
of E implies the occurrence of F .If E ( F and F ( E , we say that E and F are equal
and write E = F.
A graphical representation that is useful for illustrating logical relations among
events is the Venn diagram. The sample space S is represented as consisting of all
the outcomes in a large rectangle, and the events E , F , G ,...are represented as con-
sisting of all the outcomes in given circles within the rectangle. Events of interest
can then be indicated by shading appropriate regions of the diagram. For instance, in
the three Venn diagrams shown in Figure 2.1, the shaded areas represent, respec-
tively, the events E ∪ F , EF ,and Ec. The Venn diagram in Figure 2.2 indicates
that E ( F.
```
```
EFEF
```
```
SS
```
```
(a) Shaded region: E  F. (b) Shaded region: EF.
S
```
```
(c) Shaded region: Ec.
```
```
E
```
```
FIGURE 2.1: Venn Diagrams
```

```
Section 2.2 Sample Space and Events 25
```
```
S
```
```
F
```
```
E
```
```
FIGURE 2.2: E ( F
```
The operations of forming unions, intersections, and complements of events obey
certain rules similar to the rules of algebra. We list a few of these rules:

```
Commutative laws E ∪ F = F ∪ EEF = FE
Associative laws ( E ∪ F )∪ G = E ∪( F ∪ G )( EF ) G = E ( FG )
Distributive laws ( E ∪ F ) G = EG ∪ FG EF ∪ G =( E ∪ G )( F ∪ G )
```
These relations are verified by showing that any outcome that is contained in the
event on the left side of the equality sign is also contained in the event on the right
side, and vice versa. One way of showing this is by means of Venn diagrams. For
instance, the distributive law may be verified by the sequence of diagrams in
Figure 2.3.

```
EF
```
```
(a) Shaded region: EG.
```
```
G
```
```
E F
```
```
(b) Shaded region: FG.
```
```
G
```
```
EF
```
```
(c) Shaded region: ( E  F ) G.
```
```
G
```
```
FIGURE 2.3: ( E ∪ F ) G = EG ∪ FG
```

**26** Chapter 2 Axioms of Probability

```
The following useful relationships between the three basic operations of forming
unions, intersections, and complements are known as DeMorgan’s laws :
⎛
```
```
⎝
```
```
⋃ n
```
```
i = 1
```
```
Ei
```
##### ⎞

##### ⎠

```
c
=
```
```
⋂ n
```
```
i = 1
```
```
Eci
```
```
⎛
```
```
⎝
```
```
⋂ n
```
```
i = 1
```
```
Ei
```
##### ⎞

##### ⎠

```
c
=
```
```
⋃ n
```
```
i = 1
```
```
Eci
```
```
To prove DeMorgan’s laws, suppose first that x is an outcome of
```
##### (

```
⋃ n
i = 1
```
```
Ei
```
```
) c
```
. Then

```
x is not contained in
```
```
⋃ n
i = 1
```
```
Ei , which means that x is not contained in any of the events
```
```
Ei , i =1, 2,..., n , implying that x is contained in Eci for all i =1, 2,..., n and thus is
```
```
contained in
```
```
⋂ n
i = 1
```
```
Eci. To go the other way, suppose that x is an outcome of
```
```
⋂ n
i = 1
```
```
Eci. Then
```
```
x is contained in Eci for all i =1, 2,..., n , which means that x is not contained in Ei for
```
```
any i =1, 2,..., n , implying that x is not contained in
```
```
⋃ n
i
```
```
Ei , in turn implying that x is
```
```
contained in
```
##### (

```
⋃ n
1
```
```
Ei
```
```
) c
```
. This proves the first of DeMorgan’s laws.

```
To prove the second of DeMorgan’s laws, we use the first law to obtain
⎛
```
```
⎝
```
```
⋃ n
```
```
i = 1
```
```
Eci
```
##### ⎞

##### ⎠

```
c
```
```
=
```
```
⋂ n
```
```
i = 1
```
```
( Eci ) c
```
```
which, since( Ec ) c = E , is equivalent to
⎛
```
```
⎝
```
```
⋃ n
```
```
1
```
```
Eci
```
##### ⎞

##### ⎠

```
c
=
```
```
⋂ n
```
```
1
```
```
Ei
```
```
Taking complements of both sides of the preceding equation yields the result we seek,
namely,
⋃ n
```
```
1
```
```
Eci =
```
##### ⎛

##### ⎝

```
⋂ n
```
```
1
```
```
Ei
```
##### ⎞

##### ⎠

```
c
```
### 2.3 Axioms of Probability

```
One way of defining the probability of an event is in terms of its relative frequency.
Such a definition usually goes as follows: We suppose that an experiment, whose sam-
ple space is S , is repeatedly performed under exactly the same conditions. For each
event E of the sample space S , we define n ( E )to be the number of times in the first n
repetitions of the experiment that the event E occurs. Then P ( E ), the probability of
the event E , is defined as
P ( E )= lim
n →q
```
```
n ( E )
n
```

```
Section 2.3 Axioms of Probability 27
```
That is, _P_ ( _E_ )is defined as the (limiting) proportion of time that _E_ occurs. It is thus
the limiting frequency of _E_.
Although the preceding definition is certainly intuitively pleasing and should always
be kept in mind by the reader, it possesses a serious drawback: How do we know that
_n_ ( _E_ )/ _n_ will converge to some constant limiting value that will be the same for each
possible sequence of repetitions of the experiment? For example, suppose that the
experiment to be repeatedly performed consists of flipping a coin. How do we know
that the proportion of heads obtained in the first _n_ flips will converge to some value
as _n_ gets large? Also, even if it does converge to some value, how do we know that,
if the experiment is repeatedly performed a second time, we shall obtain the same
limiting proportion of heads?
Proponents of the relative frequency definition of probability usually answer this
objection by stating that the convergence of _n_ ( _E_ )/ _n_ to a constant limiting value is an
assumption, or an _axiom_ , of the system. However, to assume that _n_ ( _E_ )/ _n_ will neces-
sarily converge to some constant value seems to be an extraordinarily complicated
assumption. For, although we might indeed hope that such a constant limiting fre-
quency exists, it does not at all seem to be a priori evident that this need be the
case. In fact, would it not be more reasonable to assume a set of simpler and more
self-evident axioms about probability and then attempt to prove that such a con-
stant limiting frequency does in some sense exist? The latter approach is the modern
axiomatic approach to probability theory that we shall adopt in this text. In particular,
we shall assume that, for each event _E_ in the sample space _S_ , there exists a value _P_ ( _E_ ),
referred to as the probability of _E_. We shall then assume that all these probabilities
satisfy a certain set of axioms, which, we hope the reader will agree, is in accordance
with our intuitive notion of probability.
Consider an experiment whose sample space is _S_. For each event _E_ of the sample
space _S_ , we assume that a number _P_ ( _E_ )is defined and satisfies the following three
axioms:

```
Axiom 1
```
##### 0 ... P ( E )... 1

```
Axiom 2
```
##### P ( S )= 1

```
Axiom 3
For any sequence of mutually exclusive events E 1 , E 2 ,...(that is, events for which
EiEj =Ø when i Z j ),
```
##### P

##### ⎛

##### ⎝

```
⋃q
```
```
i = 1
```
```
Ei
```
##### ⎞

##### ⎠=

```
∑q
```
```
i = 1
```
```
P ( Ei )
```
```
We refer to P ( E )as the probability of the event E.
```
Thus, Axiom 1 states that the probability that the outcome of the experiment is an
outcome in _E_ is some number between 0 and 1. Axiom 2 states that, with probability
1, the outcome will be a point in the sample space _S_. Axiom 3 states that, for any
sequence of mutually exclusive events, the probability of at least one of these events
occurring is just the sum of their respective probabilities.


**28** Chapter 2 Axioms of Probability

```
If we consider a sequence of events E 1 , E 2 ,..., where E 1 = S and Ei =Øfor i >1,
then, because the events are mutually exclusive and because S =
```
```
⋃q
i = 1
```
```
Ei , we have, from
```
```
Axiom 3,
P ( S )=
```
```
∑q
```
```
i = 1
```
```
P ( Ei )= P ( S )+
```
```
∑q
```
```
i = 2
```
##### P (Ø)

```
implying that
P (Ø)= 0
```
```
That is, the null event has probability 0 of occurring.
Note that it follows that, for any finite sequence of mutually exclusive events E 1 ,
E 2 ,..., En ,
```
```
P
```
##### ⎛

##### ⎝

```
⋃ n
```
```
1
```
```
Ei
```
##### ⎞

##### ⎠=

```
∑ n
```
```
i = 1
```
```
P ( Ei ) (3.1)
```
```
This equation follows from Axiom 3 by defining Ei as the null event for all values
of i greater than n. Axiom 3 is equivalent to Equation (3.1) when the sample space
is finite. (Why?) However, the added generality of Axiom 3 is necessary when the
sample space consists of an infinite number of points.
```
```
EXAMPLE 3a
If our experiment consists of tossing a coin and if we assume that a head is as likely
to appear as a tail, then we would have
```
##### P ({ H })= P ({ T })=

##### 1

##### 2

```
On the other hand, if the coin were biased and we felt that a head were twice as likely
to appear as a tail, then we would have
```
##### P ({ H })=

##### 2

##### 3

##### P ({ T })=

##### 1

##### 3

##### .

```
EXAMPLE 3b
If a die is rolled and we suppose that all six sides are equally likely to appear, then
we would have P ({ 1 })= P ({ 2 })= P ({ 3 })= P ({ 4 })= P ({ 5 })= P ({ 6 })=^16. From
Axiom 3, it would thus follow that the probability of rolling an even number would
equal
P ({2, 4, 6})= P ({ 2 })+ P ({ 4 })+ P ({ 6 })=
```
##### 1

##### 2

##### .

```
The assumption of the existence of a set function P , defined on the events of a
sample space S and satisfying Axioms 1, 2, and 3, constitutes the modern mathemat-
ical approach to probability theory. Hopefully, the reader will agree that the axioms
are natural and in accordance with our intuitive concept of probability as related to
chance and randomness. Furthermore, using these axioms we shall be able to prove
that if an experiment is repeated over and over again, then, with probability 1, the
proportion of time during which any specific event E occurs will equal P ( E ). This
result, known as the strong law of large numbers, is presented in Chapter 8. In addi-
tion, we present another possible interpretation of probability—as being a measure
of belief—in Section 2.7.
```

```
Section 2.4 Some Simple Propositions 29
```
```
Technical Remark. We have supposed that P ( E )is defined for all the events E
of the sample space. Actually, when the sample space is an uncountably infinite set,
P ( E )is defined only for a class of events called measurable. However, this restriction
need not concern us, as all events of any practical interest are measurable.
```
### 2.4 Some Simple Propositions

```
In this section, we prove some simple propositions regarding probabilities. We first
note that, since E and Ec are always mutually exclusive and since E ∪ Ec = S ,we
have, by Axioms 2 and 3,
```
```
1 = P ( S )= P ( E ∪ Ec )= P ( E )+ P ( Ec )
```
```
Or, equivalently, we have Proposition 4.1.
```
```
Proposition 4.1.
P ( Ec )= 1 − P ( E )
In words, Proposition 4.1 states that the probability that an event does not occur is
1 minus the probability that it does occur. For instance, if the probability of obtaining
a head on the toss of a coin is^38 , then the probability of obtaining a tail must be^58.
Our second proposition states that if the event E is contained in the event F ,then
the probability of E is no greater than the probability of F.
```
```
Proposition 4.2. If E ( F ,then P ( E )... P ( F ).
Proof. Since E ( F , it follows that we can express F as
```
```
F = E ∪ EcF
```
```
Hence, because E and EcF are mutually exclusive, we obtain, from Axiom 3,
```
```
P ( F )= P ( E )+ P ( EcF )
```
```
which proves the result, since P ( EcF )Ú0.
```
```
Proposition 4.2 tells us, for instance, that the probability of rolling a 1 with a die is
less than or equal to the probability of rolling an odd value with the die.
The next proposition gives the relationship between the probability of the union
of two events, expressed in terms of the individual probabilities, and the probability
of the intersection of the events.
```
```
Proposition 4.3.
P ( E ∪ F )= P ( E )+ P ( F )− P ( EF )
```
```
Proof. To derive a formula for P ( E ∪ F ), we first note that E ∪ F can be written
as the union of the two disjoint events E and EcF. Thus, from Axiom 3, we obtain
```
```
P ( E ∪ F )= P ( E ∪ EcF )
= P ( E )+ P ( EcF )
```
```
Furthermore, since F = EF ∪ EcF , we again obtain from Axiom 3
```
```
P ( F )= P ( EF )+ P ( EcF )
```

**30** Chapter 2 Axioms of Probability

```
EF
```
```
FIGURE 2.4: Venn Diagram
```
```
EF
```
```
I II III
```
```
FIGURE 2.5: Venn Diagram in Sections
```
```
or, equivalently,
P ( EcF )= P ( F )− P ( EF )
```
```
thereby completing the proof.
```
```
Proposition 4.3 could also have been proved by making use of the Venn diagram
in Figure 2.4.
Let us divide E ∪ F into three mutually exclusive sections, as shown in Figure 2.5.
In words, section I represents all the points in E that are not in F (that is, EFc ),
section II represents all points both in E and in F (that is, EF ), and section III repre-
sents all points in F that are not in E (that is, EcF ).
From Figure 2.5, we see that
E ∪ F =I∪II∪III
E =I∪II
F =II∪III
```
```
As I, II, and III are mutually exclusive, it follows from Axiom 3 that
P ( E ∪ F )= P (I)+ P (II)+ P (III)
P ( E )= P (I)+ P (II)
P ( F )= P (II)+ P (III)
```
```
which shows that
P ( E ∪ F )= P ( E )+ P ( F )− P (II)
```
```
and Proposition 4.3 is proved, since II= EF.
```
```
EXAMPLE 4a
J is taking two books along on her holiday vacation. With probability .5, she will like
the first book; with probability .4, she will like the second book; and with probabil-
ity .3, she will like both books. What is the probability that she likes neither book?
```

```
Section 2.4 Some Simple Propositions 31
```
**_Solution._** Let _Bi_ denote the event that J likes book _i_ , _i_ =1, 2. Then the probability
that she likes at least one of the books is

```
P ( B 1 ∪ B 2 )= P ( B 1 )+ P ( B 2 )− P ( B 1 B 2 )=. 5 +. 4 −. 3 =. 6
```
Because the event that J likes neither book is the complement of the event that she
likes at least one of them, we obtain the result

```
P ( Bc 1 Bc 2 )= P
```
##### (

```
( B 1 ∪ B 2 ) c
```
##### )

##### = 1 − P ( B 1 ∪ B 2 )=. 4.

We may also calculate the probability that any one of the three events _E_ , _F_ ,and _G_
occurs, namely,

```
P ( E ∪ F ∪ G )= P [( E ∪ F )∪ G ]
```
which, by Proposition 4.3, equals

```
P ( E ∪ F )+ P ( G )− P [( E ∪ F ) G ]
```
Now, it follows from the distributive law that the events( _E_ ∪ _F_ ) _G_ and _EG_ ∪ _FG_ are
equivalent; hence, from the preceding equations, we obtain

```
P ( E ∪ F ∪ G )
= P ( E )+ P ( F )− P ( EF )+ P ( G )− P ( EG ∪ FG )
= P ( E )+ P ( F )− P ( EF )+ P ( G )− P ( EG )− P ( FG )+ P ( EGFG )
= P ( E )+ P ( F )+ P ( G )− P ( EF )− P ( EG )− P ( FG )+ P ( EFG )
```
In fact, the following proposition, known as the _inclusion–exclusion identity_ , can
be proved by mathematical induction:

**Proposition 4.4.**

```
P ( E 1 ∪ E 2 ∪ ··· ∪ En )=
```
```
∑ n
```
```
i = 1
```
```
P ( Ei )−
```
##### ∑

```
i 1 < i 2
```
```
P ( Ei 1 Ei 2 )+ ···
```
```
+(− 1 ) r +^1
```
##### ∑

```
i 1 < i 2 <···< ir
```
```
P ( Ei 1 Ei 2 ··· Eir )
```
```
+ ··· +(− 1 ) n +^1 P ( E 1 E 2 ··· En )
```
The summation

##### ∑

```
i 1 < i 2 <···< ir
```
```
P ( Ei 1 Ei 2 ··· Eir )is taken over all of the
```
##### (

```
n
r
```
##### )

```
possible sub-
```
sets of size _r_ of the set{1, 2,..., _n_ }.

In words, Proposition 4.4 states that the probability of the union of _n_ events equals
the sum of the probabilities of these events taken one at a time, minus the sum of the
probabilities of these events taken two at a time, plus the sum of the probabilities of
these events taken three at a time, and so on.

**Remarks.** 1. For a noninductive argument for Proposition 4.4, note first that if an
outcome of the sample space is not a member of any of the sets _Ei_ , then its probability
does not contribute anything to either side of the equality. Now, suppose that an
outcome is in exactly _m_ of the events _Ei_ , where _m_ > 0. Then, since it is in

##### ⋃

```
i
```
```
Ei ,its
```

**32** Chapter 2 Axioms of Probability

```
probability is counted once in P
```
##### (

##### ⋃

```
i
```
```
Ei
```
##### )

```
; also, as this outcome is contained in
```
##### (

```
m
k
```
##### )

```
subsets of the type Ei 1 Ei 2 ··· Eik , its probability is counted
(
m
1
```
##### )

##### −

##### (

```
m
2
```
##### )

##### +

##### (

```
m
3
```
##### )

##### − ···;

##### (

```
m
m
```
##### )

```
times on the right of the equality sign in Proposition 4.4. Thus, for m >0, we must
show that
```
```
1 =
```
##### (

```
m
1
```
##### )

##### −

##### (

```
m
2
```
##### )

##### +

##### (

```
m
3
```
##### )

##### − ···;

##### (

```
m
m
```
##### )

```
However, since 1=
```
##### (

```
m
0
```
##### )

```
, the preceding equation is equivalent to
```
```
∑ m
```
```
i = 0
```
##### (

```
m
i
```
##### )

```
(− 1 ) i = 0
```
```
and the latter equation follows from the binomial theorem, since
```
```
0 =(− 1 + 1 ) m =
```
```
∑ m
```
```
i = 0
```
##### (

```
m
i
```
##### )

```
(− 1 ) i ( 1 ) m − i
```
2. The following is a succinct way of writing the inclusion–exclusion identity:

```
P (∪ ni = 1 Ei )=
```
```
∑ n
```
```
r = 1
```
```
(− 1 ) r +^1
```
##### ∑

```
i 1 <···< ir
```
```
P ( Ei 1 ··· Eir )
```
3. In the inclusion–exclusion identity, going out one term results in an upper bound
on the probability of the union, going out two terms results in a lower bound on the
probability, going out three terms results in an upper bound on the probability, going
out four terms results in a lower bound, and so on. That is, for events _E_ 1 ,..., _En_ ,
we have

```
P (∪ ni = 1 Ei )...
```
```
∑ n
```
```
i = 1
```
```
P ( Ei ) (4.1)
```
```
P (∪ ni = 1 Ei )Ú
```
```
∑ n
```
```
i = 1
```
```
P ( Ei )−
```
##### ∑

```
j < i
```
```
P ( EiEj ) (4.2)
```
```
P (∪ ni = 1 Ei )...
```
```
∑ n
```
```
i = 1
```
```
P ( Ei )−
```
##### ∑

```
j < i
```
```
P ( EiEj )+
```
##### ∑

```
k < j < i
```
```
P ( EiEjEk ) (4.3)
```
```
and so on. To prove the validity of these bounds, note the identity
```
```
∪ ni = 1 Ei = E 1 ∪ Ec 1 E 2 ∪ Ec 1 Ec 2 E 3 ∪ ··· ∪ Ec 1 ··· Ecn − 1 En
```

```
Section 2.5 Sample Spaces Having Equally Likely Outcomes 33
```
```
That is, at least one of the events Ei occurs if E 1 occurs, or if E 1 does not occur but
E 2 does, or if E 1 and E 2 do not occur but E 3 does, and so on. Because the right-hand
side is the union of disjoint events, we obtain
```
```
P (∪ ni = 1 Ei )= P ( E 1 )+ P ( Ec 1 E 2 )+ P ( Ec 1 Ec 2 E 3 )+...+ P ( Ec 1 ··· Ecn − 1 En )
```
##### = P ( E 1 )+

```
∑ n
```
```
i = 2
```
```
P ( Ec 1 ··· Eci − 1 Ei ) (4.4)
```
```
Now, let Bi = Ec 1 ··· Eci − 1 =(∪ j < iEj ) c be the event that none of the first i −1 events
occur. Applying the identity
```
```
P ( Ei )= P ( BiEi )+ P ( BciEi )
```
```
shows that
P ( Ei )= P ( Ec 1 ··· Eci − 1 Ei )+ P ( Ei ∪ j < iEj )
```
```
or, equivalently,
P ( Ec 1 ··· Eci − 1 Ei )= P ( Ei )− P (∪ j < iEiEj )
```
```
Substituting this equation into (4.4) yields
```
```
P (∪ ni = 1 Ei )=
```
##### ∑

```
i
```
```
P ( Ei )−
```
##### ∑

```
i
```
```
P (∪ j < iEiEj ) (4.5)
```
```
Because probabilities are always nonnegative, Inequality (4.1) follows directly from
Equation (4.5). Now, fixing i and applying Inequality (4.1) to P (∪ j < iEiEj )yields
```
```
P (∪ j < iEiEj )...
```
##### ∑

```
j < i
```
```
P ( EiEj )
```
```
which, by Equation (4.5), gives Inequality (4.2). Similarly, fixing i and applying Inequal-
ity (4.2) to P (∪ j < iEiEj )yields
```
```
P (∪ j < iEiEj )Ú
```
##### ∑

```
j < i
```
```
P ( EiEj )−
```
##### ∑

```
k < j < i
```
```
P ( EiEjEiEk )
```
##### =

##### ∑

```
j < i
```
```
P ( EiEj )−
```
##### ∑

```
k < j < i
```
```
P ( EiEjEk )
```
```
which, by Equation (4.5), gives Inequality (4.3). The next inclusion–exclusion inequal-
ity is now obtained by fixing i and applying Inequality (4.3) to P (∪ j < iEiEj ),and
so on.
```
### 2.5 Sample Spaces Having Equally Likely Outcomes

```
In many experiments, it is natural to assume that all outcomes in the sample space
are equally likely to occur. That is, consider an experiment whose sample space S is a
finite set, say, S ={1, 2,..., N }. Then it is often natural to assume that
```
```
P ({ 1 })= P ({ 2 })=···= P ({ N })
```
```
which implies, from Axioms 2 and 3 (why?), that
```
```
P ({ i })=
```
##### 1

##### N

```
i =1, 2,..., N
```

**34** Chapter 2 Axioms of Probability

```
From this equation, it follows from Axiom 3 that, for any event E ,
```
##### P ( E )=

```
number of outcomes in E
number of outcomes in S
In words, if we assume that all outcomes of an experiment are equally likely to occur,
then the probability of any event E equals the proportion of outcomes in the sample
space that are contained in E.
```
```
EXAMPLE 5a
If two dice are rolled, what is the probability that the sum of the upturned faces will
equal 7?
```
```
Solution. We shall solve this problem under the assumption that all of the 36 possible
outcomes are equally likely. Since there are 6 possible outcomes—namely, (1, 6), (2,
5), (3, 4), (4, 3), (5, 2), and (6, 1)—that result in the sum of the dice being equal to 7,
the desired probability is 366 =^16..
```
```
EXAMPLE 5b
If 3 balls are “randomly drawn” from a bowl containing 6 white and 5 black balls,
what is the probability that one of the balls is white and the other two black?
```
```
Solution. If we regard the order in which the balls are selected as being relevant,
then the sample space consists of 11· 10 · 9 =990 outcomes. Furthermore, there are
6 · 5 · 4 =120 outcomes in which the first ball selected is white and the other two
are black; 5 · 6 · 4 =120 outcomes in which the first is black, the second is white,
and the third is black; and 5 · 4 · 6 =120 in which the first two are black and the
third is white. Hence, assuming that “randomly drawn” means that each outcome in
the sample space is equally likely to occur, we see that the desired probability is
```
```
120 + 120 + 120
990
```
##### =

##### 4

##### 11

```
This problem could also have been solved by regarding the outcome of the experi-
ment as the unordered set of drawn balls. From this point of view, there are
```
##### (

##### 11

##### 3

##### )

##### =

```
165 outcomes in the sample space. Now, each set of 3 balls corresponds to 3! out-
comes when the order of selection is noted. As a result, if all outcomes are assumed
equally likely when the order of selection is noted, then it follows that they remain
equally likely when the outcome is taken to be the unordered set of selected balls.
Hence, using the latter representation of the experiment, we see that the desired
probability is (
6
1
```
##### )(

##### 5

##### 2

##### )

##### (

##### 11

##### 3

##### ) =

##### 4

##### 11

```
which, of course, agrees with the answer obtained previously.
When the experiment consists of a random selection of k items from a set of n
items, we have the flexibility of either letting the outcome of the experiment be the
ordered selection of the k items or letting it be the unordered set of items selected.
In the former case we would assume that each new selection is equally likely to be
```

```
Section 2.5 Sample Spaces Having Equally Likely Outcomes 35
```
any of the so far unselected items of the set, and in the latter case we would assume
that all

```
( n
k
```
##### )

possible subsets of _k_ items are equally likely to be the set selected. For
instance, suppose 5 people are to be randomly selected from a group of 20 individuals
consisting of 10 married couples, and we want to determine _P_ ( _N_ ), the probability
that the 5 chosen are all unrelated. (That is, no two are married to each other.) If
we regard the sample space as the set of 5 people chosen, then there are

##### ( 20

```
5
```
##### )

equally
likely outcomes. An outcome that does not contain a married couple can be thought
of as being the result of a six-stage experiment: In the first stage, 5 of the 10 couples
to have a member in the group are chosen; in the next 5 stages, 1 of the 2 members

of each of these couples is selected. Thus, there are

##### ( 10

```
5
```
##### )

25 possible outcomes in which
the 5 members selected are unrelated, yielding the desired probability of

##### P ( N )=

##### (

##### 10

##### 5

##### )

##### 25

##### (

##### 20

##### 5

##### )

In contrast, we could let the outcome of the experiment be the _ordered_ selection
of the 5 individuals. In this setting, there are 20 · 19 · 18 · 17 ·16 equally likely
outcomes, of which 20· 18 · 16 · 14 ·12 outcomes result in a group of 5 unrelated
individuals, yielding the result

```
P ( N )=
```
##### 20 · 18 · 16 · 14 · 12

##### 20 · 19 · 18 · 17 · 16

```
We leave it for the reader to verify that the two answers are identical..
```
**_EXAMPLE 5c_**

A committee of 5 is to be selected from a group of 6 men and 9 women. If the selection
is made randomly, what is the probability that the committee consists of 3 men and 2
women?

**_Solution._** Because each of the

##### ( 15

```
5
```
##### )

possible committees is equally likely to be selected,
the desired probability is (
6
3

##### )(

##### 9

##### 2

##### )

##### (

##### 15

##### 5

##### ) =

##### 240

##### 1001

##### .

**_EXAMPLE 5d_**

An urn contains _n_ balls, one of which is special. If _k_ of these balls are withdrawn one
at a time, with each selection being equally likely to be any of the balls that remain at
the time, what is the probability that the special ball is chosen?

**_Solution._** Since all of the balls are treated in an identical manner, it follows that the

set of _k_ balls selected is equally likely to be any of the

##### (

```
n
k
```
##### )

```
sets of k balls. Therefore,
```
```
P {special ball is selected}=
```
##### (

##### 1

##### 1

##### )(

```
n − 1
k − 1
```
##### )

##### (

```
n
k
```
##### ) =

```
k
n
```

**36** Chapter 2 Axioms of Probability

```
We could also have obtained this result by letting Ai denote the event that the special
ball is the i th ball to be chosen, i =1,..., k. Then, since each one of the n balls is
equally likely to be the i th ball chosen, it follows that P ( Ai )= 1 / n. Hence, because
these events are clearly mutually exclusive, we have
```
```
P {special ball is selected}= P
```
##### ⎛

##### ⎝

```
⋃ k
```
```
i = 1
```
```
Ai
```
##### ⎞

##### ⎠=

```
∑ k
```
```
i = 1
```
```
P ( Ai )=
```
```
k
n
```
```
We could also have argued that P ( Ai )= 1 / n , by noting that there are n ( n − 1 )···( n −
k + 1 )= n !/( n − k )! equally likely outcomes of the experiment, of which( n − 1 )( n −
2 )···( n − i + 1 )( 1 )( n − i )···( n − k + 1 )=( n − 1 )!/( n − k )! result in the special
ball being the i th one chosen. From this reasoning, it follows that
```
```
P ( Ai )=
```
```
( n − 1 )!
n!
```
##### =

##### 1

```
n
```
##### .

```
EXAMPLE 5e
Suppose that n + m balls, of which n are red and m are blue, are arranged in a linear
order in such a way that all( n + m )! possible orderings are equally likely. If we
record the result of this experiment by listing only the colors of the successive balls,
show that all the possible results remain equally likely.
```
```
Solution. Consider any one of the( n + m )! possible orderings, and note that any per-
mutation of the red balls among themselves and of the blue balls among themselves
does not change the sequence of colors. As a result, every ordering of colorings cor-
responds to n! m! different orderings of the n + m balls, so every ordering of the
colors has probability( nn +! mm !)!of occurring.
For example, suppose that there are 2 red balls, numbered r 1 , r 2 , and 2 blue balls,
numbered b 1 , b 2. Then, of the 4! possible orderings, there will be 2! 2! orderings that
result in any specified color combination. For instance, the following orderings result
in the successive balls alternating in color, with a red ball first:
```
```
r 1 , b 1 , r 2 , b 2 r 1 , b 2 , r 2 , b 1 r 2 , b 1 , r 1 , b 2 r 2 , b 2 , r 1 , b 1
```
```
Therefore, each of the possible orderings of the colors has probability 244 =^16 of
occurring..
```
```
EXAMPLE 5f
A poker hand consists of 5 cards. If the cards have distinct consecutive values and
are not all of the same suit, we say that the hand is a straight. For instance, a hand
consisting of the five of spades, six of spades, seven of spades, eight of spades, and
nine of hearts is a straight. What is the probability that one is dealt a straight?
```
```
Solution. We start by assuming that all
```
##### (

##### 52

##### 5

##### )

```
possible poker hands are equally
likely. To determine the number of outcomes that are straights, let us first determine
the number of possible outcomes for which the poker hand consists of an ace, two,
three, four, and five (the suits being irrelevant). Since the ace can be any 1 of the 4
possible aces, and similarly for the two, three, four, and five, it follows that there are
45 outcomes leading to exactly one ace, two, three, four, and five. Hence, since in 4 of
these outcomes all the cards will be of the same suit (such a hand is called a straight
```

```
Section 2.5 Sample Spaces Having Equally Likely Outcomes 37
```
flush), it follows that there are 4^5 −4 hands that make up a straight of the form ace,
two, three, four, and five. Similarly, there are 4^5 −4 hands that make up a straight
of the form ten, jack, queen, king, and ace. Thus, there are 10( 45 − 4 )hands that are
straights, and it follows that the desired probability is

```
10 ( 45 − 4 )
(
52
5
```
##### ) L. 0039.

**_EXAMPLE 5g_**

A 5-card poker hand is said to be a full house if it consists of 3 cards of the same
denomination and 2 other cards of the same denomination (of course, different from
the first denomination). Thus, one kind of full house is three of a kind plus a pair.
What is the probability that one is dealt a full house?

**_Solution._** Again, we assume that all

##### (

##### 52

##### 5

##### )

```
possible hands are equally likely. To
```
determine the number of possible full houses, we first note that there are

##### (

##### 4

##### 2

##### )(

##### 4

##### 3

##### )

different combinations of, say, 2 tens and 3 jacks. Because there are 13 different
choices for the kind of pair and, after a pair has been chosen, there are 12 other
choices for the denomination of the remaining 3 cards, it follows that the probability
of a full house is

```
13 · 12 ·
```
##### (

##### 4

##### 2

##### )(

##### 4

##### 3

##### )

##### (

##### 52

##### 5

##### ) L. 0014.

**_EXAMPLE 5h_**

In the game of bridge, the entire deck of 52 cards is dealt out to 4 players. What is the
probability that

```
(a) one of the players receives all 13 spades;
(b) each player receives 1 ace?
```
**_Solution._** (a) Letting _Ei_ be the event that hand _i_ has all 13 spades, then

```
P ( Ei )=
```
##### 1

##### ( 52

```
13
```
```
), i =1, 2, 3, 4
```
Because the events _Ei_ , _i_ =1, 2, 3, 4, are mutually exclusive, the probability that one
of the hands is dealt all 13 spades is

```
P (∪^4 i = 1 Ei )=
```
##### ∑^4

```
i = 1
```
```
P ( Ei )= 4 /
```
##### (

##### 52

##### 13

##### )

##### L 6. 3 * 10 −^12

```
(b) To determine the number of outcomes in which each of the distinct players
```
receives exactly 1 ace, put aside the aces and note that there are

##### (

##### 48

##### 12, 12, 12, 12

##### )

```
pos-
```
sible divisions of the other 48 cards when each player is to receive 12. Because there


**38** Chapter 2 Axioms of Probability

```
are 4! ways of dividing the 4 aces so that each player receives 1, we see that the num-
ber of possible outcomes in which each player receives exactly 1 ace is 4!
```
##### (

##### 48

##### 12, 12, 12, 12

##### )

##### .

```
As there are
```
##### ( 52

```
13,13,13,13
```
##### )

```
possible hands, the desired probability is thus
```
##### 4!

##### ( 48

```
12,12,12,12
```
##### )

##### ( 52

```
13,13,13,13
```
##### ) L.^1055.

```
Some results in probability are quite surprising when initially encountered. Our
next two examples illustrate this phenomenon.
```
```
EXAMPLE 5i
If n people are present in a room, what is the probability that no two of them cele-
brate their birthday on the same day of the year? How large need n be so that this
probability is less than^12?
```
```
Solution. As each person can celebrate his or her birthday on any one of 365 days,
there is a total of( 365 ) n possible outcomes. (We are ignoring the possibility of some-
one’s having been born on February 29.) Assuming that each outcome is equally
likely, we see that the desired probability is( 365 )( 364 )( 363 )...( 365 − n + 1 )/( 365 ) n.
It is a rather surprising fact that when n Ú23, this probability is less than^12. That is, if
there are 23 or more people in a room, then the probability that at least two of them
have the same birthday exceeds^12. Many people are initially surprised by this result,
since 23 seems so small in relation to 365, the number of days of the year. However,
every pair of individuals has probability
```
##### 365

##### ( 365 )^2

##### =

##### 1

##### 365

```
of having the same birthday,
```
```
and in a group of 23 people there are
```
##### (

##### 23

##### 2

##### )

```
=253 different pairs of individuals.
Looked at this way, the result no longer seems so surprising.
When there are 50 people in the room, the probability that at least two share the
same birthday is approximately .970, and with 100 persons in the room, the odds are
```
```
better than 3,000,000:1. (That is, the probability is greater than
```
##### 3 * 106

##### 3 * 106 + 1

```
that at
least two people have the same birthday.).
```
```
EXAMPLE 5j
A deck of 52 playing cards is shuffled, and the cards are turned up one at a time until
the first ace appears. Is the next card—that is, the card following the first ace—more
likely to be the ace of spades or the two of clubs?
```
```
Solution. To determine the probability that the card following the first ace is the ace
of spades, we need to calculate how many of the (52)! possible orderings of the cards
have the ace of spades immediately following the first ace. To begin, note that each
ordering of the 52 cards can be obtained by first ordering the 51 cards different from
the ace of spades and then inserting the ace of spades into that ordering. Furthermore,
for each of the (51)! orderings of the other cards, there is only one place where the
ace of spades can be placed so that it follows the first ace. For instance, if the ordering
of the other 51 cards is
4 c ,6 h , Jd ,5 s , Ac ,7 d ,..., Kh
```

```
Section 2.5 Sample Spaces Having Equally Likely Outcomes 39
```
then the only insertion of the ace of spades into this ordering that results in its follow-
ing the first ace is
4 _c_ ,6 _h_ , _Jd_ ,5 _s_ , _Ac_ , _As_ ,7 _d_ ,..., _Kh_

Therefore, there are (51)! orderings that result in the ace of spades following the first
ace, so

```
P {the ace of spades follows the first ace}=
```
##### ( 51 )!

##### ( 52 )!

##### =

##### 1

##### 52

In fact, by exactly the same argument, it follows that the probability that the two of
clubs (or any other specified card) follows the first ace is also 521. In other words, each
of the 52 cards of the deck is equally likely to be the one that follows the first ace!
Many people find this result rather surprising. Indeed, a common reaction is to
suppose initially that it is more likely that the two of clubs (rather than the ace of
spades) follows the first ace, since that first ace might itself be the ace of spades. This
reaction is often followed by the realization that the two of clubs might itself appear
before the first ace, thus negating its chance of immediately following the first ace.
However, as there is one chance in four that the ace of spades will be the first ace
(because all 4 aces are equally likely to be first) and only one chance in five that
the two of clubs will appear before the first ace (because each of the set of 5 cards
consisting of the two of clubs and the 4 aces is equally likely to be the first of this set
to appear), it again appears that the two of clubs is more likely. However, this is not
the case, and a more complete analysis shows that they are equally likely..

**_EXAMPLE 5k_**

A football team consists of 20 offensive and 20 defensive players. The players are to
be paired in groups of 2 for the purpose of determining roommates. If the pairing is
done at random, what is the probability that there are no offensive–defensive room-
mate pairs? What is the probability that there are 2 _i_ offensive–defensive roommate
pairs, _i_ =1, 2,..., 10?

**_Solution._** There are (
40
2, 2,...,2

##### )

##### =

##### ( 40 )!

##### (2!)^20

ways of dividing the 40 players into 20 _ordered_ pairs of two each. [That is, there
are( 40 )!/ 220 ways of dividing the players into a _first_ pair, a _second_ pair, and so on.]
Hence, there are( 40 )!/ 220 ( 20 )! ways of dividing the players into (unordered) pairs of
2 each. Furthermore, since a division will result in no offensive–defensive pairs if the
offensive (and defensive) players are paired among themselves, it follows that there
are [( 20 )!/ 210 ( 10 )!]^2 such divisions. Hence, the probability of no offensive–defensive
roommate pairs, call it _P_ 0 , is given by

##### P 0 =

##### (

##### ( 20 )!

##### 210 ( 10 )!

##### ) 2

##### ( 40 )!

##### 220 ( 20 )!

##### =

##### [( 20 )!]^3

##### [( 10 )!]^2 ( 40 )!

To determine _P_ 2 _i_ , the probability that there are 2 _i_ offensive–defensive pairs, we first

note that there are

##### (

##### 20

```
2 i
```
##### ) 2

```
ways of selecting the 2 i offensive players and the 2 i defen-
```
sive players who are to be in the offensive–defensive pairs. These 4 _i_ players can then


**40** Chapter 2 Axioms of Probability

```
be paired up into (2 i )! possible offensive–defensive pairs. (This is so because the first
offensive player can be paired with any of the 2 i defensive players, the second offen-
sive player with any of the remaining 2 i −1 defensive players, and so on.) As the
remaining 20 − 2 i offensive (and defensive) players must be paired among them-
selves, it follows that there are
(
20
2 i
```
##### ) 2

```
( 2 i )!
```
##### [

```
( 20 − 2 i )!
210 − i ( 10 − i )!
```
##### ] 2

```
divisions which lead to 2 i offensive–defensive pairs. Hence,
```
```
P 2 i =
```
##### (

##### 20

```
2 i
```
##### ) 2

```
( 2 i )!
```
##### [

```
( 20 − 2 i )!
210 − i ( 10 − i )!
```
##### ] 2

##### ( 40 )!

##### 220 ( 20 )!

```
i =0, 1,...,10
```
```
The P 2 i , i =0, 1,..., 10, can now be computed, or they can be approximated by mak-
ing use of a result of Stirling which shows that n! can be approximated by nn +^1 /^2 e − n
```
##### √

```
2 π.
For instance, we obtain
```
```
P 0 L 1. 3403 * 10 −^6
P 10 L. 345861
P 20 L 7. 6068 * 10 −^6.
```
```
Our next three examples illustrate the usefulness of Proposition 4.4. In Example 5l,
the introduction of probability enables us to obtain a quick solution to a counting
problem.
```
```
EXAMPLE 5l
A total of 36 members of a club play tennis, 28 play squash, and 18 play badminton.
Furthermore, 22 of the members play both tennis and squash, 12 play both tennis and
badminton, 9 play both squash and badminton, and 4 play all three sports. How many
members of this club play at least one of three sports?
```
```
Solution. Let N denote the number of members of the club, and introduce probabil-
ity by assuming that a member of the club is randomly selected. If, for any subset C
of members of the club, we let P ( C )denote the probability that the selected member
is contained in C ,then
```
```
P ( C )=
```
```
number of members in C
N
Now, with T being the set of members that plays tennis, S being the set that plays
squash, and B being the set that plays badminton, we have, from Proposition 4.4,
```
```
P ( T ∪ S ∪ B )
= P ( T )+ P ( S )+ P ( B )− P ( TS )− P ( TB )− P ( SB )+ P ( TSB )
```
```
=
```
##### 36 + 28 + 18 − 22 − 12 − 9 + 4

##### N

##### =

##### 43

##### N

```
Hence, we can conclude that 43 members play at least one of the sports..
```

```
Section 2.5 Sample Spaces Having Equally Likely Outcomes 41
```
The next example in this section not only possesses the virtue of giving rise to a
somewhat surprising answer, but is also of theoretical interest.

**_EXAMPLE 5m The matching problem_**

Suppose that each of _N_ men at a party throws his hat into the center of the room.
The hats are first mixed up, and then each man randomly selects a hat. What is the
probability that none of the men selects his own hat?

**_Solution._** We first calculate the complementary probability of at least one man’s
selecting his own hat. Let us denote by _Ei_ , _i_ =1, 2,..., _N_ the event that the _i_ th man

selects his own hat. Now, by Proposition 4.4 _P_

##### (

##### ⋃ N

```
i = 1
```
```
Ei
```
##### )

```
, the probability that at least
```
one of the men selects his own hat is given by

##### P

##### ⎛

##### ⎝

##### ⋃ N

```
i = 1
```
```
Ei
```
##### ⎞

##### ⎠=

##### ∑ N

```
i = 1
```
```
P ( Ei )−
```
##### ∑

```
i 1 < i 2
```
```
P ( Ei 1 Ei 2 )+ ···
```
```
+(− 1 ) n +^1
```
##### ∑

```
i 1 < i 2 ···< in
```
```
P ( Ei 1 Ei 2 ··· Ein )
```
##### + ··· +(− 1 ) N +^1 P ( E 1 E 2 ··· EN )

If we regard the outcome of this experiment as a vector of _N_ numbers, where the _i_ th
element is the number of the hat drawn by the _i_ th man, then there are _N_! possible
outcomes. [The outcome(1, 2, 3,..., _N_ )means, for example, that each man selects
his own hat.] Furthermore, _Ei_ 1 _Ei_ 2 ... _Ein_ , the event that each of the _n_ men _i_ 1 , _i_ 2 ,..., _in_
selects his own hat, can occur in any of( _N_ − _n_ )( _N_ − _n_ − 1 )··· 3 · 2 · 1 =( _N_ − _n_ )!
possible ways; for, of the remaining _N_ − _n_ men, the first can select any of _N_ − _n_
hats, the second can then select any of _N_ − _n_ −1 hats, and so on. Hence, assuming
that all _N_! possible outcomes are equally likely, we see that

```
P ( Ei 1 Ei 2 ··· Ein )=
```
```
( N − n )!
N!
```
Also, as there are

##### (

##### N

```
n
```
##### )

```
terms in
```
##### ∑

```
i 1 < i 2 ···< in
```
```
P ( Ei 1 Ei 2 ··· Ein ), it follows that
```
##### ∑

```
i 1 < i 2 ···< in
```
```
P ( Ei 1 Ei 2 ··· Ein )=
```
```
N !( N − n )!
( N − n )! n! N!
```
##### =

##### 1

```
n!
```
Thus,

##### P

##### ⎛

##### ⎝

##### ⋃ N

```
i = 1
```
```
Ei
```
##### ⎞

##### ⎠= 1 −^1

##### 2!

##### +

##### 1

##### 3!

##### − ··· +(− 1 ) N +^1

##### 1

##### N!

Hence, the probability that none of the men selects his own hat is

##### 1 − 1 +

##### 1

##### 2!

##### −

##### 1

##### 3!

##### + ··· +

##### (− 1 ) N

##### N!


**42** Chapter 2 Axioms of Probability

```
which is approximately equal to e −^1 L.36788 for N large. In other words, for N large,
the probability that none of the men selects his own hat is approximately .37. (How
many readers would have incorrectly thought that this probability would go to 1 as
N →q?).
```
```
For another illustration of the usefulness of Proposition 4.4, consider the following
example.
```
```
EXAMPLE 5n
Compute the probability that 10 married couples are seated at random at a round
table, then no wife sits next to her husband.
```
```
Solution. If we let Ei , i =1, 2,..., 10 denote the event that the i th couple sit next
```
```
to each other, it follows that the desired probability is 1 − P
```
##### (

##### ⋃^10

```
i = 1
```
```
Ei
```
##### )

. Now, from

```
Proposition 4.4,
```
##### P

##### ⎛

##### ⎝

##### ⋃^10

```
1
```
```
Ei
```
##### ⎞

##### ⎠=

##### ∑^10

```
1
```
```
P ( Ei )− ··· +(− 1 ) n +^1
```
##### ∑

```
i 1 < i 2 <···< in
```
```
P ( Ei 1 Ei 2 ··· Ein )
```
##### + ··· − P ( E 1 E 2 ··· E 10 )

```
To compute P ( Ei 1 Ei 2 ··· Ein ), we first note that there are 19! ways of arranging 20
people around a round table. (Why?) The number of arrangements that result in a
specified set of n men sitting next to their wives can most easily be obtained by first
thinking of each of the n married couples as being single entities. If this were the case,
then we would need to arrange 20− n entities around a round table, and there are
clearly( 20 − n − 1 )! such arrangements. Finally, since each of the n married couples
can be arranged next to each other in one of two possible ways, it follows that there
are 2 n ( 20 − n − 1 )! arrangements that result in a specified set of n men each sitting
next to their wives. Therefore,
```
```
P ( Ei 1 Ei 2 ··· Ein )=
```
```
2 n ( 19 − n )!
( 19 )!
```
```
Thus, from Proposition 4.4, we obtain that the probability that at least one married
couple sits together, namely,
(
10
1
```
##### )

##### 21

##### ( 18 )!

##### ( 19 )!

##### −

##### (

##### 10

##### 2

##### )

##### 22

##### ( 17 )!

##### ( 19 )!

##### +

##### (

##### 10

##### 3

##### )

##### 23

##### ( 16 )!

##### ( 19 )!

##### − ··· −

##### (

##### 10

##### 10

##### )

##### 210

##### 9!

##### ( 19 )!

##### L. 6605

```
and the desired probability is approximately .3395..
```
```
∗ EXAMPLE 5o Runs
```
```
Consider an athletic team that had just finished its season with a final record of n
wins and m losses. By examining the sequence of wins and losses, we are hoping to
determine whether the team had stretches of games in which it was more likely to
win than at other times. One way to gain some insight into this question is to count
the number of runs of wins and then see how likely that result would be when all
```

```
Section 2.5 Sample Spaces Having Equally Likely Outcomes 43
```
( _n_ + _m_ )!/( _n_! _m_ !)orderings of the _n_ wins and _m_ losses are assumed equally likely. By
a run of wins, we mean a consecutive sequence of wins. For instance, if _n_ =10, _m_ =6,
and the sequence of outcomes was _WWLLWWWLWLLLWWWW_ , then there would
be 4 runs of wins—the first run being of size 2, the second of size 3, the third of size 1,
and the fourth of size 4.
Suppose now that a team has _n_ wins and _m_ losses. Assuming that all( _n_ + _m_ )!/

( _n_! _m_ !)=

##### (

```
n + m
n
```
##### )

```
orderings are equally likely, let us determine the probability
```
that there will be exactly _r_ runs of wins. To do so, consider first any vector of positive
integers _x_ 1 , _x_ 2 ,..., _xr_ with _x_ 1 +···+ _xr_ = _n_ , and let us see how many outcomes result
in _r_ runs of wins in which the _i_ th run is of size _xi_ , _i_ =1,..., _r_. For any such outcome,
if we let _y_ 1 denote the number of losses before the first run of wins, _y_ 2 the number of
losses between the first 2 runs of wins,..., _yr_ + 1 the number of losses after the last run
of wins, then the _yi_ satisfy

```
y 1 + y 2 + ··· + yr + 1 = my 1 Ú0, yr + 1 Ú0, yi >0, i =2,..., r
```
and the outcome can be represented schematically as

```
LL ︸ ︷︷... L ︸
y 1
```
##### WW ︸ ︷︷... W ︸

```
x 1
```
##### L ︸...︷︷ L ︸

```
y 2
```
##### WW ︸ ︷︷... W ︸

```
x 2
```
##### ··· WW ︸︷︷︸

```
xr
```
##### L ︸...︷︷ L ︸

```
yr + 1
```
Hence, the number of outcomes that result in _r_ runs of wins—the _i_ th of size _xi_ , _i_ =
1,... _r_ —is equal to the number of integers _y_ 1 ,..., _yr_ + 1 that satisfy the foregoing, or,
equivalently, to the number of positive integers

```
y 1 = y 1 + 1 yi = yi , i =2,..., r , yr + 1 = yr + 1 + 1
```
that satisfy
_y_ 1 + _y_ 2 + ··· + _yr_ + 1 = _m_ + 2

By Proposition 6.1 in Chapter 1, there are

##### (

```
m + 1
r
```
##### )

```
such outcomes. Hence, the
```
total number of outcomes that result in _r_ runs of wins is

##### (

```
m + 1
r
```
##### )

```
, multiplied by
```
the number of positive integral solutions of _x_ 1 + ··· + _xr_ = _n_. Thus, again from

Proposition 6.1, there are

##### (

```
m + 1
r
```
##### )(

```
n − 1
r − 1
```
##### )

```
outcomes resulting in r runs of wins.
```
As there are

##### (

```
n + m
n
```
##### )

```
equally likely outcomes, it follows that
```
```
P ({ r runs of wins})=
```
##### (

```
m + 1
r
```
##### )(

```
n − 1
r − 1
```
##### )

##### (

```
m + n
n
```
```
) r Ú 1
```
For example, if _n_ =8and _m_ =6, then the probability of 7 runs is

##### (

##### 7

##### 7

##### )(

##### 7

##### 6

##### )/

##### (

##### 14

##### 8

##### )

```
= 1 /429 if all
```
##### (

##### 14

##### 8

##### )

```
outcomes are equally likely. Hence, if the outcome
```
was _WLWLWLWLWWLWLW_ , then we might suspect that the team’s probability
of winning was changing over time. (In particular, the probability that the team wins


```
44 Chapter 2 Axioms of Probability
```
```
seems to be quite high when it lost its last game and quite low when it won its last
game.) On the other extreme, if the outcome were WWWWWWWWLLLLLL ,then
there would have been only 1 run, and as P ({1run})=
```
##### (

##### 7

##### 1

##### )(

##### 7

##### 0

##### )/(

##### 14

##### 8

##### )

##### = 1 /429,

```
it would thus again seem unlikely that the team’s probability of winning remained
unchanged over its 14 games..
```
##### ∗ 2.6 PROBABILITY AS A CONTINUOUS SET FUNCTION

```
A sequence of events{ En , n Ú 1 }is said to be an increasing sequence if
```
```
E 1 ( E 2 (···( En ( En + 1 (···
```
```
whereas it is said to be a decreasing sequence if
```
```
E 1 ) E 2 )···) En ) En + 1 )···
```
```
If{ En , n Ú 1 }is an increasing sequence of events, then we define a new event, denoted
by lim
n →q
En ,by
```
```
lim
n →q
En =
```
```
⋃q
```
```
i = 1
```
```
Ei
```
```
Similarly, if{ En , n Ú 1 }is a decreasing sequence of events, we define lim
n
```
```
En by
```
```
lim
n →q
```
```
En =
```
```
⋂q
```
```
i = 1
```
```
Ei
```
```
We now prove the following Proposition 1:
```
```
Proposition 6.1.
If{ En , n Ú 1 }is either an increasing or a decreasing sequence of events, then
```
```
lim
n →q
P ( En )= P (lim
n →q
En )
```
```
Proof. Suppose, first, that{ En , n Ú 1 }is an increasing sequence, and define the
events Fn , n Ú1, by
```
```
F 1 = E 1
```
```
Fn = En
```
##### ⎛

##### ⎝

```
n ⋃− 1
```
```
1
```
```
Ei
```
##### ⎞

##### ⎠

```
c
```
```
= EnEcn − 1 n > 1
```
```
where we have used the fact that
```
```
n ⋃− 1
```
```
1
```
```
Ei = En − 1 , since the events are increasing.
```
```
In words, Fn consists of those outcomes in En which are not in any of the earlier
Ei , i < n. It is easy to verify that the Fn are mutually exclusive events such that
```
```
⋃q
```
```
i = 1
```
```
Fi =
```
```
⋃q
```
```
i = 1
```
```
Ei and
```
```
⋃ n
```
```
i = 1
```
```
Fi =
```
```
⋃ n
```
```
i = 1
```
```
Ei for all n Ú 1
```

```
Section 2.6 Probability as a Continuous Set Function 45
```
Thus,

##### P

##### ⎛

##### ⎝

```
⋃q
```
```
1
```
```
Ei
```
##### ⎞

##### ⎠= P

##### ⎛

##### ⎝

```
⋃q
```
```
1
```
```
Fi
```
##### ⎞

##### ⎠

##### =

```
∑q
```
```
1
```
```
P ( Fi )(by Axiom 3)
```
```
= lim
n →q
```
```
∑ n
```
```
1
```
```
P ( Fi )
```
```
= lim
n →q
```
##### P

##### ⎛

##### ⎝

```
⋃ n
```
```
1
```
```
Fi
```
##### ⎞

##### ⎠

```
= lim
n →q
```
##### P

##### ⎛

##### ⎝

```
⋃ n
```
```
1
```
```
Ei
```
##### ⎞

##### ⎠

```
= lim
n →q
```
```
P ( En )
```
which proves the result when{ _En_ , _n_ Ú 1 }is increasing.

If{ _En_ , _n_ Ú 1 }is a decreasing sequence, then{ _Ecn_ , _n_ Ú 1 }is an increasing sequence;
hence, from the preceding equations,

##### P

##### ⎛

##### ⎝

```
⋃q
```
```
1
```
```
Eci
```
##### ⎞

```
⎠= lim
n →q
P ( Enc )
```
However, because

```
⋃q
1
```
```
Eci =
```
##### (

```
⋂q
1
```
```
Ei
```
```
) c
, it follows that
```
##### P

##### ⎛

##### ⎜

##### ⎝

##### ⎛

##### ⎝

```
⋂q
```
```
1
```
```
Ei
```
##### ⎞

##### ⎠

```
c
```
##### ⎞

##### ⎟

```
⎠= lim
n →q
```
```
P ( Ecn )
```
or, equivalently,

##### 1 − P

##### ⎛

##### ⎝

```
⋂q
```
```
1
```
```
Ei
```
##### ⎞

```
⎠= lim
n →q
```
```
[1− P ( En )]= 1 − lim
n →q
```
```
P ( En )
```
or

##### P

##### ⎛

##### ⎝

```
⋂q
```
```
1
```
```
Ei
```
##### ⎞

```
⎠= lim
n →q
P ( En )
```
which proves the result.


**46** Chapter 2 Axioms of Probability

```
EXAMPLE 6a Probability and a paradox
Suppose that we possess an infinitely large urn and an infinite collection of balls
labeled ball number 1, number 2, number 3, and so on. Consider an experiment per-
formed as follows: At 1 minute to 12P.M., balls numbered 1 through 10 are placed
in the urn and ball number 10 is withdrawn. (Assume that the withdrawal takes
no time.) At^12 minute to 12P.M., balls numbered 11 through 20 are placed in the
urn and ball number 20 is withdrawn. At^14 minute to 12P.M., balls numbered 21
through 30 are placed in the urn and ball number 30 is withdrawn. At^18 minute
to 12P.M., and so on. The question of interest is, How many balls are in the urn at
12 P.M.?
The answer to this question is clearly that there is an infinite number of
balls in the urn at 12P.M., since any ball whose number is not of the form 10 n ,
n Ú1, will have been placed in the urn and will not have been withdrawn before
12 P.M. Hence, the problem is solved when the experiment is performed as
described.
However, let us now change the experiment and suppose that at 1 minute to 12P.M.
balls numbered 1 through 10 are placed in the urn and ball number 1 is withdrawn; at
1
2 minute to 12P.M., balls numbered 11 through 20 are placed in the urn and ball num-
ber 2 is withdrawn; at^14 minute to 12P.M., balls numbered 21 through 30 are placed
in the urn and ball number 3 is withdrawn; at^18 minute to 12P.M., balls numbered 31
through 40 are placed in the urn and ball number 4 is withdrawn, and so on. For this
new experiment, how many balls are in the urn at 12P.M.?
Surprisingly enough, the answer now is that the urn is empty at 12P.M.For, consider
any ball—say, ball number n. At some time prior to 12P.M.[in particular, at
```
##### (

```
1
2
```
```
) n − 1
```
```
minutes to 12P.M.], this ball would have been withdrawn from the urn. Hence, for
each n , ball number n is not in the urn at 12P.M.; therefore, the urn must be empty at
that time.
We see then, from the preceding discussion that the manner in which the balls are
withdrawn makes a difference. For, in the first case only balls numbered 10 n , n Ú1,
are ever withdrawn, whereas in the second case all of the balls are eventually with-
drawn. Let us now suppose that whenever a ball is to be withdrawn, that ball is
randomly selected from among those present. That is, suppose that at 1 minute to
12 P.M.balls numbered 1 through 10 are placed in the urn and a ball is randomly
selected and withdrawn, and so on. In this case, how many balls are in the urn at
12 P.M.?
```
```
Solution. We shall show that, with probability 1, the urn is empty at 12P.M.Let us
first consider ball number 1. Define En to be the event that ball number 1 is still in
the urn after the first n withdrawals have been made. Clearly,
```
```
P ( En )=
```
```
9 · 18 · 27 ···( 9 n )
10 · 19 · 28 ···( 9 n + 1 )
```
```
[To understand this equation, just note that if ball number 1 is still to be in the
urn after the first n withdrawals, the first ball withdrawn can be any one of 9, the
second any one of 18 (there are 19 balls in the urn at the time of the second with-
drawal, one of which must be ball number 1), and so on. The denominator is similarly
obtained.]
```

```
Section 2.6 Probability as a Continuous Set Function 47
```
```
Now, the event that ball number 1 is in the urn at 12P.M.is just the event
```
```
⋂q
n = 1
```
```
En.
```
Because the events _En_ , _n_ Ú1, are decreasing events, it follows from Proposition 6.1 that

```
P {ball number 1 is in the urn at 12P.M.}
```
##### = P

##### ⎛

##### ⎝

```
⋂q
```
```
n = 1
```
```
En
```
##### ⎞

##### ⎠

```
= lim
n →q
P ( En )
```
##### =

```
∏q
```
```
n = 1
```
##### (

```
9 n
9 n + 1
```
##### )

We now show that

```
∏q
```
```
n = 1
```
```
9 n
9 n + 1
```
##### = 0

Since

```
∏q
```
```
n = 1
```
##### (

```
9 n
9 n + 1
```
##### )

##### =

##### ⎡

##### ⎣

```
∏q
```
```
n = 1
```
##### (

```
9 n + 1
9 n
```
##### )

##### ⎤

##### ⎦

```
− 1
```
this is equivalent to showing that

```
∏q
```
```
n = 1
```
##### (

##### 1 +

##### 1

```
9 n
```
##### )

```
=q
```
Now, for all _m_ Ú1,

```
∏q
```
```
n = 1
```
##### (

##### 1 +

##### 1

```
9 n
```
##### )

##### Ú

```
∏ m
```
```
n = 1
```
##### (

##### 1 +

##### 1

```
9 n
```
##### )

##### =

##### (

##### 1 +

##### 1

##### 9

##### )(

##### 1 +

##### 1

##### 18

##### )(

##### 1 +

##### 1

##### 27

##### )

##### ···

##### (

##### 1 +

##### 1

```
9 m
```
##### )

##### >

##### 1

##### 9

##### +

##### 1

##### 18

##### +

##### 1

##### 27

##### + ··· +

##### 1

```
9 m
```
```
=
```
##### 1

##### 9

```
∑ m
```
```
i = 1
```
##### 1

```
i
```
Hence, letting _m_ →qand using the fact that

```
∑q
i = 1
```
```
1 / i =qyields
```
```
∏q
```
```
n = 1
```
##### (

##### 1 +

##### 1

```
9 n
```
##### )

```
=q
```
Thus, letting _Fi_ denote the event that ball number _i_ is in the urn at 12P.M., we have
shown that _P_ ( _F_ 1 )=0. Similarly, we can show that _P_ ( _Fi_ )=0 for all _i_.


**48** Chapter 2 Axioms of Probability

```
(For instance, the same reasoning shows that P ( Fi )=
```
```
∏q
n = 2
```
```
[9 n /( 9 n + 1 )]for i =
```
```
11, 12,..., 20.) Therefore, the probability that the urn is not empty at 12P.M., P
```
##### (

```
⋃q
1
```
```
Fi
```
##### )

##### ,

```
satisfies
```
##### P

##### ⎛

##### ⎝

```
⋃q
```
```
1
```
```
Fi
```
##### ⎞

##### ⎠...

```
∑q
```
```
1
```
```
P ( Fi )= 0
```
```
by Boole’s inequality. (See Self-Test Exercise 14.)
Thus, with probability 1, the urn will be empty at 12P.M..
```
### 2.7 Probability as a Measure of Belief

```
Thus far we have interpreted the probability of an event of a given experiment as
being a measure of how frequently the event will occur when the experiment is con-
tinually repeated. However, there are also other uses of the term probability .For
instance, we have all heard such statements as “It is 90 percent probable that Shake-
speare actually wrote Hamlet ” or “The probability that Oswald acted alone in assas-
sinating Kennedy is .8.” How are we to interpret these statements?
The most simple and natural interpretation is that the probabilities referred to
are measures of the individual’s degree of belief in the statements that he or she
is making. In other words, the individual making the foregoing statements is quite
certain that Oswald acted alone and is even more certain that Shakespeare wrote
Hamlet. This interpretation of probability as being a measure of the degree of one’s
belief is often referred to as the personal or subjective view of probability.
It seems logical to suppose that a “measure of the degree of one’s belief” should
satisfy all of the axioms of probability. For example, if we are 70 percent certain that
Shakespeare wrote Julius Caesar and 10 percent certain that it was actually Mar-
lowe, then it is logical to suppose that we are 80 percent certain that it was either
Shakespeare or Marlowe. Hence, whether we interpret probability as a measure of
belief or as a long-run frequency of occurrence, its mathematical properties remain
unchanged.
```
```
EXAMPLE 7a
Suppose that, in a 7-horse race, you feel that each of the first 2 horses has a 20 percent
chance of winning, horses 3 and 4 each have a 15 percent chance, and the remaining
3 horses have a 10 percent chance each. Would it be better for you to wager at even
money that the winner will be one of the first three horses or to wager, again at even
money, that the winner will be one of the horses 1, 5, 6, and 7?
```
```
Solution. On the basis of your personal probabilities concerning the outcome of
the race, your probability of winning the first bet is. 2 +. 2 +. 15 =.55, whereas
it is. 2 +. 1 +. 1 +. 1 = .5 for the second bet. Hence, the first wager is more
attractive..
```
```
Note that, in supposing that a person’s subjective probabilities are always consis-
tent with the axioms of probability, we are dealing with an idealized rather than an
```

```
Summary 49
```
actual person. For instance, if we were to ask someone what he thought the chances
were of

```
(a) rain today,
(b) rain tomorrow,
(c) rain both today and tomorrow,
(d) rain either today or tomorrow,
```
it is quite possible that, after some deliberation, he might give 30 percent, 40 percent,
20 percent, and 60 percent as answers. Unfortunately, such answers (or such subjec-
tive probabilities) are not consistent with the axioms of probability. (Why not?) We
would of course hope that, after this was pointed out to the respondent, she would
change his answers. (One possibility we could accept is 30 percent, 40 percent, 10
percent, and 60 percent.)

#### Summary

Let _S_ denote the set of all possible outcomes of an experiment. _S_ is called the _sample
space_ of the experiment. An event is a subset of _S_ .If _Ai_ , _i_ =1,..., _n_ , are events, then
⋃ _n_

_i_ = 1

```
Ai , called the union of these events, consists of all outcomes that are in at least
```
one of the events _Ai_ , _i_ =1,..., _n_. Similarly,

```
⋂ n
i = 1
```
```
Ai , sometimes written as A 1 ··· An ,is
```
called the _intersection_ of the events _Ai_ and consists of all outcomes that are in all of
the events _Ai_ , _i_ =1,..., _n_.
For any event _A_ , we define _Ac_ to consist of all outcomes in the sample space that
are not in _A_. We call _Ac_ the _complement_ of the event _A_. The event _Sc_ , which is empty
of outcomes, is designated by Ø and is called the _null_ set. If _AB_ =Ø, then we say that
_A_ and _B_ are _mutually exclusive_.
For each event _A_ of the sample space _S_ , we suppose that a number _P_ ( _A_ ), called
the probability of _A_ , is defined and is such that

```
(i) 0... P ( A )... 1
(ii) P ( S )= 1
(iii) For mutually exclusive events Ai , i Ú1,
```
##### P

##### ⎛

##### ⎝

```
⋃q
```
```
i = 1
```
```
Ai
```
##### ⎞

##### ⎠=

```
∑q
```
```
i = 1
```
```
P ( Ai )
```
_P_ ( _A_ )represents the probability that the outcome of the experiment is in _A_.
It can be shown that

```
P ( Ac )= 1 − P ( A )
```
A useful result is that

##### P ( A ∪ B )= P ( A )+ P ( B )− P ( AB )


**50** Chapter 2 Axioms of Probability

```
which can be generalized to give
```
##### P

##### ⎛

##### ⎝

```
⋃ n
```
```
i = 1
```
```
Ai
```
##### ⎞

##### ⎠=

```
∑ n
```
```
i = 1
```
```
P ( Ai )−
```
##### ∑∑

```
i < j
```
```
P ( AiAj )+
```
##### ∑∑∑

```
i < j < k
```
```
P ( AiAjAk )
```
```
+ ··· +(− 1 ) n +^1 P ( A 1 ··· An )
```
```
If S is finite and each one point set is assumed to have equal probability, then
```
##### P ( A )=

##### | A |

##### | S |

```
where| E |denotes the number of outcomes in the event E.
P ( A )can be interpreted either as a long-run relative frequency or as a measure of
one’s degree of belief.
```
#### Problems...................................

**1.** A box contains 3 marbles: 1 red, 1 green, and 1
    blue. Consider an experiment that consists of tak-
    ing 1 marble from the box and then replacing it
    in the box and drawing a second marble from the
    box. Describe the sample space. Repeat when the
    second marble is drawn without replacing the first
    marble.
**2.** In an experiment, die is rolled continually until a
    6 appears, at which point the experiment stops.
    What is the sample space of this experiment? Let
    _En_ denote the event that _n_ rolls are necessary to
    complete the experiment. What points of the sam-

```
ple space are contained in En? What is
```
```
(
⋃q
1
```
```
En
```
```
) c
?
```
**3.** Two dice are thrown. Let _E_ be the event that the
    sum of the dice is odd, let _F_ be the event that
    at least one of the dice lands on 1, and let _G_ be
    the event that the sum is 5. Describe the events
    _EF_ , _E_ ∪ _F_ , _FG_ , _EFc_ ,and _EFG_.
**4.** _A_ , _B_ ,and _C_ take turns flipping a coin. The first one
    to get a head wins. The sample space of this exper-
    iment can be defined by

```
S =
```
```
{
1, 01, 001, 0001,...,
0000 ···
```
```
(a) Interpret the sample space.
(b) Define the following events in terms of S :
(i) A wins= A.
(ii) B wins= B.
(iii) ( A ∪ B ) c.
Assume that A flips first, then B ,then C ,
then A , and so on.
```
**5.** A system is comprised of 5 components, each of
    which is either working or failed. Consider an
    experiment that consists of observing the status of

```
each component, and let the outcome of the exper-
iment be given by the vector ( x 1 , x 2 , x 3 , x 4 , x 5 ),
where xi is equal to 1 if component i is working
and is equal to 0 if component i is failed.
(a) How many outcomes are in the sample space
of this experiment?
(b) Suppose that the system will work if compo-
nents 1 and 2 are both working, or if compo-
nents 3 and 4 are both working, or if compo-
nents 1, 3, and 5 are all working. Let W be the
event that the system will work. Specify all the
outcomes in W.
(c) Let A be the event that components 4 and 5
are both failed. How many outcomes are con-
tained in the event A?
(d) Write out all the outcomes in the event AW.
```
**6.** A hospital administrator codes incoming patients
    suffering gunshot wounds according to whether
    they have insurance (coding 1 if they do and 0
    if they do not) and according to their condition,
    which is rated as good (g), fair (f), or serious (s).
    Consider an experiment that consists of the coding
    of such a patient.
    **(a)** Give the sample space of this experiment.
    **(b)** Let _A_ be the event that the patient is in serious
       condition. Specify the outcomes in _A_.
    **(c)** Let _B_ be the event that the patient is unin-
       sured. Specify the outcomes in _B_.
    **(d)** Give all the outcomes in the event _Bc_ ∪ _A_.
**7.** Consider an experiment that consists of determin-
ing the type of job—either blue-collar or white-
collar—and the political affiliation—Republican,
Democratic, or Independent—of the 15 members
of an adult soccer team. How many outcomes are
**(a)** in the sample space?
**(b)** in the event that at least one of the team mem-
bers is a blue-collar worker?


```
Problems 51
```
```
(c) in the event that none of the team members
considers himself or herself an Independent?
```
**8.** Suppose that _A_ and _B_ are mutually exclusive
    events for which _P_ ( _A_ )=.3and _P_ ( _B_ )=.5. What is
    the probability that
    **(a)** either _A_ or _B_ occurs?
    **(b)** _A_ occurs but _B_ does not?
    **(c)** both _A_ and _B_ occur?
**9.** A retail establishment accepts either the American
    Express or the VISA credit card. A total of 24 per-
    cent of its customers carry an American Express
    card, 61 percent carry a VISA card, and 11 per-
    cent carry both cards. What percentage of its cus-
    tomers carry a credit card that the establishment
    will accept?
**10.** Sixty percent of the students at a certain school
wear neither a ring nor a necklace. Twenty per-
cent wear a ring and 30 percent wear a necklace.
If one of the students is chosen randomly, what is
the probability that this student is wearing
**(a)** aringoranecklace?
**(b)** aringandanecklace?
**11.** A total of 28 percent of American males smoke
cigarettes, 7 percent smoke cigars, and 5 percent
smoke both cigars and cigarettes.
**(a)** What percentage of males smokes neither
cigars nor cigarettes?
**(b)** What percentage smokes cigars but not
cigarettes?
**12.** An elementary school is offering 3 language
classes: one in Spanish, one in French, and one in
German. The classes are open to any of the 100
students in the school. There are 28 students in the
Spanish class, 26 in the French class, and 16 in the
German class. There are 12 students that are in
both Spanish and French, 4 that are in both Span-
ish and German, and 6 that are in both French and
German. In addition, there are 2 students taking
all 3 classes.
**(a)** If a student is chosen randomly, what is the
probability that he or she is not in any of the
language classes?
**(b)** If a student is chosen randomly, what is the
probability that he or she is taking exactly one
language class?
**(c)** If 2 students are chosen randomly, what is the
probability that at least 1 is taking a language
class?
**13.** A certain town with a population of 100,000 has
3 newspapers: I, II, and III. The proportions of
townspeople who read these papers are as follows:

```
I: 10 percent I and II: 8 percent I and II and
III: 1 percent
II: 30 percent I and III: 2 percent
III: 5 percent II and III: 4 percent
```
```
(The list tells us, for instance, that 8000 people
read newspapers I and II.)
(a) Find the number of people who read only one
newspaper.
(b) How many people read at least two
newspapers?
(c) If I and III are morning papers and II is an
evening paper, how many people read at least
one morning paper plus an evening paper?
(d) How many people do not read any
newspapers?
(e) How many people read only one morning
paper and one evening paper?
```
**14.** The following data were given in a study of a group
    of 1000 subscribers to a certain magazine: In ref-
    erence to job, marital status, and education, there
    were 312 professionals, 470 married persons, 525
    college graduates, 42 professional college gradu-
    ates, 147 married college graduates, 86 married
    professionals, and 25 married professional college
    graduates. Show that the numbers reported in the
    study must be incorrect.
    _Hint_ :Let _M_ , _W_ ,and _G_ denote, respectively, the
    set of professionals, married persons, and college
    graduates. Assume that one of the 1000 persons
    is chosen at random, and use Proposition 4.4 to
    show that if the given numbers are correct, then
    _P_ ( _M_ ∪ _W_ ∪ _G_ )>1.
**15.** If it is assumed that all

```
(
52
5
```
```
)
poker hands are
equally likely, what is the probability of being dealt
(a) a flush? (A hand is said to be a flush if all 5
cards are of the same suit.)
(b) one pair? (This occurs when the cards have
denominations a , a , b , c , d ,where a , b , c ,and
d are all distinct.)
(c) two pairs? (This occurs when the cards have
denominations a , a , b , b , c ,where a , b ,and c
are all distinct.)
(d) three of a kind? (This occurs when the cards
have denominations a , a , a , b , c ,where a , b ,
and c are all distinct.)
(e) four of a kind? (This occurs when the cards
have denominations a , a , a , a , b .)
```
**16.** Poker dice is played by simultaneously rolling 5
    dice. Show that
    **(a)** _P_ {no two alike}=.0926;
    **(b)** _P_ {one pair}=.4630;
    **(c)** _P_ {two pair}=.2315;
    **(d)** _P_ {three alike}=.1543;
    **(e)** _P_ {full house}=.0386;
    **(f)** _P_ {four alike}=.0193;
    **(g)** _P_ {five alike}=.0008.
**17.** If 8 rooks (castles) are randomly placed on a
    chessboard, compute the probability that none of
    the rooks can capture any of the others. That is,


**52** Chapter 2 Axioms of Probability

```
compute the probability that no row or file con-
tains more than one rook.
```
**18.** Two cards are randomly selected from an ordinary
    playing deck. What is the probability that they
    form a blackjack? That is, what is the probability
    that one of the cards is an ace and the other one is
    either a ten, a jack, a queen, or a king?
**19.** Two symmetric dice have both had two of their
    sides painted red, two painted black, one painted
    yellow, and the other painted white. When this
    pair of dice is rolled, what is the probability that
    both dice land with the same color face up?
**20.** Suppose that you are playing blackjack against a
    dealer. In a freshly shuffled deck, what is the prob-
    ability that neither you nor the dealer is dealt a
    blackjack?
**21.** A small community organization consists of 20
    families, of which 4 have one child, 8 have two chil-
    dren, 5 have three children, 2 have four children,
    and 1 has five children.
    **(a)** If one of these families is chosen at random,
       what is the probability it has _i_ children, _i_ =
       1, 2, 3, 4, 5?
    **(b)** If one of the children is randomly chosen,
       what is the probability that child comes from
       a family having _i_ children, _i_ =1, 2, 3, 4, 5?
**22.** Consider the following technique for shuffling a
    deck of _n_ cards: For any initial ordering of the
    cards, go through the deck one card at a time and
    at each card, flip a fair coin. If the coin comes
    up heads, then leave the card where it is; if the
    coin comes up tails, then move that card to the
    end of the deck. After the coin has been flipped _n_
    times, say that one round has been completed. For
    instance, if _n_ =4 and the initial ordering is 1, 2, 3,
    4, then if the successive flips result in the outcome
    _h_ , _t_ , _t_ , _h_ , then the ordering at the end of the round
    is 1, 4, 2, 3. Assuming that all possible outcomes of
    the sequence of _n_ coin flips are equally likely, what
    is the probability that the ordering after one round
    is the same as the initial ordering?
**23.** A pair of fair dice is rolled. What is the probabil-
    ity that the second die lands on a higher value than
    does the first?
**24.** If two dice are rolled, what is the probability that
    the sum of the upturned faces equals _i_ ?Finditfor
    _i_ =2, 3,..., 11, 12.
**25.** A pair of dice is rolled until a sum of either 5 or 7
    appears. Find the probability that a 5 occurs first.
    _Hint_ :Let _En_ denote the event that a 5 occurs on
    the _n_ th roll and no 5 or 7 occurs on the first _n_ − 1
    rolls. Compute _P_ ( _En_ )and argue that

```
∑q
n = 1
```
```
P ( En )is
the desired probability.
```
**26.** The game of craps is played as follows: A player
    rolls two dice. If the sum of the dice is either a 2,

```
3, or 12, the player loses; if the sum is either a 7
or an 11, the player wins. If the outcome is any-
thing else, the player continues to roll the dice until
she rolls either the initial outcome or a 7. If the 7
comes first, the player loses, whereas if the initial
outcome reoccurs before the 7 appears, the player
wins. Compute the probability of a player winning
at craps.
Hint :Let Ei denote the event that the initial out-
come is i and the player wins. The desired prob-
ability is
```
```
∑^12
i = 2
```
```
P ( Ei ). To compute P ( Ei ), define the
events Ei , n to be the event that the initial sum is
i and the player wins on the n th roll. Argue that
P ( Ei )=
```
```
∑q
n = 1
```
```
P ( Ei , n ).
```
**27.** An urn contains 3 red and 7 black balls. Players _A_
    and _B_ withdraw balls from the urn consecutively
    until a red ball is selected. Find the probability that
    _A_ selects the red ball. ( _A_ draws the first ball, then
    _B_ , and so on. There is no replacement of the balls
    drawn.)
**28.** An urn contains 5 red, 6 blue, and 8 green balls.
    If a set of 3 balls is randomly selected, what is the
    probability that each of the balls will be (a) of the
    same color? (b) of different colors? Repeat under
    the assumption that whenever a ball is selected, its
    color is noted and it is then replaced in the urn
    before the next selection. This is known as _sam-_
    _pling with replacement_.
**29.** An urn contains _n_ white and _m_ black balls, where
    _n_ and _m_ are positive numbers.
    **(a)** If two balls are randomly withdrawn, what is
       the probability that they are the same color?
    **(b)** If a ball is randomly withdrawn and then
       replaced before the second one is drawn, what
       is the probability that the withdrawn balls are
       the same color?
    **(c)** Show that the probability in part (b) is always
       larger than the one in part (a).
**30.** The chess clubs of two schools consist of, respec-
    tively, 8 and 9 players. Four members from each
    club are randomly chosen to participate in a con-
    test between the two schools. The chosen play-
    ers from one team are then randomly paired with
    those from the other team, and each pairing plays
    a game of chess. Suppose that Rebecca and her sis-
    ter Elise are on the chess clubs at different schools.
    What is the probability that
    **(a)** Rebecca and Elise will be paired?
    **(b)** Rebecca and Elise will be chosen to represent
       their schools but will not play each other?
    **(c)** either Rebecca or Elise will be chosen to
       represent her school?


```
Problems 53
```
**31.** A 3-person basketball team consists of a guard, a
    forward, and a center.
    **(a)** If a person is chosen at random from each of
       three different such teams, what is the proba-
       bility of selecting a complete team?
    **(b)** What is the probability that all 3 players
       selected play the same position?
**32.** A group of individuals containing _b_ boys and _g_
    girls is lined up in random order; that is, each of
    the( _b_ + _g_ )! permutations is assumed to be equally
    likely. What is the probability that the person in
    the _i_ th position, 1... _i_ ... _b_ + _g_ ,isagirl?
**33.** A forest contains 20 elk, of which 5 are captured,
    tagged, and then released. A certain time later, 4
    of the 20 elk are captured. What is the probability
    that 2 of these 4 have been tagged? What assump-
    tions are you making?
**34.** The second Earl of Yarborough is reported to
    have bet at odds of 1000 to 1 that a bridge hand
    of 13 cards would contain at least one card that is
    ten or higher. (By _ten or higher_ we mean that a
    card is either a ten, a jack, a queen, a king, or an
    ace.) Nowadays, we call a hand that has no cards
    higher than 9 _a Yarborough_. What is the proba-
    bility that a randomly selected bridge hand is a
    Yarborough?
**35.** Seven balls are randomly withdrawn from an urn
    that contains 12 red, 16 blue, and 18 green balls.
    Find the probability that
    **(a)** 3 red, 2 blue, and 2 green balls are withdrawn;
    **(b)** at least 2 red balls are withdrawn;
    **(c)** all withdrawn balls are the same color;
    **(d)** either exactly 3 red balls or exactly 3 blue balls
       are withdrawn.
**36.** Two cards are chosen at random from a deck of 52
    playing cards. What is the probability that they
    **(a)** are both aces?
    **(b)** have the same value?
**37.** An instructor gives her class a set of 10 problems
    with the information that the final exam will con-
    sist of a random selection of 5 of them. If a student
    has figured out how to do 7 of the problems, what is
    the probability that he or she will answer correctly
    **(a)** all 5 problems?
    **(b)** at least 4 of the problems?
**38.** There are _n_ socks, 3 of which are red, in a drawer.
    What is the value of _n_ if, when 2 of the socks
    are chosen randomly, the probability that they are
    both red is^12?
**39.** There are 5 hotels in a certain town. If 3 people
    check into hotels in a day, what is the probability
    that they each check into a different hotel? What
    assumptions are you making?
**40.** A town contains 4 people who repair televisions.
    If 4 sets break down, what is the probability that

```
exactly i of the repairers are called? Solve the
problem for i =1, 2, 3, 4. What assumptions are
you making?
```
**41.** If a die is rolled 4 times, what is the probability that
    6 comes up at least once?
**42.** Two dice are thrown _n_ times in succession. Com-
    pute the probability that double 6 appears at least
    once. How large need _n_ be to make this probability
    at least^12?
**43. (a)** If _N_ people, including _A_ and _B_ , are randomly
    arranged in a line, what is the probability that
    _A_ and _B_ are next to each other?
    **(b)** What would the probability be if the people
       were randomly arranged in a circle?
**44.** Five people, designated as _A_ , _B_ , _C_ , _D_ , _E_ ,are
    arranged in linear order. Assuming that each pos-
    sible order is equally likely, what is the probabil-
    ity that
    **(a)** there is exactly one person between _A_ and _B_?
    **(b)** there are exactly two people between _A_
       and _B_?
    **(c)** there are three people between _A_ and _B_?
**45.** A woman has _n_ keys, of which one will open
    her door.
    **(a)** If she tries the keys at random, discarding
       those that do not work, what is the probability
       that she will open the door on her _k_ th try?
    **(b)** What if she does not discard previously tried
       keys?
**46.** How many people have to be in a room in order
    that the probability that at least two of them cele-
    brate their birthday in the same month is at least
       1
       2? Assume that all possible monthly outcomes are
    equally likely.
**47.** If there are 12 strangers in a room, what is the
    probability that no two of them celebrate their
    birthday in the same month?
**48.** Given 20 people, what is the probability that,
    among the 12 months in the year, there are 4
    months containing exactly 2 birthdays and 4 con-
    taining exactly 3 birthdays?
**49.** A group of 6 men and 6 women is randomly
    divided into 2 groups of size 6 each. What is the
    probability that both groups will have the same
    number of men?
**50.** In a hand of bridge, find the probability that you
    have 5 spades and your partner has the remain-
    ing 8.
**51.** Suppose that _n_ balls are randomly distributed into
    _N_ compartments. Find the probability that _m_ balls
    will fall into the first compartment. Assume that all
    _Nn_ arrangements are equally likely.


**54** Chapter 2 Axioms of Probability

**52.** A closet contains 10 pairs of shoes. If 8 shoes
    are randomly selected, what is the probability that
    there will be
    **(a)** no complete pair?
    **(b)** exactly 1 complete pair?
**53.** If 4 married couples are arranged in a row, find the
    probability that no husband sits next to his wife.
**54.** Compute the probability that a bridge hand is void
    in at least one suit. Note that the answer is not
       (
          4
          1

```
)(
39
13
```
```
)
```
```
(
52
13
```
```
)
```
```
(Why not?)
Hint : Use Proposition 4.4.
```
**55.** Compute the probability that a hand of 13 cards
    contains
    **(a)** the ace and king of at least one suit;
    **(b)** all 4 of at least 1 of the 13 denominations.
**56.** Two players play the following game: Player _A_
    chooses one of the three spinners pictured in
    Figure 2.6, and then player _B_ chooses one of the
    remaining two spinners. Both players then spin
    their spinner, and the one that lands on the higher
    number is declared the winner. Assuming that
    each spinner is equally likely to land in any of its
    3 regions, would you rather be player _A_ or player
    _B_? Explain your answer!

**95**

**1**

_a_

**38**

**4**

_b_

**76**

**2**

_c_

```
FIGURE 2.6: Spinners
```
#### Theoretical Exercises

```
Prove the following relations:
```
**1.** _EF_ ( _E_ ( _E_ ∪ _F_.
**2.** If _E_ ( _F_ ,then _Fc_ ( _Ec_.
**3.** _F_ = _FE_ ∪ _FEc_ and _E_ ∪ _F_ = _E_ ∪ _EcF_.

```
4.
```
```
(
⋃q
1
```
```
Ei
```
```
)
F =
```
```
⋃q
1
```
```
EiF and
(
⋂q
1
```
```
Ei
```
```
)
∪ F =
```
```
⋂q
1
```
```
( Ei ∪ F ).
```

```
Theoretical Exercises 55
```
**5.** For any sequence of events _E_ 1 , _E_ 2 ,..., define a
    new sequence _F_ 1 , _F_ 2 ,...of disjoint events (that is,
    events such that _FiFj_ =Ø whenever _i_ Z _j_ )such
    that for all _n_ Ú1,

```
⋃ n
```
```
1
```
```
Fi =
```
```
⋃ n
```
```
1
```
```
Ei
```
**6.** Let _E_ , _F_ ,and _G_ be three events. Find expressions
    for the events so that, of _E_ , _F_ ,and _G_ ,
    **(a)** only _E_ occurs;
    **(b)** both _E_ and _G_ , but not _F_ , occur;
    **(c)** at least one of the events occurs;
    **(d)** at least two of the events occur;
    **(e)** all three events occur;
    **(f)** none of the events occurs;
    **(g)** at most one of the events occurs;
    **(h)** at most two of the events occur;
    **(i)** exactly two of the events occur;
    **(j)** at most three of the events occur.
**7.** Find the simplest expression for the following
    events:
    **(a)** ( _E_ ∪ _F_ )( _E_ ∪ _Fc_ );
    **(b)** ( _E_ ∪ _F_ )( _Ec_ ∪ _F_ )( _E_ ∪ _Fc_ );
    **(c)** ( _E_ ∪ _F_ )( _F_ ∪ _G_ ).
**8.** Let _S_ be a given set. If, for some _k_ > 0,
    _S_ 1 , _S_ 2 ,..., _Sk_ are mutually exclusive nonempty
    subsets of _S_ such that

```
⋃ k
i = 1
```
```
Si = S ,thenwe
call the set{ S 1 , S 2 ,..., Sk }a partition of S .Let
Tn denote the number of different partitions of
{1, 2,..., n }. Thus, T 1 =1 (the only partition being
S 1 ={ 1 })and T 2 = 2 (the two partitions being
{{1, 2,}},{{ 1 },{ 2 }}).
(a) Show, by computing all partitions, that T 3 =
5, T 4 =15.
(b) Show that
```
```
Tn + 1 = 1 +
```
```
∑ n
```
```
k = 1
```
```
(
n
k
```
```
)
Tk
```
```
and use this equation to compute T 10.
Hint : One way of choosing a partition of n + 1
items is to call one of the items special .Thenwe
obtain different partitions by first choosing k , k =
0, 1,..., n , then a subset of size n − k of the non-
special items, and then any of the Tk partitions of
the remaining k nonspecial items. By adding the
special item to the subset of size n − k , we obtain
a partition of all n +1 items.
```
**9.** Suppose that an experiment is performed _n_ times.
    For any event _E_ of the sample space, let _n_ ( _E_ )
    denote the number of times that event _E_ occurs
    and define _f_ ( _E_ )= _n_ ( _E_ )/ _n_. Show that _f_ (·)satisfies
    Axioms 1, 2, and 3.
       **10.** Prove that _P_ ( _E_ ∪ _F_ ∪ _G_ )= _P_ ( _E_ )+ _P_ ( _F_ )+
          _P_ ( _G_ ) − _P_ ( _EcFG_ )− _P_ ( _EFcG_ ) − _P_ ( _EFGc_ ) −
          2 _P_ ( _EFG_ ).
       **11.** If _P_ ( _E_ )=.9and _P_ ( _F_ )=.8, show that _P_ ( _EF_ )Ú.7.
          In general, prove Bonferroni’s inequality, namely,

```
P ( EF )Ú P ( E )+ P ( F )− 1
```
**12.** Show that the probability that exactly one of the
    events _E_ or _F_ occurs equals _P_ ( _E_ ) + _P_ ( _F_ ) −
    2 _P_ ( _EF_ ).
**13.** Prove that _P_ ( _EFc_ )= _P_ ( _E_ )− _P_ ( _EF_ ).
**14.** Prove Proposition 4.4 by mathematical induction.
**15.** An urn contains _M_ white and _N_ black balls. If a
    random sample of size _r_ is chosen, what is the prob-
    ability that it contains exactly _k_ white balls?
**16.** Use induction to generalize Bonferroni’s inequal-
    ity to _n_ events. That is, show that

```
P ( E 1 E 2 ··· En )Ú P ( E 1 )+ ··· + P ( En )−( n − 1 )
```
**17.** Consider the matching problem, Example 5m, and
    define _AN_ to be the number of ways in which the
    _N_ men can select their hats so that no man selects
    his own. Argue that

```
AN =( N − 1 )( AN − 1 + AN − 2 )
```
```
This formula, along with the boundary conditions
A 1 =0, A 2 =1, can then be solved for AN ,and
the desired probability of no matches would be
AN / N !.
Hint : After the first man selects a hat that is not his
own, there remain N −1 men to select among a set
of N −1 hats that does not contain the hat of one
of these men. Thus, there is one extra man and one
extra hat. Argue that we can get no matches either
with the extra man selecting the extra hat or with
the extra man not selecting the extra hat.
```
**18.** Let _fn_ denote the number of ways of tossing a coin
    _n_ times such that successive heads never appear.
    Argue that

```
fn = fn − 1 + fn − 2 n Ú2, where f 0 K1, f 1 K 2
```
```
Hint : How many outcomes are there that start
with a head, and how many start with a tail? If
Pn denotes the probability that successive heads
never appear when a coin is tossed n times, find
Pn (in terms of fn ) when all possible outcomes of
the n tosses are assumed equally likely. Compute
P 10.
```
**19.** An urn contains _n_ red and _m_ blue balls. They are
    withdrawn one at a time until a total of _r_ , _r_ ... _n_ ,


**56** Chapter 2 Axioms of Probability

```
red balls have been withdrawn. Find the probabil-
ity that a total of k balls are withdrawn.
Hint : A total of k balls will be withdrawn if there
are r −1 red balls in the first k −1 withdrawals
and the k th withdrawal is a red ball.
```
**20.** Consider an experiment whose sample space con-
    sists of a countably infinite number of points.
    Show that not all points can be equally likely.
    Can all points have a positive probability of
    occurring?
∗ **21.** Consider Example 5o, which is concerned with the
number of runs of wins obtained when _n_ wins and
_m_ losses are randomly permuted. Now

```
consider the total number of runs—that is, win
runs plus loss runs—and show that
```
```
P { 2 k runs}= 2
```
```
(
m − 1
k − 1
```
```
)(
n − 1
k − 1
```
```
)
```
```
(
m + n
n
```
```
)
```
```
P { 2 k +1 runs}
```
```
=
```
```
(
m − 1
k − 1
```
```
)(
n − 1
k
```
```
)
+
```
```
(
m − 1
k
```
```
)(
n − 1
k − 1
```
```
)
```
```
(
m + n
n
```
```
)
```
#### Self-Test Problems and Exercises

**1.** A cafeteria offers a three-course meal consisting
    of an entree, a starch, and a dessert. The possible
    choices are given in the following table:

```
Course Choices
```
```
Entree Chicken or roast beef
Starch Pasta or rice or potatoes
Dessert Ice cream or Jello or apple pie or a peach
```
```
A person is to choose one course from each cate-
gory.
(a) How many outcomes are in the sample space?
(b) Let A be the event that ice cream is chosen.
How many outcomes are in A?
(c) Let B be the event that chicken is chosen.
How many outcomes are in B?
(d) List all the outcomes in the event AB.
(e) Let C be the event that rice is chosen. How
many outcomes are in C?
(f) List all the outcomes in the event ABC.
```
**2.** A customer visiting the suit department of a cer-
    tain store will purchase a suit with probability .22,
    a shirt with probability .30, and a tie with proba-
    bility .28. The customer will purchase both a suit
    and a shirt with probability .11, both a suit and a
    tie with probability .14, and both a shirt and a tie
    with probability .10. A customer will purchase all 3
    items with probability .06. What is the probability
    that a customer purchases
    **(a)** none of these items?
    **(b)** exactly 1 of these items?
**3.** A deck of cards is dealt out. What is the proba-
    bility that the 14th card dealt is an ace? What is
    the probability that the first ace occurs on the 14th
    card?
       **4.** Let _A_ denote the event that the midtown temper-
          ature in Los Angeles is 70◦F, and let _B_ denote the
          event that the midtown temperature in New York
          is 70◦F. Also, let _C_ denote the event that the max-
          imum of the midtown temperatures in New York
          and in Los Angeles is 70◦F. If _P_ ( _A_ )=.3, _P_ ( _B_ )=
          .4, and _P_ ( _C_ )=.2, find the probability that the min-
          imum of the two midtown temperatures is 70◦F.
**5.** An ordinary deck of 52 cards is shuffled. What is
the probability that the top four cards have
**(a)** different denominations?
**(b)** different suits?
**6.** Urn _A_ contains 3 red and 3 black balls, whereas
urn _B_ contains 4 red and 6 black balls. If a ball is
randomly selected from each urn, what is the prob-
ability that the balls will be the same color?
**7.** In a state lottery, a player must choose 8 of the
numbers from 1 to 40. The lottery commission
then performs an experiment that selects 8 of these
40 numbers. Assuming that the choice of the lot-
tery commission is equally likely to be any of the(
40
8

```
)
combinations, what is the probability that a
player has
(a) all 8 of the numbers selected by the lottery
commission?
(b) 7 of the numbers selected by the lottery com-
mission?
(c) at least 6 of the numbers selected by the lot-
tery commission?
```
**8.** From a group of 3 freshmen, 4 sophomores, 4
    juniors, and 3 seniors a committee of size 4 is ran-
    domly selected. Find the probability that the com-
    mittee will consist of
    **(a)** 1 from each class;
    **(b)** 2 sophomores and 2 juniors;
    **(c)** only sophomores or juniors.


```
Self -Test Problems and Exercises 57
```
**9.** For a finite set _A_ ,let _N_ ( _A_ )denote the number of
    elements in _A_.
    **(a)** Show that

```
N ( A ∪ B )= N ( A )+ N ( B )− N ( AB )
```
```
(b) More generally, show that
```
```
N
```
```
⎛
⎝
```
```
⋃ n
```
```
i = 1
```
```
Ai
```
```
⎞
⎠=
```
```
∑
```
```
i
```
```
N ( Ai )−
```
```
∑∑
```
```
i < j
```
```
N ( AiAj )
```
```
+ ··· +(− 1 ) n +^1 N ( A 1 ··· An )
```
**10.** Consider an experiment that consists of six horses,
    numbered 1 through 6, running a race, and sup-
    pose that the sample space consists of the 6! pos-
    sible orders in which the horses finish. Let _A_ be
    the event that the number-1 horse is among the
    top three finishers, and let _B_ be the event that the
    number-2 horse comes in second. How many out-
    comes are in the event _A_ ∪ _B_?
**11.** A 5-card hand is dealt from a well-shuffled deck of
    52 playing cards. What is the probability that the
    hand contains at least one card from each of the
    four suits?
**12.** A basketball team consists of 6 frontcourt and
    4 backcourt players. If players are divided into
    roommates at random, what is the probability that
    there will be exactly two roommate pairs made up
    of a backcourt and a frontcourt player?
**13.** Suppose that a person chooses a letter at random
    from R E S E R V E and then chooses one at ran-
    dom from V E R T I C A L. What is the probability
    that the same letter is chosen?
**14.** Prove Boole’s inequality:

```
P
```
```
⎛
⎝
```
```
⋃q
```
```
i = 1
```
```
Ai
```
```
⎞
⎠...
```
```
∑q
```
```
i = 1
```
```
P ( Ai )
```
**15.** Show that if _P_ ( _Ai_ ) = 1forall _i_ Ú 1, then
    _P_

```
(
⋂q
i = 1
```
```
Ai
```
```
)
=1.
```
**16.** Let _Tk_ ( _n_ )denote the number of partitions of the
    set{1,..., _n_ }into _k_ nonempty subsets, where 1...
    _k_ ... _n_. (See Theoretical Exercise 8 for the defini-
    tion of a partition.) Argue that

```
Tk ( n )= kTk ( n − 1 )+ Tk − 1 ( n − 1 )
```
```
Hint : In how many partitions is{ 1 }a subset, and in
how many is 1 an element of a subset that contains
other elements?
```
**17.** Five balls are randomly chosen, without replace-
    ment, from an urn that contains 5 red, 6 white, and
    7 blue balls. Find the probability that at least one
    ball of each color is chosen.
**18.** Four red, 8 blue, and 5 green balls are randomly
    arranged in a line.
    **(a)** What is the probability that the first 5 balls are
       blue?
    **(b)** What is the probability that none of the first 5
       balls are blue?
    **(c)** What is the probability that the final 3 balls
       are differently colored.
    **(d)** What is the probability that all the red balls
       are together?
**19.** Ten cards are randomly chosen from a deck of 52
    cards that consists of 13 cards of each of 4 different
    suits. Each of the selected cards is put in one of 4
    piles, depending on the suit of the card.
    **(a)** What is the probability that the largest pile
       has 4 cards, the next largest has 3, the next
       largest has 2, and the smallest has 1 card?
    **(b)** What is the probability that two of the piles
       have 3 cards, one has 4 cards, and one has no
       cards?
**20.** Balls are randomly removed from an urn initially
    containing 20 red and 10 blue balls. What is the
    probability that all of the red balls are removed
    before all of the blue ones have been removed?


## CHAPTER 3

# Conditional Probability and Independence

### 3.1 Introduction

### 3.2 Conditional Probabilities

**3.3 BAYES’S FORMULA
3.4 INDEPENDENT EVENTS
3.5** **_P_** **(** · **|** **_F_** **) IS A PROBABILITY**

##### 3.1 INTRODUCTION

```
In this chapter, we introduce one of the most important concepts in probability theory,
that of conditional probability. The importance of this concept is twofold. In the first
place, we are often interested in calculating probabilities when some partial informa-
tion concerning the result of an experiment is available; in such a situation, the desired
probabilities are conditional. Second, even when no partial information is available,
conditional probabilities can often be used to compute the desired probabilities more
easily.
```
**3.2 CONDITIONAL PROBABILITIES**

```
Suppose that we toss 2 dice, and suppose that each of the 36 possible outcomes is
equally likely to occur and hence has probability 361. Suppose further that we observe
that the first die is a 3. Then, given this information, what is the probability that the
sum of the 2 dice equals 8? To calculate this probability, we reason as follows: Given
that the initial die is a 3, there can be at most 6 possible outcomes of our experiment,
namely, (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), and (3, 6). Since each of these outcomes
originally had the same probability of occurring, the outcomes should still have equal
probabilities. That is, given that the first die is a 3, the (conditional) probability of
each of the outcomes (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), and (3, 6) is^16 , whereas the
(conditional) probability of the other 30 points in the sample space is 0. Hence, the
desired probability will be^16.
If we let E and F denote, respectively, the event that the sum of the dice is 8 and the
event that the first die is a 3, then the probability just obtained is called the conditional
probability that E occurs given that F has occurred and is denoted by
```
```
P ( E | F )
```
```
A general formula for P ( E | F )that is valid for all events E and F is derived in the same
manner: If the event F occurs, then, in order for E to occur, it is necessary that the
actual occurrence be a point both in E and in F ; that is, it must be in EF. Now, since
we know that F has occurred, it follows that F becomes our new, or reduced, sample
space; hence, the probability that the event EF occurs will equal the probability of
EF relative to the probability of F. That is, we have the following definition.
```
**58**


```
Section 3.2 Conditional Probabilities 59
```
```
Definition
If P ( F )>0, then
P ( E | F )=
```
##### P ( EF )

##### P ( F )

##### (2.1)

**_EXAMPLE 2a_**

A student is taking a one-hour-time-limit makeup examination. Suppose the proba-
bility that the student will finish the exam in less than _x_ hours is _x_ /2, for all 0... _x_ ...1.
Then, given that the student is still working after.75 hour, what is the conditional
probability that the full hour is used?

**_Solution._** Let _Lx_ denote the event that the student finishes the exam in less than _x_
hours, 0... _x_ ...1, and let _F_ be the event that the student uses the full hour. Because
_F_ is the event that the student is not finished in less than 1 hour,

```
P ( F )= P ( Lc 1 )= 1 − P ( L 1 )=. 5
```
Now, the event that the student is still working at time.75 is the complement of the
event _L_. 75 , so the desired probability is obtained from

```
P ( F | Lc. 75 )=
```
```
P ( FLc. 75 )
P ( Lc. 75 )
```
```
=
```
##### P ( F )

##### 1 − P ( L. 75 )

##### =

##### . 5

##### . 625

##### =. 8

##### .

If each outcome of a finite sample space _S_ is equally likely, then, conditional on
the event that the outcome lies in a subset _F_ ( _S_ , all outcomes in _F_ become equally
likely. In such cases, it is often convenient to compute conditional probabilities of
the form _P_ ( _E_ | _F_ )by using _F_ as the sample space. Indeed, working with this reduced
sample space often results in an easier and better understood solution. Our next few
examples illustrate this point.

**_EXAMPLE 2b_**

A coin is flipped twice. Assuming that all four points in the sample space _S_ ={( _h_ , _h_ ),
( _h_ , _t_ ),( _t_ , _h_ ),( _t_ , _t_ )}are equally likely, what is the conditional probability that both flips
land on heads, given that (a) the first flip lands on heads? (b) at least one flip lands
on heads?

**_Solution._** Let _B_ ={( _h_ , _h_ )}be the event that both flips land on heads; let _F_ ={( _h_ , _h_ ),
( _h_ , _t_ )}be the event that the first flip lands on heads; and let _A_ ={( _h_ , _h_ ),( _h_ , _t_ ),( _t_ , _h_ )}be
the event that at least one flip lands on heads. The probability for (a) can be obtained
from


**60** Chapter 3 Conditional Probability and Independence

##### P ( B | F )=

##### P ( BF )

##### P ( F )

##### =

```
P ({( h , h )})
P ({( h , h ),( h , t )})
```
```
=
```
##### 1 / 4

##### 2 / 4

##### = 1 / 2

```
For (b), we have
```
##### P ( B | A )=

##### P ( BA )

##### P ( A )

##### =

```
P ({( h , h )})
P ({( h , h ),( h , t ),( t , h )})
```
```
=
```
##### 1 / 4

##### 3 / 4

##### = 1 / 3

```
Thus, the conditional probability that both flips land on heads given that the first
one does is 1/2, whereas the conditional probability that both flips land on heads
given that at least one does is only 1/3. Many students initially find this latter result
surprising. They reason that, given that at least one flip lands on heads, there are
two possible results: Either they both land on heads or only one does. Their mistake,
however, is in assuming that these two possibilities are equally likely. For, initially,
there are 4 equally likely outcomes. Because the information that at least one flip
lands on heads is equivalent to the information that the outcome is not( t , t ), we are
left with the 3 equally likely outcomes( h , h ),( h , t ),( t , h ), only one of which results in
both flips landing on heads..
```
```
EXAMPLE 2c
In the card game bridge, the 52 cards are dealt out equally to 4 players—called East,
West, North, and South. If North and South have a total of 8 spades among them,
what is the probability that East has 3 of the remaining 5 spades?
```
```
Solution. Probably the easiest way to compute the desired probability is to work
with the reduced sample space. That is, given that North–South have a total of 8
spades among their 26 cards, there remains a total of 26 cards, exactly 5 of them
being spades, to be distributed among the East–West hands. Since each distribution
is equally likely, it follows that the conditional probability that East will have exactly
3 spades among his or her 13 cards is
(
5
3
```
##### )(

##### 21

##### 10

##### )

##### (

##### 26

##### 13

) L. (^339).
**_EXAMPLE 2d_**
A total of _n_ balls are sequentially and randomly chosen, without replacement, from
an urn containing _r_ red and _b_ blue balls ( _n_ ... _r_ + _b_ ). Given that _k_ of the _n_ balls are
blue, what is the conditional probability that the first ball chosen is blue?


```
Section 3.2 Conditional Probabilities 61
```
**_Solution._** If we imagine that the balls are numbered, with the blue balls having num-
bers 1 through _b_ and the red balls _b_ +1 through _b_ + _r_ , then the outcome of the
experiment of selecting _n_ balls without replacement is a vector of distinct integers
_x_ 1 ,..., _xn_ , where each _xi_ is between 1 and _r_ + _b_. Moreover, each such vector is equally
likely to be the outcome. So, given that the vector contains _k_ blue balls (that is, it
contains _k_ values between 1 and _b_ ), it follows that each of these outcomes is equally
likely. But because the first ball chosen is, therefore, equally likely to be any of the _n_
chosen balls, of which _k_ are blue, it follows that the desired probability is _k_ / _n_.
If we did not choose to work with the reduced sample space, we could have solved
the problem by letting _B_ be the event that the first ball chosen is blue and _Bk_ be the
event that a total of _k_ blue balls are chosen. Then

```
P ( B | Bk )=
```
```
P ( BBk )
P ( Bk )
```
```
=
```
```
P ( Bk | B ) P ( B )
P ( Bk )
```
Now, _P_ ( _Bk_ | _B_ )is the probability that a random choice of _n_ −1 balls from an urn
containing _r_ red and _b_ − 1 blue balls results in a total of _k_ − 1 blue balls being
chosen; consequently,

```
P ( Bk | B )=
```
```
( b − 1
k − 1
```
```
)( r
n − k
```
##### )

```
( r + b − 1
n − 1
```
##### )

Using the preceding formula along with

##### P ( B )=

```
b
r + b
```
and the hypergeometric probability

```
P ( Bk )=
```
```
( b
k
```
```
)( r
n − k
```
##### )

```
( r + b
n
```
##### )

again yields the result that

```
P ( B | Bk )=
```
```
k
n.
```
```
Multiplying both sides of Equation (2.1) by P ( F ), we obtain
```
```
P ( EF )= P ( F ) P ( E | F ) (2.2)
```
In words, Equation (2.2) states that the probability that both _E_ and _F_ occur is equal
to the probability that _F_ occurs multiplied by the conditional probability of _E_ given
that _F_ occurred. Equation (2.2) is often quite useful in computing the probability of
the intersection of events.

**_EXAMPLE 2e_**

Celine is undecided as to whether to take a French course or a chemistry course. She
estimates that her probability of receiving an A grade would be^12 in a French course

and^23 in a chemistry course. If Celine decides to base her decision on the flip of a fair
coin, what is the probability that she gets an A in chemistry?


**62** Chapter 3 Conditional Probability and Independence

```
Solution. (a) Let the event that Celine takes chemistry and A denote the event that
she receives an A in whatever course she takes, then the desired probability is P ( CA ),
which is calculated by using Equation (2.2) as follows:
```
```
P ( CA )= P ( C ) P ( A | C )
```
```
=
```
##### (

##### 1

##### 2

##### )(

##### 2

##### 3

##### )

##### =

##### 1

(^3).
**_EXAMPLE 2f_**
Suppose that an urn contains 8 red balls and 4 white balls. We draw 2 balls from the
urn without replacement. (a) If we assume that at each draw each ball in the urn is
equally likely to be chosen, what is the probability that both balls drawn are red? (b)
Now suppose that the balls have different weights, with each red ball having weight _r_
and each white ball having weight _w_. Suppose that the probability that a given ball in
the urn is the next one selected is its weight divided by the sum of the weights of all
balls currently in the urn. Now what is the probability that both balls are red?
**_Solution._** Let _R_ 1 and _R_ 2 denote, respectively, the events that the first and second
balls drawn are red. Now, given that the first ball selected is red, there are 7 remaining
red balls and 4 white balls, so _P_ ( _R_ 2 | _R_ 1 ) = 117 .As _P_ ( _R_ 1 )is clearly 128 , the desired
probability is
_P_ ( _R_ 1 _R_ 2 )= _P_ ( _R_ 1 ) _P_ ( _R_ 2 | _R_ 1 )
=

##### (

##### 2

##### 3

##### )(

##### 7

##### 11

##### )

##### =

##### 14

##### 33

```
Of course, this probability could have been computed by P ( R 1 R 2 )=
```
##### ( 8

```
2
```
##### )

##### /

##### ( 12

```
2
```
##### )

##### .

```
For part (b), we again let Ri be the event that the i th ball chosen is red and use
```
```
P ( R 1 R 2 )= P ( R 1 ) P ( R 2 | R 1 )
```
```
Now, number the red balls, and let Bi , i =1,..., 8 be the event that the first ball
drawn is red ball number i. Then
```
```
P ( R 1 )= P (∪^8 i = 1 Bi )=
```
##### ∑^8

```
i = 1
```
```
P ( Bi )= 8
```
```
r
8 r + 4 w
```
```
Moreover, given that the first ball is red, the urn then contains 7 red and 4 white balls.
Thus, by an argument similar to the preceding one,
```
##### P ( R 2 | R 1 )=

```
7 r
7 r + 4 w
```
```
Hence, the probability that both balls are red is
```
##### P ( R 1 R 2 )=

```
8 r
8 r + 4 w
```
```
7 r
7 r + 4 w.
```
```
A generalization of Equation (2.2), which provides an expression for the probabil-
ity of the intersection of an arbitrary number of events, is sometimes referred to as
the multiplication rule.
```

```
Section 3.2 Conditional Probabilities 63
```
```
The multiplication rule
```
```
P ( E 1 E 2 E 3 ··· En )= P ( E 1 ) P ( E 2 | E 1 ) P ( E 3 | E 1 E 2 )··· P ( En | E 1 ··· En − 1 )
```
To prove the multiplication rule, just apply the definition of conditional probability
to its right-hand side, giving

##### P ( E 1 )

##### P ( E 1 E 2 )

##### P ( E 1 )

##### P ( E 1 E 2 E 3 )

##### P ( E 1 E 2 )

##### ···

```
P ( E 1 E 2 ··· En )
P ( E 1 E 2 ··· En − 1 )
```
```
= P ( E 1 E 2 ··· En )
```
**_EXAMPLE 2g_**
In the match problem stated in Example 5m of Chapter 2, it was shown that _PN_ ,the
probability that there are no matches when _N_ people randomly select from among
their own _N_ hats, is given by

```
PN =
```
##### ∑ N

```
i = 0
```
```
(− 1 ) i / i!
```
What is the probability that exactly _k_ of the _N_ people have matches?

**_Solution._** Let us fix our attention on a particular set of _k_ people and determine the
probability that these _k_ individuals have matches and no one else does. Letting _E_
denote the event that everyone in this set has a match, and letting _G_ be the event that
none of the other _N_ − _k_ people have a match, we have

```
P ( EG )= P ( E ) P ( G | E )
```
Now, let _Fi_ , _i_ =1,..., _k_ , be the event that the _i_ th member of the set has a match.
Then

```
P ( E )= P ( F 1 F 2 ··· Fk )
= P ( F 1 ) P ( F 2 | F 1 ) P ( F 3 | F 1 F 2 )··· P ( Fk | F 1 ··· Fk − 1 )
```
```
=
```
##### 1

##### N

##### 1

##### N − 1

##### 1

##### N − 2

##### ···

##### 1

```
N − k + 1
```
```
=
```
```
( N − k )!
N!
```
Given that everyone in the set of _k_ has a match, the other _N_ − _k_ people will be
randomly choosing among their own _N_ − _k_ hats, so the probability that none of
them has a match is equal to the probability of no matches in a problem having _N_ − _k_
people choosing among their own _N_ − _k_ hats. Therefore,

```
P ( G | E )= PN − k =
```
```
N ∑− k
```
```
i = 0
```
```
(− 1 ) i / i!
```
showing that the probability that a specified set of _k_ people have matches and no one
else does is

```
P ( EG )=
```
```
( N − k )!
N!
```
```
PN − k
```

**64** Chapter 3 Conditional Probability and Independence

```
Because there will be exactly k matches if the preceding is true for any of the
```
##### ( N

```
k
```
##### )

```
sets
of k individuals, the desired probability is
```
```
P (exactly k matches)= PN − k / k!
L e −^1 / k! when N is large.
```
```
We will now employ the multiplication rule to obtain a second approach to solving
Example 5h(b) of Chapter 2.
```
```
EXAMPLE 2h
An ordinary deck of 52 playing cards is randomly divided into 4 piles of 13 cards each.
Compute the probability that each pile has exactly 1 ace.
```
```
Solution. Define events Ei , i =1, 2, 3, 4, as follows:
```
```
E 1 ={the ace of spades is in any one of the piles}
E 2 ={the ace of spades and the ace of hearts are in different piles}
E 3 ={the aces of spades, hearts, and diamonds are all in different piles}
E 4 ={all 4 aces are in different piles}
```
```
The desired probability is P ( E 1 E 2 E 3 E 4 ), and by the multiplication rule,
```
```
P ( E 1 E 2 E 3 E 4 )= P ( E 1 ) P ( E 2 | E 1 ) P ( E 3 | E 1 E 2 ) P ( E 4 | E 1 E 2 E 3 )
```
```
Now,
P ( E 1 )= 1
```
```
since E 1 is the sample space S. Also,
```
##### P ( E 2 | E 1 )=

##### 39

##### 51

```
since the pile containing the ace of spades will receive 12 of the remaining 51 cards,
and
P ( E 3 | E 1 E 2 )=
```
##### 26

##### 50

```
since the piles containing the aces of spades and hearts will receive 24 of the remain-
ing 50 cards. Finally,
```
```
P ( E 4 | E 1 E 2 E 3 )=
```
##### 13

##### 49

```
Therefore, the probability that each pile has exactly 1 ace is
```
##### P ( E 1 E 2 E 3 E 4 )=

##### 39 · 26 · 13

##### 51 · 50 · 49

##### L. 105

```
That is, there is approximately a 10.5 percent chance that each pile will contain an
ace. (Problem 13 gives another way of using the multiplication rule to solve this
problem.).
```
```
Remarks. Our definition of P ( E | F )is consistent with the interpretation of prob-
ability as being a long-run relative frequency. To see this, suppose that n repeti-
tions of the experiment are to be performed, where n is large. We claim that if
```

```
Section 3.3 Bayes’s Formula 65
```
```
we consider only those experiments in which F occurs, then P ( E | F )will equal the
long-run proportion of them in which E also occurs. To verify this statement, note
that, since P ( F ) is the long-run proportion of experiments in which F occurs,
it follows that in the n repetitions of the experiment F will occur approximately
nP ( F )times. Similarly, in approximately nP ( EF )of these experiments both E and
F will occur. Hence, out of the approximately nP ( F ) experiments in which
F occurs, the proportion of them in which E also occurs is approximately
equal to
```
```
nP ( EF )
nP ( F )
```
##### =

##### P ( EF )

##### P ( F )

```
Because this approximation becomes exact as n becomes larger and larger, we have
the appropriate definition of P ( E | F ).
```
### 3.3 Bayes’s Formula

```
Let E and F be events. We may express E as
```
```
E = EF ∪ EFc
```
```
for, in order for an outcome to be in E , it must either be in both E and F or be in
E but not in F. (See Figure 3.1.) As EF and EFc are clearly mutually exclusive, we
have, by Axiom 3,
```
```
P ( E )= P ( EF )+ P ( EFc )
= P ( E | F ) P ( F )+ P ( E | Fc ) P ( Fc )
= P ( E | F ) P ( F )+ P ( E | Fc )[1− P ( F )]
```
##### (3.1)

```
Equation (3.1) states that the probability of the event E is a weighted average of the
conditional probability of E given that F has occurred and the conditional proba-
bility of E given that F has not occurred—each conditional probability being given
as much weight as the event on which it is conditioned has of occurring. This is an
extremely useful formula, because its use often enables us to determine the prob-
ability of an event by first “conditioning” upon whether or not some second event
has occurred. That is, there are many instances in which it is difficult to compute the
probability of an event directly, but it is straightforward to compute it once we know
whether or not some second event has occurred. We illustrate this idea with some
examples.
```
```
EF
```
```
EFc EF
```
```
FIGURE 3.1: E = EF ∪ EFc. EF =Shaded Area; EFc =Striped Area
```

**66** Chapter 3 Conditional Probability and Independence

```
EXAMPLE 3a (Part 1)
An insurance company believes that people can be divided into two classes: those
who are accident prone and those who are not. The company’s statistics show that
an accident-prone person will have an accident at some time within a fixed 1-year
period with probability .4, whereas this probability decreases to .2 for a person who is
not accident prone. If we assume that 30 percent of the population is accident prone,
what is the probability that a new policyholder will have an accident within a year of
purchasing a policy?
```
```
Solution. We shall obtain the desired probability by first conditioning upon whether
or not the policyholder is accident prone. Let A 1 denote the event that the policy-
holder will have an accident within a year of purchasing the policy, and let A denote
the event that the policyholder is accident prone. Hence, the desired probability is
given by
```
```
P ( A 1 )= P ( A 1 | A ) P ( A )+ P ( A 1 | Ac ) P ( Ac )
```
=(. 4 )(. 3 )+(. 2 )(. 7 )=. (^26).
**_EXAMPLE 3a (Part 2)_**
Suppose that a new policyholder has an accident within a year of purchasing a policy.
What is the probability that he or she is accident prone?
**_Solution._** The desired probability is

##### P ( A | A 1 )=

##### P ( AA 1 )

##### P ( A 1 )

##### =

##### P ( A ) P ( A 1 | A )

##### P ( A 1 )

##### =

##### (. 3 )(. 4 )

##### . 26

##### =

##### 6

(^13).
**_EXAMPLE 3b_**
Consider the following game played with an ordinary deck of 52 playing cards: The
cards are shuffled and then turned over one at a time. At any time, the player can
guess that the next card to be turned over will be the ace of spades; if it is, then the
player wins. In addition, the player is said to win if the ace of spades has not yet
appeared when only one card remains and no guess has yet been made. What is a
good strategy? What is a bad strategy?
**_Solution._** Every strategy has probability 1/52 of winning! To show this, we will use
induction to prove the stronger result that, for an _n_ card deck, one of whose cards
is the ace of spades, the probability of winning is 1/ _n_ , no matter what strategy is
employed. Since this is clearly true for _n_ =1, assume it to be true for an _n_ − 1
card deck, and now consider an _n_ card deck. Fix any strategy, and let _p_ denote the
probability that the strategy guesses that the first card is the ace of spades. Given that
it does, the player’s probability of winning is 1/ _n_. If, however, the strategy does not
guess that the first card is the ace of spades, then the probability that the player wins
is the probability that the first card is not the ace of spades, namely,( _n_ − 1 )/ _n_ , multi-
plied by the conditional probability of winning given that the first card is not the ace
of spades. But this latter conditional probability is equal to the probability of winning


```
Section 3.3 Bayes’s Formula 67
```
whenusingan _n_ − 1 card deck containing a single ace of spades; it is thus, by the
induction hypothesis, 1/( _n_ − 1 ). Hence, given that the strategy does not guess the
first card, the probability of winning is

```
n − 1
n
```
##### 1

```
n − 1
```
##### =

##### 1

```
n
```
Thus, letting _G_ be the event that the first card is guessed, we obtain

```
P {win}= P {win| G } P ( G )+ P {win| Gc }( 1 − P ( G ))=
```
##### 1

```
n
```
```
p +
```
##### 1

```
n
```
```
( 1 − p )
```
##### =

##### 1

```
n
.
```
**_EXAMPLE 3c_**

In answering a question on a multiple-choice test, a student either knows the answer
or guesses. Let _p_ be the probability that the student knows the answer and 1− _p_
be the probability that the student guesses. Assume that a student who guesses at the
answer will be correct with probability 1/ _m_ , where _m_ is the number of multiple-choice
alternatives. What is the conditional probability that a student knew the answer to a
question given that he or she answered it correctly?

**_Solution._** Let _C_ and _K_ denote, respectively, the events that the student answers the
question correctly and the event that he or she actually knows the answer. Now,

##### P ( K | C )=

##### P ( KC )

##### P ( C )

##### =

##### P ( C | K ) P ( K )

```
P ( C | K ) P ( K )+ P ( C | Kc ) P ( Kc )
=
```
```
p
p +( 1 / m )( 1 − p )
=
```
```
mp
1 +( m − 1 ) p
```
For example, if _m_ =5, _p_ =^12 , then the probability that the student knew the answer

to a question he or she answered correctly is^56..

**_EXAMPLE 3d_**

A laboratory blood test is 95 percent effective in detecting a certain disease when it
is, in fact, present. However, the test also yields a “false positive” result for 1 percent
of the healthy persons tested. (That is, if a healthy person is tested, then, with prob-
ability .01, the test result will imply that he or she has the disease.) If .5 percent of
the population actually has the disease, what is the probability that a person has the
disease given that the test result is positive?


**68** Chapter 3 Conditional Probability and Independence

```
Solution. Let D be the event that the person tested has the disease and E the event
that the test result is positive. Then the desired probability is
```
##### P ( D | E )=

##### P ( DE )

##### P ( E )

##### =

##### P ( E | D ) P ( D )

```
P ( E | D ) P ( D )+ P ( E | Dc ) P ( Dc )
```
```
=
```
##### (. 95 )(. 005 )

##### (. 95 )(. 005 )+(. 01 )(. 995 )

##### =

##### 95

##### 294

##### L. 323

```
Thus, only 32 percent of those persons whose test results are positive actually have
the disease. Many students are often surprised at this result (they expect the per-
centage to be much higher, since the blood test seems to be a good one), so it is
probably worthwhile to present a second argument that, although less rigorous than
the preceding one, is probably more revealing. We now do so.
Since .5 percent of the population actually has the disease, it follows that, on the
average, 1 person out of every 200 tested will have it. The test will correctly confirm
that this person has the disease with probability .95. Thus, on the average, out of every
200 persons tested, the test will correctly confirm that .95 person has the disease.
On the other hand, however, out of the (on the average) 199 healthy people, the
test will incorrectly state that (199)(.01) of these people have the disease. Hence, for
every .95 diseased person that the test correctly states is ill, there are (on the average)
(199)(.01) healthy persons that the test incorrectly states are ill. Thus, the proportion
of time that the test result is correct when it states that a person is ill is
```
. 95
. 95 +( 199 )(. 01 )

##### =

##### 95

##### 294

L. (^323).
Equation (3.1) is also useful when one has to reassess one’s personal probabilities
in the light of additional information. For instance, consider the examples that follow.
**_EXAMPLE 3e_**
Consider a medical practitioner pondering the following dilemma: “If I’m at least 80
percent certain that my patient has this disease, then I always recommend surgery,
whereas if I’m not quite as certain, then I recommend additional tests that are expen-
sive and sometimes painful. Now, initially I was only 60 percent certain that Jones
had the disease, so I ordered the series A test, which always gives a positive result
when the patient has the disease and almost never does when he is healthy. The test
result was positive, and I was all set to recommend surgery when Jones informed me,
for the first time, that he was diabetic. This information complicates matters because,
although it doesn’t change my original 60 percent estimate of his chances of having
the disease in question, it does affect the interpretation of the results of the A test.
This is so because the A test, while never yielding a positive result when the patient
is healthy, does unfortunately yield a positive result 30 percent of the time in the case
of _diabetic_ patients who are not suffering from the disease. Now what do I do? More
tests or immediate surgery?”
**_Solution._** In order to decide whether or not to recommend surgery, the doctor should
first compute her updated probability that Jones has the disease given that the A test


```
Section 3.3 Bayes’s Formula 69
```
result was positive. Let _D_ denote the event that Jones has the disease and _E_ the event
that the A test result is positive. The desired conditional probability is then

##### P ( D | E )=

##### P ( DE )

##### P ( E )

##### =

##### P ( D ) P ( E | D )

```
P ( E | D ) P ( D )+ P ( E | Dc ) P ( Dc )
```
```
=
```
##### (. 6 ) 1

##### 1 (. 6 )+(. 3 )(. 4 )

##### =. 833

Note that we have computed the probability of a positive test result by conditioning
on whether or not Jones has the disease and then using the fact that, because Jones is
a diabetic, his conditional probability of a positive result given that he does not have
the disease, _P_ ( _E_ | _Dc_ ), equals .3. Hence, as the doctor should now be over 80 percent
certain that Jones has the disease, she should recommend surgery..

**_EXAMPLE 3f_**

At a certain stage of a criminal investigation, the inspector in charge is 60 percent con-
vinced of the guilt of a certain suspect. Suppose, however, that a _new_ piece of evidence
which shows that the criminal has a certain characteristic (such as left-handedness,
baldness, or brown hair) is uncovered. If 20 percent of the population possesses this
characteristic, how certain of the guilt of the suspect should the inspector now be if it
turns out that the suspect has the characteristic?

**_Solution._** Letting _G_ denote the event that the suspect is guilty and _C_ the event that
he possesses the characteristic of the criminal, we have

##### P ( G | C )=

##### P ( GC )

##### P ( C )

##### =

##### P ( C | G ) P ( G )

```
P ( C | G ) P ( G )+ P ( C | Gc ) P ( Gc )
```
```
=
```
##### 1 (. 6 )

##### 1 (. 6 )+(. 2 )(. 4 )

##### L. 882

where we have supposed that the probability of the suspect having the characteristic
if he is, in fact, innocent is equal to .2, the proportion of the population possessing the
characteristic..

**_EXAMPLE 3g_**

In the world bridge championships held in Buenos Aires in May 1965, the famous
British bridge partnership of Terrence Reese and Boris Schapiro was accused of
cheating by using a system of finger signals that could indicate the number of hearts
held by the players. Reese and Schapiro denied the accusation, and eventually a hear-
ing was held by the British bridge league. The hearing was in the form of a legal
proceeding with prosecution and defense teams, both having the power to call and
cross-examine witnesses. During the course of the proceeding, the prosecutor exam-
ined specific hands played by Reese and Schapiro and claimed that their playing these


**70** Chapter 3 Conditional Probability and Independence

```
hands was consistent with the hypothesis that they were guilty of having illicit knowl-
edge of the heart suit. At this point, the defense attorney pointed out that their play
of these hands was also perfectly consistent with their standard line of play. How-
ever, the prosecution then argued that, as long as their play was consistent with the
hypothesis of guilt, it must be counted as evidence toward that hypothesis. What do
you think of the reasoning of the prosecution?
```
```
Solution. The problem is basically one of determining how the introduction of new
evidence (in the preceding example, the playing of the hands) affects the probability
of a particular hypothesis. If we let H denote a particular hypothesis (such as the
hypothesis that Reese and Schapiro are guilty) and E the new evidence, then
```
##### P ( H | E )=

##### P ( HE )

##### P ( E )

##### =

##### P ( E | H ) P ( H )

```
P ( E | H ) P ( H )+ P ( E | Hc )[1− P ( H )]
```
##### (3.2)

```
where P(H) is our evaluation of the likelihood of the hypothesis before the intro-
duction of the new evidence. The new evidence will be in support of the hypothesis
whenever it makes the hypothesis more likely—that is, whenever P ( H | E )Ú P ( H ).
From Equation (3.2), this will be the case whenever
```
```
P ( E | H )Ú P ( E | H ) P ( H )+ P ( E | Hc )[1− P ( H )]
```
```
or, equivalently, whenever
P ( E | H )Ú P ( E | Hc )
```
```
In other words, any new evidence can be considered to be in support of a particular
hypothesis only if its occurrence is more likely when the hypothesis is true than when
it is false. In fact, the new probability of the hypothesis depends on its initial proba-
bility and the ratio of these conditional probabilities, since, from Equation (3.2),
```
##### P ( H | E )=

##### P ( H )

##### P ( H )+[1− P ( H )]

```
P ( E | Hc )
P ( E | H )
```
```
Hence, in the problem under consideration, the play of the cards can be con-
sidered to support the hypothesis of guilt only if such play would have been more
likely if the partnership were cheating than if they were not. As the prosecutor never
made this claim, his assertion that the evidence is in support of the guilt hypothesis is
invalid..
```
```
When the author of this text drinks iced tea at a coffee shop, he asks for a glass of
water along with the (same-sized) glass of tea. As he drinks the tea, he continuously
refills the tea glass with water. Assuming a perfect mixing of water and tea, he won-
dered about the probability that his final gulp would be tea. This wonderment led to
part (a) of the following problem and to a very interesting answer.
```
```
EXAMPLE 3h
Urn 1 initially has n red molecules and urn 2 has n blue molecules. Molecules are
randomly removed from urn 1 in the following manner: After each removal from
urn 1, a molecule is taken from urn 2 (if urn 2 has any molecules) and placed in urn 1.
The process continues until all the molecules have been removed. (Thus, there are
2 n removals in all.)
```

```
Section 3.3 Bayes’s Formula 71
```
```
(a) Find P ( R ), where R is the event that the final molecule removed from urn 1
is red.
(b) Repeat the problem when urn 1 initially has r 1 red molecules and b 1 blue
molecules and urn 2 initially has r 2 red molecules and b 2 blue molecules.
```
**_Solution._** (a) Focus attention on any particular red molecule, and let _F_ be the event
that this molecule is the final one selected. Now, in order for _F_ to occur, the molecule
in question must still be in the urn after the first _n_ molecules have been removed (at
which time urn 2 is empty). So, letting _Ni_ be the event that this molecule is not the _i_ th
molecule to be removed, we have

```
P ( F )= P ( N 1 ··· NnF )
= P ( N 1 ) P ( N 2 | N 1 )··· P ( Nn | N 1 ··· Nn − 1 ) P ( F | N 1 ··· Nn )
```
```
=
```
##### (

##### 1 −

##### 1

```
n
```
##### )

##### ···

##### (

##### 1 −

##### 1

```
n
```
##### )

##### 1

```
n
```
where the preceding formula uses the fact that the conditional probability that the
molecule under consideration is the final molecule to be removed, given that it is still
in urn 1 when only _n_ molecules remain, is, by symmetry, 1/ _n_.
Therefore, if we number the _n_ red molecules and let _Rj_ be the event that red
molecule number _j_ is the final molecule removed, then it follows from the preceding
formula that

```
P ( Rj )=
```
##### (

##### 1 −

##### 1

```
n
```
```
) n
1
n
```
Because the events _Rj_ are mutually exclusive, we obtain

##### P ( R )= P

##### ⎛

##### ⎜

##### ⎝

```
⋃ n
```
```
j = 1
```
```
Rj
```
##### ⎞

##### ⎟

##### ⎠=

```
∑ n
```
```
j = 1
```
```
P ( Rj )=( 1 −
```
##### 1

```
n
```
```
) n L e −^1
```
(b) Suppose now that urn _i_ initially has _ri_ red and _bi_ blue molecules, for _i_ =1, 2.To
find _P_ ( _R_ ), the probability that the final molecule removed is red, focus attention on
any molecule that is initially in urn 1. As in part (a), it follows that the probability
that this molecule is the final one removed is

```
p =
```
##### (

##### 1 −

##### 1

```
r 1 + b 1
```
```
) r 2 + b 2
1
r 1 + b 1
```
That is,

##### (

```
1 − r 1 +^1 b 1
```
```
) r 2 + b 2
is the probability that the molecule under consideration
```
is still in urn 1 when urn 2 becomes empty, and _r_ 1 +^1 _b_ 1 is the conditional probability,
given the preceding event, that the molecule under consideration is the final molecule
removed. Hence, if we let _O_ be the event that the last molecule removed is one of the
molecules originally in urn 1, then

```
P ( O )=( r 1 + b 1 ) p =
```
##### (

##### 1 −

##### 1

```
r 1 + b 1
```
```
) r 2 + b 2
```
To determine _P_ ( _R_ ), we condition on whether _O_ occurs, to obtain

```
P ( R )= P ( R | O ) P ( O )+ P ( R | Oc ) P ( Oc )
```
##### =

```
r 1
r 1 + b 1
```
##### (

##### 1 −

##### 1

```
r 1 + b 1
```
```
) r 2 + b 2
+
```
```
r 2
r 2 + b 2
```
##### (

##### 1 −

##### (

##### 1 −

##### 1

```
r 1 + b 1
```
```
) r 2 + b 2 )
```

**72** Chapter 3 Conditional Probability and Independence

```
If r 1 + b 1 = r 2 + b 2 = n , so that both urns initially have n molecules, then, when n
is large,
P ( L )L
```
```
r 1
r 1 + b 1
```
```
e −^1 +
```
```
r 2
r 2 + b 2
```
```
( 1 − e −^1 ).
```
```
The change in the probability of a hypothesis when new evidence is introduced can
be expressed compactly in terms of the change in the odds of that hypothesis, where
the concept of odds is defined as follows.
```
```
Definition
The odds of an event A are defined by
```
```
P ( A )
P ( Ac )
```
##### =

##### P ( A )

##### 1 − P ( A )

```
That is, the odds of an event A tell how much more likely it is that the event A occurs
than it is that it does not occur. For instance, if P ( A )=^23 ,then P ( A )= 2 P ( Ac ),so
the odds are 2. If the odds are equal toα, then it is common to say that the odds are
“αto 1” in favor of the hypothesis.
```
```
Consider now a hypothesis H that is true with probability P ( H ), and suppose that
new evidence E is introduced. Then the conditional probabilities, given the evidence
E ,that H is true and that H is not true are respectively given by
```
```
P ( H | E )=
```
##### P ( E | H ) P ( H )

##### P ( E )

```
P ( Hc | E )=
```
```
P ( E | Hc ) P ( Hc )
P ( E )
Therefore, the new odds after the evidence E has been introduced are
```
```
P ( H | E )
P ( Hc | E )
```
##### =

##### P ( H )

```
P ( Hc )
```
##### P ( E | H )

```
P ( E | Hc )
```
##### (3.3)

```
That is, the new value of the odds of H is the old value, multiplied by the ratio of the
conditional probability of the new evidence given that H is true to the conditional
probability given that H is not true. Thus, Equation (3.3) verifies the result of Exam-
ple 3f, since the odds, and thus the probability of H , increase whenever the new evi-
dence is more likely when H is true than when it is false. Similarly, the odds decrease
whenever the new evidence is more likely when H is false than when it is true.
```
```
EXAMPLE 3i
An urn contains two type A coins and one type B coin. When a type A coin is flipped,
it comes up heads with probability 1/4, whereas when a type B coin is flipped, it comes
up heads with probability 3/4. A coin is randomly chosen from the urn and flipped.
Given that the flip landed on heads, what is the probability that it was a type A coin?
```
```
Solution. Let A be the event that a type A coin was flipped, and let B = Ac be the
event that a type B coin was flipped. We want P ( A |heads), where heads is the event
that the flip landed on heads. From Equation (3.3), we see that
P ( A |heads)
P ( Ac |heads)
```
##### =

##### P ( A )

##### P ( B )

```
P (heads| A )
P (heads| B )
```
```
=
```
##### 2 / 3

##### 1 / 3

##### 1 / 4

##### 3 / 4

##### = 2 / 3


```
Section 3.3 Bayes’s Formula 73
```
Hence, the odds are 2/3 : 1, or, equivalently, the probability is 2/5 that a type _A_ coin
was flipped..

Equation (3.1) may be generalized as follows: Suppose that _F_ 1 , _F_ 2 ,..., _Fn_ are mutu-
ally exclusive events such that

```
⋃ n
```
```
i = 1
```
```
Fi = S
```
In other words, exactly one of the events _F_ 1 , _F_ 2 ,..., _Fn_ must occur. By writing

##### E =

```
⋃ n
```
```
i = 1
```
```
EFi
```
and using the fact that the events _EFi_ , _i_ =1,..., _n_ are mutually exclusive, we obtain

##### P ( E )=

```
∑ n
```
```
i = 1
```
```
P ( EFi )
```
##### =

```
∑ n
```
```
i = 1
```
```
P ( E | Fi ) P ( Fi ) (3.4)
```
Thus, Equation (3.4) shows how, for given events _F_ 1 , _F_ 2 ,..., _Fn_ , of which one and
only one must occur, we can compute _P_ ( _E_ )by first conditioning on which one of
the _Fi_ occurs. That is, Equation (3.4) states that _P_ ( _E_ )is equal to a weighted average
of _P_ ( _E_ | _Fi_ ), each term being weighted by the probability of the event on which it is
conditioned.

**_EXAMPLE 3j_**

In Example 5j of Chapter _2_ , we considered the probability that, for a randomly shuf-
fled deck, the card following the first ace is some specified card, and we gave a combi-
natorial argument to show that this probability is 521 .Here is a probabilistic argument
based on conditioning: Let _E_ be the event that the card following the first ace is some
specified card, say, card _x_. To compute _P_ ( _E_ ), we ignore card _x_ and condition on the
relative ordering of the other _51_ cards in the deck. Letting **O** be the ordering gives

```
P ( E )=
```
##### ∑

```
O
```
##### P ( E | O ) P ( O )

Now, given **O** , there are _52_ possible orderings of the cards, corresponding to hav-
ing card _x_ being the _i_ th card in the deck, _i_ = 1,...,52.But because all 52! possi-
ble orderings were initially equally likely, it follows that, conditional on **O** , each
of the _52_ remaining possible orderings is equally likely. Because card _x_ will follow
the first ace for only one of these orderings, we have _P_ ( _E_ | **O** )= 1 /52, implying that
_P_ ( _E_ )= 1 /52..

Again, let _F_ 1 ,..., _Fn_ be a set of mutually exclusive and exhaustive events (meaning
that exactly one of these events must occur).
Suppose now that _E_ has occurred and we are interested in determining which one
of the _Fj_ also occurred. Then, by Equation (3.4), we have the following proposition.


**74** Chapter 3 Conditional Probability and Independence

```
Proposition 3.1.
```
```
P ( Fj | E )=
```
```
P ( EFj )
P ( E )
```
```
=
```
```
P ( E | Fj ) P ( Fj )
∑ n
```
```
i = 1
```
```
P ( E | Fi ) P ( Fi )
```
##### (3.5)

```
Equation (3.5) is known as Bayes’s formula, after the English philosopher Thomas
Bayes. If we think of the events Fj as being possible “hypotheses” about some sub-
ject matter, then Bayes’s formula may be interpreted as showing us how opinions
about these hypotheses held before the experiment was carried out [that is, the P ( Fj )]
should be modified by the evidence produced by the experiment.
```
```
EXAMPLE 3k
A plane is missing, and it is presumed that it was equally likely to have gone down
in any of 3 possible regions. Let 1− β i , i =1, 2, 3, denote the probability that the
plane will be found upon a search of the i th region when the plane is, in fact, in that
region. (The constantsβ i are called overlook probabilities , because they represent the
probability of overlooking the plane; they are generally attributable to the geograph-
ical and environmental conditions of the regions.) What is the conditional probability
that the plane is in the i th region given that a search of region 1 is unsuccessful?
```
```
Solution. Let Ri , i =1, 2, 3, be the event that the plane is in region i , and let E be
the event that a search of region 1 is unsuccessful. From Bayes’s formula, we obtain
```
##### P ( R 1 | E )=

##### P ( ER 1 )

##### P ( E )

##### =

##### P ( E | R 1 ) P ( R 1 )

##### ∑^3

```
i = 1
```
```
P ( E | Ri ) P ( Ri )
```
##### =

```
(β 1 )^13
(β 1 )^13 +( 1 )^13 +( 1 )^13
```
```
=
```
```
β 1
β 1 + 2
```
```
For j =2, 3,
```
```
P ( Rj | E )=
```
```
P ( E | Rj ) P ( Rj )
P ( E )
```
```
=
```
##### ( 1 )^13

```
(β 1 )^13 +^13 +^13
```
```
=
```
##### 1

```
β 1 + 2
```
```
j =2, 3
```
```
Note that the updated (that is, the conditional) probability that the plane is in
region j , given the information that a search of region 1 did not find it, is greater than
```

```
Section 3.3 Bayes’s Formula 75
```
the initial probability that it was in region _j_ when _j_ Z1 and is less than the initial prob-
ability when _j_ =1. This statement is certainly intuitive, since not finding the plane in
region 1 would seem to decrease its chance of being in that region and increase its
chance of being elsewhere. Further, the conditional probability that the plane is in
region 1 given an unsuccessful search of that region is an increasing function of the
overlook probabilityβ 1. This statement is also intuitive, since the largerβ 1 is, the
more it is reasonable to attribute the unsuccessful search to “bad luck” as opposed
to the plane’s not being there. Similarly, _P_ ( _Rj_ | _E_ ), _j_ Z 1, is a decreasing function
ofβ 1..

The next example has often been used by unscrupulous probability students to win
money from their less enlightened friends.

**_EXAMPLE 3l_**

Suppose that we have 3 cards that are identical in form, except that both sides of the
first card are colored red, both sides of the second card are colored black, and one
side of the third card is colored red and the other side black. The 3 cards are mixed
up in a hat, and 1 card is randomly selected and put down on the ground. If the upper
side of the chosen card is colored red, what is the probability that the other side is
colored black?

**_Solution._** Let _RR, BB_ ,and _RB_ denote, respectively, the events that the chosen card
is all red, all black, or the red–black card. Also, let _R_ be the event that the upturned
side of the chosen card is red. Then the desired probability is obtained by

##### P ( RB | R )=

##### P ( RB ∩ R )

##### P ( R )

##### =

##### P ( R | RB ) P ( RB )

##### P ( R | RR ) P ( RR )+ P ( R | RB ) P ( RB )+ P ( R | BB ) P ( BB )

##### =

##### (

```
1
2
```
##### )(

```
1
3
```
##### )

##### ( 1 )

##### (

```
1
3
```
##### )

##### +

##### (

```
1
2
```
##### )(

```
1
3
```
##### )

##### + 0

##### (

```
1
3
```
##### )=

##### 1

##### 3

Hence, the answer is^13. Some students guess^12 as the answer by incorrectly reasoning
that, given that a red side appears, there are two equally likely possibilities: that the
card is the all-red card or the red–black card. Their mistake, however, is in assuming
that these two possibilities are equally likely. For, if we think of each card as consist-
ing of two distinct sides, then we see that there are 6 equally likely outcomes of the
experiment—namely, _R_ 1 , _R_ 2 , _B_ 1 , _B_ 2 , _R_ 3 , _B_ 3 —where the outcome is _R_ 1 if the first side
of the all-red card is turned face up, _R_ 2 if the second side of the all-red card is turned
face up, _R_ 3 if the red side of the red–black card is turned face up, and so on. Since the
other side of the upturned red side will be black only if the outcome is _R_ 3 , we see that
the desired probability is the conditional probability of _R_ 3 given that either _R_ 1 or _R_ 2
or _R_ 3 occurred, which obviously equals^13..

**_EXAMPLE 3m_**

A new couple, known to have two children, has just moved into town. Suppose that
the mother is encountered walking with one of her children. If this child is a girl, what
is the probability that both children are girls?


**76** Chapter 3 Conditional Probability and Independence

```
Solution. Let us start by defining the following events:
G 1 : the first (that is, the oldest) child is a girl.
G 2 : the second child is a girl.
G : the child seen with the mother is a girl.
Also, let B 1 , B 2 ,and B denote similar events, except that “girl” is replaced by “boy.”
Now, the desired probability is P ( G 1 G 2 | G ), which can be expressed as follows:
```
##### P ( G 1 G 2 | G )=

##### P ( G 1 G 2 G )

##### P ( G )

##### =

##### P ( G 1 G 2 )

##### P ( G )

```
Also,
```
```
P ( G )= P ( G | G 1 G 2 ) P ( G 1 G 2 )+ P ( G | G 1 B 2 ) P ( G 1 B 2 )
+ P ( G | B 1 G 2 ) P ( B 1 G 2 )+ P ( G | B 1 B 2 ) P ( B 1 B 2 )
= P ( G 1 G 2 )+ P ( G | G 1 B 2 ) P ( G 1 B 2 )+ P ( G | B 1 G 2 ) P ( B 1 G 2 )
```
```
where the final equation used the results P ( G | G 1 G 2 )=1and P ( G | B 1 B 2 )=0. If we
now make the usual assumption that all 4 gender possibilities are equally likely, then
we see that
```
##### P ( G 1 G 2 | G )=

```
1
4
1
4 + P ( G | G^1 B^2 )/^4 + P ( G | B^1 G^2 )/^4
=
```
##### 1

##### 1 + P ( G | G 1 B 2 )+ P ( G | B 1 G 2 )

```
Thus, the answer depends on whatever assumptions we want to make about the con-
ditional probabilities that the child seen with the mother is a girl given the event G 1 B 2
and that the child seen with the mother is a girl given the event G 2 B 1. For instance, if
we want to assume, on the one hand, that, independently of the genders of the chil-
dren, the child walking with the mother is the elder child with some probability p ,
then it would follow that
```
```
P ( G | G 1 B 2 )= p = 1 − P ( G | B 1 G 2 )
```
```
implying under this scenario that
```
##### P ( G 1 G 2 | G )=

##### 1

##### 2

```
If, on the other hand, we were to assume that if the children are of different genders,
then the mother would choose to walk with the girl with probability q , independently
of the birth order of the children, then we would have
```
```
P ( G | G 1 B 2 )= P ( G | B 1 G 2 )= q
```
```
implying that
P ( G 1 G 2 | G )=
```
##### 1

```
1 + 2 q
```
```
For instance, if we took q =1, meaning that the mother would always choose to walk
with a daughter, then the conditional probability the she has two daughters would be
```

```
Section 3.3 Bayes’s Formula 77
```
1
3 , which is in accord with Example 2b because seeing the mother with a daughter is
now equivalent to the event that she has at least one daughter.
Hence, as stated, the problem is incapable of solution. Indeed, even when the usual
assumption about equally likely gender probabilities is made, we still need to make
additional assumptions before a solution can be given. This is because the sample
space of the experiment consists of vectors of the form _s_ 1 , _s_ 2 , _i_ , where _s_ 1 is the gen-
der of the older child, _s_ 2 is the gender of the younger child, and _i_ identifies the birth
order of the child seen with the mother. As a result, to specify the probabilities of
the events of the sample space, it is not enough to make assumptions only about
the genders of the children; it is also necessary to assume something about the con-
ditional probabilities as to which child is with the mother given the genders of the
children..

**_EXAMPLE 3n_**

A bin contains 3 different types of disposable flashlights. The probability that a type 1
flashlight will give over 100 hours of use is .7, with the corresponding probabilities for
type 2 and type 3 flashlights being .4 and .3, respectively. Suppose that 20 percent of
the flashlights in the bin are type 1, 30 percent are type 2, and 50 percent are type 3.

```
(a) What is the probability that a randomly chosen flashlight will give more than
100 hours of use?
(b) Given that a flashlight lasted over 100 hours, what is the conditional probability
that it was a type j flashlight, j =1, 2, 3?
```
**_Solution._** (a) Let _A_ denote the event that the flashlight chosen will give over 100
hours of use, and let _Fj_ be the event that a type _j_ flashlight is chosen, _j_ =1, 2, 3. To
compute _P_ ( _A_ ), we condition on the type of the flashlight, to obtain

```
P ( A )= P ( A | F 1 ) P ( F 1 )+ P ( A | F 2 ) P ( F 2 )+ P ( A | F 3 ) P ( F 3 )
=(. 7 )(. 2 )+(. 4 )(. 3 )+(. 3 )(. 5 )=. 41
```
There is a 41 percent chance that the flashlight will last for over 100 hours.
(b) The probability is obtained by using Bayes’s formula:

```
P ( Fj | A )=
```
```
P ( AFj )
P ( A )
```
```
=
```
```
P ( A | Fj ) P ( Fj )
```
. 41

Thus,

```
P ( F 1 | A )=(. 7 )(. 2 )/. 41 = 14 / 41
P ( F 2 | A )=(. 4 )(. 3 )/. 41 = 12 / 41
P ( F 3 | A )=(. 3 )(. 5 )/. 41 = 15 / 41
```
For instance, whereas the initial probability that a type 1 flashlight is chosen is only
.2, the information that the flashlight has lasted over 100 hours raises the probability
of this event to 14/ 41 L.341..

**_EXAMPLE 3o_**

A crime has been committed by a solitary individual, who left some DNA at the
scene of the crime. Forensic scientists who studied the recovered DNA noted that


**78** Chapter 3 Conditional Probability and Independence

```
only five strands could be identified and that each innocent person, independently,
would have a probability of 10−^5 of having his or her DNA match on all five strands.
The district attorney supposes that the perpetrator of the crime could be any of the
one million residents of the town. Ten thousand of these residents have been released
from prison within the past 10 years; consequently, a sample of their DNA is on file.
Before any checking of the DNA file, the district attorney feels that each of the ten
thousand ex-criminals has probabilityαof being guilty of the new crime, while each
of the remaining 990,000 residents has probabilityβ, whereα = c β. (That is, the
district attorney supposes that each recently released convict is c times as likely to
be the crime’s perpetrator as is each town member who is not a recently released
convict.) When the DNA that is analyzed is compared against the database of the
ten thousand ex-convicts, it turns out that A. J. Jones is the only one whose DNA
matches the profile. Assuming that the district attorney’s estimate of the relationship
betweenαandβis accurate, what is the probability that A. J. is guilty?
```
```
Solution. To begin, note that, because probabilities must sum to 1, we have
```
```
1 =10,000α+990,000β=(10,000 c +990,000)β
```
```
Thus,
```
```
β=
```
##### 1

```
10,000 c +990,000
```
```
, α=
```
```
c
10,000 c +990,000
```
```
Now, let G be the event that A. J. is guilty, and let M denote the event that A. J. is
the only one of the ten thousand on file to have a match. Then
```
##### P ( G | M )=

##### P ( GM )

##### P ( M )

##### =

##### P ( G ) P ( M | G )

```
P ( M | G ) P ( G )+ P ( M | Gc ) P ( Gc )
```
```
On the one hand, if A. J. is guilty, then he will be the only one to have a DNA match
if none of the others on file have a match. Therefore,
```
```
P ( M | G )=( 1 − 10 −^5 )^9999
```
```
On the other hand, if A. J. is innocent, then in order for him to be the only match, his
DNA must match (which will occur with probability 10−^5 ), all others in the database
must be innocent, and none of these others can have a match. Now, given that A. J.
is innocent, the conditional probability that all the others in the database are also
innocent is
```
```
P (all others innocent| AJ innocent)=
```
```
P (all in database innocent)
P ( AJ innocent)
```
```
=
```
```
1 −10,000α
1 −α
```
```
Also, the conditional probability, given their innocence, that none of the others in the
database will have a match is( 1 − 10 −^5 )^9999. Therefore,
```
```
P ( M | Gc )= 10 −^5
```
##### (

```
1 −10,000α
1 −α
```
##### )

##### ( 1 − 10 −^5 )^9999


```
Section 3.4 Independent Events 79
```
```
Because P ( G )=α, the preceding formula gives
```
##### P ( G | M )=

```
α
α+ 10 −^5 ( 1 −10,000α)
```
##### =

##### 1

##### . 9 +^10

```
− 5
α
Thus, if the district attorney’s initial feelings were that an arbitrary ex-convict was
100 times more likely to have committed the crime than was a nonconvict (that is,
c =100), thenα=19,900^1 and
```
##### P ( G | M )=

##### 1

##### 1. 099

##### L 0. 9099

```
If the district attorney initially felt that the appropriate ratio was c =10, thenα=
1
109, 000
```
```
and
```
##### P ( G | M )=

##### 1

##### 1. 99

##### L 0. 5025

```
If the district attorney initially felt that the criminal was equally likely to be any of
the members of the town( c = 1 ),thenα= 10 −^6 and
```
##### P ( G | M )=

##### 1

##### 10. 9

##### L 0. 0917

```
Thus, the probability ranges from approximately 9 percent when the district attor-
ney’s initial assumption is that all the members of the population have the same
chance of being the perpetrator to approximately 91 percent when she assumes that
each ex-convict is 100 times more likely to be the criminal than is a specified townsper-
son who is not an ex-convict..
```
### 3.4 IndependentEvents.............................

```
The previous examples of this chapter show that P ( E | F ), the conditional probabil-
ity of E given F , is not generally equal to P ( E ), the unconditional probability of E.
In other words, knowing that F has occurred generally changes the chances of E ’s
occurrence. In the special cases where P ( E | F )does in fact equal P ( E ), we say that E
is independent of F. That is, E is independent of F if knowledge that F has occurred
does not change the probability that E occurs.
Since P ( E | F )= P ( EF )/ P ( F ), it follows that E is independent of F if
```
```
P ( EF )= P ( E ) P ( F ) (4.1)
```
```
The fact that Equation (4.1) is symmetric in E and F shows that whenever E is inde-
pendent of F , F is also independent of E. We thus have the following definition.
```
```
Definition
```
```
Two events E and F are said to be independent if Equation (4.1) holds.
Two events E and F that are not independent are said to be dependent.
```
```
EXAMPLE 4a
A card is selected at random from an ordinary deck of 52 playing cards. If E is the
event that the selected card is an ace and F is the event that it is a spade, then E
```

**80** Chapter 3 Conditional Probability and Independence

```
and F are independent. This follows because P ( EF )= 521 , whereas P ( E )= 524 and
P ( F )=^1352..
```
```
EXAMPLE 4b
Two coins are flipped, and all 4 outcomes are assumed to be equally likely. If E is
the event that the first coin lands on heads and F the event that the second lands
on tails, then E and F are independent, since P ( EF )= P ({( H , T )})=^14 , whereas
P ( E )= P ({( H , H ),( H , T )})=^12 and P ( F )= P ({( H , T ),( T , T )})=^12..
```
```
EXAMPLE 4c
Suppose that we toss 2 fair dice. Let E 1 denote the event that the sum of the dice is 6
and F denote the event that the first die equals 4. Then
```
##### P ( E 1 F )= P ({(4, 2)})=

##### 1

##### 36

```
whereas
```
```
P ( E 1 ) P ( F )=
```
##### (

##### 5

##### 36

##### )(

##### 1

##### 6

##### )

##### =

##### 5

##### 216

```
Hence, E 1 and F are not independent. Intuitively, the reason for this is clear because
if we are interested in the possibility of throwing a 6 (with 2 dice), we shall be quite
happy if the first die lands on 4 (or, indeed, on any of the numbers 1, 2, 3, 4, and 5),
for then we shall still have a possibility of getting a total of 6. If, however, the first
die landed on 6, we would be unhappy because we would no longer have a chance of
getting a total of 6. In other words, our chance of getting a total of 6 depends on the
outcome of the first die; thus, E 1 and F cannot be independent.
Now, suppose that we let E 2 be the event that the sum of the dice equals 7. Is E 2
independent of F? The answer is yes, since
```
##### P ( E 2 F )= P ({(4, 3)})=

##### 1

##### 36

```
whereas
```
```
P ( E 2 ) P ( F )=
```
##### (

##### 1

##### 6

##### )(

##### 1

##### 6

##### )

##### =

##### (

##### 1

##### 36

##### )

```
We leave it for the reader to present the intuitive argument why the event that the
sum of the dice equals 7 is independent of the outcome on the first die..
```
```
EXAMPLE 4d
If we let E denote the event that the next president is a Republican and F the event
that there will be a major earthquake within the next year, then most people would
probably be willing to assume that E and F are independent. However, there would
probably be some controversy over whether it is reasonable to assume that E is inde-
pendent of G , where G is the event that there will be a recession within two years
after the election..
```
```
We now show that if E is independent of F ,then E is also independent of Fc.
```

```
Section 3.4 Independent Events 81
```
**Proposition 4.1.** If _E_ and _F_ are independent, then so are _E_ and _Fc_.

```
Proof. Assume that E and F are independent. Since E = EF ∪ EFc and EF and
EFc are obviously mutually exclusive, we have
```
```
P ( E )= P ( EF )+ P ( EFc )
= P ( E ) P ( F )+ P ( EFc )
```
```
or, equivalently,
```
```
P ( EFc )= P ( E )[1− P ( F )]
= P ( E ) P ( Fc )
```
```
and the result is proved.
```
Thus, if _E_ is independent of _F_ , then the probability of _E_ ’s occurrence is unchanged
by information as to whether or not _F_ has occurred.
Suppose now that _E_ is independent of _F_ and is also independent of _G_ .Is _E_ then
necessarily independent of _FG_? The answer, somewhat surprisingly, is no, as the fol-
lowing example demonstrates.

**_EXAMPLE 4e_**
Two fair dice are thrown. Let _E_ denote the event that the sum of the dice is 7. Let _F_
denote the event that the first die equals 4 and _G_ denote the event that the second
die equals 3. From Example 4c, we know that _E_ is independent of _F_ , and the same
reasoning as applied there shows that _E_ is also independent of _G_ ; but clearly, _E_ is not
independent of _FG_ [since _P_ ( _E_ | _FG_ )=1]..

It would appear to follow from Example 4e that an appropriate definition of the
independence of three events _E_ , _F_ ,and _G_ would have to go further than merely

assuming that all of the

##### (

##### 3

##### 2

##### )

```
pairs of events are independent. We are thus led to the
```
following definition.

```
Definition
Three events E , F ,and G are said to be independent if
```
```
P ( EFG )= P ( E ) P ( F ) P ( G )
P ( EF )= P ( E ) P ( F )
P ( EG )= P ( E ) P ( G )
P ( FG )= P ( F ) P ( G )
```
Note that if _E_ , _F_ ,and _G_ are independent, then _E_ will be independent of any event
formed from _F_ and _G_. For instance, _E_ is independent of _F_ ∪ _G_ , since

```
P [ E ( F ∪ G )]= P ( EF ∪ EG )
= P ( EF )+ P ( EG )− P ( EFG )
= P ( E ) P ( F )+ P ( E ) P ( G )− P ( E ) P ( FG )
= P ( E )[ P ( F )+ P ( G )− P ( FG )]
= P ( E ) P ( F ∪ G )
```

**82** Chapter 3 Conditional Probability and Independence

```
Of course, we may also extend the definition of independence to more than three
events. The events E 1 , E 2 ,..., En are said to be independent if, for every subset
E 1 ′, E 2 ′,..., Er ′, r ... n , of these events,
```
```
P ( E 1 ′ E 2 ′··· Er ′)= P ( E 1 ′) P ( E 2 ′)··· P ( Er ′)
```
```
Finally, we define an infinite set of events to be independent if every finite subset of
those events is independent.
Sometimes, a probability experiment under consideration consists of performing a
sequence of subexperiments. For instance, if the experiment consists of continually
tossing a coin, we may think of each toss as being a subexperiment. In many cases, it
is reasonable to assume that the outcomes of any group of the subexperiments have
no effect on the probabilities of the outcomes of the other subexperiments. If such
is the case, we say that the subexperiments are independent. More formally, we say
that the subexperiments are independent if E 1 , E 2 ,..., En ,...is necessarily an inde-
pendent sequence of events whenever Ei is an event whose occurrence is completely
determined by the outcome of the i th subexperiment.
If each subexperiment has the same set of possible outcomes, then the subexperi-
ments are often called trials.
```
```
EXAMPLE 4f
An infinite sequence of independent trials is to be performed. Each trial results in a
success with probability p and a failure with probability 1− p. What is the probabil-
ity that
(a) at least 1 success occurs in the first n trials;
(b) exactly k successes occur in the first n trials;
(c) all trials result in successes?
```
```
Solution. In order to determine the probability of at least 1 success in the first n trials,
it is easiest to compute first the probability of the complementary event: that of no
successes in the first n trials. If we let Ei denote the event of a failure on the i th trial,
then the probability of no successes is, by independence,
```
```
P ( E 1 E 2 ··· En )= P ( E 1 ) P ( E 2 )··· P ( En )=( 1 − p ) n
```
```
Hence, the answer to part (a) is 1−( 1 − p ) n.
To compute the answer to part (b), consider any particular sequence of the first
n outcomes containing k successes and n − k failures. Each one of these sequences
will, by the assumed independence of trials, occur with probability pk ( 1 − p ) n − k.
Since there are
```
##### (

```
n
k
```
##### )

```
such sequences (there are n !/ k !( n − k )! permutations of k
successes and n − k failures), the desired probability in part (b) is
```
```
P {exactly k successes}=
```
##### (

```
n
k
```
##### )

```
pk ( 1 − p ) n − k
```
```
To answer part (c), we note that, by part (a), the probability of the first n trials all
resulting in success is given by
```
```
P ( Ec 1 Ec 2 ··· Ecn )= pn
```

```
Section 3.4 Independent Events 83
```
Thus, using the continuity property of probabilities (Section 2.6), we see that the
desired probability is given by

##### P

##### ⎛

##### ⎝

```
⋂q
```
```
i = 1
```
```
Eci
```
##### ⎞

##### ⎠= P

##### ⎛

```
⎝lim
n →q
```
```
⋂ n
```
```
i = 1
```
```
Eci
```
##### ⎞

##### ⎠

```
= lim
n →q
```
##### P

##### ⎛

##### ⎝

```
⋂ n
```
```
i = 1
```
```
Eci
```
##### ⎞

##### ⎠

```
=lim
n
pn =
```
##### {

```
0if p < 1
1if p = 1
```
##### .

**_EXAMPLE 4g_**
A system composed of _n_ separate components is said to be a parallel system if it
functions when at least one of the components functions. (See Figure 3.2.) For such a
system, if component _i_ , which is independent of the other components, functions with
probability _pi_ , _i_ =1,..., _n_ , what is the probability that the system functions?

**_Solution._** Let _Ai_ denote the event that component _i_ functions. Then

```
P {system functions}= 1 − P {system does not function}
= 1 − P {all components do not function}
```
##### = 1 − P

##### ⎛

##### ⎝

##### ⋂

```
i
```
```
Aci
```
##### ⎞

##### ⎠

##### = 1 −

```
∏ n
```
```
i = 1
```
```
( 1 − pi ) by independence.
```
```
A B
```
```
1
```
```
2
```
```
3
```
```
n
```
```
FIGURE 3.2: Parallel System: Functions if Current Flows from A to B
```
**_EXAMPLE 4h_**
Independent trials consisting of rolling a pair of fair dice are performed. What is the
probability that an outcome of 5 appears before an outcome of 7 when the outcome
of a roll is the sum of the dice?

**_Solution._** If we let _En_ denote the event that no 5 or 7 appears on the first _n_ −1 trials
anda5appears on the _n_ th trial, then the desired probability is

##### P

##### ⎛

##### ⎝

```
⋃q
```
```
n = 1
```
```
En
```
##### ⎞

##### ⎠=

```
∑q
```
```
n = 1
```
```
P ( En )
```

**84** Chapter 3 Conditional Probability and Independence

```
Now, since P {5 on any trial}= 364 and P {7 on any trial}= 366 , we obtain, by the inde-
pendence of trials,
```
```
P ( En )=
```
##### (

##### 1 −

##### 10

##### 36

```
) n − 1
4
36
```
```
Thus,
```
##### P

##### ⎛

##### ⎝

```
⋃q
```
```
n = 1
```
```
En
```
##### ⎞

##### ⎠=^1

##### 9

```
∑q
```
```
n = 1
```
##### (

##### 13

##### 18

```
) n − 1
```
##### =

##### 1

##### 9

##### 1

##### 1 −^1318

##### =

##### 2

##### 5

```
This result could also have been obtained by the use of conditional probabilities.
If we let E be the event that a 5 occurs before a 7, then we can obtain the desired
probability, P ( E ), by conditioning on the outcome of the first trial, as follows: Let F
be the event that the first trial results in a 5, let G be the event that it results in a 7, and
let H be the event that the first trial results in neither a 5 nor a 7. Then, conditioning
on which one of these events occurs gives
```
```
P ( E )= P ( E | F ) P ( F )+ P ( E | G ) P ( G )+ P ( E | H ) P ( H )
```
```
However,
```
```
P ( E | F )= 1
P ( E | G )= 0
P ( E | H )= P ( E )
```
```
The first two equalities are obvious. The third follows because if the first outcome
results in neither a 5 nor a 7, then at that point the situation is exactly as it was when
the problem first started—namely, the experimenter will continually roll a pair of fair
dice until either a 5 or 7 appears. Furthermore, the trials are independent; therefore,
the outcome of the first trial will have no effect on subsequent rolls of the dice. Since
P ( F )= 364 , P ( G )= 366 ,and P ( H )=^2636 , it follows that
```
##### P ( E )=

##### 1

##### 9

##### + P ( E )

##### 13

##### 18

```
or
P ( E )=
```
##### 2

##### 5

```
The reader should note that the answer is quite intuitive. That is, because a 5 occurs
on any roll with probability 364 and a 7 with probability 366 , it seems intuitive that the
odds that a 5 appears before a 7 should be 6 to 4 against. The probability should then
be 104 , as indeed it is.
The same argument shows that if E and F are mutually exclusive events of an
experiment, then, when independent trials of the experiment are performed, the
event E will occur before the event F with probability
P ( E )
P ( E )+ P ( F ).
```

```
Section 3.4 Independent Events 85
```
**_EXAMPLE 4i_**
There are _n_ types of coupons, and each new one collected is independently of type _i_
with probability _pi_ ,

∑ _n
i_ = 1 _pi_ =1. Suppose _k_ coupons are to be collected. If _Ai_ is the
event that there is at least one type _i_ coupon among those collected, then, for _i_ Z _j_ ,
find

```
(a) P ( Ai )
(b) P ( Ai ∪ Aj )
(c) P ( Ai | Aj )
```
**_Solution._**

```
P ( Ai )= 1 − P ( Aci )
= 1 − P {no coupon is type i }
= 1 −( 1 − pi ) k
```
where the preceding used that each coupon is, independently, not of type _i_ with prob-
ability 1− _pi_ .Similarly,

```
P ( Ai ∪ Aj )= 1 − P (
```
##### (

```
Ai ∪ Aj ) c
```
##### )

```
= 1 − P {no coupon is either type i or type j }
= 1 −( 1 − pi − pj ) k
```
where the preceding used that each coupon is, independently, neither of type _i_ nor
type _j_ with probability 1− _pi_ − _pj_.
To determine _P_ ( _Ai_ | _Aj_ ), we will use the identity

```
P ( Ai ∪ Aj )= P ( Ai )+ P ( Aj )− P ( AiAj )
```
which, in conjunction with parts (a) and (b), yields

```
P ( AiAj )= 1 −( 1 − pi ) k + 1 −( 1 − pj ) k −[1−( 1 − pi − pj ) k ]
= 1 −( 1 − pi ) k −( 1 − pj ) k +( 1 − pi − pj ) k
```
Consequently,

```
P ( Ai | Aj )=
```
```
P ( AiAj )
P ( Aj )
```
##### =

```
1 −( 1 − pi ) k −( 1 − pj ) k +( 1 − pi − pj ) k
1 −( 1 − pj ) k.
```
The next example presents a problem that occupies an honored place in the his-
tory of probability theory. This is the famous _problem of the points_. In general terms,
the problem is this: Two players put up stakes and play some game, with the stakes
to go to the winner of the game. An interruption requires them to stop before either
has won and when each has some sort of a “partial score.” How should the stakes be
divided?
This problem was posed to the French mathematician Blaise Pascal in 1654 by
the Chevalier de Mer ́e, who was a professional gambler at that time. In attacking ́
the problem, Pascal introduced the important idea that the proportion of the prize
deserved by the competitors should depend on their respective probabilities of win-
ning if the game were to be continued at that point. Pascal worked out some special
cases and, more importantly, initiated a correspondence with the famous French-
man Pierre de Fermat, who had a great reputation as a mathematician. The resulting
exchange of letters not only led to a complete solution to the problem of the points,


**86** Chapter 3 Conditional Probability and Independence

```
but also laid the framework for the solution to many other problems connected with
games of chance. This celebrated correspondence, dated by some as the birth date
of probability theory, was also important in stimulating interest in probability among
the mathematicians in Europe, for Pascal and Fermat were both recognized as being
among the foremost mathematicians of the time. For instance, within a short time of
their correspondence, the young Dutch mathematician Christiaan Huygens came to
Paris to discuss these problems and solutions, and interest and activity in this new
field grew rapidly.
```
```
EXAMPLE 4j The problem of the points
Independent trials resulting in a success with probability p and a failure with proba-
bility 1− p are performed. What is the probability that n successes occur before m
failures? If we think of A and B as playing a game such that A gains 1 point when a
success occurs and B gains 1 point when a failure occurs, then the desired probability
is the probability that A would win if the game were to be continued in a position
where A needed n and B needed m more points to win.
```
```
Solution. We shall present two solutions. The first is due to Pascal and the second to
Fermat.
Let us denote by Pn , m the probability that n successes occur before m failures. By
conditioning on the outcome of the first trial, we obtain
```
```
Pn , m = pPn −1, m +( 1 − p ) Pn , m − 1 n Ú1, m Ú 1
```
```
(Why? Reason it out.) Using the obvious boundary conditions Pn ,0=0, P 0, m =1, we
can solve these equations for Pn , m. Rather than go through the tedious details, let us
instead consider Fermat’s solution.
Fermat argued that, in order for n successes to occur before m failures, it is nec-
essary and sufficient that there be at least n successes in the first m + n −1 trials.
(Even if the game were to end before a total of m + n −1 trials were completed, we
could still imagine that the necessary additional trials were performed.) This is true,
for if there are at least n successes in the first m + n − 1 trials, there could be at
most m −1 failures in those m + n −1 trials; thus, n successes would occur before
m failures. If, however, there were fewer than n successes in the first m + n − 1
trials, there would have to be at least m failures in that same number of trials; thus, n
successes would not occur before m failures.
Hence, since, as shown in Example 4f, the probability of exactly k successes in
m + n −1 trials is
```
##### (

```
m + n − 1
k
```
##### )

```
pk ( 1 − p ) m + n −^1 − k , it follows that the desired
probability of n successes before m failures is
```
```
Pn , m =
```
```
m +∑ n − 1
```
```
k = n
```
##### (

```
m + n − 1
k
```
##### )

```
pk ( 1 − p ) m + n −^1 − k
.
```
```
Our next two examples deal with gambling problems, with the first having a sur-
prisingly elegant analysis.∗
```
```
EXAMPLE 4k
Suppose that initially there are r players, with player i having ni units, ni >0, i =
1,..., r .At each stage, two of the players are chosen to play a game, with the winner
∗The remainder of this section should be considered optional.
```

```
Section 3.4 Independent Events 87
```
of the game receiving 1 unit from the loser. Any player whose fortune drops to 0 is
eliminated, and this continues until a single player has all _n_ K

∑ _r
i_ = 1 _ni_ units, with
that player designated as the victor. Assuming that the results of successive games
are independent and that each game is equally likely to be won by either of its two
players, find _Pi_ , the probability that player _i_ is the victor?

**_Solution._** To begin, suppose that there are _n_ players, with each player initially having
1 unit. Consider player _i_. Each stage she plays will be equally likely to result in her
either winning or losing 1 unit, with the results from each stage being independent.
In addition, she will continue to play stages until her fortune becomes either 0 or _n_.
Because this is the same for all _n_ players, it follows that each player has the same
chance of being the victor, implying that each player has probability 1/ _n_ of being the
victor. Now, suppose these _n_ players are divided into _r_ teams, with team _i_ containing
_ni_ players, _i_ =1,..., _r_ .Then the probability that the victor is a member of team _i_ is
_ni_ / _n_ .But because

```
(a) team i initially has a total fortune of ni units, i =1,..., r ,and
(b) each game played by members of different teams is equally likely to be won by
either player and results in the fortune of members of the winning team increas-
ing by 1 and the fortune of the members of the losing team decreasing by 1 ,
```
it is easy to see that the probability that the victor is from team _i_ is exactly the prob-
ability we desire. Thus, _Pi_ = _ni_ / _n_ .Interestingly, our argument shows that this result
does _not_ depend on how the players in each stage are chosen..

In the _gambler’s ruin problem_ , there are only _2_ gamblers, but they are not assumed
to be of equal skill.

**_EXAMPLE 4l The gambler’s ruin problem_**

Two gamblers, _A_ and _B_ , bet on the outcomes of successive flips of a coin. On each
flip, if the coin comes up heads, _A_ collects 1 unit from _B_ , whereas if it comes up tails,
_A_ pays 1 unit to _B_. They continue to do this until one of them runs out of money. If
it is assumed that the successive flips of the coin are independent and each flip results
in a head with probability _p_ , what is the probability that _A_ ends up with all the money
if he starts with _i_ units and _B_ starts with _N_ − _i_ units?

**_Solution._** Let _E_ denote the event that _A_ ends up with all the money when he starts
with _i_ and _B_ starts with _N_ − _i_ , and to make clear the dependence on the initial fortune
of _A_ , let _Pi_ = _P_ ( _E_ ). We shall obtain an expression for _P(E)_ by conditioning on the
outcome of the first flip as follows: Let _H_ denote the event that the first flip lands on
heads; then

```
Pi = P ( E )= P ( E | H ) P ( H )+ P ( E | Hc ) P ( Hc )
= pP ( E | H )+( 1 − p ) P ( E | Hc )
```
Now, given that the first flip lands on heads, the situation after the first bet is that
_A_ has _i_ +1 units and _B_ has _N_ −( _i_ + 1 ). Since the successive flips are assumed to
be independent with a common probability _p_ of heads, it follows that, from that point
on, _A_ ’s probability of winning all the money is exactly the same as if the game were
just starting with _A_ having an initial fortune of _i_ +1and _B_ having an initial fortune
of _N_ −( _i_ + 1 ). Therefore,

```
P ( E | H )= Pi + 1
```

**88** Chapter 3 Conditional Probability and Independence

```
and similarly,
P ( E | Hc )= Pi − 1
```
```
Hence, letting q = 1 − p , we obtain
```
```
Pi = pPi + 1 + qPi − 1 i =1, 2,..., N − 1 (4.2)
```
```
By making use of the obvious boundary conditions P 0 =0and PN =1, we shall
now solve Equation (4.2). Since p + q =1, these equations are equivalent to
```
```
pPi + qPi = pPi + 1 + qPi − 1
```
```
or
Pi + 1 − Pi =
```
```
q
p
```
```
( Pi − Pi − 1 ) i =1, 2,..., N − 1 (4.3)
```
```
Hence, since P 0 =0, we obtain, from Equation (4.3),
```
##### P 2 − P 1 =

```
q
p
```
##### ( P 1 − P 0 )=

```
q
p
```
##### P 1

##### P 3 − P 2 =

```
q
p
```
##### ( P 2 − P 1 )=

##### (

```
q
p
```
##### ) 2

##### P 1

##### .

##### .

##### . (4.4)

```
Pi − Pi − 1 =
```
```
q
p
```
```
( Pi − 1 − Pi − 2 )=
```
##### (

```
q
p
```
```
) i − 1
P 1
```
```
.
.
.
```
```
PN − PN − 1 =
```
```
q
p
```
##### ( PN − 1 − PN − 2 )=

##### (

```
q
p
```
##### ) N − 1

##### P 1

```
Adding the first i −1 equations of (4.4) yields
```
```
Pi − P 1 = P 1
```
##### [(

```
q
p
```
##### )

##### +

##### (

```
q
p
```
##### ) 2

##### + ··· +

##### (

```
q
p
```
```
) i − 1 ]
```
```
or
```
```
Pi =
```
##### ⎧

##### ⎪⎪

##### ⎪⎨

##### ⎪⎪

##### ⎪⎩

```
1 −( q / p ) i
1 −( q / p )
```
```
P 1 if
```
```
q
p
```
##### Z 1

```
iP 1 if
```
```
q
p
```
##### = 1

```
Using the fact that PN =1, we obtain
```
##### P 1 =

##### ⎧

##### ⎪⎪

##### ⎨

##### ⎪⎪

##### ⎩

```
1 −( q / p )
1 −( q / p ) N
```
```
if p Z^12
```
```
1
N if p =
```
```
1
2
```

```
Section 3.4 Independent Events 89
```
Hence,

```
Pi =
```
##### ⎧

##### ⎪⎪

##### ⎨

##### ⎪⎪

##### ⎩

```
1 −( q / p ) i
1 −( q / p ) N
```
```
if p Z^12
```
```
i
N if p =
```
```
1
2
```
##### (4.5)

Let _Qi_ denote the probability that _B_ winds up with all the money when _A_ starts
with _i_ and _B_ starts with _N_ − _i_. Then, by symmetry to the situation described, and on
replacing _p_ by _q_ and _i_ by _N_ − _i_ , it follows that

```
Qi =
```
##### ⎧

##### ⎪⎪

##### ⎪⎨

##### ⎪⎪

##### ⎪⎩

```
1 −( p / q ) N − i
1 −( p / q ) N
```
```
if q Z^12
```
```
N − i
N
```
```
if q =^12
```
Moreover, since _q_ =^12 is equivalent to _p_ =^12 , we have, when _q_ Z^12 ,

```
Pi + Qi =
```
```
1 −( q / p ) i
1 −( q / p ) N
```
##### +

```
1 −( p / q ) N − i
1 −( p / q ) N
```
##### =

```
pN − pN ( q / p ) i
pN − qN
```
##### +

```
qN − qN ( p / q ) N − i
qN − pN
```
##### =

```
pN − pN − iqi − qN + qipN − i
pN − qN
= 1
```
This result also holds when _p_ = _q_ =^12 ,so

```
Pi + Qi = 1
```
In words, this equation states that, with probability 1, either _A_ or _B_ will wind up
with all of the money; in other words, the probability that the game continues indefi-
nitely with _A_ ’s fortune always being between 1 and _N_ −1 is zero. (The reader must
be careful because, a priori, there are three possible outcomes of this gambling game,
not two: Either _A_ wins, or _B_ wins, or the game goes on forever with nobody winning.
We have just shown that this last event has probability 0.)
As a numerical illustration of the preceding result, if _A_ were to start with 5 units
and _B_ with 10, then the probability of _A_ ’s winning would be^13 if _p_ were^12 , whereas it
would jump to

```
1 −
```
##### (

```
2
3
```
##### ) 5

##### 1 −

##### (

```
2
3
```
##### ) 15 L.^87

if _p_ were .6.
A special case of the gambler’s ruin problem, which is also known as the problem of
_duration of play_ , was proposed to Huygens by Fermat in 1657. The version Huygens
proposed, which he himself solved, was that _A_ and _B_ have 12 coins each. They play
for these coins in a game with 3 dice as follows: Whenever 11 is thrown (by either—it
makes no difference who rolls the dice), _A_ gives a coin to _B_. Whenever 14 is thrown,
_B_ gives a coin to _A_. The person who first wins all the coins wins the game. Since


**90** Chapter 3 Conditional Probability and Independence

```
P {roll 11}= 21627 and P {roll 14}= 21615 , we see from Example 4h that, for A ,thisis
just the gambler’s ruin problem with p =^1542 , i =12, and N =24. The general form
of the gambler’s ruin problem was solved by the mathematician James Bernoulli and
published 8 years after his death in 1713.
For an application of the gambler’s ruin problem to drug testing, suppose that two
new drugs have been developed for treating a certain disease. Drug i has a cure rate
Pi , i =1, 2, in the sense that each patient treated with drug i will be cured with proba-
bility Pi. These cure rates are, however, not known, and we are interested in finding a
method for deciding whether P 1 > P 2 or P 2 > P 1. To decide on one of these alterna-
tives, consider the following test: Pairs of patients are to be treated sequentially, with
one member of the pair receiving drug 1 and the other drug 2. The results for each
pair are determined, and the testing stops when the cumulative number of cures from
one of the drugs exceeds the cumulative number of cures from the other by some
fixed, predetermined number. More formally, let
```
```
Xj =
```
##### {

```
1 if the patient in the j th pair that receives drug 1 is cured
0 otherwise
```
```
Yj =
```
##### {

```
1 if the patient in the j th pair that receives drug 2 is cured
0 otherwise
```
```
For a predetermined positive integer M , the test stops after pair N , where N is the
first value of n such that either
```
```
X 1 + ··· + Xn −( Y 1 + ··· + Yn )= M
```
```
or
X 1 + ··· + Xn −( Y 1 + ··· + Yn )=− M
```
```
In the former case, we assert that P 1 > P 2 and in the latter that P 2 > P 1.
In order to help ascertain whether the foregoing is a good test, one thing we would
like to know is the probability that it leads to an incorrect decision. That is, for given
P 1 and P 2 , where P 1 > P 2 , what is the probability that the test will incorrectly assert
that P 2 > P 1? To determine this probability, note that after each pair is checked,
the cumulative difference of cures using drug 1 versus drug 2 will go up by 1 with
probability P 1 ( 1 − P 2 )—since this is the probability that drug 1 leads to a cure and
drug 2 does not—or go down by 1 with probability( 1 − P 1 ) P 2 , or remain the same
with probability P 1 P 2 +( 1 − P 1 )( 1 − P 2 ). Hence, if we consider only those pairs
in which the cumulative difference changes, then the difference will go up by 1 with
probability
```
```
P = P {up 1|up 1 or down 1}
```
```
=
```
##### P 1 ( 1 − P 2 )

##### P 1 ( 1 − P 2 )+( 1 − P 1 ) P 2

```
and down by 1 with probability
```
##### 1 − P =

##### P 2 ( 1 − P 1 )

##### P 1 ( 1 − P 2 )+( 1 − P 1 ) P 2

```
Thus, the probability that the test will assert that P 2 > P 1 is equal to the probability
that a gambler who wins each (one-unit) bet with probability P will go down M before
going up M. But Equation (4.5), with i = M , N = 2 M , shows that this probability is
given by
```

```
Section 3.4 Independent Events 91
```
```
P {test asserts that P 2 > P 1 }
```
##### = 1 −

##### 1 −

##### (

##### 1 − P

##### P

##### ) M

##### 1 −

##### (

##### 1 − P

##### P

##### ) 2 M

##### = 1 −

##### 1

##### 1 +

##### (

##### 1 − P

##### P

##### ) M

##### =

##### 1

```
1 +γ M
```
where

```
γ=
```
##### P

##### 1 − P

##### =

##### P 1 ( 1 − P 2 )

##### P 2 ( 1 − P 1 )

For instance, if _P_ 1 =.6and _P_ 2 =.4, then the probability of an incorrect decision is
.017 when _M_ =5 and reduces to .0003 when _M_ =10..

Suppose that we are presented with a set of elements and we want to determine
whether at least one member of the set has a certain property. We can attack this
question probabilistically by randomly choosing an element of the set in such a way
that each element has a positive probability of being selected. Then the original ques-
tion can be answered by a consideration of the probability that the randomly selected
element does not have the property of interest. If this probability is equal to 1, then
none of the elements of the set have the property; if it is less than 1, then at least one
element of the set has the property.
The final example of this section illustrates this technique.

**_EXAMPLE 4m_**

The complete graph having _n_ vertices is defined to be a set of _n_ points (called vertices)

in the plane and the

##### (

```
n
2
```
##### )

```
lines (called edges) connecting each pair of vertices. The
```
complete graph having 3 vertices is shown in Figure 3.3. Suppose now that each edge
in a complete graph having _n_ vertices is to be colored either red or blue. For a fixed
integer _k_ , a question of interest is, Is there a way of coloring the edges so that no set

of _k_ vertices has all of its

##### (

```
k
2
```
##### )

```
connecting edges the same color? It can be shown by
```
a probabilistic argument that if _n_ is not too large, then the answer is yes.

```
FIGURE 3.3
```

**92** Chapter 3 Conditional Probability and Independence

```
The argument runs as follows: Suppose that each edge is, independently, equally
likely to be colored either red or blue. That is, each edge is red with probability^12.
```
```
Number the
```
##### (

```
n
k
```
##### )

```
sets of k vertices and define the events Ei , i = 1,...,
```
##### (

```
n
k
```
##### )

```
as
follows:
Ei ={all of the connecting edges of the i th set
of k vertices are the same color}
```
```
Now, since each of the
```
##### (

```
k
2
```
##### )

```
connecting edges of a set of k vertices is equally likely to
be either red or blue, it follows that the probability that they are all the same color is
```
```
P ( Ei )= 2
```
##### (

##### 1

##### 2

```
) k ( k − 1 )/ 2
```
```
Therefore, because
```
##### P

##### ⎛

##### ⎝

##### ⋃

```
i
```
```
Ei
```
##### ⎞

##### ⎠...

##### ∑

```
i
```
```
P ( Ei )(Boole’s inequality)
```
```
we find that P
```
##### (

##### ⋃

```
i
```
```
Ei
```
##### )

```
, the probability that there is a set of k vertices all of whose
```
```
connecting edges are similarly colored, satisfies
```
##### P

##### ⎛

##### ⎝

##### ⋃

```
i
```
```
Ei
```
##### ⎞

##### ⎠...

##### (

```
n
k
```
##### )(

##### 1

##### 2

```
) k ( k − 1 )/ 2 − 1
```
```
Hence, if
(
n
k
```
##### )(

##### 1

##### 2

```
) k ( k − 1 )/ 2 − 1
< 1
```
```
or, equivalently, if
(
n
k
```
##### )

```
< 2 k ( k −^1 )/^2 −^1
```
```
then the probability that at least one of the
```
##### (

```
n
k
```
##### )

```
sets of k vertices has all of its
connecting edges the same color is less than 1. Consequently, under the preceding
condition on n and k , it follows that there is a positive probability that no set of k
vertices has all of its connecting edges the same color. But this conclusion implies
that there is at least one way of coloring the edges for which no set of k vertices has
all of its connecting edges the same color..
```
```
Remarks. (a) Whereas the preceding argument established a condition on n and
k that guarantees the existence of a coloring scheme satisfying the desired property,
it gives no information about how to obtain such a scheme (although one possibility
would be simply to choose the colors at random, check to see if the resulting coloring
satisfies the property, and repeat the procedure until it does).
```

```
Section 3.5 P (·| F ) Is a Probability 93
```
```
(b) The method of introducing probability into a problem whose statement is
purely deterministic has been called the probabilistic method .†Other examples of this
method are given in Theoretical Exercise 24 and Examples 2t and 2u of Chapter 7.
```
### 3.5 P (·| F ) Is a Probability

```
Conditional probabilities satisfy all of the properties of ordinary probabilities, as is
proved by Proposition 5.1, which shows that P ( E | F )satisfies the three axioms of a
probability.
```
```
Proposition 5.1.
```
```
(a) 0... P ( E | F )... 1.
(b) P ( S | F )=1.
(c) If Ei , i =1, 2,..., are mutually exclusive events, then
```
##### P

##### ⎛

##### ⎝

```
⋃q
```
```
1
```
```
Ei | F
```
##### ⎞

##### ⎠=

```
∑q
```
```
1
```
```
P ( Ei | F )
```
```
Proof. To prove part (a), we must show that 0 ... P ( EF )/ P ( F )...1. The left-side
inequality is obvious, whereas the right side follows because EF ( F , which implies
that P ( EF )... P ( F ). Part (b) follows because
```
##### P ( S | F )=

##### P ( SF )

##### P ( F )

##### =

##### P ( F )

##### P ( F )

##### = 1

```
Part (c) follows from
```
##### P

##### ⎛

##### ⎝

```
⋃q
```
```
i = 1
```
```
Ei | F
```
##### ⎞

##### ⎠=

##### P

##### ⎛

##### ⎝

##### (

```
⋃q
i = 1
```
```
Ei
```
##### )

##### F

##### ⎞

##### ⎠

##### P ( F )

##### =

##### P

##### (

```
⋃q
1
```
```
EiF
```
##### )

##### P ( F )

```
since
```
##### ⎛

##### ⎝

```
⋃q
```
```
1
```
```
Ei
```
##### ⎞

##### ⎠ F =

```
⋃q
```
```
1
```
```
EiF
```
##### =

```
∑q
```
```
1
```
```
P ( EiF )
```
##### P ( F )

##### =

```
∑q
```
```
1
```
```
P ( Ei | F )
```
```
where the next-to-last equality follows because EiEj = Ø implies that
EiFEjF =Ø.
```
```
†See N. Alon, J. Spencer, and P. Erdos, The Probabilistic Method (New York: John Wiley &
Sons, Inc., 1992).
```

**94** Chapter 3 Conditional Probability and Independence

```
If we define Q ( E )= P ( E | F ), then, from Proposition 5.1, Q(E) may be regarded
as a probability function on the events of S. Hence, all of the propositions previously
proved for probabilities apply to Q ( E ). For instance, we have
```
```
Q ( E 1 ∪ E 2 )= Q ( E 1 )+ Q ( E 2 )− Q ( E 1 E 2 )
```
```
or, equivalently,
```
```
P ( E 1 ∪ E 2 | F )= P ( E 1 | F )+ P ( E 2 | F )− P ( E 1 E 2 | F )
```
```
Also, if we define the conditional probability Q ( E 1 | E 2 )by Q ( E 1 | E 2 )= Q ( E 1 E 2 )/
Q ( E 2 ), then, from Equation (3.1), we have
```
```
Q ( E 1 )= Q ( E 1 | E 2 ) Q ( E 2 )+ Q ( E 1 | Ec 2 ) Q ( E 2 c ) (5.1)
```
```
Since
```
```
Q ( E 1 | E 2 )=
```
##### Q ( E 1 E 2 )

##### Q ( E 2 )

##### =

##### P ( E 1 E 2 | F )

##### P ( E 2 | F )

##### =

##### P ( E 1 E 2 F )

##### P ( F )

##### P ( E 2 F )

##### P ( F )

##### = P ( E 1 | E 2 F )

```
Equation (5.1) is equivalent to
```
```
P ( E 1 | F )= P ( E 1 | E 2 F ) P ( E 2 | F )+ P ( E 1 | Ec 2 F ) P ( Ec 2 | F )
```
```
EXAMPLE 5a
Consider Example 3a, which is concerned with an insurance company which believes
that people can be divided into two distinct classes: those who are accident prone
and those who are not. During any given year, an accident-prone person will have an
accident with probability .4, whereas the corresponding figure for a person who is not
prone to accidents is .2. What is the conditional probability that a new policyholder
will have an accident in his or her second year of policy ownership, given that the
policyholder has had an accident in the first year?
Solution. If we let A be the event that the policyholder is accident prone and we let
Ai , i =1, 2, be the event that he or she has had an accident in the i th year, then the
desired probability P ( A 2 | A 1 )may be obtained by conditioning on whether or not the
policyholder is accident prone, as follows:
```
```
P ( A 2 | A 1 )= P ( A 2 | AA 1 ) P ( A | A 1 )+ P ( A 2 | AcA 1 ) P ( Ac | A 1 )
```
```
Now,
P ( A | A 1 )=
```
##### P ( A 1 A )

##### P ( A 1 )

##### =

##### P ( A 1 | A ) P ( A )

##### P ( A 1 )

```
However, P ( A )is assumed to equal 103 , and it was shown in Example 3a that P ( A 1 )=
.26. Hence,
P ( A | A 1 )=
```
##### (. 4 )(. 3 )

##### . 26

##### =

##### 6

##### 13


```
Section 3.5 P (·| F ) Is a Probability 95
```
Thus,

```
P ( Ac | A 1 )= 1 − P ( A | A 1 )=
```
##### 7

##### 13

Since _P_ ( _A_ 2 | _AA_ 1 )=.4and _P_ ( _A_ 2 | _AcA_ 1 )=.2, it follows that

##### P ( A 2 | A 1 )=(. 4 )

##### 6

##### 13

##### +(. 2 )

##### 7

##### 13

##### L. 29

##### .

**_EXAMPLE 5b_**

A female chimp has given birth. It is not certain, however, which of two male chimps
is the father. Before any genetic analysis has been performed, it is felt that the
probability that male number 1 is the father is _p_ and the probability that male number
2 is the father is 1− _p_ .DNA obtained from the mother, male number 1, and male
number 2 indicate that, on one specific location of the genome, the mother has the
gene pair( _A_ , _A_ ), male number 1 has the gene pair( _a_ , _a_ ), and male number 2 has the
gene pair( _A_ , _a_ ). If a DNA test shows that the baby chimp has the gene pair( _A_ , _a_ ),
what is the probability that male number 1 is the father?

**_Solution._** Let all probabilities be conditional on the event that the mother has the
gene pair( _A_ , _A_ ), male number 1 has the gene pair( _a_ , _a_ ), and male number 2 has
the gene pair( _A_ , _a_ ). Now, let _Mi_ be the event that male number _i_ , _i_ = 1, 2, is the
father, and let _BA_ , _a_ be the event that the baby chimp has the gene pair( _A_ , _a_ ).Then
_P_ ( _M_ 1 | _BA_ , _a_ )is obtained as follows:

```
P ( M 1 | BA , a )=
```
```
P ( M 1 BA , a )
P ( BA , a )
```
```
=
```
```
P ( BA , a | M 1 ) P ( M 1 )
P ( BA , a | M 1 ) P ( M 1 )+ P ( BA , a | M 2 ) P ( M 2 )
```
```
=
```
```
1 · p
1 · p +( 1 / 2 )( 1 − p )
```
```
=
```
```
2 p
1 + p
```
Because 12 + _pp_ > _p_ when _p_ <1, the information that the baby’s gene pair is( _A_ , _a_ )

increases the probability that male number 1 is the father. This result is intuitive
because it is more likely that the baby would have gene pair( _A_ , _a_ )if _M_ 1 is true than
if _M_ 2 is true (the respective conditional probabilities being 1 and 1/2)..

```
The next example deals with a problem in the theory of runs.
```
**_EXAMPLE 5c_**

Independent trials, each resulting in a success with probability _p_ or a failure with
probability _q_ = 1 − _p_ , are performed. We are interested in computing the probability
that a run of _n_ consecutive successes occurs before a run of _m_ consecutive failures.

**_Solution._** Let _E_ be the event that a run of _n_ consecutive successes occurs before a run
of _m_ consecutive failures. To obtain _P_ ( _E_ ), we start by conditioning on the outcome of
the first trial. That is, letting _H_ denote the event that the first trial results in a success,
we obtain
_P_ ( _E_ )= _pP_ ( _E_ | _H_ )+ _qP_ ( _E_ | _Hc_ ) (5.2)


**96** Chapter 3 Conditional Probability and Independence

```
Now, given that the first trial was successful, one way we can get a run of n successes
before a run of m failures would be to have the next n −1 trials all result in successes.
So, let us condition on whether or not that occurs. That is, letting F be the event that
trials 2 through n all are successes, we obtain
```
```
P ( E | H )= P ( E | FH ) P ( F | H )+ P ( E | FcH ) P ( Fc | H ) (5.3)
```
```
On the one hand, clearly, P ( E | FH )=1; on the other hand, if the event FcH occurs,
then the first trial would result in a success, but there would be a failure some time
during the next n −1 trials. However, when this failure occurs, it would wipe out all
of the previous successes, and the situation would be exactly as if we started out with
a failure. Hence,
P ( E | FcH )= P ( E | Hc )
```
```
Because the independence of trials implies that F and H are independent, and because
P ( F )= pn −^1 , it follows from Equation (5.3) that
```
```
P ( E | H )= pn −^1 +( 1 − pn −^1 ) P ( E | Hc ) (5.4)
```
```
We now obtain an expression for P ( E | Hc )in a similar manner. That is, we let G
denote the event that trials 2 through m are all failures. Then
```
```
P ( E | Hc )= P ( E | GHc ) P ( G | Hc )+ P ( E | GcHc ) P ( Gc | Hc ) (5.5)
```
```
Now, GHc is the event that the first m trials all result in failures, so P ( E | GHc )=0.
Also, if GcHc occurs, then the first trial is a failure, but there is at least one success
in the next m −1 trials. Hence, since this success wipes out all previous failures, we
see that
P ( E | GcHc )= P ( E | H )
```
```
Thus, because P ( Gc | Hc )= P ( Gc )= 1 − qm −^1 , we obtain, from (5.5),
```
```
P ( E | Hc )=( 1 − qm −^1 ) P ( E | H ) (5.6)
```
```
Solving Equations (5.4) and (5.6) yields
```
##### P ( E | H )=

```
pn −^1
pn −^1 + qm −^1 − pn −^1 qm −^1
```
```
and
```
```
P ( E | Hc )=
```
```
( 1 − qm −^1 ) pn −^1
pn −^1 + qm −^1 − pn −^1 qm −^1
```
```
Thus,
```
```
P ( E )= pP ( E | H )+ qP ( E | Hc )
```
```
=
```
```
pn + qpn −^1 ( 1 − qm −^1 )
pn −^1 + qm −^1 − pn −^1 qm −^1
```
```
=
```
```
pn −^1 ( 1 − qm )
pn −^1 + qm −^1 − pn −^1 qm −^1
```
##### (5.7)


```
Section 3.5 P (·| F ) Is a Probability 97
```
It is interesting to note that, by the symmetry of the problem, the probability of
obtaining a run of _m_ failures before a run of _n_ successes would be given by Equa-
tion (5.7) with _p_ and _q_ interchanged and _n_ and _m_ interchanged. Hence, this probabil-
ity would equal

```
P {run of m failures before a run of n successes}
```
```
=
```
```
qm −^1 ( 1 − pn )
qm −^1 + pn −^1 − qm −^1 pn −^1
```
##### (5.8)

Since Equations (5.7) and (5.8) sum to 1, it follows that, with probability 1, either a
run of _n_ successes or a run of _m_ failures will eventually occur.
As an example of Equation (5.7), we note that, in tossing a fair coin, the probability
that a run of 2 heads will precede a run of 3 tails is 107. For 2 consecutive heads before

4 consecutive tails, the probability rises to^56..

In our next example, we return to the matching problem (Example 5m, Chapter 2)
and this time obtain a solution by using conditional probabilities.

**_EXAMPLE 5d_**
At a party, _n_ men take off their hats. The hats are then mixed up, and each man
randomly selects one. We say that a match occurs if a man selects his own hat. What
is the probability of

```
(a) no matches?
(b) exactly k matches?
```
**_Solution._** (a) Let _E_ denote the event that no matches occur, and to make explicit the
dependence on _n_ , write _Pn_ = _P_ ( _E_ ). We start by conditioning on whether or not the
first man selects his own hat—call these events _M_ and _Mc_ , respectively. Then

```
Pn = P ( E )= P ( E | M ) P ( M )+ P ( E | Mc ) P ( Mc )
```
Clearly, _P_ ( _E_ | _M_ )=0, so

```
Pn = P ( E | Mc )
```
```
n − 1
n
```
##### (5.9)

Now, _P_ ( _E_ | _Mc_ )is the probability of no matches when _n_ −1 men select from a set of
_n_ −1 hats that does not contain the hat of one of these men. This can happen in either
of two mutually exclusive ways: Either there are no matches and the extra man does
not select the extra hat (this being the hat of the man who chose first), or there are
no matches and the extra man does select the extra hat. The probability of the first of
these events is just _Pn_ − 1 , which is seen by regarding the extra hat as “belonging” to
the extra man. Because the second event has probability [1/( _n_ − 1 )] _Pn_ − 2 , we have

```
P ( E | Mc )= Pn − 1 +
```
##### 1

```
n − 1
```
```
Pn − 2
```
Thus, from Equation (5.9),

```
Pn =
```
```
n − 1
n
```
```
Pn − 1 +
```
##### 1

```
n
```
```
Pn − 2
```
or, equivalently,

```
Pn − Pn − 1 =−
```
##### 1

```
n
```
```
( Pn − 1 − Pn − 2 ) (5.10)
```

**98** Chapter 3 Conditional Probability and Independence

```
However, since Pn is the probability of no matches when n men select among their
own hats, we have
P 1 = 0 P 2 =
```
##### 1

##### 2

```
So, from Equation (5.10),
```
##### P 3 − P 2 =−

##### ( P 2 − P 1 )

##### 3

##### =−

##### 1

##### 3!

```
or P 3 =
```
##### 1

##### 2!

##### −

##### 1

##### 3!

##### P 4 − P 3 =−

##### ( P 3 − P 2 )

##### 4

##### =

##### 1

##### 4!

```
or P 4 =
```
##### 1

##### 2!

##### −

##### 1

##### 3!

##### +

##### 1

##### 4!

```
and, in general,
Pn =
```
##### 1

##### 2!

##### −

##### 1

##### 3!

##### +

##### 1

##### 4!

##### − ··· +

```
(− 1 ) n
n!
(b) To obtain the probability of exactly k matches, we consider any fixed group of
k men. The probability that they, and only they, select their own hats is
```
```
1
n
```
##### 1

```
n − 1
```
##### ···

##### 1

```
n −( k − 1 )
```
```
Pn − k =
```
```
( n − k )!
n!
```
```
Pn − k
```
```
where Pn − k is the conditional probability that the other n − k men, selecting among
their own hats, have no matches. Since there are
```
##### (

```
n
k
```
##### )

```
choices of a set of k men, the
desired probability of exactly k matches is
```
```
Pn − k
k!
```
##### =

```
1
2!−
```
```
1
3! + ··· +
```
```
(− 1 ) n − k
( n − k )!
k!
```
##### .

```
An important concept in probability theory is that of the conditional independence
of events. We say that the events E 1 and E 2 are conditionally independent given F
if, given that F occurs, the conditional probability that E 1 occurs is unchanged by
information as to whether or not E 2 occurs. More formally, E 1 and E 2 are said to be
conditionally independent given F if
```
```
P ( E 1 | E 2 F )= P ( E 1 | F ) (5.11)
```
```
or, equivalently,
P ( E 1 E 2 | F )= P ( E 1 | F ) P ( E 2 | F ) (5.12)
```
```
The notion of conditional independence can easily be extended to more than two
events, and this extension is left as an exercise.
The reader should note that the concept of conditional independence was implic-
itly employed in Example 5a, where it was assumed that the events that a policyholder
had an accident in his or her i th year, i =1, 2,..., were conditionally independent
given whether or not the person was accident prone. The following example, some-
times referred to as Laplace’s rule of succession, further illustrates the concept of
conditional independence.
```
```
EXAMPLE 5e Laplace’s rule of succession
There are k + 1 coins in a box. When flipped, the i th coin will turn up heads with
probability i / k , i =0, 1,..., k. A coin is randomly selected from the box and is then
```

```
Section 3.5 P (·| F ) Is a Probability 99
```
repeatedly flipped. If the first _n_ flips all result in heads, what is the conditional prob-
ability that the( _n_ + 1 )st flip will do likewise?

**_Solution._** Let _Ci_ denote the event that the _i_ th coin, _i_ =0, 1,..., _k_ , is initially selected;
let _Fn_ denote the event that the first _n_ flips all result in heads; and let _H_ be the event
that the( _n_ + 1 )st flip is a head. The desired probability, _P_ ( _H_ | _Fn_ ), is now obtained as
follows:

```
P ( H | Fn )=
```
```
∑ k
```
```
i = 0
```
```
P ( H | FnCi ) P ( Ci | Fn )
```
Now, given that the _i_ th coin is selected, it is reasonable to assume that the outcomes
will be conditionally independent, with each one resulting in a head with probability
_i/k_. Hence,

```
P ( H | FnCi )= P ( H | Ci )=
```
```
i
k
```
Also,

```
P ( Ci | Fn )=
```
```
P ( CiFn )
P ( Fn )
```
##### =

```
P ( Fn | Ci ) P ( Ci )
∑ k
```
```
j = 0
```
```
P ( Fn | Cj ) P ( Cj )
```
##### =

```
( i / k ) n [1/( k + 1 )]
∑ k
```
```
j = 0
```
```
( j / k ) n [1/( k + 1 )]
```
Thus,

```
P ( H | Fn )=
```
```
∑ k
```
```
i = 0
```
```
( i / k ) n +^1
```
```
∑ k
```
```
j = 0
```
```
( j / k ) n
```
But if _k_ is large, we can use the integral approximations

```
1
k
```
```
∑ k
```
```
i = 0
```
##### (

```
i
k
```
```
) n + 1
L
```
##### ∫ 1

```
0
```
```
xn +^1 dx =
```
##### 1

```
n + 2
```
```
1
k
```
```
∑ k
```
```
j = 0
```
##### (

```
j
k
```
```
) n
L
```
##### ∫ 1

```
0
```
```
xndx =
```
##### 1

```
n + 1
```
So, for _k_ large,

```
P ( H | Fn )L
```
```
n + 1
n + 2.
```
**_EXAMPLE 5f Updating information sequentially_**

Suppose there are _n_ mutually exclusive and exhaustive possible hypotheses, with ini-
tial (sometimes referred to as _prior_ ) probabilities _P_ ( _Hi_ ),

∑ _n
i_ = 1 _P_ ( _Hi_ )=1. Now, if
information that the event _E_ has occurred is received, then the conditional probabil-
ity that _Hi_ is the true hypothesis (sometimes referred to as the _updated_ or _posterior_
probability of _Hi_ )is

```
P ( Hi | E )=
```
```
P ( E | Hi ) P ( Hi )
∑
jP ( E | Hj ) P ( Hj )
```
##### (5.13)


**100** Chapter 3 Conditional Probability and Independence

```
Suppose now that we learn first that E 1 has occurred and then that E 2 has occurred.
Then, given only the first piece of information, the conditional probability that Hi is
the true hypothesis is
```
```
P ( Hi | E 1 )=
```
```
P ( E 1 | Hi ) P ( Hi )
P ( E 1 )
```
##### =

```
P ( E 1 | Hi ) P ( Hi )
∑
jP ( E^1 | Hj ) P ( Hj )
```
```
whereas given both pieces of information, the conditional probability that Hi is the
true hypothesis is P ( Hi | E 1 E 2 ), which can be computed by
```
```
P ( Hi | E 1 E 2 )=
```
```
P ( E 1 E 2 | Hi ) P ( Hi )
∑
jP ( E^1 E^2 | Hj ) P ( Hj )
```
```
One might wonder, however, when one can compute P ( Hi | E 1 E 2 )by using the
right side of Equation (5.13) with E = E 2 and with P ( Hj )replaced by P ( Hj | E 1 ),
j = 1,..., n. That is, when is it legitimate to regard P ( Hj | E 1 ), j Ú 1, as the prior
probabilities and then use (5.13) to compute the posterior probabilities?
```
```
Solution. The answer is that the preceding is legitimate, provided that, for each j =
1,..., n , the events E 1 and E 2 are conditionally independent, given Hj. For if this is
the case, then
P ( E 1 E 2 | Hj )= P ( E 2 | Hj ) P ( E 1 | Hj ), j =1,..., n
```
```
Therefore,
```
```
P ( Hi | E 1 E 2 )=
```
```
P ( E 2 | Hi ) P ( E 1 | Hi ) P ( Hi )
P ( E 1 E 2 )
```
```
=
```
```
P ( E 2 | Hi ) P ( E 1 Hi )
P ( E 1 E 2 )
```
```
=
```
```
P ( E 2 | Hi ) P ( Hi | E 1 ) P ( E 1 )
P ( E 1 E 2 )
```
```
=
```
```
P ( E 2 | Hi ) P ( Hi | E 1 )
Q (1, 2)
```
```
where Q (1, 2)= PP ( E ( E^1 E 1 )^2 ). Since the preceding equation is valid for all i , we obtain,
upon summing,
```
##### 1 =

```
∑ n
```
```
i = 1
```
```
P ( Hi | E 1 E 2 )=
```
```
∑ n
```
```
i = 1
```
```
P ( E 2 | Hi ) P ( Hi | E 1 )
Q (1, 2)
```
```
showing that
```
```
Q (1, 2)=
```
```
∑ n
```
```
i = 1
```
```
P ( E 2 | Hi ) P ( Hi | E 1 )
```
```
and yielding the result
```
```
P ( Hi | E 1 E 2 )=
```
```
P ( E 2 | Hi ) P ( Hi | E 1 )
∑ n
i = 1 P ( E^2 | Hi ) P ( Hi | E^1 )
For instance, suppose that one of two coins is chosen to be flipped. Let Hi be the event
that coin i , i =1, 2, is chosen, and suppose that when coin i is flipped, it lands on heads
with probability pi , i =1, 2. Then the preceding equations show that, to sequentially
```

```
Summary 101
```
update the probability that coin 1 is the one being flipped, given the results of the
previous flips, all that must be saved after each new flip is the conditional probability
that coin 1 is the coin being used. That is, it is not necessary to keep track of all earlier
results..

#### Summary

For events _E_ and _F_ , the conditional probability of _E_ given that _F_ has occurred is
denoted by _P_ ( _E_ | _F_ )andisdefinedby

##### P ( E | F )=

##### P ( EF )

##### P ( F )

The identity

```
P ( E 1 E 2 ··· En )= P ( E 1 ) P ( E 2 | E 1 )··· P ( En | E 1 ··· En − 1 )
```
is known as the _multiplication rule_ of probability.
A valuable identity is

```
P ( E )= P ( E | F ) P ( F )+ P ( E | Fc ) P ( Fc )
```
which can be used to compute _P_ ( _E_ )by “conditioning” on whether _F_ occurs.
_P_ ( _H_ )/ _P_ ( _Hc_ )is called the _odds_ of the event _H_. The identity

```
P ( H | E )
P ( Hc | E )
```
##### =

##### P ( H ) P ( E | H )

```
P ( Hc ) P ( E | Hc )
```
shows that when new evidence _E_ is obtained, the value of the odds of _H_ becomes its
old value multiplied by the ratio of the conditional probability of the new evidence
when _H_ is true to the conditional probability when _H_ is not true.
Let _Fi_ , _i_ =1,..., _n_ , be mutually exclusive events whose union is the entire sample
space. The identity

```
P ( Fj | E )=
```
```
P ( E | Fj ) P ( Fj )
∑ n
```
```
i = 1
```
```
P ( E | Fi ) P ( Fi )
```
is known as _Bayes’s formula_. If the events _Fi_ , _i_ =1,..., _n_ , are competing hypotheses,
then Bayes’s formula shows how to compute the conditional probabilities of these
hypotheses when additional evidence _E_ becomes available.
If _P_ ( _EF_ )= _P_ ( _E_ ) _P_ ( _F_ ), then we say that the events _E_ and _F_ are _independent_. This
condition is equivalent to _P_ ( _E_ | _F_ )= _P_ ( _E_ )and to _P_ ( _F_ | _E_ )= _P_ ( _F_ ). Thus, the events _E_
and _F_ are independent if knowledge of the occurrence of one of them does not affect
the probability of the other.
The events _E_ 1 ,..., _En_ are said to be independent if, for any subset _Ei_ 1 ,..., _Eir_
of them,

```
P ( Ei 1 ··· Eir )= P ( Ei 1 )··· P ( Eir )
```
For a fixed event _F_ , _P_ ( _E_ | _F_ )can be considered to be a probability function on the
events _E_ of the sample space.


**102** Chapter 3 Conditional Probability and Independence

#### Problems...................................

```
3.1. Two fair dice are rolled. What is the conditional
probability that at least one lands on 6 given that
the dice land on different numbers?
3.2. If two fair dice are rolled, what is the conditional
probability that the first one lands on 6 given that
thesumofthediceis i? Compute for all values of
i between 2 and 12.
3.3. Use Equation (2.1) to compute, in a hand of
bridge, the conditional probability that East has
3 spades given that North and South have a com-
bined total of 8 spades.
3.4. What is the probability that at least one of a pair of
fair dice lands on 6, given that the sum of the dice
is i , i =2, 3,..., 12?
3.5. An urn contains 6 white and 9 black balls. If 4 balls
are to be randomly selected without replacement,
what is the probability that the first 2 selected are
white and the last 2 black?
3.6. Consider an urn containing 12 balls, of which 8
arewhite.Asampleofsize4istobedrawnwith
replacement (without replacement). What is the
conditional probability (in each case) that the first
and third balls drawn will be white given that the
sample drawn contains exactly 3 white balls?
3.7. The king comes from a family of 2 children. What
is the probability that the other child is his sister?
3.8. A couple has 2 children. What is the probability
that both are girls if the older of the two is a girl?
3.9. Consider 3 urns. Urn A contains 2 white and 4 red
balls, urn B contains 8 white and 4 red balls, and
urn C contains 1 white and 3 red balls. If 1 ball is
selected from each urn, what is the probability that
the ball chosen from urn A was white given that
exactly 2 white balls were selected?
3.10. Three cards are randomly selected, without
replacement, from an ordinary deck of 52 playing
cards. Compute the conditional probability that
the first card selected is a spade given that the sec-
ond and third cards are spades.
3.11. Two cards are randomly chosen without replace-
ment from an ordinary deck of 52 cards. Let B be
the event that both cards are aces, let As be the
event that the ace of spades is chosen, and let A be
the event that at least one ace is chosen. Find
(a) P ( B | As )
(b) P ( B | A )
3.12. A recent college graduate is planning to take the
first three actuarial examinations in the coming
summer. She will take the first actuarial exam in
June. If she passes that exam, then she will take
the second exam in July, and if she also passes that
one, then she will take the third exam in Septem-
ber. If she fails an exam, then she is not allowed
```
```
to take any others. The probability that she passes
the first exam is .9. If she passes the first exam, then
the conditional probability that she passes the sec-
ond one is .8, and if she passes both the first and
the second exams, then the conditional probability
that she passes the third exam is .7.
(a) What is the probability that she passes all
three exams?
(b) Given that she did not pass all three exams,
what is the conditional probability that she
failed the second exam?
3.13. Suppose that an ordinary deck of 52 cards (which
contains 4 aces) is randomly divided into 4 hands
of 13 cards each. We are interested in determining
p , the probability that each hand has an ace. Let Ei
be the event that the i th hand has exactly one ace.
Determine p = P ( E 1 E 2 E 3 E 4 )by using the multi-
plication rule.
3.14. An urn initially contains 5 white and 7 black balls.
Each time a ball is selected, its color is noted and
it is replaced in the urn along with 2 other balls of
the same color. Compute the probability that
(a) the first 2 balls selected are black and the next
2 are white;
(b) of the first 4 balls selected, exactly 2 are black.
3.15. An ectopic pregnancy is twice as likely to develop
when the pregnant woman is a smoker as it is when
she is a nonsmoker. If 32 percent of women of
childbearing age are smokers, what percentage of
women having ectopic pregnancies are smokers?
3.16. Ninety-eight percent of all babies survive delivery.
However, 15 percent of all births involve Cesarean
(C) sections, and when a C section is performed,
the baby survives 96 percent of the time. If a ran-
domly chosen pregnant woman does not have a
C section, what is the probability that her baby
survives?
3.17. In a certain community, 36 percent of the families
own a dog and 22 percent of the families that own
a dog also own a cat. In addition, 30 percent of the
families own a cat. What is
(a) the probability that a randomly selected fam-
ily owns both a dog and a cat?
(b) the conditional probability that a randomly
selected family owns a dog given that it owns
acat?
3.18. A total of 46 percent of the voters in a certain city
classify themselves as Independents, whereas 30
percent classify themselves as Liberals and 24 per-
cent say that they are Conservatives. In a recent
local election, 35 percent of the Independents, 62
percent of the Liberals, and 58 percent of the Con-
servatives voted. A voter is chosen at random.
```

```
Problems 103
```
```
Given that this person voted in the local election,
what is the probability that he or she is
(a) an Independent?
(b) a Liberal?
(c) a Conservative?
(d) What fraction of voters participated in the
local election?
```
**3.19.** A total of 48 percent of the women and 37 percent
of the men that took a certain “quit smoking” class
remained nonsmokers for at least one year after
completing the class. These people then attended
a success party at the end of a year. If 62 percent
of the original class was male,
**(a)** what percentage of those attending the party
were women?
**(b)** what percentage of the original class attended
the party?

**3.20.** Fifty-two percent of the students at a certain col-
lege are females. Five percent of the students in
this college are majoring in computer science. Two
percent of the students are women majoring in
computer science. If a student is selected at ran-
dom, find the conditional probability that
**(a)** the student is female given that the student is
majoring in computer science;
**(b)** this student is majoring in computer science
given that the student is female.
**3.21.** A total of 500 married working couples were
polled about their annual salaries, with the follow-
ing information resulting:

```
Husband
```
```
Wife Less than More than
$25,000 $25,000
```
```
Less than $25,000 212 198
More than $25,000 36 54
```
For instance, in 36 of the couples, the wife earned
more and the husband earned less than $25,000. If
one of the couples is randomly chosen, what is
**(a)** the probability that the husband earns less
than $25,000?
**(b)** the conditional probability that the wife earns
more than $25,000 given that the husband
earns more than this amount?
**(c)** the conditional probability that the wife earns
more than $25,000 given that the husband
earns less than this amount?
**3.22.** A red die, a blue die, and a yellow die (all six
sided) are rolled. We are interested in the prob-
ability that the number appearing on the blue die
is less than that appearing on the yellow die, which
is less than that appearing on the red die. That is,

```
with B , Y ,and R denoting, respectively, the num-
ber appearing on the blue, yellow, and red die, we
are interested in P ( B < Y < R ).
(a) What is the probability that no two of the dice
land on the same number?
(b) Given that no two of the dice land on the same
number, what is the conditional probability
that B < Y < R?
(c) What is P ( B < Y < R )?
3.23. Urn I contains 2 white and 4 red balls, whereas urn
II contains 1 white and 1 red ball. A ball is ran-
domly chosen from urn I and put into urn II, and a
ball is then randomly selected from urn II. What is
(a) the probability that the ball selected from urn
II is white?
(b) the conditional probability that the trans-
ferred ball was white given that a white ball
is selected from urn II?
3.24. Each of 2 balls is painted either black or gold and
then placed in an urn. Suppose that each ball is col-
ored black with probability^12 and that these events
are independent.
(a) Suppose that you obtain information that the
gold paint has been used (and thus at least
one of the balls is painted gold). Compute
the conditional probability that both balls are
painted gold.
(b) Suppose now that the urn tips over and 1 ball
falls out. It is painted gold. What is the prob-
ability that both balls are gold in this case?
Explain.
3.25. The following method was proposed to estimate
the number of people over the age of 50 who reside
in a town of known population 100,000: “As you
walk along the streets, keep a running count of the
percentage of people you encounter who are over
```
50. Do this for a few days; then multiply the per-
centage you obtain by 100,000 to obtain the esti-
mate.” Comment on this method.
_Hint_ :Let _p_ denote the proportion of people in the
town who are over 50. Furthermore, letα 1 denote
the proportion of time that a person under the age
of 50 spends in the streets, and letα 2 be the cor-
responding value for those over 50. What quantity
does the method suggested estimate? When is the
estimate approximately equal to _p_?
**3.26.** Suppose that 5 percent of men and .25 percent
of women are color blind. A color-blind person
is chosen at random. What is the probability of
this person being male? Assume that there are an
equal number of males and females. What if the
population consisted of twice as many males as
females?
**3.27.** All the workers at a certain company drive to
work and park in the company’s lot. The company


**104** Chapter 3 Conditional Probability and Independence

```
is interested in estimating the average number of
workers in a car. Which of the following methods
will enable the company to estimate this quantity?
Explain your answer.
```
1. Randomly choose _n_ workers, find out how
    many were in the cars in which they were
    driven, and take the average of the _n_ values.
2. Randomly choose _n_ cars in the lot, find out how
    many were driven in those cars, and take the
    average of the _n_ values.
**3.28.** Suppose that an ordinary deck of 52 cards is shuf-
fled and the cards are then turned over one at a
time until the first ace appears. Given that the first
ace is the 20th card to appear, what is the condi-
tional probability that the card following it is the
**(a)** ace of spades?
**(b)** two of clubs?
**3.29.** There are 15 tennis balls in a box, of which 9 have
not previously been used. Three of the balls are
randomly chosen, played with, and then returned
to the box. Later, another 3 balls are randomly
chosen from the box. Find the probability that
none of these balls has ever been used.
**3.30.** Consider two boxes, one containing 1 black and 1
white marble, the other 2 black and 1 white mar-
ble. A box is selected at random, and a marble is
drawn from it at random. What is the probability
that the marble is black? What is the probability
that the first box was the one selected given that
the marble is white?
**3.31.** Ms. Aquina has just had a biopsy on a possibly can-
cerous tumor. Not wanting to spoil a weekend fam-
ily event, she does not want to hear any bad news
in the next few days. But if she tells the doctor to
call only if the news is good, then if the doctor does
not call, Ms. Aquina can conclude that the news is
bad. So, being a student of probability, Ms. Aquina
instructs the doctor to flip a coin. If it comes up
heads, the doctor is to call if the news is good and
not call if the news is bad. If the coin comes up
tails, the doctor is not to call. In this way, even if
the doctor doesn’t call, the news is not necessarily
bad. Letαbe the probability that the tumor is can-
cerous; letβbe the conditional probability that the
tumor is cancerous given that the doctor does not
call.
**(a)** Which should be larger,αorβ?
**(b)** Findβin terms ofα, and prove your answer
in part (a).
**3.32.** A family has _j_ children with probability _pj_ ,where
_p_ 1 = .1, _p_ 2 = .25, _p_ 3 = .35, _p_ 4 = .3. A child
from this family is randomly chosen. Given that
this child is the eldest child in the family, find the
conditional probability that the family has

```
(a) only 1 child;
(b) 4 children.
Redo (a) and (b) when the randomly selected child
is the youngest child of the family.
3.33. On rainy days, Joe is late to work with probability
.3; on nonrainy days, he is late with probability .1.
With probability .7, it will rain tomorrow.
(a) Find the probability that Joe is early tomor-
row.
(b) Given that Joe was early, what is the condi-
tional probability that it rained?
3.34. In Example 3f, suppose that the new evidence is
subject to different possible interpretations and in
fact shows only that it is 90 percent likely that the
criminal possesses the characteristic in question. In
this case, how likely would it be that the suspect is
guilty (assuming, as before, that he has the charac-
teristic)?
3.35. With probability .6, the present was hidden by
mom; with probability .4, it was hidden by dad.
When mom hides the present, she hides it upstairs
70 percent of the time and downstairs 30 percent
of the time. Dad is equally likely to hide it upstairs
or downstairs.
(a) What is the probability that the present is
upstairs?
(b) Given that it is downstairs, what is the proba-
bility it was hidden by dad?
3.36. Stores A , B ,and C have 50, 75, and 100 employees,
respectively, and 50, 60, and 70 percent of them
respectively are women. Resignations are equally
likely among all employees, regardless of sex. One
woman employee resigns. What is the probability
that she works in store C?
3.37. (a) A gambler has a fair coin and a two-headed
coin in his pocket. He selects one of the coins
at random; when he flips it, it shows heads.
What is the probability that it is the fair coin?
(b) Suppose that he flips the same coin a second
time and, again, it shows heads. Now what is
the probability that it is the fair coin?
(c) Suppose that he flips the same coin a third
time and it shows tails. Now what is the prob-
ability that it is the fair coin?
3.38. Urn A has 5 white and 7 black balls. Urn B has
3 white and 12 black balls. We flip a fair coin. If
the outcome is heads, then a ball from urn A is
selected, whereas if the outcome is tails, then a ball
from urn B is selected. Suppose that a white ball
is selected. What is the probability that the coin
landed tails?
3.39. In Example 3a, what is the probability that some-
one has an accident in the second year given that
he or she had no accidents in the first year?
3.40. Consider a sample of size 3 drawn in the following
manner: We start with an urn containing 5 white
```

```
Problems 105
```
and 7 red balls. At each stage, a ball is drawn
and its color is noted. The ball is then returned
to the urn, along with an additional ball of the
same color. Find the probability that the sample
will contain exactly
**(a)** 0 white balls;
**(b)** 1 white ball;
**(c)** 3 white balls;
**(d)** 2 white balls.
**3.41.** A deck of cards is shuffled and then divided into
two halves of 26 cards each. A card is drawn from
one of the halves; it turns out to be an ace. The ace
is then placed in the second half-deck. The half is
then shuffled, and a card is drawn from it. Com-
pute the probability that this drawn card is an ace.
_Hint_ : Condition on whether or not the inter-
changed card is selected.
**3.42.** Three cooks, _A_ , _B_ ,and _C_ , bake a special kind of
cake, and with respective probabilities .02, .03, and
.05, it fails to rise. In the restaurant where they
work, _A_ bakes 50 percent of these cakes, _B_ 30 per-
cent, and _C_ 20 percent. What proportion of “fail-
ures” is caused by _A_?
**3.43.** There are 3 coins in a box. One is a two-headed
coin, another is a fair coin, and the third is a biased
coin that comes up heads 75 percent of the time.
When one of the 3 coins is selected at random and
flipped, it shows heads. What is the probability that
it was the two-headed coin?
**3.44.** Three prisoners are informed by their jailer that
one of them has been chosen at random to be
executed and the other two are to be freed. Pris-
oner _A_ asks the jailer to tell him privately which of
his fellow prisoners will be set free, claiming that
there would be no harm in divulging this informa-
tion because he already knows that at least one of
the two will go free. The jailer refuses to answer
the question, pointing out that if _A_ knew which
of his fellow prisoners were to be set free, then
his own probability of being executed would rise
from^13 to^12 because he would then be one of two
prisoners. What do you think of the jailer’s
reasoning?
**3.45.** Suppose we have 10 coins such that if the _i_ th
coin is flipped, heads will appear with probabil-
ity _i_ /10, _i_ = 1, 2,..., 10. When one of the coins
is randomly selected and flipped, it shows heads.
What is the conditional probability that it was the
fifth coin?
**3.46.** In any given year, a male automobile policyholder
will make a claim with probability _pm_ and a female
policyholder will make a claim with probability _pf_ ,
where _pf_ Z _pm_. The fraction of the policyholders
that are male isα,0<α<1. A policyholder is
randomly chosen. If _Ai_ denotes the event that this

```
policyholder will make a claim in year i , show that
```
```
P ( A 2 | A 1 )> P ( A 1 )
```
```
Give an intuitive explanation of why the preceding
inequality is true.
3.47. An urn contains 5 white and 10 black balls. A fair
die is rolled and that number of balls is randomly
chosen from the urn. What is the probability that
all of the balls selected are white? What is the con-
ditional probability that the die landed on 3 if all
the balls selected are white?
3.48. Each of 2 cabinets identical in appearance has 2
drawers. Cabinet A contains a silver coin in each
drawer, and cabinet B contains a silver coin in
one of its drawers and a gold coin in the other.
A cabinet is randomly selected, one of its drawers
is opened, and a silver coin is found. What is the
probability that there is a silver coin in the other
drawer?
3.49. Prostate cancer is the most common type of can-
cer found in males. As an indicator of whether a
male has prostate cancer, doctors often perform
a test that measures the level of the prostate-
specific antigen (PSA) that is produced only by the
prostate gland. Although PSA levels are indica-
tive of cancer, the test is notoriously unreli-
able. Indeed, the probability that a noncancerous
man will have an elevated PSA level is approx-
imately.135, increasing to approximately.268 if
the man does have cancer. If, on the basis of other
factors, a physician is 70 percent certain that a
male has prostate cancer, what is the conditional
probability that he has the cancer given that
(a) the test indicated an elevated PSA level?
(b) the test did not indicate an elevated PSA
level?
Repeat the preceding calculation, this time assum-
ing that the physician initially believes that there
is a 30 percent chance that the man has prostate
cancer.
3.50. Suppose that an insurance company classifies peo-
ple into one of three classes: good risks, average
risks, and bad risks. The company’s records indi-
cate that the probabilities that good-, average-, and
bad-risk persons will be involved in an accident
over a 1-year span are, respectively, .05, .15, and
.30. If 20 percent of the population is a good risk,
50 percent an average risk, and 30 percent a bad
risk, what proportion of people have accidents in
a fixed year? If policyholder A had no accidents
in 1997, what is the probability that he or she is a
good or average risk?
3.51. A worker has asked her supervisor for a letter of
recommendation for a new job. She estimates that
there is an 80 percent chance that she will get the
```

**106** Chapter 3 Conditional Probability and Independence

```
job if she receives a strong recommendation, a 40
percent chance if she receives a moderately good
recommendation, and a 10 percent chance if she
receives a weak recommendation. She further esti-
mates that the probabilities that the recommenda-
tion will be strong, moderate, and weak are .7, .2,
and .1, respectively.
(a) How certain is she that she will receive the
new job offer?
(b) Given that she does receive the offer, how
likely should she feel that she received a
strong recommendation? a moderate recom-
mendation? a weak recommendation?
(c) Given that she does not receive the job offer,
how likely should she feel that she received a
strong recommendation? a moderate recom-
mendation? a weak recommendation?
3.52. A high school student is anxiously waiting to
receive mail telling her whether she has been
accepted to a certain college. She estimates that
the conditional probabilities of receiving notifica-
tion on each day of next week, given that she is
accepted and that she is rejected, are as follows:
```
```
Day P (mail|accepted) P (mail|rejected)
```
```
Monday .15 .05
Tuesday .20 .10
Wednesday .25 .10
Thursday .15 .15
Friday .10 .20
```
```
She estimates that her probability of being
accepted is .6.
(a) What is the probability that she receives mail
on Monday?
(b) What is the conditional probability that she
received mail on Tuesday given that she does
not receive mail on Monday?
(c) If there is no mail through Wednesday, what
is the conditional probability that she will be
accepted?
(d) What is the conditional probability that she
will be accepted if mail comes on Thursday?
(e) What is the conditional probability that she
will be accepted if no mail arrives that week?
3.53. A parallel system functions whenever at least one
of its components works. Consider a parallel sys-
tem of n components, and suppose that each com-
ponent works independently with probability^12.
Find the conditional probability that component 1
works given that the system is functioning.
3.54. If you had to construct a mathematical model for
events E and F , as described in parts (a) through
```
```
(e), would you assume that they were independent
events? Explain your reasoning.
(a) E is the event that a businesswoman has blue
eyes, and F is the event that her secretary has
blue eyes.
(b) E is the event that a professor owns a car,
and F is the event that he is listed in the tele-
phone book.
(c) E is the event that a man is under 6 feet tall,
and F is the event that he weighs over 200
pounds.
(d) E is the event that a woman lives in the United
States, and F is the event that she lives in the
Western Hemisphere.
(e) E is the event that it will rain tomorrow, and
F is the event that it will rain the day after
tomorrow.
3.55. In a class, there are 4 freshman boys, 6 freshman
girls, and 6 sophomore boys. How many sopho-
more girls must be present if sex and class are to
be independent when a student is selected at ran-
dom?
3.56. Suppose that you continually collect coupons and
that there are m different types. Suppose also that
each time a new coupon is obtained, it is a type
i coupon with probability pi , i =1,..., m. Suppose
that you have just collected your n th coupon. What
is the probability that it is a new type?
Hint : Condition on the type of this coupon.
3.57. A simplified model for the movement of the price
of a stock supposes that on each day the stock’s
price either moves up 1 unit with probability p or
moves down 1 unit with probability 1 − p .The
changes on different days are assumed to be inde-
pendent.
(a) What is the probability that after 2 days the
stock will be at its original price?
(b) What is the probability that after 3 days the
stock’s price will have increased by 1 unit?
(c) Given that after 3 days the stock’s price has
increased by 1 unit, what is the probability
that it went up on the first day?
3.58. Suppose that we want to generate the outcome
of the flip of a fair coin, but that all we have at
our disposal is a biased coin which lands on heads
with some unknown probability p that need not be
equal to^12. Consider the following procedure for
accomplishing our task:
```
1. Flip the coin.
2. Flip the coin again.
3. If both flips land on heads or both land on tails,
    return to step 1.
4. Let the result of the last flip be the result of the
    experiment.


```
Problems 107
```
**(a)** Show that the result is equally likely to be
either heads or tails.
**(b)** Could we use a simpler procedure that contin-
ues to flip the coin until the last two flips are
different and then lets the result be the out-
come of the final flip?
**3.59.** Independent flips of a coin that lands on heads
with probability _p_ are made. What is the proba-
bility that the first four outcomes are
**(a)** _H_ , _H_ , _H_ , _H_?
**(b)** _T_ , _H_ , _H_ , _H_?
**(c)** What is the probability that the pattern _T_ , _H_ ,
_H_ , _H_ occurs before the pattern _H_ , _H_ , _H_ , _H_?
_Hint for part (c)_ : How can the pattern _H_ , _H_ , _H_ , _H_
occur first?
**3.60.** The color of a person’s eyes is determined by a sin-
gle pair of genes. If they are both blue-eyed genes,
then the person will have blue eyes; if they are
both brown-eyed genes, then the person will have
brown eyes; and if one of them is a blue-eyed gene
and the other a brown-eyed gene, then the per-
son will have brown eyes. (Because of the latter
fact, we say that the brown-eyed gene is _dominant_
over the blue-eyed one.) A newborn child inde-
pendently receives one eye gene from each of its
parents, and the gene it receives from a parent is
equally likely to be either of the two eye genes of
that parent. Suppose that Smith and both of his
parents have brown eyes, but Smith’s sister has
blue eyes.
**(a)** What is the probability that Smith possesses a
blue-eyed gene?
**(b)** Suppose that Smith’s wife has blue eyes. What
is the probability that their first child will have
blue eyes?
**(c)** If their first child has brown eyes, what is the
probability that their next child will also have
brown eyes?
**3.61.** Genes relating to albinism are denoted by _A_ and
_a_. Only those people who receive the _a_ gene from
both parents will be albino. Persons having the
gene pair _A_ , _a_ are normal in appearance and,
because they can pass on the trait to their off-
spring, are called carriers. Suppose that a normal
couple has two children, exactly one of whom is
an albino. Suppose that the nonalbino child mates
with a person who is known to be a carrier for
albinism.
**(a)** What is the probability that their first off-
spring is an albino?
**(b)** What is the conditional probability that their
second offspring is an albino given that their
firstborn is not?
**3.62.** Barbara and Dianne go target shooting. Suppose
that each of Barbara’s shots hits a wooden duck
target with probability _p_ 1 , while each shot of

```
Dianne’s hits it with probability p 2. Suppose that
they shoot simultaneously at the same target. If
the wooden duck is knocked over (indicating that
it was hit), what is the probability that
(a) both shots hit the duck?
(b) Barbara’s shot hit the duck?
What independence assumptions have you made?
3.63. A and B are involved in a duel. The rules of the
duel are that they are to pick up their guns and
shoot at each other simultaneously. If one or both
are hit, then the duel is over. If both shots miss,
then they repeat the process. Suppose that the
results of the shots are independent and that each
shot of A will hit B with probability pA , and each
shot of B will hit A with probability pB. What is
(a) the probability that A is not hit?
(b) the probability that both duelists are hit?
(c) the probability that the duel ends after the n th
round of shots?
(d) the conditional probability that the duel ends
after the n th round of shots given that A is
not hit?
(e) the conditional probability that the duel ends
after the n th round of shots given that both
duelists are hit?
3.64. A true–false question is to be posed to a husband-
and-wife team on a quiz show. Both the husband
and the wife will independently give the correct
answer with probability p. Which of the following
is a better strategy for the couple?
(a) Choose one of them and let that person
answer the question.
(b) Have them both consider the question, and
then either give the common answer if they
agree or, if they disagree, flip a coin to deter-
mine which answer to give.
3.65. In Problem 3.5, if p =.6 and the couple uses the
strategy in part (b), what is the conditional prob-
ability that the couple gives the correct answer
given that the husband and wife (a) agree? (b) dis-
agree?
3.66. The probability of the closing of the i th relay in the
circuits shown in Figure 3.4 is given by pi , i =1, 2,
3, 4, 5. If all relays function independently, what is
the probability that a current flows between A and
B for the respective circuits?
Hint for (b) : Condition on whether relay 3 closes.
3.67. An engineering system consisting of n compo-
nents is said to be a k -out-of- n system( k ... n )
if the system functions if and only if at least
k of the n components function. Suppose that
all components function independently of each
other.
(a) If the i th component functions with probabil-
ity Pi , i =1, 2, 3, 4, compute the probability
that a 2-out-of-4 system functions.
```

**108** Chapter 3 Conditional Probability and Independence

```
A B
```
```
14
```
```
25
```
```
3
```
```
A B
```
```
1
```
```
3
```
```
2
```
```
4
```
```
5
```
```
(a)
```
```
(b)
```
```
FIGURE 3.4: Circuits for Problem 3.66
```
```
(b) Repeat part (a) for a 3-out-of-5 system.
(c) Repeat for a k -out-of- n system when all the Pi
equal p (that is, Pi = p , i =1, 2,..., n ).
3.68. In Problem 3.65a, find the conditional probability
that relays 1 and 2 are both closed given that a cur-
rent flows from A to B.
3.69. A certain organism possesses a pair of each of 5
different genes (which we will designate by the
first 5 letters of the English alphabet). Each gene
appears in 2 forms (which we designate by low-
ercase and capital letters). The capital letter will
be assumed to be the dominant gene, in the sense
that if an organism possesses the gene pair xX ,
then it will outwardly have the appearance of the
X gene. For instance, if X stands for brown eyes
and x for blue eyes, then an individual having
either gene pair XX or xX will have brown eyes,
whereas one having gene pair xx will have blue
eyes. The characteristic appearance of an organ-
ism is called its phenotype, whereas its genetic
constitution is called its genotype. (Thus, 2 organ-
isms with respective genotypes aA, bB, cc, dD,
ee and AA, BB, cc, DD, ee would have different
genotypes but the same phenotype.) In a mating
between 2 organisms, each one contributes, at ran-
dom, one of its gene pairs of each type. The 5
contributions of an organism (one of each of the
5 types) are assumed to be independent and are
also independent of the contributions of the organ-
ism’s mate. In a mating between organisms hav-
ing genotypes aA, bB, cC, dD, eE and aa, bB, cc,
Dd, ee what is the probability that the progeny
will (i) phenotypically and (ii) genotypically
resemble
(a) the first parent?
(b) the second parent?
```
```
(c) either parent?
(d) neither parent?
3.70. There is a 50–50 chance that the queen carries the
gene for hemophilia. If she is a carrier, then each
prince has a 50–50 chance of having hemophilia. If
the queen has had three princes without the dis-
ease, what is the probability that the queen is a
carrier? If there is a fourth prince, what is the prob-
ability that he will have hemophilia?
3.71. On the morning of September 30, 1982, the won–
lost records of the three leading baseball teams in
the Western Division of the National League were
as follows:
```
```
Team Won Lost
```
```
Atlanta Braves 87 72
San Francisco Giants 86 73
Los Angeles Dodgers 86 73
```
```
Each team had 3 games remaining. All 3 of the
Giants’ games were with the Dodgers, and the 3
remaining games of the Braves were against the
San Diego Padres. Suppose that the outcomes of
all remaining games are independent and each
game is equally likely to be won by either partic-
ipant. For each team, what is the probability that it
will win the division title? If two teams tie for first
place, they have a playoff game, which each team
has an equal chance of winning.
3.72. A town council of 7 members contains a steering
committee of size 3. New ideas for legislation go
first to the steering committee and then on to the
council as a whole if at least 2 of the 3 commit-
tee members approve the legislation. Once at the
full council, the legislation requires a majority vote
```

```
Problems 109
```
(of at least 4) to pass. Consider a new piece of
legislation, and suppose that each town council
member will approve it, independently, with prob-
ability _p_. What is the probability that a given steer-
ing committee member’s vote is decisive in the
sense that if that person’s vote were reversed,
then the final fate of the legislation would be
reversed? What is the corresponding probability
for a given council member not on the steering
committee?
**3.73.** Suppose that each child born to a couple is equally
likely to be a boy or a girl, independently of the
sex distribution of the other children in the fam-
ily. For a couple having 5 children, compute the
probabilities of the following events:
**(a)** All children are of the same sex.
**(b)** The 3 eldest are boys and the others girls.
**(c)** Exactly 3 are boys.
**(d)** The 2 oldest are girls.
**(e)** There is at least 1 girl.
**3.74.** _A_ and _B_ alternate rolling a pair of dice, stopping
either when _A_ rolls the sum 9 or when _B_ rolls the
sum 6. Assuming that _A_ rolls first, find the proba-
bility that the final roll is made by _A_.
**3.75.** In a certain village, it is traditional for the eldest
son (or the older son in a two-son family) and
his wife to be responsible for taking care of his
parents as they age. In recent years, however, the
women of this village, not wanting that responsi-
bility, have not looked favorably upon marrying an
eldest son.
**(a)** If every family in the village has two children,
what proportion of all sons are older sons?
**(b)** If every family in the village has three chil-
dren, what proportion of all sons are eldest
sons?
Assume that each child is, independently, equally
likely to be either a boy or a girl.
**3.76.** Suppose that _E_ and _F_ are mutually exclusive
events of an experiment. Show that if independent
trials of this experiment are performed, then _E_
will occur before _F_ with probability _P_ ( _E_ )/[ _P_ ( _E_ )+
_P_ ( _F_ )].
**3.77.** Consider an unending sequence of independent
trials, where each trial is equally likely to result in
any of the outcomes 1, 2, or 3. Given that outcome
3 is the last of the three outcomes to occur, find the
conditional probability that
**(a)** the first trial results in outcome 1;
**(b)** the first two trials both result in outcome 1.
**3.78.** _A_ and _B_ play a series of games. Each game is inde-
pendently won by _A_ with probability _p_ and by _B_
with probability 1− _p_. They stop when the total
number of wins of one of the players is two greater
than that of the other player. The player with the

```
greater number of total wins is declared the winner
of the series.
(a) Find the probability that a total of 4 games are
played.
(b) Find the probability that A is the winner of
the series.
3.79. In successive rolls of a pair of fair dice, what is the
probability of getting 2 sevens before 6 even num-
bers?
3.80. In a certain contest, the players are of equal skill
and the probability is^12 that a specified one of
the two contestants will be the victor. In a group
of 2 n players, the players are paired off against
each other at random. The 2 n −^1 winners are again
paired off randomly, and so on, until a single win-
ner remains. Consider two specified contestants, A
and B , and define the events Ai , i ... n , E by
```
```
Ai : A plays in exactly i contests:
E : A and B never play each other.
```
```
(a) Find P ( Ai ), i =1,..., n.
(b) Find P ( E ).
(c) Let Pn = P ( E ). Show that
```
```
Pn =
```
```
1
2 n − 1
```
```
+
```
```
2 n − 2
2 n − 1
```
```
(
1
2
```
```
) 2
Pn − 1
```
```
and use this formula to check the answer you
obtained in part (b).
Hint :Find P ( E )by conditioning on which of
the events Ai , i =1,..., n occur. In simplifying
your answer, use the algebraic identity
n ∑− 1
```
```
i = 1
```
```
ixi −^1 =
1 − nxn −^1 +( n − 1 ) xn
( 1 − x )^2
```
```
For another approach to solving this problem,
note that there are a total of 2 n −1 games
played.
(d) Explain why 2 n −1 games are played.
Number these games, and let Bi denote the
event that A and B play each other in game
i , i =1,...,2 n −1.
(e) What is P ( Bi )?
(f) Use part (e) to find P ( E ).
3.81. An investor owns shares in a stock whose present
value is 25. She has decided that she must sell her
stock if it goes either down to 10 or up to 40. If each
change of price is either up 1 point with probabil-
ity .55 or down 1 point with probability .45, and
the successive changes are independent, what is
the probability that the investor retires a winner?
3.82. A and B flip coins. A starts and continues flipping
until a tail occurs, at which point B starts flipping
and continues until there is a tail. Then A takes
```

**110** Chapter 3 Conditional Probability and Independence

```
over, and so on. Let P 1 be the probability of the
coin’s landing on heads when A flips and P 2 when
B flips. The winner of the game is the first one
to get
(a) 2 heads in a row;
(b) a total of 2 heads;
(c) 3 heads in a row;
(d) a total of 3 heads.
In each case, find the probability that A wins.
3.83. Die A has 4 red and 2 white faces, whereas die B
has 2 red and 4 white faces. A fair coin is flipped
once. If it lands on heads, the game continues with
die A ; if it lands on tails, then die B is to be used.
(a) Show that the probability of red at any throw
is^12.
(b) If the first two throws result in red, what is the
probability of red at the third throw?
(c) If red turns up at the first two throws, what
is the probability that it is die A that is being
used?
3.84. An urn contains 12 balls, of which 4 are white.
Three players— A , B ,and C —successively draw
from the urn, A first, then B ,then C ,then A ,andso
on. The winner is the first one to draw a white ball.
Find the probability of winning for each player if
(a) each ball is replaced after it is drawn;
(b) the balls that are withdrawn are not replaced.
3.85. Repeat Problem 3.84 when each of the 3 players
selects from his own urn. That is, suppose that
there are 3 different urns of 12 balls with 4 white
balls in each urn.
3.86. Let S ={1, 2,..., n }and suppose that A and B are,
independently, equally likely to be any of the 2 n
subsets (including the null set and S itself) of S.
(a) Show that
```
```
P { A ( B }=
```
```
(
3
4
```
```
) n
```
```
Hint :Let N ( B )denote the number of ele-
ments in B .Use
```
```
P { A ( B }=
```
```
∑ n
```
```
i = 0
```
```
P { A ( B | N ( B )= i } P { N ( B )= i }
```
```
Show that P { AB =Ø}=
```
```
(
3
4
```
```
) n
```
```
3.87. In Example 5e, what is the conditional probability
that the i th coin was selected given that the first n
trials all result in heads?
3.88. In Laplace’s rule of succession (Example 5e), are
the outcomes of the successive flips independent?
Explain.
3.89. A person tried by a 3-judge panel is declared guilty
if at least 2 judges cast votes of guilty. Suppose
that when the defendant is in fact guilty, each
judge will independently vote guilty with proba-
bility .7, whereas when the defendant is in fact
innocent, this probability drops to .2. If 70 per-
cent of defendants are guilty, compute the condi-
tional probability that judge number 3 votes guilty
given that
(a) judges 1 and 2 vote guilty;
(b) judges 1 and 2 cast 1 guilty and 1 not
guilty vote;
(c) judges 1 and 2 both cast not guilty votes.
Let Ei , i = 1, 2, 3 denote the event that judge
i casts a guilty vote. Are these events inde-
pendent. Are they conditionally independent?
Explain.
3.90. Suppose that n independent trials, each of which
results in any of the outcomes 0, 1, or 2, with
respective probabilities p 0 , p 1 ,and p 2 ,
```
```
∑ 2
i = 0 pi =1,
are performed. Find the probability that outcomes
1 and 2 both occur at least once.
```
#### Theoretical Exercises

```
3.1. Show that if P ( A )>0, then
```
```
P ( AB | A )Ú P ( AB | A ∪ B )
```
```
3.2. Let A ( B. Express the following probabilities as
simply as possible:
```
```
P ( A | B ), P ( A | Bc ), P ( B | A ), P ( B | Ac )
```
```
3.3. Consider a school community of m families, with ni
of them having i children, i =1,..., k ,
```
```
∑ k
i = 1
```
```
ni = m.
Consider the following two methods for choosing
a child:
```
1. Choose one of the _m_ families at random and
    then randomly choose a child from that family.
2. Choose one of the

```
∑ k
i = 1
```
```
ini children at random.
```
```
Show that method 1 is more likely than method 2
to result in the choice of a firstborn child.
Hint : In solving this problem, you will need to
show that
```
```
∑ k
```
```
i = 1
```
```
ini
```
```
∑ k
```
```
j = 1
```
```
nj
j
```
```
Ú
```
```
∑ k
```
```
i = 1
```
```
ni
```
```
∑ k
```
```
j = 1
```
```
nj
```

```
Theoretical Exercises 111
```
To do so, multiply the sums and show that, for all
pairs _i_ , _j_ , the coefficient of the term _ninj_ is greater
in the expression on the left than in the one on the
right.
**3.4.** A ball is in any one of _n_ boxes and is in the _i_ th box
with probability _Pi_. If the ball is in box _i_ , a search of
that box will uncover it with probabilityα _i_. Show
that the conditional probability that the ball is in
box _j_ , given that a search of box _i_ did not uncover
it, is
_Pj_
1 −α _iPi_

```
if j Z i
```
```
( 1 −α i ) Pi
1 −α iPi
```
```
if j = i
```
**3.5.** An event _F_ is said to carry negative information
about an event _E_ , and we write _F_ R _E_ ,if

```
P ( E | F )... P ( E )
```
Prove or give counterexamples to the following
assertions:
**(a)** If _F_ R _E_ ,then _E_ R _F_.
**(b)** If _F_ R _E_ and _E_ R _G_ ,then _F_ R _G_.
**(c)** If _F_ R _E_ and _G_ R _E_ ,then _FG_ R _E_.
Repeat parts (a), (b), and (c) whenRis replaced
byQ, where we say that _F_ carries positive informa-
tion about _E_ , written _F_ Q _E_ ,when _P_ ( _E_ | _F_ )Ú _P_ ( _E_ ).
**3.6.** Prove that if _E_ 1 , _E_ 2 ,..., _En_ are independent
events, then

```
P ( E 1 ∪ E 2 ∪ ··· ∪ En )= 1 −
```
```
∏ n
```
```
i = 1
```
```
[1− P ( Ei )]
```
**3.7. (a)** An urn contains _n_ white and _m_ black balls.
The balls are withdrawn one at a time until
only those of the same color are left. Show
that, with probability _n_ /( _n_ + _m_ ),theyareall
white.
_Hint_ : Imagine that the experiment continues
until all the balls are removed, and consider
the last ball withdrawn.
**(b)** A pond contains 3 distinct species of fish,
which we will call the Red, Blue, and Green
fish. There are _r_ Red, _b_ Blue, and _g_ Green fish.
Suppose that the fish are removed from the
pond in a random order. (That is, each selec-
tion is equally likely to be any of the remain-
ing fish.) What is the probability that the Red
fish are the first species to become extinct in
the pond?
_Hint_ :Write _P_ { _R_ }= _P_ { _RBG_ }+ _P_ { _RGB_ },
and compute the probabilities on the right
by first conditioning on the last species to be
removed.

```
3.8. Let A , B ,and C be events relating to the experi-
ment of rolling a pair of dice.
(a) If
```
```
P ( A | C )> P ( B | C ) and P ( A | Cc )> P ( B | Cc )
```
```
either prove that P ( A )> P ( B )or give a coun-
terexample by defining events A , B ,and C for
which that relationship is not true.
(b) If
```
```
P ( A | C )> P ( A | Cc ) and P ( B | C )> P ( B | Cc )
```
```
either prove that P ( AB | C )> P ( AB | Cc )or
give a counterexample by defining events
A , B ,and C for which that relationship is not
true.
Hint :Let C be the event that the sum of a pair of
dice is 10; let A be the event that the first die lands
on 6; let B be the event that the second die lands
on 6.
3.9. Consider two independent tosses of a fair coin. Let
A be the event that the first toss results in heads, let
B be the event that the second toss results in heads,
and let C be the event that in both tosses the coin
lands on the same side. Show that the events A , B ,
and C are pairwise independent—that is, A and B
are independent, A and C are independent, and B
and C are independent—but not independent.
3.10. Consider a collection of n individuals. Assume that
each person’s birthday is equally likely to be any of
the 365 days of the year and also that the birthdays
are independent. Let Ai , j , i Z j , denote the event
that persons i and j have the same birthday. Show
that these events are pairwise independent, but not
independent. That is, show that Ai , j and Ar , s are
independent, but the
```
```
(
n
2
```
```
)
events Ai , j , i Z j are not
independent.
3.11. In each of n independent tosses of a coin, the coin
lands on heads with probability p. How large need
n be so that the probability of obtaining at least
one head is at least^12?
3.12. Show that 0... ai ...1, i =1, 2,...,then
```
```
∑q
```
```
i = 1
```
```
⎡
⎢
⎣ ai
```
```
i ∏− 1
```
```
j = 1
```
```
( 1 − aj )
```
```
⎤
⎥
⎦+
```
```
∏q
```
```
i = 1
```
```
( 1 − ai )= 1
```
```
Hint : Suppose that an infinite number of coins are
to be flipped. Let ai be the probability that the i th
coin lands on heads, and consider when the first
head occurs.
3.13. The probability of getting a head on a single toss
of a coin is p. Suppose that A starts and continues
to flip the coin until a tail shows up, at which point
```

**112** Chapter 3 Conditional Probability and Independence

```
B starts flipping. Then B continues to flip until a
tail comes up, at which point A takes over, and so
on. Let Pn , m denote the probability that A accu-
mulates a total of n heads before B accumulates
m. Show that
```
```
Pn , m = pPn −1, m +( 1 − p )( 1 − Pm , n )
```
∗ **3.14.** Suppose that you are gambling against an infinitely

```
rich adversary and at each stage you either win
or lose 1 unit with respective probabilities p and
1 − p. Show that the probability that you eventu-
ally go broke is
```
```
1if p ...^12
( q / p ) i if p >^12
```
```
where q = 1 − p and where i is your initial fortune.
3.15. Independent trials that result in a success with
probability p are successively performed until a
total of r successes is obtained. Show that the prob-
ability that exactly n trials are required is
(
n − 1
r − 1
```
```
)
pr ( 1 − p ) n − r
```
```
Use this result to solve the problem of the points
(Example 4j).
Hint :Inorderforittotake n trials to obtain r suc-
cesses, how many successes must occur in the first
n −1 trials?
3.16. Independent trials that result in a success with
probability p and a failure with probability 1−
p are called Bernoulli trials .Let Pn denote the
probability that n Bernoulli trials result in an even
number of successes (0 being considered an even
number). Show that
```
```
Pn = p ( 1 − Pn − 1 )+( 1 − p ) Pn − 1 n Ú 1
```
```
and use this formula to prove (by induction) that
```
```
Pn =
1 +( 1 − 2 p ) n
2
```
```
3.17. Suppose that n independent trials are performed,
with trial i being a success with probability 1/( 2 i +
1 ).Let Pn denote the probability that the total
number of successes that result is an odd number.
(a) Find Pn for n =1, 2, 3, 4, 5.
(b) Conjecture a general formula for Pn.
(c) Derive a formula for Pn in terms of Pn − 1.
(d) Verify that your conjecture in part (b) satisfies
the recursive formula in part (d). Because the
recursive formula has a unique solution, this
then proves that your conjecture is correct.
```
```
3.18. Let Qn denote the probability that no run of 3 con-
secutive heads appears in n tosses of a fair coin.
Show that
```
```
Qn =
1
2
```
```
Qn − 1 +
1
4
```
```
Qn − 2 +
1
8
```
```
Qn − 3
Q 0 = Q 1 = Q 2 = 1
```
```
Find Q 8.
Hint : Condition on the first tail.
3.19. Consider the gambler’s ruin problem, with the
exception that A and B agree to play no more than
n games. Let Pn , i denote the probability that A
winds up with all the money when A starts with
i and B starts with N − i. Derive an equation
for Pn , i in terms of Pn −1, i + 1 and Pn −1, i − 1 ,and
compute P 7, 3, N =5.
3.20. Consider two urns, each containing both white
and black balls. The probabilities of drawing white
balls from the first and second urns are, respec-
tively, p and p ′. Balls are sequentially selected with
replacement as follows: With probabilityα,aball
is initially chosen from the first urn, and with prob-
ability 1−α, it is chosen from the second urn. The
subsequent selections are then made according to
the rule that whenever a white ball is drawn (and
replaced), the next ball is drawn from the same
urn, but when a black ball is drawn, the next ball is
taken from the other urn. Letα n denote the prob-
ability that the n th ball is chosen from the first urn.
Show that
```
```
α n + 1 =α n ( p + p ′− 1 )+ 1 − p ′ n Ú 1
```
```
and use this formula to prove that
```
```
α n =
```
```
1 − p ′
2 − p − p ′
```
```
+
```
```
(
α−
```
```
1 − p ′
2 − p − p ′
```
```
)
```
```
*( p + p ′− 1 ) n −^1
```
```
Let Pn denote the probability that the n th
ball selected is white. Find Pn. Also, compute
lim n →qα n and lim n →q Pn.
3.21. The Ballot Problem. In an election, candidate A
receives n votes and candidate B receives m votes,
where n > m. Assuming that all of the( n +
m )!/ n! m! orderings of the votes are equally likely,
let Pn , m denote the probability that A is always
ahead in the counting of the votes.
(a) Compute P 2,1, P 3,1, P 3,2, P 4,1, P 4,2, P 4,3.
(b) Find Pn ,1, Pn ,2.
(c) On the basis of your results in parts (a) and
(b), conjecture the value of Pn , m.
(d) Derive a recursion for Pn , m in terms of Pn −1, m
and Pn , m − 1 by conditioning on who receives
the last vote.
```

```
Theoretical Exercises 113
```
```
(e) Use part (d) to verify your conjecture in part
(c) by an induction proof on n + m.
3.22. As a simplified model for weather forecasting, sup-
pose that the weather (either wet or dry) tomor-
row will be the same as the weather today with
probability p. Show that the weather is dry on Jan-
uary 1, then Pn , the probability that it will be dry n
days later, satisfies
```
```
Pn =( 2 p − 1 ) Pn − 1 +( 1 − p ) n Ú 1
P 0 = 1
```
```
Prove that
```
```
Pn =
```
```
1
2
+
```
```
1
2
( 2 p − 1 ) n n Ú 0
```
```
3.23. A bag contains a white and b black balls. Balls
are chosen from the bag according to the following
method:
```
1. A ball is chosen at random and is discarded.
2. A second ball is then chosen. If its color is
    different from that of the preceding ball, it is
    replaced in the bag and the process is repeated
    from the beginning. If its color is the same, it is
    discarded and we start from step 2.
In other words, balls are sampled and discarded
until a change in color occurs, at which point the
last ball is returned to the urn and the process
starts anew. Let _Pa_ , _b_ denote the probability that
the last ball in the bag is white. Prove that

_Pa_ , _b_ =
1
2
_Hint_ : Use induction on _k_ K _a_ + _b_.
∗ **3.24.** A round-robin tournament of _n_ contestants is a

```
tournament in which each of the
```
```
(
n
2
```
```
)
pairs of
contestants play each other exactly once, with the
outcome of any play being that one of the contes-
tants wins and the other loses. For a fixed integer
k , k < n , a question of interest is whether it is pos-
sible that the tournament outcome is such that, for
every set of k players, there is a player who beat
each member of that set. Show that if
(
n
k
```
```
)[
1 −
```
```
(
1
2
```
```
) k ] n − k
< 1
```
```
then such an outcome is possible.
Hint : Suppose that the results of the games are
independent and that each game is equally likely
```
```
to be won by either contestant. Number the
```
```
(
n
k
```
```
)
```
```
sets of k contestants, and let Bi denote the event
that no contestant beat all of the k players in
the i th set. Then use Boole’s inequality to bound
```
```
P
```
```
(
⋃
i
```
```
Bi
```
```
)
.
```
```
3.25. Prove directly that
```
```
P ( E | F )= P ( E | FG ) P ( G | F )+ P ( E | FGc ) P ( Gc | F )
```
```
3.26. Prove the equivalence of Equations (5.11) and
(5.12).
3.27. Extend the definition of conditional independence
to more than 2 events.
3.28. Prove or give a counterexample. If E 1 and E 2 are
independent, then they are conditionally indepen-
dent given F.
3.29. In Laplace’s rule of succession (Example 5e),
show that if the first n flips all result in heads,
then the conditional probability that the next m
flips also result in all heads is ( n + 1 )/( n +
m + 1 ).
3.30. In Laplace’s rule of succession (Example 5e), sup-
pose that the first n flips resulted in r heads and
n − r tails. Show that the probability that the
( n + 1 )st flip turns up heads is( r + 1 )/( n + 2 ).To
do so, you will have to prove and use the identity
∫ 1
```
```
0
```
```
yn ( 1 − y ) mdy =
```
```
n! m!
( n + m + 1 )!
Hint : To prove the identity, let C ( n , m ) =
∫ 1
0 y
n ( 1 − y ) mdy. Integrating by parts yields
```
```
C ( n , m )=
```
```
m
n + 1
```
```
C ( n +1, m − 1 )
```
```
Starting with C ( n ,0)= 1 /( n + 1 ), prove the iden-
tity by induction on m.
3.31. Suppose that a nonmathematical, but philosophi-
cally minded, friend of yours claims that Laplace’s
rule of succession must be incorrect because it can
lead to ridiculous conclusions. “For instance,” says
he, “the rule states that if a boy is 10 years old,
having lived 10 years, the boy has probability^1112 of
living another year. On the other hand, if the boy
has an 80-year-old grandfather, then, by Laplace’s
rule, the grandfather has probability^8182 of sur-
viving another year. However, this is ridiculous.
Clearly, the boy is more likely to survive an addi-
tional year than the grandfather is.” How would
you answer your friend?
```

**114** Chapter 3 Conditional Probability and Independence

#### Self-Test Problems and Exercises

```
3.1. In a game of bridge, West has no aces. What is the
probability of his partner’s having (a) no aces? (b)
2 or more aces? (c) What would the probabilities
be if West had exactly 1 ace?
3.2. The probability that a new car battery functions
for over 10,000 miles is .8, the probability that it
functions for over 20,000 miles is .4, and the prob-
ability that it functions for over 30,000 miles is .1. If
a new car battery is still working after 10,000 miles,
what is the probability that
(a) its total life will exceed 20,000 miles?
(b) its additional life will exceed 20,000 miles?
3.3. How can 20 balls, 10 white and 10 black, be put
into two urns so as to maximize the probability of
drawing a white ball if an urn is selected at random
and a ball is drawn at random from it?
3.4. Urn A contains 2 white balls and 1 black ball,
whereas urn B contains 1 white ball and 5 black
balls. A ball is drawn at random from urn A and
placed in urn B. A ball is then drawn from urn B.
It happens to be white. What is the probability that
the ball transferred was white?
3.5. An urn has r red and w white balls that are ran-
domly removed one at a time. Let Ri be the event
that the i th ball removed is red. Find
(a) P ( Ri )
(b) P ( R 5 | R 3 )
(c) P ( R 3 | R 5 )
3.6. An urn contains b black balls and r red balls. One
of the balls is drawn at random, but when it is
put back in the urn, c additional balls of the same
color are put in with it. Now, suppose that we
draw another ball. Show that the probability that
the first ball was black, given that the second ball
drawn was red, is b /( b + r + c ).
3.7. A friend randomly chooses two cards, without
replacement, from an ordinary deck of 52 playing
cards. In each of the following situations, deter-
mine the conditional probability that both cards
are aces.
(a) You ask your friend if one of the cards is the
ace of spades, and your friend answers in the
affirmative.
(b) You ask your friend if the first card selected
is an ace, and your friend answers in the affir-
mative.
(c) You ask your friend if the second card
selected is an ace, and your friend answers in
the affirmative.
(d) You ask your friend if either of the cards
selected is an ace, and your friend answers in
the affirmative.
```
```
3.8. Show that
P ( H | E )
P ( G | E )
```
```
=
```
```
P ( H )
P ( G )
```
```
P ( E | H )
P ( E | G )
Suppose that, before new evidence is observed, the
hypothesis H is three times as likely to be true as
is the hypothesis G. If the new evidence is twice
as likely when G is true than it is when H is true,
which hypothesis is more likely after the evidence
has been observed?
3.9. You ask your neighbor to water a sickly plant
while you are on vacation. Without water, it will
die with probability .8; with water, it will die with
probability .15. You are 90 percent certain that
your neighbor will remember to water the plant.
(a) What is the probability that the plant will be
alive when you return?
(b) If the plant is dead upon your return, what is
the probability that your neighbor forgot to
water it?
3.10. Six balls are to be randomly chosen from an urn
containing 8 red, 10 green, and 12 blue balls.
(a) What is the probability at least one red ball is
chosen?
(b) Given that no red balls are chosen, what is the
conditional probability that there are exactly
2 green balls among the 6 chosen?
3.11. A type C battery is in working condition with prob-
ability.7, whereas a type D battery is in work-
ing condition with probability.4. A battery is ran-
domly chosen from a bin consisting of 8 type C and
6 type D batteries.
(a) What is the probability that the battery
works?
(b) Given that the battery does not work, what is
the conditional probability that it was a type
C battery?
3.12. Maria will take two books with her on a trip. Sup-
pose that the probability that she will like book 1
is.6, the probability that she will like book 2 is.5,
and the probability that she will like both books
is.4. Find the conditional probability that she will
like book 2 given that she did not like book 1.
3.13. Balls are randomly removed from an urn that ini-
tially contains 20 red and 10 blue balls.
(a) What is the probability that all of the red balls
are removed before all of the blue ones have
been removed?
Now suppose that the urn initially contains 20
red, 10 blue, and 8 green balls.
(b) Now what is the probability that all of the red
balls are removed before all of the blue ones
have been removed?
```

```
Self-Test Problems and Exercises 115
```
**(c)** What is the probability that the colors are
depleted in the order blue, red, green?
**(d)** What is the probability that the group of blue
balls is the first of the three groups to be
removed?
**3.14.** A coin having probability.8 of landing on heads
is flipped. _A_ observes the result—either heads or
tails—and rushes off to tell _B_. However, with prob-
ability.4, _A_ will have forgotten the result by the
time he reaches _B_ .If _A_ has forgotten, then, rather
than admitting this to _B_ , he is equally likely to tell
_B_ that the coin landed on heads or that it landed
tails. (If he does remember, then he tells _B_ the cor-
rect result.)
**(a)** What is the probability that _B_ is told that the
coin landed on heads?
**(b)** What is the probability that _B_ is told the cor-
rect result?
**(c)** Given that _B_ is told that the coin landed on
heads, what is the probability that it did in fact
land on heads?
**3.15.** In a certain species of rats, black dominates over
brown. Suppose that a black rat with two black
parents has a brown sibling.
**(a)** What is the probability that this rat is a pure
black rat (as opposed to being a hybrid with
one black and one brown gene)?
**(b)** Suppose that when the black rat is mated with
a brown rat, all 5 of their offspring are black.
Now what is the probability that the rat is a
pure black rat?
**3.16. (a)** In Problem 3.65b, find the probability that a
current flows from _A_ to _B_ , by conditioning on
whether relay 1 closes.
**(b)** Find the conditional probability that relay 3 is
closed given that a current flows from _A_ to _B_.
**3.17.** For the _k_ -out-of- _n_ system described in
Problem 3.67, assume that each component
independently works with probability^12 .Findthe
conditional probability that component 1 is work-
ing, given that the system works, when
**(a)** _k_ =1, _n_ =2;
**(b)** _k_ =2, _n_ =3.
**3.18.** Mr. Jones has devised a gambling system for win-
ning at roulette. When he bets, he bets on red and
places a bet only when the 10 previous spins of
the roulette have landed on a black number. He
reasons that his chance of winning is quite large
because the probability of 11 consecutive spins
resulting in black is quite small. What do you think
of this system?
**3.19.** Three players simultaneously toss coins. The coin
tossed by _A_ ( _B_ )[ _C_ ] turns up heads with probability
_P_ 1 ( _P_ 2 )[ _P_ 3 ]. If one person gets an outcome differ-
ent from those of the other two, then he is the odd

```
man out. If there is no odd man out, the players flip
again and continue to do so until they get an odd
man out. What is the probability that A will be the
odd man?
3.20. Suppose that there are n possible outcomes of
a trial, with outcome i resulting with probability
pi , i =1,..., n ,
```
```
∑ n
i = 1
```
```
pi =1. If two independent tri-
als are observed, what is the probability that the
result of the second trial is larger than that of the
first?
3.21. If A flips n +1and B flips n fair coins, show that
the probability that A gets more heads than B is^12.
Hint : Condition on which player has more heads
after each has flipped n coins. (There are three
possibilities.)
3.22. Prove or give counterexamples to the following
statements:
(a) If E is independent of F and E is independent
of G ,then E is independent of F ∪ G.
(b) If E is independent of F ,and E is independent
of G ,and FG =Ø, then E is independent of
F ∪ G.
(c) If E is independent of F ,and F is independent
of G ,and E is independent of FG ,then G is
independent of EF.
3.23. Let A and B be events having positive probabil-
ity. State whether each of the following statements
is (i) necessarily true, (ii) necessarily false, or (iii)
possibly true.
(a) If A and B are mutually exclusive, then they
are independent.
(b) If A and B are independent, then they are
mutually exclusive.
(c) P ( A )= P ( B )=.6, and A and B are mutually
exclusive.
(d) P ( A )= P ( B )=.6, and A and B are indepen-
dent.
3.24. Rank the following from most likely to least likely
to occur:
```
1. A fair coin lands on heads.
2. Three independent trials, each of which is a suc-
    cess with probability .8, all result in successes.
3. Seven independent trials, each of which is a suc-
    cess with probability .9, all result in successes.
**3.25.** Two local factories, _A_ and _B_ , produce radios. Each
radio produced at factory _A_ is defective with prob-
ability .05, whereas each one produced at factory _B_
is defective with probability .01. Suppose you pur-
chase two radios that were produced at the same
factory, which is equally likely to have been either
factory _A_ or factory _B_. If the first radio that you
check is defective, what is the conditional proba-
bility that the other one is also defective?


**116** Chapter 3 Conditional Probability and Independence

```
3.26. Show that if P ( A | B )=1, then P ( Bc | Ac )=1.
3.27. An urn initially contains 1 red and 1 blue ball.
At each stage, a ball is randomly withdrawn and
replaced by two other balls of the same color.
(For instance, if the red ball is initially chosen,
thentherewouldbe2redand1blueballin
the urn when the next selection occurs.) Show
by mathematical induction that the probability
that there are exactly i red balls in the urn
after n stages have been completed is n +^11 ,1...
i ... n + 1.
3.28. A total of 2 n cards, of which 2 are aces, are
to be randomly divided among two players, with
each player receiving n cards. Each player is then
to declare, in sequence, whether he or she has
received any aces. What is the conditional proba-
bility that the second player has no aces, given that
the first player declares in the affirmative, when
(a) n =2? (b) n = 10? (c) n = 100? To what
does the probability converge as n goes to infinity?
Why?
```
```
3.29. There are n distinct types of coupons, and
each coupon obtained is, independently of prior
types collected, of type∑ i with probability pi ,
n
i = 1 pi =1.
(a) If n coupons are collected, what is the proba-
bility that one of each type is obtained?
(b) Now suppose that p 1 = p 2 = ··· = pn = 1 / n.
Let Ei be the event that there are no type
i coupons among the n collected. Apply the
inclusion–exclusion identity for the probabil-
ity of the union of events to P (∪ iEi )to prove
the identity
```
```
n !=
```
```
∑ n
```
```
k = 0
```
```
(− 1 ) k
```
```
(
n
k
```
```
)
( n − k ) n
```
```
3.30. Show that, for any events E and F ,
```
```
P ( E | E ∪ F )Ú P ( E | F )
```
```
Hint : Compute P ( E | E ∪ F )by conditioning on
whether F occurs.
```

## CHAPTER 4

# Random Variables

### 4.1 Random Variables..............................

**4.2 DISCRETE RANDOM VARIABLES
4.3 EXPECTED VALUE
4.4 EXPECTATION OF A FUNCTION OF A RANDOM VARIABLE
4.5 VARIANCE
4.6 THE BERNOULLI AND BINOMIAL RANDOM VARIABLES
4.7 THE POISSON RANDOM VARIABLE
4.8 OTHER DISCRETE PROBABILITY DISTRIBUTIONS
4.9 EXPECTED VALUE OF SUMS OF RANDOM VARIABLES
4.10 PROPERTIES OF THE CUMULATIVE DISTRIBUTION FUNCTION**

##### 4.1 RANDOM VARIABLES

```
Frequently, when an experiment is performed, we are interested mainly in some func-
tion of the outcome as opposed to the actual outcome itself. For instance, in tossing
dice, we are often interested in the sum of the two dice and are not really concerned
about the separate values of each die. That is, we may be interested in knowing
that the sum is 7 and may not be concerned over whether the actual outcome was
(1, 6), (2, 5), (3, 4), (4, 3), (5, 2), or (6, 1). Also, in flipping a coin, we may be inter-
ested in the total number of heads that occur and not care at all about the actual
head–tail sequence that results. These quantities of interest, or, more formally, these
real-valued functions defined on the sample space, are known as random variables.
Because the value of a random variable is determined by the outcome of the exper-
iment, we may assign probabilities to the possible values of the random variable.
```
```
EXAMPLE 1a
Suppose that our experiment consists of tossing 3 fair coins. If we let Y denote the
number of heads that appear, then Y is a random variable taking on one of the values
0, 1, 2, and 3 with respective probabilities
```
##### P { Y = 0 }= P {( T , T , T )}=

##### 1

##### 8

##### P { Y = 1 }= P {( T , T , H ),( T , H , T ),( H , T , T )}=

##### 3

##### 8

##### P { Y = 2 }= P {( T , H , H ),( H , T , H ),( H , H , T )}=

##### 3

##### 8

##### P { Y = 3 }= P {( H , H , H )}=

##### 1

##### 8

```
117
```

**118** Chapter 4 Random Variables

```
Since Y must take on one of the values 0 through 3, we must have
```
##### 1 = P

##### ⎛

##### ⎝

##### ⋃^3

```
i = 0
```
```
{ Y = i }
```
##### ⎞

##### ⎠=

##### ∑^3

```
i = 0
```
```
P { Y = i }
```
```
which, of course, is in accord with the preceding probabilities..
```
```
EXAMPLE 1b
Three balls are to be randomly selected without replacement from an urn contain-
ing 20 balls numbered 1 through 20. If we bet that at least one of the balls that are
drawn has a number as large as or larger than 17, what is the probability that we
win the bet?
```
```
Solution. Let X denote the largest number selected. Then X is a random variable
taking on one of the values 3, 4,( ..., 20. Furthermore, if we suppose that each of the
20
3
```
##### )

```
possible selections are equally likely to occur, then
```
```
P { X = i }=
```
##### (

```
i − 1
2
```
##### )

##### (

##### 20

##### 3

```
) i =3,..., 20 (1.1)
```
```
Equation (1.1) follows because the number of selections that result in the event
{ X = i }is just the number of selections that result in the ball numbered i and two
of the balls numbered 1 through i −1 being chosen. Because there are clearly
```
##### (

##### 1

##### 1

##### )

##### (

```
i − 1
2
```
##### )

```
such selections, we obtain the probabilities expressed in Equation (1.1),
from which we see that
```
##### P { X = 20 }=

##### (

##### 19

##### 2

##### )

##### (

##### 20

##### 3

##### )=

##### 3

##### 20

##### =. 150

##### P { X = 19 }=

##### (

##### 18

##### 2

##### )

##### (

##### 20

##### 3

##### )=

##### 51

##### 380

##### L. 134

##### P { X = 18 }=

##### (

##### 17

##### 2

##### )

##### (

##### 20

##### 3

##### )=

##### 34

##### 285

##### L. 119

##### P { X = 17 }=

##### (

##### 16

##### 2

##### )

##### (

##### 20

##### 3

##### )=

##### 2

##### 19

##### L. 105


```
Section 4.1 Random Variables 119
```
Hence, since the event{ _X_ Ú 17 }is the union of the disjoint events{ _X_ = _i_ },
_i_ = 17, 18, 19, 20, it follows that the probability of our winning the bet is given by

##### P { X Ú 17 }L. 105 +. 119 +. 134 +. 150 =. 508.

**_EXAMPLE 1c_**

Independent trials consisting of the flipping of a coin having probability _p_ of coming
up heads are continually performed until either a head occurs or a total of _n_ flips is
made. If we let _X_ denote the number of times the coin is flipped, then _X_ is a random
variable taking on one of the values 1, 2, 3,..., _n_ with respective probabilities

```
P { X = 1 }= P { H }= p
```
```
P { X = 2 }= P {( T , H )}=( 1 − p ) p
```
```
P { X = 3 }= P {( T , T , H )}=( 1 − p )^2 p
```
##### #

##### #

##### #

```
P { X = n − 1 }= P {( T ︸, T ,︷︷..., T ︸,
n − 2
```
```
H )}=( 1 − p ) n −^2 p
```
```
P { X = n }= P {( T , T ,..., T ,
︸ ︷︷ ︸
n − 1
```
##### T ),( T , T ,..., T ,

##### ︸ ︷︷ ︸

```
n − 1
```
```
H )}=( 1 − p ) n −^1
```
As a check, note that

##### P

##### ⎛

##### ⎝

```
⋃ n
```
```
i = 1
```
```
{ X = i }
```
##### ⎞

##### ⎠=

```
∑ n
```
```
i = 1
```
```
P { X = i }
```
##### =

```
n ∑− 1
```
```
i = 1
```
```
p ( 1 − p ) i −^1 +( 1 − p ) n −^1
```
```
= p
```
##### [

```
1 −( 1 − p ) n −^1
1 −( 1 − p )
```
##### ]

```
+( 1 − p ) n −^1
```
```
= 1 −( 1 − p ) n −^1 +( 1 − p ) n −^1
= 1
```
##### .

**_EXAMPLE 1d_**

Three balls are randomly chosen from an urn containing 3 white, 3 red, and 5 black
balls. Suppose that we win $1 for each white ball selected and lose $1 for each red ball


**120** Chapter 4 Random Variables

```
selected. If we let X denote our total winnings from the experiment, then X is a ran-
dom variable taking on the possible values 0,;1,;2,;3 with respective probabilities
```
##### P { X = 0 }=

##### (

##### 5

##### 3

##### )

##### +

##### (

##### 3

##### 1

##### )(

##### 3

##### 1

##### )(

##### 5

##### 1

##### )

##### (

##### 11

##### 3

##### ) =

##### 55

##### 165

##### P { X = 1 }= P { X =− 1 }=

##### (

##### 3

##### 1

##### )(

##### 5

##### 2

##### )

##### +

##### (

##### 3

##### 2

##### )(

##### 3

##### 1

##### )

##### (

##### 11

##### 3

##### ) =

##### 39

##### 165

##### P { X = 2 }= P { X =− 2 }=

##### (

##### 3

##### 2

##### )(

##### 5

##### 1

##### )

##### (

##### 11

##### 3

##### ) =

##### 15

##### 165

##### P { X = 3 }= P { X =− 3 }=

##### (

##### 3

##### 3

##### )

##### (

##### 11

##### 3

##### )=

##### 1

##### 165

```
These probabilities are obtained, for instance, by noting that in order for X to
equal 0, either all 3 balls selected must be black or 1 ball of each color must be
selected. Similarly, the event{ X = 1 }occurs either if 1 white and 2 black balls are
selected or if 2 white and 1 red is selected. As a check, we note that
```
##### ∑^3

```
i = 0
```
```
P { X = i }+
```
##### ∑^3

```
i = 1
```
```
P { X =− i }=
```
##### 55 + 39 + 15 + 1 + 39 + 15 + 1

##### 165

##### = 1

```
The probability that we win money is given by
```
##### ∑^3

```
i = 1
```
```
P { X = i }=
```
##### 55

##### 165

##### =

##### 1

##### 3

##### .

```
EXAMPLE 1e
Suppose that there are N distinct types of coupons and that each time one obtains a
coupon, it is, independently of previous selections, equally likely to be any one of the
N types. One random variable of interest is T , the number of coupons that needs to
be collected until one obtains a complete set of at least one of each type. Rather than
derive P { T = n }directly, let us start by considering the probability that T is greater
than n. To do so, fix n and define the events A 1 , A 2 ,..., AN as follows: Aj is the event
```

```
Section 4.1 Random Variables 121
```
that no type _j_ coupon is contained among the first _n_ coupons collected, _j_ =1,..., _N_.
Hence,

```
P { T > n }= P
```
##### ⎛

##### ⎜

##### ⎝

##### ⋃ N

```
j = 1
```
```
Aj
```
##### ⎞

##### ⎟

##### ⎠

##### =

##### ∑

```
j
```
```
P ( Aj )−
```
##### ∑∑

```
j 1 < j 2
```
```
P ( Aj 1 Aj 2 )+ ···
```
```
+(− 1 ) k +^1
```
##### ∑∑∑

```
j 1 < j 2 <···< jk
```
```
P ( Aj 1 Aj 2 ··· Ajk )···
```
##### +(− 1 ) N +^1 P ( A 1 A 2 ··· AN )

Now, _Aj_ will occur if each of the _n_ coupons collected is not of type _j_. Since each of the
coupons will not be of type _j_ with probability( _N_ − 1 )/ _N_ , we have, by the assumed
independence of the types of successive coupons,

```
P ( Aj )=
```
##### (

##### N − 1

##### N

```
) n
```
Also, the event _Aj_ 1 _Aj_ 2 will occur if none of the first _n_ coupons collected is of either
type _j_ 1 or type _j_ 2. Thus, again using independence, we see that

```
P ( Aj 1 Aj 2 )=
```
##### (

##### N − 2

##### N

```
) n
```
The same reasoning gives

```
P ( Aj 1 Aj 2 ··· Ajk )=
```
##### (

```
N − k
N
```
```
) n
```
and we see that, for _n_ >0,

```
P { T > n }= N
```
##### (

##### N − 1

##### N

```
) n
−
```
##### (

##### N

##### 2

##### )(

##### N − 2

##### N

```
) n
+
```
##### (

##### N

##### 3

##### )(

##### N − 3

##### N

```
) n
− ···
```
##### +(− 1 ) N

##### (

##### N

##### N − 1

##### )(

##### 1

##### N

```
) n
```
##### =

##### N ∑− 1

```
i = 1
```
##### (

##### N

```
i
```
##### )(

```
N − i
N
```
```
) n
(− 1 ) i +^1 (1.2)
```
The probability that _T_ equals _n_ can now be obtained from the preceding formula by
the use of

```
P { T > n − 1 }= P { T = n }+ P { T > n }
```
or, equivalently,

```
P { T = n }= P { T > n − 1 }− P { T > n }
```
Another random variable of interest is the number of distinct types of coupons
that are contained in the first _n_ selections—call this random variable _Dn_. To compute


**122** Chapter 4 Random Variables

```
P { Dn = k }, let us start by fixing attention on a particular set of k distinct types,
and let us then determine the probability that this set constitutes the set of distinct
types obtained in the first n selections. Now, in order for this to be the situation, it is
necessary and sufficient that, of the first n coupons obtained,
```
```
A : each is one of these k types.
B : each of these k types is represented.
```
```
Now, each coupon selected will be one of the k types with probability k/N ,sothe
probability that A will be valid is( k / N ) n. Also, given that a coupon is of one of the k
types under consideration, it is easy to see that it is equally likely to be of any one of
these k types. Hence, the conditional probability of B given that A occurs is the same
as the probability that a set of n coupons, each equally likely to be any of k possible
types, contains a complete set of all k types. But this is just the probability that the
number needed to amass a complete set, when choosing among k types, is less than
or equal to n and is thus obtainable from Equation (1.2) with k replacing N. Thus,
we have
```
##### P ( A )=

##### (

```
k
N
```
```
) n
```
##### P ( B | A )= 1 −

```
k ∑− 1
```
```
i = 1
```
##### (

```
k
i
```
##### )(

```
k − i
k
```
```
) n
(− 1 ) i +^1
```
```
Finally, as there are
```
##### (

##### N

```
k
```
##### )

```
possible choices for the set of k types, we arrive at
```
```
P { Dn = k }=
```
##### (

##### N

```
k
```
##### )

##### P ( AB )

##### =

##### (

##### N

```
k
```
##### )(

```
k
N
```
```
) n
```
##### ⎡

##### ⎣ 1 −

```
k ∑− 1
```
```
i = 1
```
##### (

```
k
i
```
##### )(

```
k − i
k
```
```
) n
(− 1 ) i +^1
```
##### ⎤

##### ⎦

```
Remark. Since one must collect at least N coupons to obtain a compete set, it
follows that P { T > n }=1if n < N. Therefore, from Equation (1.2), we obtain the
interesting combinatorial identity that, for integers 1 ... n < N ,
```
```
N ∑− 1
```
```
i = 1
```
##### (

##### N

```
i
```
##### )(

```
N − i
N
```
```
) n
(− 1 ) i +^1 = 1
```
```
which can be written as
N ∑− 1
```
```
i = 0
```
##### (

##### N

```
i
```
##### )(

```
N − i
N
```
```
) n
(− 1 ) i +^1 = 0
```
```
or, upon multiplying by(− 1 ) NNn and letting j = N − i ,
```
```
∑ N
```
```
j = 1
```
##### (

##### N

```
j
```
##### )

```
jn (− 1 ) j −^1 = 01 ... n < N
.
```

```
Section 4.2 Discrete Random Variables 123
```
```
For a random variable X , the function F defined by
```
```
F ( x )= P { X ... x }−q< x <q
```
```
is called the cumulative distribution function , or, more simply, the distribution func-
tion ,of X. Thus, the distribution function specifies, for all real values x , the probability
that the random variable is less than or equal to x.
Now, suppose that a ... b. Then, because the event{ X ... a }is contained in the
event{ X ... b }, it follows that F ( a ), the probability of the former, is less than or
equal to F ( b ), the probability of the latter. In other words, F ( x )is a nondecreas-
ing function of x. Other general properties of the distribution function are given in
Section 4.10.
```
### 4.2 Discrete Random Variables

```
A random variable that can take on at most a countable number of possible values is
said to be discrete. For a discrete random variable X , we define the probability mass
function p ( a )of X by
p ( a )= P { X = a }
```
```
The probability mass function p ( a )is positive for at most a countable number of val-
ues of a. That is, if X must assume one of the values x 1 , x 2 ,...,then
```
```
p ( xi )Ú0for i =1, 2,...
p ( x )=0 for all other values of x
```
```
Since X must take on one of the values xi , we have
```
```
∑q
```
```
i = 1
```
```
p ( xi )= 1
```
```
It is often instructive to present the probability mass function in a graphical format
by plotting p ( xi )on the y -axis against xi on the x -axis. For instance, if the probability
mass function of X is
```
```
p ( 0 )=
```
##### 1

##### 4

```
p ( 1 )=
```
##### 1

##### 2

```
p ( 2 )=
```
##### 1

##### 4

(^1) –
4
0
_x
p_ ( _x_ )
(^1) –
2
1
12
**FIGURE 4.1**


**124** Chapter 4 Random Variables

```
—^1
36
```
```
0
```
```
x
```
```
p ( x )
```
```
—^2
36
```
```
12
```
```
—^6
36
```
```
—^3
36
```
```
—^4
36
```
```
—^5
36
```
```
3 4 567 8 9 10 11 12
```
```
FIGURE 4.2
```
```
we can represent this function graphically as shown in Figure 4.1. Similarly, a graph
of the probability mass function of the random variable representing the sum when
two dice are rolled looks like Figure 4.2.
```
```
EXAMPLE 2a
The probability mass function of a random variable X is given by p ( i ) = c λ i / i !,
i = 0, 1, 2,..., whereλis some positive value. Find (a) P { X = 0 }and (b) P { X > 2 }.
```
```
Solution. Since
```
```
∑q
i = 0
```
```
p ( i )=1, we have
```
```
c
```
```
∑q
```
```
i = 0
```
```
λ i
i!
```
##### = 1

```
which, because ex =
```
```
∑q
i = 0
```
```
xi / i !, implies that
```
```
ce λ=1or c = e −λ
```
```
Hence,
(a) P { X = 0 }= e −λλ^0 /0!= e −λ
(b) P { X > 2 }= 1 − P { X ... 2 }= 1 − P { X = 0 }− P { X = 1 }
− P { X = 2 }
```
```
= 1 − e −λ−λ e −λ−
```
```
λ^2 e −λ
2.
The cumulative distribution function F can be expressed in terms of p ( a )by
```
```
F ( a )=
```
##### ∑

```
all x ... a
```
```
p ( x )
```
```
If X is a discrete random variable whose possible values are x 1 , x 2 , x 3 ,..., where
x 1 < x 2 < x 3 <···, then the distribution function F of X is a step function. That is,
```

```
Section 4.3 Expected Value 125
```
```
the value of F is constant in the intervals [ xi − 1 , xi )and then takes a step (or jump) of
size p ( xi )at xi. For instance, if X has a probability mass function given by
```
```
p ( 1 )=
```
##### 1

##### 4

```
p ( 2 )=
```
##### 1

##### 2

```
p ( 3 )=
```
##### 1

##### 8

```
p ( 4 )=
```
##### 1

##### 8

```
then its cumulative distribution function is
```
```
F ( a )=
```
##### ⎧

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎨

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎩

```
0 a < 1
1
4 1 ... a <^2
3
4 2 ... a <^3
7
8 3 ... a <^4
14 ... a
```
```
This function is depicted graphically in Figure 4.3.
```
(^1) –
4
1
123
_a
F_ ( _a_ )
4
(^3) –
4
(^7) –
8
**FIGURE 4.3**
Note that the size of the step at any of the values 1, 2, 3, and 4 is equal to the
probability that _X_ assumes that particular value.

### 4.3 ExpectedValue

```
One of the most important concepts in probability theory is that of the expectation
of a random variable. If X is a discrete random variable having a probability mass
function p ( x ), then the expectation ,orthe expected value ,of X , denoted by E [ X ], is
defined by
E [ X ]=
```
##### ∑

```
x : p ( x )> 0
```
```
xp ( x )
```
```
In words, the expected value of X is a weighted average of the possible values that
X can take on, each value being weighted by the probability that X assumes it. For
instance, on the one hand, if the probability mass function of X is given by
```
```
p ( 0 )=
```
##### 1

##### 2

```
= p ( 1 )
```
```
then
E [ X ]= 0
```
##### (

##### 1

##### 2

##### )

##### + 1

##### (

##### 1

##### 2

##### )

##### =

##### 1

##### 2


**126** Chapter 4 Random Variables

```
is just the ordinary average of the two possible values, 0 and 1, that X can assume.
On the other hand, if
```
```
p ( 0 )=
```
##### 1

##### 3

```
p ( 1 )=
```
##### 2

##### 3

```
then
```
```
E [ X ]= 0
```
##### (

##### 1

##### 3

##### )

##### + 1

##### (

##### 2

##### 3

##### )

##### =

##### 2

##### 3

```
is a weighted average of the two possible values 0 and 1, where the value 1 is given
twice as much weight as the value 0, since p ( 1 )= 2 p ( 0 ).
Another motivation of the definition of expectation is provided by the frequency
interpretation of probabilities. This interpretation (partially justified by the strong
law of large numbers, to be presented in Chapter 8) assumes that if an infinite sequence
of independent replications of an experiment is performed, then, for any event E ,
the proportion of time that E occurs will be P ( E ). Now, consider a random vari-
able X that must take on one of the values x 1 , x 2 ,... xn with respective probabilities
p ( x 1 ), p ( x 2 ),..., p ( xn ), and think of X as representing our winnings in a single game of
chance. That is, with probability p ( xi )we shall win xi units i =1, 2,..., n. By the fre-
quency interpretation, if we play this game continually, then the proportion of time
that we win xi will be p ( xi ). Since this is true for all i , i =1, 2,..., n , it follows that our
average winnings per game will be
```
```
∑ n
```
```
i = 1
```
```
xip ( xi )= E [ X ]
```
```
EXAMPLE 3a
Find E [ X ], where X is the outcome when we roll a fair die.
```
```
Solution. Since p ( 1 )= p ( 2 )= p ( 3 )= p ( 4 )= p ( 5 )= p ( 6 )=^16 , we obtain
```
##### E [ X ]= 1

##### (

##### 1

##### 6

##### )

##### + 2

##### (

##### 1

##### 6

##### )

##### + 3

##### (

##### 1

##### 6

##### )

##### + 4

##### (

##### 1

##### 6

##### )

##### + 5

##### (

##### 1

##### 6

##### )

##### + 6

##### (

##### 1

##### 6

##### )

##### =

##### 7

(^2).
**_EXAMPLE 3b_**
We say that _I_ is an indicator variable for the event _A_ if

##### I =

##### {

```
1if A occurs
0if Ac occurs
```
```
Find E [ I ].
```
```
Solution. Since p ( 1 )= P ( A ), p ( 0 )= 1 − P ( A ), we have
```
```
E [ I ]= P ( A )
```
```
That is, the expected value of the indicator variable for the event A is equal to the
probability that A occurs..
```

```
Section 4.3 Expected Value 127
```
**_EXAMPLE 3c_**

A contestant on a quiz show is presented with two questions, questions 1 and 2, which
he is to attempt to answer in some order he chooses. If he decides to try question _i_
first, then he will be allowed to go on to question _j_ , _j_ Z _i_ , only if his answer to question
_i_ is correct. If his initial answer is incorrect, he is not allowed to answer the other ques-
tion. The contestant is to receive _Vi_ dollars if he answers question _i_ correctly, _i_ =1, 2.
For instance, he will receive _V_ 1 + _V_ 2 dollars if he answers both questions correctly.
If the probability that he knows the answer to question _i_ is _Pi_ , _i_ =1, 2, which question
should he attempt to answer first so as to maximize his expected winnings? Assume
that the events _Ei_ , _i_ =1, 2, that he knows the answer to question _i_ are independent
events.

**_Solution._** On the one hand, if he attempts to answer question 1 first, then he will win

```
0 with probability 1 − P 1
V 1 with probability P 1 ( 1 − P 2 )
V 1 + V 2 with probability P 1 P 2
```
Hence, his expected winnings in this case will be

```
V 1 P 1 ( 1 − P 2 )+( V 1 + V 2 ) P 1 P 2
```
On the other hand, if he attempts to answer question 2 first, his expected winnings
will be
_V_ 2 _P_ 2 ( 1 − _P_ 1 )+( _V_ 1 + _V_ 2 ) _P_ 1 _P_ 2

Therefore, it is better to try question 1 first if

```
V 1 P 1 ( 1 − P 2 )Ú V 2 P 2 ( 1 − P 1 )
```
or, equivalently, if
_V_ 1 _P_ 1
1 − _P_ 1

##### Ú

##### V 2 P 2

##### 1 − P 2

For example, if he is 60 percent certain of answering question 1, worth $200, correctly
and he is 80 percent certain of answering question 2, worth $100, correctly, then he
should attempt to answer question 2 first because

##### 400 =

##### ( 100 )(. 8 )

##### . 2

##### >

##### ( 200 )(. 6 )

##### . 4

##### = 300.

**_EXAMPLE 3d_**

A school class of 120 students is driven in 3 buses to a symphonic performance. There
are 36 students in one of the buses, 40 in another, and 44 in the third bus. When the
buses arrive, one of the 120 students is randomly chosen. Let _X_ denote the number
of students on the bus of that randomly chosen student, and find _E_ [ _X_ ].

**_Solution._** Since the randomly chosen student is equally likely to be any of the 120
students, it follows that

##### P { X = 36 }=

##### 36

##### 120

##### P { X = 40 }=

##### 40

##### 120

##### P { X = 44 }=

##### 44

##### 120

Hence,

```
E [ X ]= 36
```
##### (

##### 3

##### 10

##### )

##### + 40

##### (

##### 1

##### 3

##### )

##### + 44

##### (

##### 11

##### 30

##### )

##### =

##### 1208

##### 30

##### = 40. 2667


**128** Chapter 4 Random Variables

```
However, the average number of students on a bus is 120/ 3 =40, showing that the
expected number of students on the bus of a randomly chosen student is larger than
the average number of students on a bus. This is a general phenomenon, and it occurs
because the more students there are on a bus, the more likely it is that a randomly
chosen student would have been on that bus. As a result, buses with many students
are given more weight than those with fewer students. (See Self-Test Problem 4.).
```
```
Remark. The probability concept of expectation is analogous to the physical con-
ceptofthe center of gravity of a distribution of mass. Consider a discrete random
variable X having probability mass function p ( xi ), i Ú1. If we now imagine a weight-
less rod in which weights with mass p ( xi ), i Ú1, are located at the points xi , i Ú 1
(see Figure 4.4), then the point at which the rod would be in balance is known as the
center of gravity. For those readers acquainted with elementary statics, it is now a
simple matter to show that this point is at E [ X ].†.
```
–1 (^0) ^ 1 2
_p_ (–1) = .10, _p_ (0) = .25, _p_ (1) = .30, _p_ (2) = .35
^ = center of gravity = .9
**FIGURE 4.4**

### 4.4 Expectation of a Function of a Random Variable

```
Suppose that we are given a discrete random variable along with its probability mass
function and that we want to compute the expected value of some function of X ,
say, g ( X ). How can we accomplish this? One way is as follows: Since g ( X )is itself a
discrete random variable, it has a probability mass function, which can be determined
from the probability mass function of X. Once we have determined the probability
mass function of g ( X ), we can compute E [ g ( X )] by using the definition of expected
value.
```
```
EXAMPLE 4a
Let X denote a random variable that takes on any of the values−1, 0, and 1 with
respective probabilities
```
```
P { X =− 1 }=. 2 P { X = 0 }=. 5 P { X = 1 }=. 3
```
```
Compute E [ X^2 ].
```
```
Solution. Let Y = X^2. Then the probability mass function of Y is given by
```
```
P { Y = 1 }= P { X =− 1 }+ P { X = 1 }=. 5
P { Y = 0 }= P { X = 0 }=. 5
```
```
Hence,
E [ X^2 ]= E [ Y ]= 1 (. 5 )+ 0 (. 5 )=. 5
```
```
†To prove this, we must show that the sum of the torques tending to turn the point around E [ X ]
is equal to 0. That is, we must show that 0=
```
```
∑
i
```
```
( xi − E [ X ]) p ( xi ), which is immediate.
```

```
Section 4.4 Expectation of a Function of a Random Variable 129
```
Note that

. 5 = _E_ [ _X_^2 ]Z( _E_ [ _X_ ])^2 =. 01.

Although the preceding procedure will always enable us to compute the expected
value of any function of _X_ from a knowledge of the probability mass function of _X_ ,
there is another way of thinking about _E_ [ _g_ ( _X_ )]: Since _g_ ( _X_ )will equal _g_ ( _x_ )whenever
_X_ is equal to _x_ , it seems reasonable that _E_ [ _g_ ( _X_ )] should just be a weighted average of
the values _g_ ( _x_ ),with _g_ ( _x_ )being weighted by the probability that _X_ is equal to _x_. That
is, the following result is quite intuitive:

**Proposition 4.1.**
If _X_ is a discrete random variable that takes on one of the values _xi_ , _i_ Ú1, with
respective probabilities _p_ ( _xi_ ), then, for any real-valued function _g_ ,

```
E [ g ( X )]=
```
##### ∑

```
i
```
```
g ( xi ) p ( xi )
```
Before proving this proposition, let us check that it is in accord with the results of
Example 4a. Applying it to that example yields

```
E { X^2 }=(− 1 )^2 (. 2 )+ 02 (. 5 )+ 12 (. 3 )
= 1 (. 2 +. 3 )+ 0 (. 5 )
=. 5
```
which is in agreement with the result given in Example 4a.

**Proof of Proposition 4.1:** The proof of Proposition 4.1 proceeds, as in the preceding
verification, by grouping together all the terms in

##### ∑

```
i
```
```
g ( xi ) p ( xi )having the same value
```
of _g_ ( _xi_ ). Specifically, suppose that _yj_ , _j_ Ú1, represent the different values of _g_ ( _xi_ ), _i_ Ú1.
Then, grouping all the _g_ ( _xi_ )having the same value gives
∑

```
i
```
```
g ( xi ) p ( xi )=
```
##### ∑

```
j
```
##### ∑

```
i : g ( xi )= yj
```
```
g ( xi ) p ( xi )
```
##### =

##### ∑

```
j
```
##### ∑

```
i : g ( xi )= yj
```
```
yjp ( xi )
```
##### =

##### ∑

```
j
```
```
yj
```
##### ∑

```
i : g ( xi )= yj
```
```
p ( xi )
```
##### =

##### ∑

```
j
```
```
yjP { g ( X )= yj }
```
```
= E [ g ( X )] 
```
**_EXAMPLE 4b_**

A product that is sold seasonally yields a net profit of _b_ dollars for each unit sold and
a net loss ofdollars for each unit left unsold when the season ends. The number of
units of the product that are ordered at a specific department store during any season
is a random variable having probability mass function _p_ ( _i_ ), _i_ Ú0. If the store must
stock this product in advance, determine the number of units the store should stock
so as to maximize its expected profit.


**130** Chapter 4 Random Variables

```
Solution. Let X denote the number of units ordered. If s units are stocked, then the
profit—call it P ( s )—can be expressed as
```
```
P ( s )= bX −( s − X ) if X ... s
= sb if X > s
```
```
Hence, the expected profit equals
```
```
E [ P ( s )]=
```
```
∑ s
```
```
i = 0
```
```
[ bi −( s − i )] p ( i )+
```
```
∑q
```
```
i = s + 1
```
```
sbp ( i )
```
```
=( b +)
```
```
∑ s
```
```
i = 0
```
```
ip ( i )− s 
```
```
∑ s
```
```
i = 0
```
```
p ( i )+ sb
```
##### ⎡

##### ⎣ 1 −

```
∑ s
```
```
i = 0
```
```
p ( i )
```
##### ⎤

##### ⎦

```
=( b +)
```
```
∑ s
```
```
i = 0
```
```
ip ( i )−( b +) s
```
```
∑ s
```
```
i = 0
```
```
p ( i )+ sb
```
```
= sb +( b +)
```
```
∑ s
```
```
i = 0
```
```
( i − s ) p ( i )
```
```
To determine the optimum value of s , let us investigate what happens to the profit
when we increase s by 1 unit. By substitution, we see that the expected profit in this
case is given by
```
```
E [ P ( s + 1 )]= b ( s + 1 )+( b +)
```
```
∑ s +^1
```
```
i = 0
```
```
( i − s − 1 ) p ( i )
```
```
= b ( s + 1 )+( b +)
```
```
∑ s
```
```
i = 0
```
```
( i − s − 1 ) p ( i )
```
```
Therefore,
```
```
E [ P ( s + 1 )]− E [ P ( s )]= b −( b +)
```
```
∑ s
```
```
i = 0
```
```
p ( i )
```
```
Thus, stocking s +1 units will be better than stocking s units whenever
```
```
∑ s
```
```
i = 0
```
```
p ( i )<
```
```
b
b +
```
##### (4.1)

```
Because the left-hand side of Equation (4.1) is increasing in s while the right-hand
side is constant, the inequality will be satisfied for all values of s ... s ∗, where s ∗is the
largest value of s satisfying Equation (4.1). Since
```
```
E [ P ( 0 )]<···< E [ P ( s ∗)]< E [ P ( s ∗+ 1 )]> E [ P ( s ∗+ 2 )]>···
```
```
it follows that stocking s ∗+1 items will lead to a maximum expected profit..
```
```
EXAMPLE 4c Utility
Suppose that you must choose one of two possible actions, each of which can result
in any of n consequences, denoted as C 1 ,..., Cn. Suppose that if the first action is
```

```
Section 4.4 Expectation of a Function of a Random Variable 131
```
chosen, then consequence _Ci_ will result with probability _pi_ , _i_ = 1,..., _n_ , whereas
if the second action is chosen, then consequence _Ci_ will result with probability _qi_ ,

_i_ =1,..., _n_ , where

```
∑ n
i = 1
```
```
pi =
```
```
∑ n
i = 1
```
```
qi =1. The following approach can be used to deter-
```
mine which action to choose: Start by assigning numerical values to the different
consequences in the following manner: First, identify the least and the most desir-
able consequences—call them _c_ and _C_ , respectively; give consequence _c_ the value 0
and give _C_ the value 1. Now consider any of the other _n_ −2 consequences, say, _Ci_ .To
value this consequence, imagine that you are given the choice between either receiv-
ing _Ci_ or taking part in a random experiment that either earns you consequence _C_
with probability _u_ or consequence _c_ with probability 1− _u_. Clearly, your choice will
depend on the value of _u_. On the one hand, if _u_ =1, then the experiment is certain
to result in consequence _C_ , and since _C_ is the most desirable consequence, you will
prefer participating in the experiment to receiving _Ci_. On the other hand, if _u_ =0,
then the experiment will result in the least desirable consequence—namely, _c_ —so in
this case you will prefer the consequence _Ci_ to participating in the experiment. Now,
as _u_ decreases from 1 to 0, it seems reasonable that your choice will at some point
switch from participating in the experiment to the certain return of _Ci_ , and at that
critical switch point you will be indifferent between the two alternatives. Take that
indifference probability _u_ as the value of the consequence _Ci_. In other words, the
value of _Ci_ is that probability _u_ such that you are indifferent between either receiv-
ing the consequence _Ci_ or taking part in an experiment that returns consequence _C_
with probability _u_ or consequence _c_ with probability 1− _u_. We call this indifference
probability the _utility_ of the consequence _Ci_ , and we designate it as _u_ ( _Ci_ ).
To determine which action is superior, we need to evaluate each one. Consider the
first action, which results in consequence _Ci_ with probability _pi_ , _i_ =1,..., _n_. We can
think of the result of this action as being determined by a two-stage experiment. In the
first stage, one of the values 1,..., _n_ is chosen according to the probabilities _p_ 1 ,..., _pn_ ;
if value _i_ is chosen, you receive consequence _Ci_. However, since _Ci_ is equivalent to
obtaining consequence _C_ with probability _u_ ( _Ci_ )or consequence _c_ with probability
1 − _u_ ( _Ci_ ), it follows that the result of the two-stage experiment is equivalent to an
experiment in which either consequence _C_ or consequence _c_ is obtained, with _C_ being
obtained with probability
∑ _n_

```
i = 1
```
```
piu ( Ci )
```
Similarly, the result of choosing the second action is equivalent to taking part in an
experiment in which either consequence _C_ or consequence _c_ is obtained, with _C_ being
obtained with probability
∑ _n_

```
i = 1
```
```
qiu ( Ci )
```
Since _C_ is preferable to _c_ , it follows that the first action is preferable to the second
action if _n_
∑

```
i = 1
```
```
piu ( Ci )>
```
```
∑ n
```
```
i = 1
```
```
qiu ( Ci )
```
In other words, the worth of an action can be measured by the expected value of the
utility of its consequence, and the action with the largest expected utility is the most
preferable..


**132** Chapter 4 Random Variables

```
A simple logical consequence of Proposition 4.1 is Corollary 4.1.
```
```
Corollary 4.1. If a and b are constants, then
```
```
E [ aX + b ]= aE [ X ]+ b
```
```
Proof.
```
```
E [ aX + b ]=
```
##### ∑

```
x : p ( x )> 0
```
```
( ax + b ) p ( x )
```
```
= a
```
##### ∑

```
x : p ( x )> 0
```
```
xp ( x )+ b
```
##### ∑

```
x : p ( x )> 0
```
```
p ( x )
```
```
= aE [ X ]+ b
```
```
The expected value of a random variable X , E [ X ], is also referred to as the mean
or the first moment of X. The quantity E [ Xn ], n Ú1, is called the nth moment of X.
By Proposition 4.1, we note that
```
```
E [ Xn ]=
```
##### ∑

```
x : p ( x )> 0
```
```
xnp ( x )
```
### 4.5 Variance

```
Given a random variable X along with its distribution function F , it would be
extremely useful if we were able to summarize the essential properties of F by cer-
tain suitably defined measures. One such measure would be E [ X ], the expected value
of X. However, although E [ X ] yields the weighted average of the possible values of
X , it does not tell us anything about the variation, or spread, of these values. For
instance, although random variables W , Y ,and Z having probability mass functions
determined by
```
```
W =0 with probability 1
```
##### Y =

##### ⎧

##### ⎨

##### ⎩

```
−1 with probability^12
+1 with probability^12
```
##### Z =

##### ⎧

##### ⎨

##### ⎩

```
−100 with probability^12
```
```
+100 with probability^12
```
```
all have the same expectation—namely, 0—there is a much greater spread in the pos-
sible values of Y than in those of W (which is a constant) and in the possible values
of Z than in those of Y.
Because we expect X to take on values around its mean E [ X ], it would appear that
a reasonable way of measuring the possible variation of X would be to look at how
far apart X would be from its mean, on the average. One possible way to measure this
variation would be to consider the quantity E [| X −μ|], whereμ= E [ X ]. However,
it turns out to be mathematically inconvenient to deal with this quantity, so a more
tractable quantity is usually considered—namely, the expectation of the square of the
difference between X and its mean. We thus have the following definition.
```

```
Section 4.5 Variance 133
```
```
Definition
If X is a random variable with meanμ, then the variance of X , denoted by Var( X ),
is defined by
Var( X )= E [( X −μ)^2 ]
```
An alternative formula for Var( _X_ )is derived as follows:

```
Var( X )= E [( X −μ)^2 ]
=
```
##### ∑

```
x
```
```
( x −μ)^2 p ( x )
```
##### =

##### ∑

```
x
```
```
( x^2 − 2 μ x +μ^2 ) p ( x )
```
##### =

##### ∑

```
x
```
```
x^2 p ( x )− 2 μ
```
##### ∑

```
x
```
```
xp ( x )+μ^2
```
##### ∑

```
x
```
```
p ( x )
```
```
= E [ X^2 ] − 2 μ^2 +μ^2
= E [ X^2 ] −μ^2
```
That is,

```
Var( X )= E [ X^2 ]−( E [ X ])^2
```
In words, the variance of _X_ is equal to the expected value of _X_^2 minus the square
of its expected value. In practice, this formula frequently offers the easiest way to
compute Var( _X_ ).

**_EXAMPLE 5a_**

Calculate Var( _X_ )if _X_ represents the outcome when a fair die is rolled.

**_Solution._** It was shown in Example 3a that _E_ [ _X_ ]=^72. Also,

##### E [ X^2 ]= 12

##### (

##### 1

##### 6

##### )

##### + 22

##### (

##### 1

##### 6

##### )

##### + 32

##### (

##### 1

##### 6

##### )

##### + 42

##### (

##### 1

##### 6

##### )

##### + 52

##### (

##### 1

##### 6

##### )

##### + 62

##### (

##### 1

##### 6

##### )

##### =

##### (

##### 1

##### 6

##### )

##### ( 91 )

```
Hence,
```
```
Var( X )=
```
##### 91

##### 6

##### −

##### (

##### 7

##### 2

##### ) 2

##### =

##### 35

(^12).
A useful identity is that, for any constants _a_ and _b_ ,
Var( _aX_ + _b_ )= _a_^2 Var( _X_ )


**134** Chapter 4 Random Variables

```
To prove this equality, letμ= E [ X ] and note from Corollary 4.1 that E [ aX + b ]=
a μ+ b. Therefore,
```
```
Var( aX + b )= E [( aX + b − a μ− b )^2 ]
= E [ a^2 ( X −μ)^2 ]
= a^2 E [( X −μ)^2 ]
= a^2 Var( X )
```
```
Remarks. (a) Analogous to the means being the center of gravity of a distribu-
tion of mass, the variance represents, in the terminology of mechanics, the moment
of inertia.
(b) The square root of the Var( X )is called the standard deviation of X , and we
denote it by SD( X ). That is,
```
```
SD( X )=
```
##### √

```
Var( X )
```
```
Discrete random variables are often classified according to their probability mass
functions. In the next few sections, we consider some of the more common types.
```
### 4.6 The Bernoulli and Binomial Random Variables

```
Suppose that a trial, or an experiment, whose outcome can be classified as either a
success or a failure is performed. If we let X =1 when the outcome is a success and
X =0 when it is a failure, then the probability mass function of X is given by
```
```
p ( 0 )= P { X = 0 }= 1 − p
p ( 1 )= P { X = 1 }= p
```
##### (6.1)

```
where p ,0... p ...1, is the probability that the trial is a success.
A random variable X is said to be a Bernoulli random variable (after the Swiss
mathematician James Bernoulli) if its probability mass function is given by Equa-
tions (6.1) for some p ∈(0, 1).
Suppose now that n independent trials, each of which results in a success with prob-
ability p and in a failure with probability 1− p , are to be performed. If X represents
the number of successes that occur in the n trials, then X is said to be a binomial
random variable with parameters ( n , p ). Thus, a Bernoulli random variable is just a
binomial random variable with parameters (1, p ).
The probability mass function of a binomial random variable having parameters
( n , p ) is given by
```
```
p ( i )=
```
##### (

```
n
i
```
##### )

```
pi ( 1 − p ) n − i i =0, 1,..., n (6.2)
```
```
The validity of Equation (6.2) may be verified by first noting that the probability of
any particular sequence of n outcomes containing i successes and n − i failures is,
by the assumed independence of trials, pi ( 1 − p ) n − i. Equation (6.2) then follows,
since there are
```
##### (

```
n
i
```
##### )

```
different sequences of the n outcomes leading to i successes and
```
```
n − i failures. This perhaps can most easily be seen by noting that there are
```
##### (

```
n
i
```
##### )

```
different choices of the i trials that result in successes. For instance, if n =4, i =2,
then there are
```
##### (

##### 4

##### 2

##### )

```
=6 ways in which the four trials can result in two successes,
```

```
Section 4.6 The Bernoulli and Binomial Random Variables 135
```
namely, any of the outcomes ( _s_ , _s_ , _f_ , _f_ ), ( _s_ , _f_ , _s_ , _f_ ), ( _s_ , _f_ , _f_ , _s_ ), ( _f_ , _s_ , _s_ , _f_ ), ( _f_ , _s_ , _f_ , _s_ ), and
( _f_ , _f_ , _s_ , _s_ ), where the outcome ( _s_ , _s_ , _f_ , _f_ ) means, for instance, that the first two trials
are successes and the last two failures. Since each of these outcomes has probability
_p_^2 ( 1 − _p_ )^2 of occurring, the desired probability of two successes in the four trials

is

##### (

##### 4

##### 2

##### )

```
p^2 ( 1 − p )^2.
Note that, by the binomial theorem, the probabilities sum to 1; that is,
```
```
∑q
```
```
i = 0
```
```
p ( i )=
```
```
∑ n
```
```
i = 0
```
##### (

```
ni
```
##### )

```
pi ( 1 − p ) n − i =[ p +( 1 − p )] n = 1
```
**_EXAMPLE 6a_**

Five fair coins are flipped. If the outcomes are assumed independent, find the proba-
bility mass function of the number of heads obtained.

**_Solution._** If we let _X_ equal the number of heads (successes) that appear, then _X_

is a binomial random variable with parameters

##### (

```
n =5, p =^12
```
##### )

. Hence, by Equa-

tion (6.2),

##### P { X = 0 }=

##### (

##### 5

##### 0

##### )(

##### 1

##### 2

##### ) 0 (

##### 1

##### 2

##### ) 5

##### =

##### 1

##### 32

##### P { X = 1 }=

##### (

##### 5

##### 1

##### )(

##### 1

##### 2

##### ) 1 (

##### 1

##### 2

##### ) 4

##### =

##### 5

##### 32

##### P { X = 2 }=

##### (

##### 5

##### 2

##### )(

##### 1

##### 2

##### ) 2 (

##### 1

##### 2

##### ) 3

##### =

##### 10

##### 32

##### P { X = 3 }=

##### (

##### 5

##### 3

##### )(

##### 1

##### 2

##### ) 3 (

##### 1

##### 2

##### ) 2

##### =

##### 10

##### 32

##### P { X = 4 }=

##### (

##### 5

##### 4

##### )(

##### 1

##### 2

##### ) 4 (

##### 1

##### 2

##### ) 1

##### =

##### 5

##### 32

##### P { X = 5 }=

##### (

##### 5

##### 5

##### )(

##### 1

##### 2

##### ) 5 (

##### 1

##### 2

##### ) 0

##### =

##### 1

##### 32.

**_EXAMPLE 6b_**

It is known that screws produced by a certain company will be defective with proba-
bility .01, independently of each other. The company sells the screws in packages of
10 and offers a money-back guarantee that at most 1 of the 10 screws is defective.
What proportion of packages sold must the company replace?

**_Solution._** If _X_ is the number of defective screws in a package, then _X_ is a binomial
random variable with parameters (10, .01). Hence, the probability that a package will
have to be replaced is

##### 1 − P { X = 0 }− P { X = 1 }= 1 −

##### (

##### 10

##### 0

##### )

##### (. 01 )^0 (. 99 )^10 −

##### (

##### 10

##### 1

##### )

##### (. 01 )^1 (. 99 )^9

##### L. 004

Thus, only .4 percent of the packages will have to be replaced..


**136** Chapter 4 Random Variables

```
EXAMPLE 6c
The following gambling game, known as the wheel of fortune (or chuck-a-luck), is
quite popular at many carnivals and gambling casinos: A player bets on one of the
numbers 1 through 6. Three dice are then rolled, and if the number bet by the player
appears i times, i =1, 2, 3, then the player wins i units; if the number bet by the player
does not appear on any of the dice, then the player loses 1 unit. Is this game fair to
the player? (Actually, the game is played by spinning a wheel that comes to rest on
a slot labeled by three of the numbers 1 through 6, but this variant is mathematically
equivalent to the dice version.)
```
```
Solution. If we assume that the dice are fair and act independently of each other,
then the number of times that the number bet appears is a binomial random variable
with parameters
```
##### (

##### 3,^16

##### )

. Hence, letting _X_ denote the player’s winnings in the game,
we have

##### P { X =− 1 }=

##### (

##### 3

##### 0

##### )(

##### 1

##### 6

##### ) 0 (

##### 5

##### 6

##### ) 3

##### =

##### 125

##### 216

##### P { X = 1 }=

##### (

##### 3

##### 1

##### )(

##### 1

##### 6

##### ) 1 (

##### 5

##### 6

##### ) 2

##### =

##### 75

##### 216

##### P { X = 2 }=

##### (

##### 3

##### 2

##### )(

##### 1

##### 6

##### ) 2 (

##### 5

##### 6

##### ) 1

##### =

##### 15

##### 216

##### P { X = 3 }=

##### (

##### 3

##### 3

##### )(

##### 1

##### 6

##### ) 3 (

##### 5

##### 6

##### ) 0

##### =

##### 1

##### 216

```
In order to determine whether or not this is a fair game for the player, let us calcu-
late E [ X ]. From the preceding probabilities, we obtain
```
##### E [ X ]=

##### − 125 + 75 + 30 + 3

##### 216

##### =

##### − 17

##### 216

```
Hence, in the long run, the player will lose 17 units per every 216 games he plays..
```
```
In the next example, we consider the simplest form of the theory of inheritance as
developed by Gregor Mendel (1822–1884).
```
```
EXAMPLE 6d
Suppose that a particular trait (such as eye color or left-handedness) of a person is
classified on the basis of one pair of genes, and suppose also that d represents a dom-
inant gene and r a recessive gene. Thus, a person with dd genes is purely dominant,
one with rr is purely recessive, and one with rd is hybrid. The purely dominant and the
hybrid individuals are alike in appearance. Children receive 1 gene from each parent.
If, with respect to a particular trait, 2 hybrid parents have a total of 4 children, what is
the probability that 3 of the 4 children have the outward appearance of the dominant
gene?
```
```
Solution. If we assume that each child is equally likely to inherit either of 2 genes
from each parent, the probabilities that the child of 2 hybrid parents will have dd,
rr ,and rd pairs of genes are, respectively,^14 ,^14 ,and^12. Hence, since an offspring will
```

```
Section 4.6 The Bernoulli and Binomial Random Variables 137
```
have the outward appearance of the dominant gene if its gene pair is either _dd_ or _rd_ ,
it follows that the number of such children is binomially distributed with parameters(

```
4,^34
```
##### )

. Thus, the desired probability is

```
(
4
3
```
##### )(

##### 3

##### 4

##### ) 3 (

##### 1

##### 4

##### ) 1

##### =

##### 27

##### 64.

**_EXAMPLE 6e_**

Consider a jury trial in which it takes 8 of the 12 jurors to convict the defendant; that
is, in order for the defendant to be convicted, at least 8 of the jurors must vote him
guilty. If we assume that jurors act independently and that, whether or not the defen-
dant is guilty, each makes the right decision with probabilityθ, what is the probability
that the jury renders a correct decision?

**_Solution._** The problem, as stated, is incapable of solution, for there is not yet enough
information. For instance, if the defendant is innocent, the probability of the jury’s
rendering a correct decision is

```
∑^12
```
```
i = 5
```
##### (

##### 12

```
i
```
##### )

```
θ i ( 1 −θ)^12 − i
```
whereas, if he is guilty, the probability of a correct decision is

```
∑^12
```
```
i = 8
```
##### (

##### 12

```
i
```
##### )

```
θ i ( 1 −θ)^12 − i
```
Therefore, ifαrepresents the probability that the defendant is guilty, then, by condi-
tioning on whether or not he is guilty, we obtain the probability that the jury renders
a correct decision:

```
α
```
##### ∑^12

```
i = 8
```
##### (

##### 12

```
i
```
##### )

```
θ i ( 1 −θ)^12 − i +( 1 −α)
```
##### ∑^12

```
i = 5
```
##### (

##### 12

```
i
```
##### )

```
θ i ( 1 −θ)^12 − i
.
```
**_EXAMPLE 6f_**

A communication system consists of _n_ components, each of which will, indepen-
dently, function with probability _p_. The total system will be able to operate effectively
if at least one-half of its components function.

```
(a) For what values of p is a 5-component system more likely to operate effectively
than a 3-component system?
(b) In general, when is a( 2 k + 1 )-component system better than a( 2 k − 1 )-
component system?
```
**_Solution._** (a) Because the number of functioning components is a binomial random
variable with parameters ( _n_ , _p_ ), it follows that the probability that a 5-component
system will be effective is
(
5
3

##### )

```
p^3 ( 1 − p )^2 +
```
##### (

##### 5

##### 4

##### )

```
p^4 ( 1 − p )+ p^5
```

**138** Chapter 4 Random Variables

```
whereas the corresponding probability for a 3-component system is
(
3
2
```
##### )

```
p^2 ( 1 − p )+ p^3
```
```
Hence, the 5-component system is better if
```
```
10 p^3 ( 1 − p )^2 + 5 p^4 ( 1 − p )+ p^5 > 3 p^2 ( 1 − p )+ p^3
```
```
which reduces to
```
```
3 ( p − 1 )^2 ( 2 p − 1 )> 0
```
```
or
```
```
p >
```
##### 1

##### 2

```
(b) In general, a system with 2 k + 1 components will be better than one with
2 k −1 components if (and only if) p >^12. To prove this, consider a system of 2 k + 1
components and let X denote the number of the first 2 k −1 that function. Then
```
```
P 2 k + 1 (effective)= P { X Ú k + 1 }+ P { X = k }( 1 −( 1 − p )^2 )
+ P { X = k − 1 } p^2
```
```
which follows because the( 2 k + 1 )-component system will be effective if either
```
```
(i) X Ú k +1;
(ii) X = k and at least one of the remaining 2 components function; or
(iii) X = k −1 and both of the next 2 components function.
Since
```
```
P 2 k − 1 (effective)= P { X Ú k }
= P { X = k }+ P { X Ú k + 1 }
```
```
we obtain
```
```
P 2 k + 1 (effective)− P 2 k − 1 (effective)
= P { X = k − 1 } p^2 −( 1 − p )^2 P { X = k }
```
```
=
```
##### (

```
2 k − 1
k − 1
```
##### )

```
pk −^1 ( 1 − p ) kp^2 −( 1 − p )^2
```
##### (

```
2 k − 1
k
```
##### )

```
pk ( 1 − p ) k −^1
```
##### =

##### (

```
2 k − 1
k
```
##### )

```
pk ( 1 − p ) k [ p −( 1 − p )] since
```
##### (

```
2 k − 1
k − 1
```
##### )

##### =

##### (

```
2 k − 1
k
```
##### )

```
> 03 p >
```
##### 1

##### 2.


```
Section 4.6 The Bernoulli and Binomial Random Variables 139
```
#### 4.6.1 Properties of Binomial Random Variables............

We will now examine the properties of a binomial random variable with parameters
_n_ and _p_. To begin, let us compute its expected value and variance. Now,

```
E [ Xk ]=
```
```
∑ n
```
```
i = 0
```
```
ik
```
##### (

```
n
i
```
##### )

```
pi ( 1 − p ) n − i
```
##### =

```
∑ n
```
```
i = 1
```
```
ik
```
##### (

```
n
i
```
##### )

```
pi ( 1 − p ) n − i
```
Using the identity

```
i
```
##### (

```
n
i
```
##### )

```
= n
```
##### (

```
n − 1
i − 1
```
##### )

gives

```
E [ Xk ]= np
```
```
∑ n
```
```
i = 1
```
```
ik −^1
```
##### (

```
n − 1
i − 1
```
##### )

```
pi −^1 ( 1 − p ) n − i
```
```
= np
```
```
n ∑− 1
```
```
j = 0
```
```
( j + 1 ) k −^1
```
##### (

```
n − 1
j
```
##### )

```
pj ( 1 − p ) n −^1 − j
```
```
by letting
j = i − 1
```
```
= npE [( Y + 1 ) k −^1 ]
```
where _Y_ is a binomial random variable with parameters _n_ −1, _p_. Setting _k_ =1inthe
preceding equation yields

```
E [ X ]= np
```
That is, the expected number of successes that occur in _n_ independent trials when
each is a success with probability _p_ is equal to _np_. Setting _k_ =2 in the preceding equa-
tion, and using the preceding formula for the expected value of a binomial random
variable yields

```
E [ X^2 ]= npE [ Y +1]
= np [( n − 1 ) p +1]
```
Since _E_ [ _X_ ]= _np_ , we obtain

```
Var( X )= E [ X^2 ]−( E [ X ])^2
= np [( n − 1 ) p +1]−( np )^2
= np ( 1 − p )
```
Summing up, we have shown the following:
If _X_ is a binomial random variable with parameters _n_ and _p_ ,then

```
E [ X ]= np
Var( X )= np ( 1 − p )
```

**140** Chapter 4 Random Variables

```
The following proposition details how the binomial probability mass function first
increases and then decreases.
Proposition 6.1. If X is a binomial random variable with parameters ( n , p ), where
0 < p <1, then as k goes from 0 to n , P { X = k }first increases monotonically and
then decreases monotonically, reaching its largest value when k is the largest integer
less than or equal to( n + 1 ) p.
```
```
Proof. We prove the proposition by considering P { X = k }/ P { X = k − 1 }and
determining for what values of k it is greater or less than 1. Now,
```
```
P { X = k }
P { X = k − 1 }
```
##### =

```
n!
( n − k )! k!
```
```
pk ( 1 − p ) n − k
```
```
n!
( n − k + 1 )!( k − 1 )!
```
```
pk −^1 ( 1 − p ) n − k +^1
```
##### =

```
( n − k + 1 ) p
k ( 1 − p )
```
```
Hence, P { X = k }Ú P { X = k − 1 }if and only if
```
```
( n − k + 1 ) p Ú k ( 1 − p )
```
```
or, equivalently, if and only if
```
```
k ...( n + 1 ) p
```
```
and the proposition is proved..
```
```
As an illustration of Proposition 6.1 consider Figure 4.5, the graph of the probabil-
ity mass function of a binomial random variable with parameters(10,^12 ).
```
```
EXAMPLE 6g
In a U.S. presidential election, the candidate who gains the maximum number of
votes in a state is awarded the total number of electoral college votes allocated to
```
```
0
```
```
k
```
```
1024  p ( k )
```
```
1234 567 8 9 10
```
```
10
```
```
45
```
```
120
```
```
210
```
```
252
```
```
1
```
```
FIGURE 4.5 Graph of p ( k )=
( 10
k
```
```
)( 1
2
```
```
) 10
```

```
Section 4.6 The Bernoulli and Binomial Random Variables 141
```
that state. The number of electoral college votes of a given state is roughly propor-
tional to the population of that state—that is, a state with population _n_ has roughly
_nc_ electoral votes. (Actually, it is closer to _nc_ +2, as a state is given an electoral
vote for each member it has in the House of Representatives, with the number of
such representatives being roughly proportional to the population of the state, and
one electoral college vote for each of its two senators.) Let us determine the average
power of a citizen in a state of size _n_ in a close presidential election, where, by _average
power in a close election_ , we mean that a voter in a state of size _n_ = 2 _k_ +1 will be
decisive if the other _n_ −1 voters split their votes evenly between the two candidates.
(We are assuming here that _n_ is odd, but the case where _n_ is even is quite similar.)
Because the election is close, we shall suppose that each of the other _n_ − 1 = 2 _k_
voters acts independently and is equally likely to vote for either candidate. Hence,
the probability that a voter in a state of size _n_ = 2 _k_ +1 will make a difference to
the outcome is the same as the probability that 2 _k_ tosses of a fair coin land heads and
tails an equal number of times. That is,

```
P {voter in state of size 2 k +1 makes a difference}
```
##### =

##### (

```
2 k
k
```
##### )(

##### 1

##### 2

```
) k (
1
2
```
```
) k
```
##### =

```
( 2 k )!
k! k !2^2 k
```
To approximate the preceding equality, we make use of Stirling’s approximation,
which says that, for _k_ large,

```
k !∼ kk +^1 /^2 e − k
```
##### √

```
2 π
```
where we say that _ak_ ∼ _bk_ when the ratio _ak_ / _bk_ approaches 1 as _k_ approachesq.
Hence, it follows that

```
P {voter in state of size 2 k +1 makes a difference}
```
##### ∼

```
( 2 k )^2 k +^1 /^2 e −^2 k
```
##### √

```
2 π
k^2 k +^1 e −^2 k ( 2 π) 22 k
```
##### =

##### 1

##### √

```
k π
```
Because such a voter (if he or she makes a difference) will affect _nc_ electoral votes,
the expected number of electoral votes a voter in a state of size _n_ will affect—or the
voter’s average power—is given by

```
average power= ncP {makes a difference}
```
```
∼
```
```
nc
√
n π/ 2
= c
```
##### √

```
2 n /π
```
Thus, the average power of a voter in a state of size _n_ is proportional to the square
root of _n_ , showing that, in presidential elections, voters in large states have more
power than do those in smaller states..


**142** Chapter 4 Random Variables

#### 4.6.2 Computing the Binomial Distribution Function

```
Suppose that X is binomial with parameters ( n , p ). The key to computing its distribu-
tion function
```
```
P { X ... i }=
```
```
∑ i
```
```
k = 0
```
##### (

```
n
k
```
##### )

```
pk ( 1 − p ) n − k i =0, 1,..., n
```
```
is to utilize the following relationship between P { X = k + 1 }and P { X = k }, which
was established in the proof of Proposition 6.1:
```
```
P { X = k + 1 }=
```
```
p
1 − p
```
```
n − k
k + 1
```
```
P { X = k } (6.3)
```
```
EXAMPLE 6h
Let X be a binomial random variable with parameters n =6, p =.4. Then, starting
with P { X = 0 }=(. 6 )^6 and recursively employing Equation (6.3), we obtain
```
```
P { X = 0 }=(. 6 )^6 L. 0467
```
##### P { X = 1 }=

##### 4

##### 6

##### 6

##### 1

##### P { X = 0 }L. 1866

##### P { X = 2 }=

##### 4

##### 6

##### 5

##### 2

##### P { X = 1 }L. 3110

##### P { X = 3 }=

##### 4

##### 6

##### 4

##### 3

##### P { X = 2 }L. 2765

##### P { X = 4 }=

##### 4

##### 6

##### 3

##### 4

##### P { X = 3 }L. 1382

##### P { X = 5 }=

##### 4

##### 6

##### 2

##### 5

##### P { X = 4 }L. 0369

##### P { X = 6 }=

##### 4

##### 6

##### 1

##### 6

##### P { X = 5 }L. 0041.

```
A computer program that utilizes the recursion (6.3) to compute the binomial
distribution function is easily written. To compute P { X ... i }, the program should
first compute P { X = i }and then use the recursion to successively compute P { X =
i − 1 }, P { X = i − 2 }, and so on.
```
```
Historical Note
Independent trials having a common probability of success p were first studied
by the Swiss mathematician Jacques Bernoulli (1654–1705). In his book Ars Con-
jectandi (The Art of Conjecturing) , published by his nephew Nicholas eight years
after his death in 1713, Bernoulli showed that if the number of such trials were
large, then the proportion of them that were successes would be close to p with a
probability near 1.
Jacques Bernoulli was from the first generation of the most famous mathemat-
ical family of all time. Altogether, there were between 8 and 12 Bernoullis, spread
over three generations, who made fundamental contributions to probability, statis-
tics, and mathematics. One difficulty in knowing their exact number is the fact that
several had the same name. (For example, two of the sons of Jacques’s brother Jean
```

```
Section 4.7 The Poisson Random Variable 143
```
```
were named Jacques and Jean.) Another difficulty is that several of the Bernoullis
were known by different names in different places. Our Jacques (sometimes writ-
ten Jaques) was, for instance, also known as Jakob (sometimes written Jacob) and
as James Bernoulli. But whatever their number, their influence and output were
prodigious. Like the Bachs of music, the Bernoullis of mathematics were a family
for the ages!
```
```
EXAMPLE 6i
If X is a binomial random variable with parameters n =100 and p =.75, find P { X =
70 }and P { X ... 70 }.
```
```
Solution. The answer is shown here in Figure 4.6.
```
```
Enter Value For p:.75
```
```
Enter Value For n: 100
```
```
Enter Value For i: 70
```
```
Binomial Distribution
```
```
Start
```
```
Quit
```
```
Probability (Number of Successes = i) = .04575381
Probability (Number of Successes < = i) = .14954105
```
```
FIGURE 4.6
```
##### 4.7 THE POISSON RANDOM VARIABLE

```
A random variable X that takes on one of the values 0, 1, 2,...is said to be a Poisson
random variable with parameterλif, for someλ>0,
```
```
p ( i )= P { X = i }= e −λ
```
```
λ i
i!
```
```
i =0, 1, 2,... (7.1)
```
```
Equation (7.1) defines a probability mass function, since
∑q
```
```
i = 0
```
```
p ( i )= e −λ
```
```
∑q
```
```
i = 0
```
```
λ i
i!
```
```
= e −λ e λ= 1
```
```
The Poisson probability distribution was introduced by Simeon Denis Poisson in a ́
book he wrote regarding the application of probability theory to lawsuits, criminal
trials, and the like. This book, published in 1837, was entitled Recherches sur la prob-
abilite des jugements en mati ́ `ere criminelle et en matiere civile (Investigations into the`
Probability of Verdicts in Criminal and Civil Matters).
The Poisson random variable has a tremendous range of applications in diverse
areas because it may be used as an approximation for a binomial random variable
with parameters ( n , p ) when n is large and p is small enough so that np is of moderate
```

**144** Chapter 4 Random Variables

```
size. To see this, suppose that X is a binomial random variable with parameters ( n , p ),
and letλ= np. Then
```
```
P { X = i }=
```
```
n!
( n − i )! i!
```
```
pi ( 1 − p ) n − i
```
##### =

```
n!
( n − i )! i!
```
##### (

```
λ
n
```
```
) i (
1 −
```
```
λ
n
```
```
) n − i
```
##### =

```
n ( n − 1 )···( n − i + 1 )
ni
```
```
λ i
i!
```
```
( 1 −λ/ n ) n
( 1 −λ/ n ) i
```
```
Now, for n large andλmoderate,
(
1 −
```
```
λ
n
```
```
) n
L e −λ
```
```
n ( n − 1 )···( n − i + 1 )
ni
```
##### L 1

##### (

##### 1 −

```
λ
n
```
```
) i
L 1
```
```
Hence, for n large andλmoderate,
```
```
P { X = i }L e −λ
```
```
λ i
i!
```
```
In other words, if n independent trials, each of which results in a success with
probability p , are performed, then, when n is large and p is small enough to make
np moderate, the number of successes occurring is approximately a Poisson random
variable with parameterλ= np. This valueλ(which will later be shown to equal the
expected number of successes) will usually be determined empirically.
Some examples of random variables that generally obey the Poisson probability
law [that is, they obey Equation (7.1)] are as follows:
```
1. The number of misprints on a page (or a group of pages) of a book
2. The number of people in a community who survive to age 100
3. The number of wrong telephone numbers that are dialed in a day
4. The number of packages of dog biscuits sold in a particular store each day
5. The number of customers entering a post office on a given day
6. The number of vacancies occurring during a year in the federal judicial system
7. The number ofα-particles discharged in a fixed period of time from some radioac-
    tive material
Each of the preceding, and numerous other random variables, are approximately
Poisson for the same reason—namely, because of the Poisson approximation to the
binomial. For instance, we can suppose that there is a small probability _p_ that each
letter typed on a page will be misprinted. Hence, the number of misprints on a page
will be approximately Poisson withλ= _np_ , where _n_ is the number of letters on a
page. Similarly, we can suppose that each person in a community has some small
probability of reaching age 100. Also, each person entering a store may be thought of
as having some small probability of buying a package of dog biscuits, and so on.

```
EXAMPLE 7a
Suppose that the number of typographical errors on a single page of this book has a
Poisson distribution with parameterλ=^12. Calculate the probability that there is at
least one error on this page.
```

```
Section 4.7 The Poisson Random Variable 145
```
**_Solution._** Letting _X_ denote the number of errors on this page, we have

_P_ { _X_ Ú 1 }= 1 − _P_ { _X_ = 0 }= 1 − _e_ −^1 /^2 L. (^393).
**_EXAMPLE 7b_**
Suppose that the probability that an item produced by a certain machine will be
defective is .1. Find the probability that a sample of 10 items will contain at most
1 defective item.
**_Solution._** The desired probability is

##### (

##### 10

##### 0

##### )

##### (. 1 )^0 (. 9 )^10 +

##### (

##### 10

##### 1

##### )

##### (. 1 )^1 (. 9 )^9 =.7361,

whereas the Poisson approximation yields the value _e_ −^1 + _e_ −^1 L.7358..

**_EXAMPLE 7c_**

Consider an experiment that consists of counting the number ofαparticles given
off in a 1-second interval by 1 gram of radioactive material. If we know from past
experience that, on the average, 3.2 suchαparticles are given off, what is a good
approximation to the probability that no more than 2αparticles will appear?

**_Solution._** If we think of the gram of radioactive material as consisting of a large num-
ber _n_ of atoms, each of which has probability of 3.2/ _n_ of disintegrating and sending off
anαparticle during the second considered, then we see that, to a very close approx-
imation, the number ofαparticles given off will be a Poisson random variable with
parameterλ= 3 .2. Hence, the desired probability is

```
P { X ... 2 }= e −^3.^2 + 3. 2 e −^3.^2 +
```
##### ( 3. 2 )^2

##### 2

```
e −^3.^2
```
L. (^3799).
Before computing the expected value and variance of the Poisson random variable
with parameterλ, recall that this random variable approximates a binomial random
variable with parameters _n_ and _p_ when _n_ is large, _p_ is small, andλ= _np_. Since such
a binomial random variable has expected value _np_ =λand variance _np_ ( 1 − _p_ )=
λ( 1 − _p_ )Lλ(since _p_ is small), it would seem that both the expected value and the
variance of a Poisson random variable would equal its parameterλ. We now verify
this result:

##### E [ X ]=

```
∑q
```
```
i = 0
```
```
ie −λλ i
i!
```
```
=λ
```
```
∑q
```
```
i = 1
```
```
e −λλ i −^1
( i − 1 )!
```
```
=λ e −λ
```
```
∑q
```
```
j = 0
```
```
λ j
j!
```
```
by letting
j = i − 1
```
```
=λ since
```
```
∑q
```
```
j = 0
```
```
λ j
j!
```
```
= e λ
```

**146** Chapter 4 Random Variables

```
Thus, the expected value of a Poisson random variable X is indeed equal to its
parameterλ. To determine its variance, we first compute E [ X^2 ]:
```
##### E [ X^2 ]=

```
∑q
```
```
i = 0
```
```
i^2 e −λλ i
i!
```
```
=λ
```
```
∑q
```
```
i = 1
```
```
ie −λλ i −^1
( i − 1 )!
```
```
=λ
```
```
∑q
```
```
j = 0
```
```
( j + 1 ) e −λλ j
j!
```
```
by letting
j = i − 1
```
```
=λ
```
##### ⎡

##### ⎢

##### ⎣

```
∑q
```
```
j = 0
```
```
je −λλ j
j!
```
##### +

```
∑q
```
```
j = 0
```
```
e −λλ j
j!
```
##### ⎤

##### ⎥

##### ⎦

```
=λ(λ+ 1 )
```
```
where the final equality follows because the first sum is the expected value of a Pois-
son random variable with parameterλand the second is the sum of the probabilities
of this random variable. Therefore, since we have shown that E [ X ]=λ, we obtain
```
```
Var( X )= E [ X^2 ]−( E [ X ])^2
=λ
```
```
Hence, the expected value and variance of a Poisson random variable are both
equal to its parameterλ.
We have shown that the Poisson distribution with parameter np is a very good
approximation to the distribution of the number of successes in n independent trials
when each trial has probability p of being a success, provided that n is large and p
small. In fact, it remains a good approximation even when the trials are not inde-
pendent, provided that their dependence is weak. For instance, recall the matching
problem (Example 5m of Chapter 2) in which n men randomly select hats from a set
consisting of one hat from each person. From the point of view of the number of men
who select their own hat, we may regard the random selection as the result of n tri-
als where we say that trial i is a success if person i selects his own hat, i =1,..., n.
Defining the events Ei , i =1,..., n ,by
```
```
Ei ={trial i is a success}
```
```
it is easy to see that
```
```
P { Ei }=
```
##### 1

```
n
```
```
and P { Ei | Ej }=
```
##### 1

```
n − 1
```
```
, j Z i
```
```
Thus, we see that, although the events Ei , i = 1,..., n are not independent, their
dependence, for large n , appears to be weak. Because of this it seems reasonable to
expect that the number of successes will approximately have a Poisson distribution
with parameter n * 1 / n =1, and indeed this is verified in Example 5m of Chapter 2.
For a second illustration of the strength of the Poisson approximation when the
trials are weakly dependent, let us consider again the birthday problem presented in
Example 5i of Chapter 2. In this example, we suppose that each of n people is equally
likely to have any of the 365 days of the year as his or her birthday, and the problem
```

```
Section 4.7 The Poisson Random Variable 147
```
is to determine the probability that a set of _n_ independent people all have different
birthdays. A combinatorial argument was used to determine this probability, which
was shown to be less than^12 when _n_ =23.
We can approximate the preceding probability by using the Poisson approximation

as follows: Imagine that we have a trial for each of the

##### (

```
n
2
```
##### )

```
pairs of individuals i and
```
_j_ , _i_ Z _j_ , and say that trial _i_ , _j_ is a success if persons _i_ and _j_ have the same birthday. If

we let _Eij_ denote the event that trial _i_ , _j_ is a success, then, whereas the

##### (

```
n
2
```
##### )

```
events
```
_Eij_ ,1... _i_ < _j_ ... _n_ , are not independent (see Theoretical Exercise 21), their depen-
dence appears to be rather weak. (Indeed, these events are even _pairwise indepen-
dent_ , in that any 2 of the events _Eij_ and _Ekl_ are independent—again, see Theoretical
Exercise 21). Since _P_ ( _Eij_ )= 1 /365, it is reasonable to suppose that the number of

successes should approximately have a Poisson distribution with mean

##### (

```
n
2
```
##### )/

##### 365 =

_n_ ( _n_ − 1 )/730. Therefore,

```
P {no 2 people have the same birthday}= P {0 successes}
```
```
Lexp
```
##### {

```
− n ( n − 1 )
730
```
##### }

To determine the smallest integer _n_ for which this probability is less than^12 , note that

```
exp
```
##### {

```
− n ( n − 1 )
730
```
##### }

##### ...

##### 1

##### 2

is equivalent to

```
exp
```
##### {

```
n ( n − 1 )
730
```
##### }

##### Ú 2

Taking logarithms of both sides, we obtain

```
n ( n − 1 )Ú730 log 2
L 505. 997
```
which yields the solution _n_ = 23, in agreement with the result of Example 5i of
Chapter 2.
Suppose now that we wanted the probability that, among the _n_ people, no 3 of
them have their birthday on the same day. Whereas this now becomes a difficult com-
binatorial problem, it is a simple matter to obtain a good approximation. To begin,

imagine that we have a trial for each of the

##### (

```
n
3
```
##### )

```
triplets i , j , k , where 1... i < j < k ... n ,
```
and call the _i_ , _j_ , _k_ trial a success if persons _i_ , _j_ ,and _k_ all have their birthday on the same
day. As before, we can then conclude that the number of successes is approximately
a Poisson random variable with parameter

```
(
n
3
```
##### )

```
P { i , j , k have the same birthday}=
```
##### (

```
n
3
```
##### )(

##### 1

##### 365

##### ) 2

##### =

```
n ( n − 1 )( n − 2 )
6 *( 365 )^2
```

**148** Chapter 4 Random Variables

```
Hence,
```
```
P {no 3 have the same birthday}Lexp
```
##### {

```
− n ( n − 1 )( n − 2 )
799350
```
##### }

```
This probability will be less than^12 when n is such that
```
```
n ( n − 1 )( n − 2 )Ú799350 log 2L 554067. 1
```
```
which is equivalent to n Ú84. Thus, the approximate probability that at least 3 people
in a group of size 84 or larger will have the same birthday exceeds^12.
For the number of events to occur to approximately have a Poisson distribution, it
is not essential that all the events have the same probability of occurrence, but only
that all of these probabilities be small. The following is referred to as the Poisson
paradigm.
```
```
Poisson Paradigm. Consider n events, with pi equal to the probability that event i
occurs, i =1,..., n .If all the pi are “small” and the trials are either independent or at
most “weakly dependent,” then the number of these events that occur approximately
has a Poisson distribution with mean
```
```
∑ n
i = 1 pi.
Our next example not only makes use of the Poisson paradigm, but also illustrates
a variety of the techniques we have studied so far.
```
```
EXAMPLE 7d Length of the longest run
A coin is flipped n times. Assuming that the flips are independent, with each one
coming up heads with probability p , what is the probability that there is a string of k
consecutive heads?
```
```
Solution. We will first use the Poisson paradigm to approximate this probability.
Now, if, for i =1,..., n − k +1, we let Hi denote the event that flips i , i +1,..., i +
k −1 all land on heads, then the desired probability is that at least one of the events
Hi occur. Because Hi is the event that, starting with flip i , the next k flips all land on
heads, it follows that P ( Hi )= pk. Thus, when pk is small, we might think that the num-
ber of the Hi that occur should have an approximate Poisson distribution. However,
such is not the case, because, although the events all have small probabilities, some of
their dependencies are too great for the Poisson distribution to be a good approxima-
tion. For instance, because the conditional probability that flips 2,..., k +1 are all
heads given that flips 1,..., k are all heads is equal to the probability that flip k + 1
is a head, it follows that
P ( H 2 | H 1 )= p
```
```
which is far greater than the unconditional probability of H 2.
The trick that enables us to use a Poisson approximation is to note that there
will be a string of k consecutive heads either if there is such a string that is imme-
diately followed by a tail or if the final k flips all land on heads. Consequently, for
i =1,..., n − k , let Ei be the event that flips i ,..., i + k −1 are all heads and flip
i + k is a tail; also, let En − k + 1 be the event that flips n − k +1,..., n are all heads.
Note that
```
```
P ( Ei )= pk ( 1 − p ), i ... n − k
P ( En − k + 1 )= pk
```

```
Section 4.7 The Poisson Random Variable 149
```
Thus, when _pk_ is small, each of the events _Ei_ has a small probability of occurring.
Moreover, for _i_ Z _j_ , if the events _Ei_ and _Ej_ refer to nonoverlapping sequences of flips,
then _P_ ( _Ei_ | _Ej_ )= _P_ ( _Ei_ ); if they refer to overlapping sequences, then _P_ ( _Ei_ | _Ej_ )=0.
Hence, in both cases, the conditional probabilities are close to the unconditional ones,
indicating that _N_ , the number of the events _Ei_ that occur, should have an approximate
Poisson distribution with mean

##### E [ N ]=

```
n −∑ k + 1
```
```
i = 1
```
```
P ( Ei )=( n − k ) pk ( 1 − p )+ pk
```
Because there will not be a run of _k_ heads if (and only if) _N_ =0, thus the preceding
gives

```
P (no head strings of length k )= P ( N = 0 )Lexp{−( n − k ) pk ( 1 − p )− pk }
```
If we let _Ln_ denote the largest number of consecutive heads in the _n_ flips, then,
because _Ln_ will be less than _k_ if (and only if) there are no head strings of length
_k_ , the preceding equation can be written as

```
P { Ln < k }Lexp{−( n − k ) pk ( 1 − p )− pk }
```
Now, let us suppose that the coin being flipped is fair; that is, suppose that _p_ = 1 /2.
Then the preceding gives

```
P { Ln < k }Lexp
```
##### {

##### −

```
n − k + 2
2 k +^1
```
##### }

```
Lexp
```
##### {

##### −

```
n
2 k +^1
```
##### }

where the final approximation supposes that _e_

_k_ − 2
2 _k_ +^1 L1 (that is, that _k_ −^2
2 _k_ +^1 L 0). Let
_j_ =log 2 _n_ , and assume that _j_ is an integer. For _k_ = _j_ + _i_ ,

```
n
2 k +^1
```
##### =

```
n
2 j 2 i +^1
```
##### =

##### 1

```
2 i +^1
```
Consequently,
_P_ { _Ln_ < _j_ + _i_ }Lexp{−( 1 / 2 ) _i_ +^1 }

which implies that

```
P { Ln = j + i }= P { Ln < j + i + 1 }− P { Ln < j + i }
Lexp{−( 1 / 2 ) i +^2 }−exp{−( 1 / 2 ) i +^1 }
```
For instance,

```
P { Ln < j − 3 }L e −^4 L. 0183
P { Ln = j − 3 }L e −^2 − e −^4 L. 1170
P { Ln = j − 2 }L e −^1 − e −^2 L. 2325
P { Ln = j − 1 }L e −^1 /^2 − e −^1 L. 2387
P { Ln = j }L e −^1 /^4 − e −^1 /^2 L. 1723
P { Ln = j + 1 }L e −^1 /^8 − e −^1 /^4 L. 1037
P { Ln = j + 2 }L e −^1 /^16 − e −^1 /^8 L. 0569
P { Ln = j + 3 }L e −^1 /^32 − e −^1 /^16 L. 0298
P { Ln Ú j + 4 }L 1 − e −^1 /^32 L. 0308
```

**150** Chapter 4 Random Variables

```
Thus, we observe the rather interesting fact that no matter how large n is, the length
of the longest run of heads in a sequence of n flips of a fair coin will be within 2 of
log 2 ( n )−1 with a probability approximately equal to.86.
We now derive an exact expression for the probability that there is a string of
k consecutive heads when a coin that lands on heads with probability p is flipped
n times. With the events Ei , i =1,..., n − k +1, as defined earlier, and with Ln
denoting, as before, the length of the longest run of heads,
```
```
P ( Ln Ú k )= P (there is a string of k consecutive heads)= P (∪ ni =− 1 k +^1 Ei )
```
```
The inclusion–exclusion identity for the probability of a union can be written as
```
```
P (∪ ni =− 1 k +^1 Ei )=
```
```
n −∑ k + 1
```
```
r = 1
```
```
(− 1 ) r +^1
```
##### ∑

```
i 1 <···< ir
```
```
P ( Ei 1 ··· Eir )
```
```
Let Si denote the set of flip numbers to which the event Ei refers. (So, for instance,
S 1 ={1,..., k + 1 }.) Now, consider one of the r -way intersection probabilities that
does not include the event En − k + 1. That is, consider P ( Ei 1 ··· Eir )where i 1 <···<
ir < n − k +1. On the one hand, if there is any overlap in the sets Si 1 ,..., Sir then this
probability is 0. On the other hand, if there is no overlap, then the events Ei 1 ,..., Eir
are independent. Therefore,
```
```
P ( Ei 1 ··· Eir )=
```
##### {

```
0, if there is any overlap in Si 1 ,..., Sir
prk ( 1 − p ) r , if there is no overlap
```
```
We must now determine the number of different choices of i 1 <···< ir < n − k + 1
for which there is no overlap in the sets Si 1 ,..., Sir. To do so, note first that each of
the Sij , j =1,..., r , refer to k + 1 flips, so, without any overlap, they together refer
to r ( k + 1 )flips. Now consider any permutation of r identical letters a (one for each
of the sets Si 1 ,..., Sir − 1 )and of n − r ( k + 1 )identical letters b (one for each of the
trials that are not part of any of Si 1 ,..., Sir − 1 , Sn − k + 1 ). Interpret the number of b ’s
before the first a as the number of flips before Si 1 , the number of b ’s between the first
and second a as the number of flips between Si 1 and Si 2 , and so on, with the number
of( b ’s after the final a representing the number of flips after Sir. Because there are
n − rk
r
```
##### )

```
permutations of r letters a and of n − r ( k + 1 )letters b , with every such
permutation corresponding (in a one-to-one fashion) to a different nonoverlapping
choice, it follows that
∑
```
```
i 1 <···< ir < n − k + 1
```
```
P ( Ei 1 ··· Eir )=
```
##### (

```
n − rk
r
```
##### )

```
prk ( 1 − p ) r
```
```
We must now consider r -way intersection probabilities of the form
```
```
P ( Ei 1 ··· Eir − 1 En − k + 1 ),
```
```
where i 1 <···< ir − 1 < n − k +1. Now, this probability will equal 0 if there is any
overlap in Si 1 ,..., Sir − 1 , Sn − k ;if there is no overlap, then the events of the intersection
will be independent, so
```
```
P ( Ei 1 ··· Eir − 1 En − k + 1 )=[ pk ( 1 − p )] r −^1 pk = pkr ( 1 − p ) r −^1
```
```
By a similar argument as before, the number of nonoverlapping sets Si 1 ,..., Sir − 1 , Sn − k
will equal the number of permutations of r −1 letters a (one for each of the sets
```

```
Section 4.7 The Poisson Random Variable 151
```
_Si_ 1 ,..., _Sir_ − 1 )and of _n_ −( _r_ − 1 )( _k_ + 1 )− _k_ = _n_ − _rk_ −( _r_ − 1 )letters _b_ (one
for each of the trials that are not part of any of _Si_ 1 ,..., _Sir_ − 1 , _Sn_ − _k_ + 1 ). Since there are
( _n_ − _rk
r_ − 1

##### )

```
permutations of r −1 letters a and of n − rk −( r − 1 )letters b , we have
```
```
∑
```
```
i 1 <...< ir − 1 < n − k + 1
```
```
P ( Ei 1 ··· Eir − 1 En − k + 1 )=
```
##### (

```
n − rk
r − 1
```
##### )

```
pkr ( 1 − p ) r −^1
```
Putting it all together yields the exact expression, namely,

```
P ( Ln Ú k )=
```
```
n −∑ k + 1
```
```
r = 1
```
```
(− 1 ) r +^1
```
##### [(

```
n − rk
r
```
##### )

##### +

##### 1

```
p
```
##### (

```
n − rk
r − 1
```
##### )]

```
pkr ( 1 − p ) r
```
where we utilize the convention that

```
( m
j
```
##### )

=0if _m_ < _j_.
From a computational point of view, a more efficient method for computing the
desired probability than the use of the preceding identity is to derive a set of recur-
sive equations. To do so, let _An_ be the event that there is a string of _k_ consecutive
heads in a sequence of _n_ flips of a fair coin, and let _Pn_ = _P_ ( _An_ ).We will derive a
set of recursive equations for _Pn_ by conditioning on when the first tail appears. For
_j_ =1,..., _k_ , let _Fj_ be the event that the first tail appears on flip _j_ , and let _H_ be the
event that the first _k_ flips are all heads. Because the events _F_ 1 ,..., _Fk_ , _H_ are mutually
exclusive and exhaustive (that is, exactly one of these events must occur), we have

```
P ( An )=
```
```
∑ k
```
```
j = 1
```
```
P ( An | Fj ) P ( Fj )+ P ( An | H ) P ( H )
```
Now, given that the first tail appears on flip _j_ , where _j_ < _k_ , it follows that those _j_
flips are wasted as far as obtaining a string of _k_ heads in a row; thus, the conditional
probability of this event is the probability that such a string will occur among the
remaining _n_ − _j_ flips. Therefore,

```
P ( An | Fj )= Pn − j
```
Because _P_ ( _An_ | _H_ )=1, the preceding equation gives

```
Pn = P ( An )
```
##### =

```
∑ k
```
```
j = 1
```
```
Pn − jP ( Fj )+ P ( H )
```
##### =

```
∑ k
```
```
j = 1
```
```
Pn − jpj −^1 ( 1 − p )+ pk
```
Starting with _Pj_ =0, _j_ < _k_ ,and _Pk_ = _pk_ , we can use the latter formula to recursively
compute _Pk_ + 1 , _Pk_ + 2 , and so on, up to _Pn_. For instance, suppose we want the prob-
ability that there is a run of 2 consecutive heads when a fair coin is flipped 4 times.
Then, with _k_ =2, we have _P_ 1 =0, _P_ 2 =( 1 / 2 )^2. Because, when _p_ = 1 /2, the recursion
becomes

```
Pn =
```
```
∑ k
```
```
j = 1
```
```
Pn − j ( 1 / 2 ) j +( 1 / 2 ) k
```

**152** Chapter 4 Random Variables

```
we obtain
P 3 = P 2 ( 1 / 2 )+ P 1 ( 1 / 2 )^2 +( 1 / 2 )^2 = 3 / 8
```
```
and
P 4 = P 3 ( 1 / 2 )+ P 2 ( 1 / 2 )^2 +( 1 / 2 )^2 = 1 / 2
```
```
which is clearly true because there are 8 outcomes that result in a string of 2 consec-
utive heads: hhhh , hhht , hhth , hthh , thhh , hhtt , thht ,and tthh. Each of these outcomes
occurs with probability 1/16..
```
```
Another use of the Poisson probability distribution arises in situations where
“events” occur at certain points in time. One example is to designate the occurrence
of an earthquake as an event; another possibility would be for events to correspond
to people entering a particular establishment (bank, post office, gas station, and so
on); and a third possibility is for an event to occur whenever a war starts. Let us sup-
pose that events are indeed occurring at certain (random) points of time, and let us
assume that, for some positive constantλ, the following assumptions hold true:
```
1. The probability that exactly 1 event occurs in a given interval of length _h_ is equal
    toλ _h_ + _o_ ( _h_ ), where _o_ ( _h_ )stands for any function _f_ ( _h_ )for which lim
       _h_ → 0

```
f ( h )/ h =0.
[For instance, f ( h )= h^2 is o ( h ), whereas f ( h )= h is not.]
```
2. The probability that 2 or more events occur in an interval of length _h_ is equal
    to _o_ ( _h_ ).
3. For any integers _n_ , _j_ 1 , _j_ 2 ,..., _jn_ and any set of _n_ nonoverlapping intervals, if we
    define _Ei_ to be the event that exactly _ji_ of the events under consideration occur
    in the _i_ th of these intervals, then events _E_ 1 , _E_ 2 ,..., _En_ are independent.
Loosely put, assumptions 1 and 2 state that, for small values of _h_ , the probability
that exactly 1 event occurs in an interval of size _h_ equalsλ _h_ plus something that is
small compared with _h_ , whereas the probability that 2 or more events occur is small
compared with _h_. Assumption 3 states that whatever occurs in one interval has no
(probability) effect on what will occur in other, nonoverlapping intervals.
We now show that, under assumptions 1, 2, and 3, the number of events occurring
in any interval of length _t_ is a Poisson random variable with parameterλ _t_ .Tobe
precise, let us call the interval [0, _t_ ] and denote the number of events occurring in that
interval by _N_ ( _t_ ). To obtain an expression for _P_ { _N_ ( _t_ )= _k_ }, we start by breaking the
interval [0, _t_ ]into _n_ nonoverlapping subintervals, each of length _t/n_ (Figure 4.7).
Now,

```
P { N ( t )= k }= P { k of the n subintervals contain exactly 1 event
and the other n − k contain 0 events} (7.2)
+ P { N ( t )= k and at least 1 subinterval contains
2 or more events}
```
```
The proceding equation holds because the event on the left side of Equation (7.2),
that is,{ N ( t )= k }, is clearly equal to the union of the two mutually exclusive events
```
```
0
t –
n
—^2 t
n
—^3 t
n ( n – 1)– nt
```
```
— nt
t = n
```
```
FIGURE 4.7
```

```
Section 4.7 The Poisson Random Variable 153
```
on the right side of the equation. Letting _A_ and _B_ denote the two mutually exclusive
events on the right side of Equation (7.2), we have

```
P ( B )... P {at least one subinterval contains 2 or more events}
```
##### = P

##### ⎛

##### ⎝

```
⋃ n
```
```
i = 1
```
```
{ i th subinterval contains 2 or more events}
```
##### ⎞

##### ⎠

##### ...

```
∑ n
```
```
i = 1
```
```
P { i th subinterval contains 2 or more events}
by Boole’s
inequality
```
##### =

```
∑ n
```
```
i = 1
```
```
o
```
##### (

```
t
n
```
##### )

```
by assumption 2
```
```
= no
```
##### (

```
t
n
```
##### )

```
= t
```
##### [

```
o ( t / n )
t / n
```
##### ]

Now, in addition for any _t_ , _t_ / _n_ →0as _n_ →q,so _o_ ( _t_ / _n_ )/( _t_ / _n_ )→0as _n_ →q, by the defini-
tion of _o_ ( _h_ ). Hence,
_P_ ( _B_ )→0as _n_ →q (7.3)

```
Moreover, since assumptions 1 and 2 imply that†
```
```
P {0 events occur in an interval of length h }
= 1 −[λ h + o ( h )+ o ( h )]= 1 −λ h − o ( h )
```
we see from the independence assumption (number 3) that

```
P ( A )= P { k of the subintervals contain exactly 1 event and the other
n − k contain 0 events}
```
##### =

##### (

```
n
k
```
##### )[

```
λ t
n
```
```
+ o
```
##### (

```
t
n
```
```
)] k [
1 −
```
##### (

```
λ t
n
```
##### )

```
− o
```
##### (

```
t
n
```
```
)] n − k
```
However, since

```
n
```
##### [

```
λ t
n
```
```
+ o
```
##### (

```
t
n
```
##### )]

```
=λ t + t
```
##### [

```
o ( t / n )
t / n
```
##### ]

```
→λ t as n →q
```
it follows, by the same argument that verified the Poisson approximation to the bino-
mial, that

```
P ( A )→ e −λ t
```
```
(λ t ) k
k!
```
```
as n →q (7.4)
```
Thus, from Equations (7.2), (7.3), and (7.4), by letting _n_ →q, we obtain

```
P { N ( t )= k }= e −λ t
```
```
(λ t ) k
k!
```
```
k =0, 1,... (7.5)
```
```
†The sum of two functions, both of which are o ( h ), is also o ( h ). This is so because if
```
lim _h_ → 0 _f_ ( _h_ )/ _h_ =lim _h_ → 0 _g_ ( _h_ )/ _h_ =0, then lim _h_ → 0 [ _f_ ( _h_ )+ _g_ ( _h_ )]/ _h_ =0.


**154** Chapter 4 Random Variables

```
Hence, if assumptions 1, 2, and 3 are satisfied, then the number of events occurring
in any fixed interval of length t is a Poisson random variable with meanλ t , and we say
that the events occur in accordance with a Poisson process having rateλ. The valueλ,
which can be shown to equal the rate per unit time at which events occur, is a constant
that must be empirically determined.
The preceding discussion explains why a Poisson random variable is usually a good
approximation for such diverse phenomena as the following:
```
1. The number of earthquakes occurring during some fixed time span
2. The number of wars per year
3. The number of electrons emitted from a heated cathode during a fixed time
    period
4. The number of deaths, in a given period of time, of the policyholders of a life
    insurance company

```
EXAMPLE 7e
Suppose that earthquakes occur in the western portion of the United States in accor-
dance with assumptions 1, 2, and 3, withλ=2 and with 1 week as the unit of time.
(That is, earthquakes occur in accordance with the three assumptions at a rate of 2
per week.)
(a) Find the probability that at least 3 earthquakes occur during the next 2 weeks.
(b) Find the probability distribution of the time, starting from now, until the next
earthquake.
```
```
Solution. (a) From Equation (7.5), we have
```
```
P { N ( 2 )Ú 3 }= 1 − P { N ( 2 )= 0 }− P { N ( 2 )= 1 }− P { N ( 2 )= 2 }
```
```
= 1 − e −^4 − 4 e −^4 −
```
##### 42

##### 2

```
e −^4
```
```
= 1 − 13 e −^4
```
```
(b) Let X denote the amount of time (in weeks) until the next earthquake. Because
X will be greater than t if and only if no events occur within the next t units of time,
we have, from Equation (7.5),
```
```
P { X > t }= P { N ( t )= 0 }= e −λ t
```
```
so the probability distribution function F of the random variable X is given by
```
```
F ( t )= P { X ... t }= 1 − P { X > t }= 1 − e −λ t
= 1 − e −^2 t.
```
#### 4.7.1 Computing the Poisson Distribution Function

```
If X is Poisson with parameterλ,then
```
```
P { X = i + 1 }
P { X = i }
```
##### =

```
e −λλ i +^1 /( i + 1 )!
e −λλ i / i!
```
##### =

```
λ
i + 1
```
##### (7.6)


```
Section 4.8 Other Discrete Probability Distributions 155
```
Starting with _P_ { _X_ = 0 }= _e_ −λ, we can use (7.6) to compute successively

```
P { X = 1 }=λ P { X = 0 }
```
```
P { X = 2 }=
```
```
λ
2
```
##### P { X = 1 }

```
P { X = i + 1 }=
```
```
λ
i + 1
```
```
P { X = i }
```
The website includes a program that uses Equation (7.6) to compute Poisson prob-
abilities.

**_EXAMPLE 7f_**

```
(a) Determine P { X ... 90 }when X is Poisson with mean 100.
(b) Determine P { Y ... 1075 }when Y is Poisson with mean 1000.
```
**_Solution._** From the website, we obtain the solutions:

```
(a) P { X ... 90 }L.1714;
(b) P { Y ... 1075 }L.9894..
```
### 4.8 Other Discrete Probability Distributions

#### 4.8.1 The Geometric Random Variable

Suppose that independent trials, each having a probability _p_ ,0< _p_ <1, of being a
success, are performed until a success occurs. If we let _X_ equal the number of trials
required, then
_P_ { _X_ = _n_ }=( 1 − _p_ ) _n_ −^1 _pn_ =1, 2,... (8.1)

Equation (8.1) follows because, in order for _X_ to equal _n_ , it is necessary and sufficient
that the first _n_ −1 trials are failures and the _n_ th trial is a success. Equation (8.1) then
follows, since the outcomes of the successive trials are assumed to be independent.
Since q
∑

```
n = 1
```
```
P { X = n }= p
```
```
∑q
```
```
n = 1
```
```
( 1 − p ) n −^1 =
```
```
p
1 −( 1 − p )
```
##### = 1

it follows that, with probability 1, a success will eventually occur. Any random vari-
able _X_ whose probability mass function is given by Equation (8.1) is said to be a
_geometric_ random variable with parameter _p_.

**_EXAMPLE 8a_**

An urn contains _N_ white and _M_ black balls. Balls are randomly selected, one at a
time, until a black one is obtained. If we assume that each ball selected is replaced
before the next one is drawn, what is the probability that

```
(a) exactly n draws are needed?
(b) at least k draws are needed?
```
**_Solution._** If we let _X_ denote the number of draws needed to select a black ball, then
_X_ satisfies Equation (8.1) with _p_ = _M_ /( _M_ + _N_ ). Hence,


**156** Chapter 4 Random Variables

```
(a)
```
```
P { X = n }=
```
##### (

##### N

##### M + N

```
) n − 1
M
M + N
```
##### =

```
MNn −^1
( M + N ) n
```
```
(b)
```
```
P { X Ú k }=
```
##### M

##### M + N

```
∑q
```
```
n = k
```
##### (

##### N

##### M + N

```
) n − 1
```
##### =

##### (

##### M

##### M + N

##### )(

##### N

##### M + N

```
) k − 1 /[
1 −
```
##### N

##### M + N

##### ]

##### =

##### (

##### N

##### M + N

```
) k − 1
```
```
Of course, part (b) could have been obtained directly, since the probability that at
least k trials are necessary to obtain a success is equal to the probability that the first
k −1 trials are all failures. That is, for a geometric random variable,
```
```
P { X Ú k }=( 1 − p ) k −^1
.
```
```
EXAMPLE 8b
Find the expected value of a geometric random variable.
```
```
Solution. With q = 1 − p , we have
```
##### E [ X ]=

```
∑q
```
```
i = 1
```
```
iqi −^1 p
```
##### =

```
∑q
```
```
i = 1
```
```
( i − 1 + 1 ) qi −^1 p
```
##### =

```
∑q
```
```
i = 1
```
```
( i − 1 ) qi −^1 p +
```
```
∑q
```
```
i = 1
```
```
qi −^1 p
```
##### =

```
∑q
```
```
j = 0
```
```
jqjp + 1
```
```
= q
```
```
∑q
```
```
j = 1
```
```
jqj −^1 p + 1
```
```
= qE [ X ]+ 1
```
```
Hence,
pE [ X ]= 1
```
```
yielding the result
```
```
E [ X ]=
```
##### 1

```
p
```

```
Section 4.8 Other Discrete Probability Distributions 157
```
In other words, if independent trials having a common probability _p_ of being success-
ful are performed until the first success occurs, then the expected number of required
trials equals 1/ _p_. For instance, the expected number of rolls of a fair die that it takes
to obtain the value 1 is 6..

**_EXAMPLE 8c_**

Find the variance of a geometric random variable.

**_Solution._** To determine Var( _X_ ), let us first compute _E_ [ _X_^2 ]. With _q_ = 1 − _p_ , we have

##### E [ X^2 ]=

```
∑q
```
```
i = 1
```
```
i^2 qi −^1 p
```
##### =

```
∑q
```
```
i = 1
```
```
( i − 1 + 1 )^2 qi −^1 p
```
##### =

```
∑q
```
```
i = 1
```
```
( i − 1 )^2 qi −^1 p +
```
```
∑q
```
```
i = 1
```
```
2 ( i − 1 ) qi −^1 p +
```
```
∑q
```
```
i = 1
```
```
qi −^1 p
```
##### =

```
∑q
```
```
j = 0
```
```
j^2 qjp + 2
```
```
∑q
```
```
j = 1
```
```
jqjp + 1
```
```
= qE [ X^2 ]+ 2 qE [ X ]+ 1
```
Using _E_ [ _X_ ]= 1 / _p_ , the equation for _E_ [ _X_^2 ] yields

```
pE [ X^2 ]=
```
```
2 q
p
```
##### + 1

Hence,

```
E [ X^2 ]=
```
```
2 q + p
p^2
```
##### =

```
q + 1
p^2
```
giving the result

```
Var( X )=
```
```
q + 1
p^2
```
##### −

##### 1

```
p^2
```
##### =

```
q
p^2
```
##### =

```
1 − p
p^2.
```
#### 4.8.2 The Negative Binomial Random Variable

Suppose that independent trials, each having probability _p_ ,0< _p_ < 1, of being a
success are performed until a total of _r_ successes is accumulated. If we let _X_ equal the
number of trials required, then

```
P { X = n }=
```
##### (

```
n − 1
r − 1
```
##### )

```
pr ( 1 − p ) n − r n = r , r +1,... (8.2)
```
Equation (8.2) follows because, in order for the _r_ th success to occur at the _n_ th trial,
there must be _r_ − 1 successes in the first _n_ −1 trials and the _n_ th trial must be a
success. The probability of the first event is
(
_n_ − 1
_r_ − 1

##### )

```
pr −^1 ( 1 − p ) n − r
```

**158** Chapter 4 Random Variables

```
and the probability of the second is p ; thus, by independence, Equation (8.2) is estab-
lished. To verify that a total of r successes must eventually be accumulated, either we
can prove analytically that
```
```
∑q
```
```
n = r
```
```
P { X = n }=
```
```
∑q
```
```
n = r
```
##### (

```
n − 1
r − 1
```
##### )

```
pr ( 1 − p ) n − r = 1 (8.3)
```
```
or we can give a probabilistic argument as follows: The number of trials required
to obtain r successes can be expressed as Y 1 + Y 2 + ··· + Yr , where Y 1 equals
the number of trials required for the first success, Y 2 the number of additional trials
after the first success until the second success occurs, Y 3 the number of additional
trials until the third success, and so on. Because the trials are independent and all
have the same probability of success, it follows that Y 1 , Y 2 ,..., Yr are all geometric
random variables. Hence, each is finite with probability 1, so
```
```
∑ r
i = 1
```
```
Yi must also be finite,
```
```
establishing Equation (8.3).
Any random variable X whose probability mass function is given by Equation (8.2)
is said to be a negative binomial random variable with parameters ( r , p ). Note that a
geometric random variable is just a negative binomial with parameter (1, p ).
In the next example, we use the negative binomial to obtain another solution of
the problem of the points.
```
```
EXAMPLE 8d
If independent trials, each resulting in a success with probability p , are performed,
what is the probability of r successes occurring before m failures?
```
```
Solution. The solution will be arrived at by noting that r successes will occur before
m failures if and only if the r th success occurs no later than the ( r + m − 1)th
trial. This follows because if the r th success occurs before or at the ( r + m −1)th
trial, then it must have occurred before the m th failure, and conversely. Hence, from
Equation (8.2), the desired probability is
r +∑ m − 1
```
```
n = r
```
##### (

```
n − 1
r − 1
```
##### )

```
pr ( 1 − p ) n − r.
```
```
EXAMPLE 8e The Banach match problem
At all times, a pipe-smoking mathematician carries 2 matchboxes—1 in his left-hand
pocket and 1 in his right-hand pocket. Each time he needs a match, he is equally likely
to take it from either pocket. Consider the moment when the mathematician first
discovers that one of his matchboxes is empty. If it is assumed that both matchboxes
initially contained N matches, what is the probability that there are exactly k matches,
k =0, 1,..., N , in the other box?
```
```
Solution. Let E denote the event that the mathematician first discovers that the right-
hand matchbox is empty and that there are k matches in the left-hand box at the
time. Now, this event will occur if and only if the( N + 1 )th choice of the right-hand
matchbox is made at the ( N + 1 + N − k )th trial. Hence, from Equation (8.2) (with
p =^12 , r = N +1, and n = 2 N − k +1), we see that
```
##### P ( E )=

##### (

```
2 N − k
N
```
##### )(

##### 1

##### 2

```
) 2 N − k + 1
```

```
Section 4.8 Other Discrete Probability Distributions 159
```
Since there is an equal probability that it is the left-hand box that is first discovered
to be empty and there are _k_ matches in the right-hand box at that time, the desired
result is

```
2 P ( E )=
```
##### (

```
2 N − k
N
```
##### )(

##### 1

##### 2

```
) 2 N − k
```
```
.
```
**_EXAMPLE 8f_**

Compute the expected value and the variance of a negative binomial random variable
with parameters _r_ and _p_.

**_Solution._** We have

```
E [ Xk ]=
```
```
∑q
```
```
n = r
```
```
nk
```
##### (

```
n − 1
r − 1
```
##### )

```
pr ( 1 − p ) n − r
```
##### =

```
r
p
```
```
∑q
```
```
n = r
```
```
nk −^1
```
##### (

```
n
r
```
##### )

```
pr +^1 ( 1 − p ) n − r since n
```
##### (

```
n − 1
r − 1
```
##### )

```
= r
```
##### (

```
n
r
```
##### )

##### =

```
r
p
```
```
∑q
```
```
m = r + 1
```
```
( m − 1 ) k −^1
```
##### (

```
m − 1
r
```
##### )

```
pr +^1 ( 1 − p ) m −( r +^1 )
```
```
by setting
m = n + 1
```
##### =

```
r
p
```
```
E [( Y − 1 ) k −^1 ]
```
where _Y_ is a negative binomial random variable with parameters _r_ +1, _p_. Setting
_k_ =1 in the preceding equation yields

##### E [ X ]=

```
r
p
```
Setting _k_ =2 in the equation for _E_ [ _Xk_ ] and using the formula for the expected value
of a negative binomial random variable gives

```
E [ X^2 ]=
```
```
r
p
```
##### E [ Y −1]

##### =

```
r
p
```
##### (

```
r + 1
p
```
##### − 1

##### )

Therefore,

```
Var( X )=
```
```
r
p
```
##### (

```
r + 1
p
```
##### − 1

##### )

##### −

##### (

```
r
p
```
##### ) 2

##### =

```
r ( 1 − p )
p^2.
```
Thus, from Example 8f, if independent trials, each of which is a success with prob-
ability _p_ , are performed, then the expected value and variance of the number of trials
that it takes to amass _r_ successes is _r/p_ and _r_ ( 1 − _p_ )/ _p_^2 , respectively.
Since a geometric random variable is just a negative binomial with parameter
_r_ =1, it follows from the preceding example that the variance of a geometric ran-
dom variable with parameter _p_ is equal to( 1 − _p_ )/ _p_^2 , which checks with the result
of Example 8c.


**160** Chapter 4 Random Variables

```
EXAMPLE 8g
Find the expected value and the variance of the number of times one must throw a
die until the outcome 1 has occurred 4 times.
```
```
Solution. Since the random variable of interest is a negative binomial with parame-
ters r =4and p =^16 , it follows that
```
```
E [ X ]= 24
```
```
Var( X )=
```
##### 4

##### (

```
5
6
```
##### )

##### (

```
1
6
```
##### ) 2 =^120

#### 4.8.3 The Hypergeometric Random Variable

```
Suppose that a sample of size n is to be chosen randomly (without replacement) from
an urn containing N balls, of which m are white and N − m are black. If we let X
denote the number of white balls selected, then
```
```
P { X = i }=
```
##### (

```
m
i
```
##### )(

```
N − m
n − i
```
##### )

##### (

##### N

```
n
```
```
) i =0, 1,..., n (8.4)
```
```
A random variable X whose probability mass function is given by Equation (8.4) for
some values of n , N , m is said to be a hypergeometric random variable.
Remark. Although we have written the hypergeometric probability mass func-
tion with i going from 0 to n , P { X = i }will actually be 0, unless i satisfies the inequali-
ties n −( N − m )... i ...min( n , m ). However, Equation (8.4) is always valid because
of our convention that
```
##### (

```
r
k
```
##### )

```
is equal to 0 when either k <0or r < k..
```
```
EXAMPLE 8h
An unknown number, say, N , of animals inhabit a certain region. To obtain some
information about the size of the population, ecologists often perform the follow-
ing experiment: They first catch a number, say, m , of these animals, mark them in
some manner, and release them. After allowing the marked animals time to disperse
throughout the region, a new catch of size, say, n , is made. Let X denote the number
of marked animals in this second capture. If we assume that the population of ani-
mals in the region remained fixed between the time of the two catches and that each
time an animal was caught it was equally likely to be any of the remaining uncaught
animals, it follows that X is a hypergeometric random variable such that
```
```
P { X = i }=
```
##### (

```
m
i
```
##### )(

```
N − m
n − i
```
##### )

##### (

##### N

```
n
```
```
) K Pi ( N )
```
```
Suppose now that X is observed to equal i. Then, since Pi ( N )represents the proba-
bility of the observed event when there are actually N animals present in the region, it
would appear that a reasonable estimate of N would be the value of N that maximizes
Pi ( N ). Such an estimate is called a maximum likelihood estimate. (See Theoretical
Exercises 13 and 18 for other examples of this type of estimation procedure.)
```

```
Section 4.8 Other Discrete Probability Distributions 161
```
```
The maximization of Pi ( N )can be done most simply by first noting that
```
```
Pi ( N )
Pi ( N − 1 )
```
##### =

```
( N − m )( N − n )
N ( N − m − n + i )
```
Now, the preceding ratio is greater than 1 if and only if

```
( N − m )( N − n )Ú N ( N − m − n + i )
```
or, equivalently, if and only if

```
N ...
```
```
mn
i
```
Thus, _Pi_ ( _N_ )is first increasing and then decreasing, and reaches its maximum value
at the largest integral value not exceeding _mn/i_. This value is the maximum likeli-
hood estimate of _N_. For example, suppose that the initial catch consisted of _m_ =
50 animals, which are marked and then released. If a subsequent catch consists of
_n_ =40 animals of which _i_ =4 are marked, then we would estimate that there are
some 500 animals in the region. (Note that the preceding estimate could also have
been obtained by assuming that the proportion of marked animals in the region,
_m/N_ , is approximately equal to the proportion of marked animals in our second
catch, _i/n_ .).

**_EXAMPLE 8i_**

A purchaser of electrical components buys them in lots of size 10. It is his policy
to inspect 3 components randomly from a lot and to accept the lot only if all 3 are
nondefective. If 30 percent of the lots have 4 defective components and 70 percent
have only 1, what proportion of lots does the purchaser reject?

**_Solution._** Let _A_ denote the event that the purchaser accepts a lot. Now,

```
P ( A )= P ( A |lot has 4 defectives)
```
##### 3

##### 10

```
+ P ( A |lot has 1 defective)
```
##### 7

##### 10

##### =

##### (

##### 4

##### 0

##### )(

##### 6

##### 3

##### )

##### (

##### 10

##### 3

##### )

##### (

##### 3

##### 10

##### )

##### +

##### (

##### 1

##### 0

##### )(

##### 9

##### 3

##### )

##### (

##### 10

##### 3

##### )

##### (

##### 7

##### 10

##### )

##### =

##### 54

##### 100

Hence, 46 percent of the lots are rejected..

If _n_ balls are randomly chosen without replacement from a set of _N_ balls of which
the fraction _p_ = _m_ / _N_ is white, then the number of white balls selected is hypergeo-
metric. Now, it would seem that when _m_ and _N_ are large in relation to _n_ , it shouldn’t
make much difference whether the selection is being done with or without replace-
ment, because, no matter which balls have previously been selected, when _m_ and _N_
are large, each additional selection will be white with a probability approximately
equal to _p_. In other words, it seems intuitive that when _m_ and _N_ are large in relation
to _n_ , the probability mass function of _X_ should approximately be that of a binomial
random variable with parameters _n_ and _p_. To verify this intuition, note that if _X_ is
hypergeometric, then, for _i_ ... _n_ ,


**162** Chapter 4 Random Variables

```
P { X = i }=
```
##### (

```
m
i
```
##### )(

```
N − m
n − i
```
##### )

##### (

##### N

```
n
```
##### )

##### =

```
m!
( m − i )! i!
```
```
( N − m )!
( N − m − n + i )!( n − i )!
```
```
( N − n )! n!
N!
```
```
=
```
##### (

```
n
i
```
##### )

```
m
N
```
```
m − 1
N − 1
```
##### ···

```
m − i + 1
N − i + 1
```
```
N − m
N − i
```
```
N − m − 1
N − i − 1
```
```
···
```
```
N − m −( n − i − 1 )
N − i −( n − i − 1 )
```
##### L

##### (

```
n
i
```
##### )

```
pi ( 1 − p ) n − i
```
```
when p = m / N and m and N are
large in relation to n and i
```
```
EXAMPLE 8j
Determine the expected value and the variance of X , a hypergeometric random vari-
able with parameters n , N ,and m.
```
```
Solution.
```
```
E [ Xk ]=
```
```
∑ n
```
```
i = 0
```
```
ikP { X = i }
```
##### =

```
∑ n
```
```
i = 1
```
```
ik
```
##### (

```
m
i
```
##### )(

```
N − m
n − i
```
##### )/(

##### N

```
n
```
##### )

```
Using the identities
```
```
i
```
##### (

```
m
i
```
##### )

```
= m
```
##### (

```
m − 1
i − 1
```
##### )

```
and n
```
##### (

##### N

```
n
```
##### )

##### = N

##### (

##### N − 1

```
n − 1
```
##### )

```
we obtain
```
```
E [ Xk ]=
```
```
nm
N
```
```
∑ n
```
```
i = 1
```
```
ik −^1
```
##### (

```
m − 1
i − 1
```
##### )(

```
N − m
n − i
```
##### )/(

##### N − 1

```
n − 1
```
##### )

##### =

```
nm
N
```
```
n ∑− 1
```
```
j = 0
```
```
( j + 1 ) k −^1
```
##### (

```
m − 1
j
```
##### )(

```
N − m
n − 1 − j
```
##### )/(

##### N − 1

```
n − 1
```
##### )

##### =

```
nm
N
```
```
E [( Y + 1 ) k −^1 ]
```
```
where Y is a hypergeometric random variable with parameters n −1, N −1, and
m −1. Hence, upon setting k =1, we have
```
##### E [ X ]=

```
nm
N
```
```
In words, if n balls are randomly selected from a set of N balls, of which m are white,
then the expected number of white balls selected is nm/N.
```

```
Section 4.8 Other Discrete Probability Distributions 163
```
```
Upon setting k =2 in the equation for E [ Xk ], we obtain
```
##### E [ X^2 ]=

```
nm
N
```
##### E [ Y +1]

##### =

```
nm
N
```
##### [

```
( n − 1 )( m − 1 )
N − 1
```
##### + 1

##### ]

where the final equality uses our preceding result to compute the expected value of
the hypergeometric random variable _Y_.
Because _E_ [ _X_ ]= _nm_ / _N_ , we can conclude that

```
Var( X )=
```
```
nm
N
```
##### [

```
( n − 1 )( m − 1 )
N − 1
```
##### + 1 −

```
nm
N
```
##### ]

Letting _p_ = _m_ / _N_ and using the identity

```
m − 1
N − 1
```
##### =

```
Np − 1
N − 1
```
```
= p −
```
```
1 − p
N − 1
```
shows that

```
Var( X )= np [( n − 1 ) p −( n − 1 )
```
```
1 − p
N − 1
```
```
+ 1 − np ]
```
```
= np ( 1 − p )( 1 −
```
```
n − 1
N − 1
```
##### )

**Remark.** We have shown in Example 8j that if _n_ balls are randomly selected with-
out replacement from a set of _N_ balls, of which the fraction _p_ are white, then the
expected number of white balls chosen is _np_. In addition, if _N_ is large in relation to _n_
[so that( _N_ − _n_ )/( _N_ − 1 )is approximately equal to 1], then

```
Var( X )L np ( 1 − p )
```
In other words, _E_ [ _X_ ] is the same as when the selection of the balls is done with
replacement (so that the number of white balls is binomial with parameters _n_
and _p_ ), and if the total collection of balls is large, then Var( _X_ )is approximately equal
to what it would be if the selection were done with replacement. This is, of course,
exactly what we would have guessed, given our earlier result that when the number
of balls in the urn is large, the number of white balls chosen approximately has the
mass function of a binomial random variable..

#### 4.8.4 TheZeta(orZipf)Distribution..................

A random variable is said to have a zeta (sometimes called the Zipf) distribution if
its probability mass function is given by

```
P { X = k }=
```
##### C

```
k α+^1
```
```
k =1, 2,...
```
for some value ofα>0. Since the sum of the foregoing probabilities must equal 1, it
follows that

##### C =

##### ⎡

##### ⎣

```
∑q
```
```
k = 1
```
##### (

##### 1

```
k
```
```
)α+ 1
```
##### ⎤

##### ⎦

```
− 1
```

**164** Chapter 4 Random Variables

```
The zeta distribution owes its name to the fact that the function
```
```
ζ( s )= 1 +
```
##### (

##### 1

##### 2

```
) s
+
```
##### (

##### 1

##### 3

```
) s
+ ··· +
```
##### (

##### 1

```
k
```
```
) s
+ ···
```
```
is known in mathematical disciplines as the Riemann zeta function (after the German
mathematician G. F. B. Riemann).
The zeta distribution was used by the Italian economist V. Pareto to describe the
distribution of family incomes in a given country. However, it was G. K. Zipf who
applied zeta distribution to a wide variety of problems in different areas and, in doing
so, popularized its use.
```
### 4.9 Expected Value of Sums of Random Variables

```
A very important property of expectations is that the expected value of a sum of
random variables is equal to the sum of their expectations. In this section, we will
prove this result under the assumption that the set of possible values of the proba-
bility experiment—that is, the sample space S —is either finite or countably infinite.
Although the result is true without this assumption (and a proof is outlined in the
theoretical exercises), not only will the assumption simplify the argument, but it will
also result in an enlightening proof that will add to our intuition about expectations.
So, for the remainder of this section, suppose that the sample space S is either a finite
or a countably infinite set.
For a random variable X , let X ( s )denote the value of X when s ∈ S is the outcome
of the experiment. Now, if X and Y are both random variables, then so is their sum.
That is, Z = X + Y is also a random variable. Moreover, Z ( s )= X ( s )+ Y ( s ).
```
```
EXAMPLE 9a
Suppose that the experiment consists of flipping a coin 5 times, with the outcome
being the resulting sequence of heads and tails. Suppose X is the number of heads in
thefirst3flipsand Y is the number of heads in the final 2 flips. Let Z = X + Y .Then,
for instance, for the outcome s =( h , t , h , t , h ),
```
```
X ( s )= 2
Y ( s )= 1
Z ( s )= X ( s )+ Y ( s )= 3
```
```
meaning that the outcome( h , t , h , t , h )results in 2 heads in the first three flips, 1 head
in the final two flips, and a total of 3 heads in the five flips..
```
```
Let p ( s ) = P ({ s })be the probability that s is the outcome of the experiment.
Because we can write any event A as the finite or countably infinite union of the
mutually exclusive events{ s }, s ∈ A , it follows by the axioms of probability that
```
##### P ( A )=

##### ∑

```
s ∈ A
```
```
p ( s )
```
```
When A = S , the preceding equation gives
```
##### 1 =

##### ∑

```
s ∈ S
```
```
p ( s )
```

```
Section 4.9 Expected Value of Sums of Random Variables 165
```
Now, let _X_ be a random variable, and consider _E_ [ _X_ ]. Because _X_ ( _s_ )is the value of _X_
when _s_ is the outcome of the experiment, it seems intuitive that _E_ [ _X_ ]—the weighted
average of the possible values of _X_ , with each value weighted by the probability that
_X_ assumes that value—should equal a weighted average of the values _X_ ( _s_ ), _s_ ∈ _S_ ,
with _X_ ( _s_ )weighted by the probability that _s_ is the outcome of the experiment. We
now prove this intuition.

**Proposition 9.1.**

```
E [ X ]=
```
##### ∑

```
s ∈ S
```
```
X ( s ) p ( s )
```
```
Proof. Suppose that the distinct values of X are xi , i Ú 1 .For each i , let Si be the
event that X is equal to xi. That is, Si ={ s : X ( s )= xi }. Then,
```
```
E [ X ]=
```
##### ∑

```
i
```
```
xiP { X = xi }
```
##### =

##### ∑

```
i
```
```
xiP ( Si )
```
##### =

##### ∑

```
i
```
```
xi
```
##### ∑

```
s ∈ Si
```
```
p ( s )
```
##### =

##### ∑

```
i
```
##### ∑

```
s ∈ Si
```
```
xip ( s )
```
##### =

##### ∑

```
i
```
##### ∑

```
s ∈ Si
```
```
X ( s ) p ( s )
```
##### =

##### ∑

```
s ∈ S
```
```
X ( s ) p ( s )
```
```
where the final equality follows because S 1 , S 2 ,...are mutually exclusive events
whose union is S.
```
**_EXAMPLE 9b_**

Suppose that two independent flips of a coin that comes up heads with probability _p_
are made, and let _X_ denote the number of heads obtained. Because

```
P ( X = 0 )= P ( t , t )=( 1 − p )^2 ,
P ( X = 1 )= P ( h , t )+ P ( t , h )= 2 p ( 1 − p )
P ( X = 2 )= P ( h , h )= p^2
```
it follows from the definition of expected value that

```
E [ X ]= 0 ·( 1 − p )^2 + 1 · 2 p ( 1 − p )+ 2 · p^2 = 2 p
```
which agrees with

```
E [ X ]= X ( h , h ) p^2 + X ( h , t ) p ( 1 − p )+ X ( t , h )( 1 − p ) p + X ( t , t )( 1 − p )^2
= 2 p^2 + p ( 1 − p )+( 1 − p ) p
= 2 p.
```
We now prove the important and useful result that the expected value of a sum of
random variables is equal to the sum of their expectations.


**166** Chapter 4 Random Variables

```
Corollary 9.2. For random variables X 1 , X 2 ,..., Xn ,
```
##### E

##### ⎡

##### ⎣

```
∑ n
```
```
i = 1
```
```
Xi
```
##### ⎤

##### ⎦=

```
∑ n
```
```
i = 1
```
```
E [ Xi ]
```
```
Proof. Let Z =
```
```
∑ n
i = 1 Xi. Then, by Proposition 9.1,
```
```
E [ Z ]=
```
##### ∑

```
s ∈ S
```
```
Z ( s ) p ( s )
```
##### =

##### ∑

```
s ∈ S
```
##### (

```
X 1 ( s )+ X 2 ( s )+...+ Xn ( s )
```
##### )

```
p ( s )
```
##### =

##### ∑

```
s ∈ S
```
```
X 1 ( s ) p ( s )+
```
##### ∑

```
s ∈ S
```
```
X 2 ( s ) p ( s )+...+
```
##### ∑

```
s ∈ S
```
```
Xn ( s ) p ( s )
```
```
= E [ X 1 ]+ E [ X 2 ]+...+ E [ Xn ].
```
```
EXAMPLE 9c
Find the expected value of the sum obtained when n fair dice are rolled.
```
```
Solution. Let X be the sum. We will compute E [ X ] by using the representation
```
##### X =

```
∑ n
```
```
i = 1
```
```
Xi
```
```
where Xi is the upturned value on die i. Because Xi is equally likely to be any of the
values from 1 to 6, it follows that
```
```
E [ Xi ]=
```
##### ∑^6

```
i = 1
```
```
i ( 1 / 6 )= 21 / 6 = 7 / 2
```
```
which yields the result
```
##### E [ X ]= E

##### ⎡

##### ⎣

```
∑ n
```
```
i = 1
```
```
Xi
```
##### ⎤

##### ⎦=

```
∑ n
```
```
i = 1
```
```
E [ Xi ]= 3. 5 n
.
```
```
EXAMPLE 9d
Find the expected total number of successes that result from n trials when trial i is a
success with probability pi , i =1,..., n.
```
```
Solution. Letting
```
```
Xi =
```
##### {

```
1, if trial i is a success
0, if trial i is a failure
```
```
we have the representation
```
##### X =

```
∑ n
```
```
i = 1
```
```
Xi
```

```
Section 4.9 Expected Value of Sums of Random Variables 167
```
Consequently,

```
E [ X ]=
```
```
∑ n
```
```
i = 1
```
```
E [ Xi ]=
```
```
∑ n
```
```
i = 1
```
```
pi
```
Note that this result does not require that the trials be independent. It includes as a
special case the expected value of a binomial random variable, which assumes inde-
pendent trials and all _pi_ = _p_ , and thus has mean _np_. It also gives the expected value
of a hypergeometric random variable representing the number of white balls selected
when _n_ balls are randomly selected, without replacement, from an urn of _N_ balls of
which _m_ are white. We can interpret the hypergeometric as representing the number
of successes in _n_ trials, where trial _i_ is said to be a success if the _i_ th ball selected is
white. Because the _i_ th ball selected is equally likely to be any of the _N_ balls and thus
has probability _m_ / _N_ of being white, it follows that the hypergeometric is the num-
ber of successes in _n_ trials in which each trial is a success with probability _p_ = _m_ / _N_.
Hence, even though these hypergeometric trials are dependent, it follows from the
result of Example 9d that the expected value of the hypergeometric is _np_ = _nm_ / _N_ ..

**_EXAMPLE 9e_**

Derive an expression for the variance of the number of successful trials in Example
9 _d_ , and apply it to obtain the variance of a binomial random variable with parameters
_n_ and _p_ , and of a hypergeometric random variable equal to the number of white balls
chosen when _n_ balls are randomly chosen from an urn containing _N_ balls of which _m_
are white.

**_Solution._** Letting _X_ be the number of successful trials, and using the same represen-
tation for _X_ —namely, _X_ =

```
∑ n
i = 1 Xi —as in the previous example, we have
```
##### E [ X^2 ]= E

##### ⎡

##### ⎢

##### ⎢

##### ⎣

##### ⎛

##### ⎝

```
∑ n
```
```
i = 1
```
```
Xi
```
##### ⎞

##### ⎠

##### ⎛

##### ⎜

##### ⎝

```
∑ n
```
```
j = 1
```
```
Xj
```
##### ⎞

##### ⎟

##### ⎠

##### ⎤

##### ⎥

##### ⎥

##### ⎦

##### = E

##### ⎡

##### ⎢

##### ⎣

```
∑ n
```
```
i = 1
```
```
Xi
```
##### ⎛

```
⎝ Xi +
```
##### ∑

```
j Z i
```
```
Xj
```
##### ⎞

##### ⎠

##### ⎤

##### ⎥

##### ⎦

##### = E

##### ⎡

##### ⎣

```
∑ n
```
```
i = 1
```
```
X^2 i +
```
```
∑ n
```
```
i = 1
```
##### ∑

```
j Z i
```
```
XiXj
```
##### ⎤

##### ⎦

##### =

```
∑ n
```
```
i = 1
```
```
E [ Xi^2 ]+
```
```
∑ n
```
```
i = 1
```
##### ∑

```
j Z i
```
```
E [ XiXj ]
```
##### =

##### ∑

```
i
```
```
pi +
```
```
∑ n
```
```
i = 1
```
##### ∑

```
j Z i
```
```
E [ XiXj ] (9.1)
```
where the final equation used that _Xi_^2 = _Xi_ .However, because the possible values of
both _Xi_ and _Xj_ are 0 or 1, it follows that

```
XiXj =
```
##### {

```
1, if Xi =1, Xj = 1
0, otherwise
```

**168** Chapter 4 Random Variables

```
Hence,
E [ XiXj ]= P { Xi =1, Xj = 1 }= P (trials i and j are successes)
```
```
Now, on the one hand, if X is binomial, then, for i Z j , the results of trial i and trial j
are independent, with each being a success with probability p. Therefore,
```
```
E [ XiXj ]= p^2 , i Z j
```
```
Together with Equation (9.1), the preceding equation shows that, for a binomial ran-
dom variable X ,
E [ X^2 ]= np + n ( n − 1 ) p^2
```
```
implying that
```
```
Var( X )= E [ X^2 ]−( E [ X ])^2 = np + n ( n − 1 ) p^2 − n^2 p^2 = np ( 1 − p )
```
```
On the other hand, if X is hypergeometric, then, given that a white ball is chosen
in trial i , each of the other N −1 balls, of which m −1 are white, is equally likely to
be the j th ball chosen, for j Z i. Consequently, for j Z i ,
```
```
P { Xi =1, Xj = 1 }= P { Xi = 1 } P { Xj = 1 | Xi = 1 }=
```
```
m
N
```
```
m − 1
N − 1
Using pi = m / N , we now obtain, from Equation (9.1),
```
##### E [ X^2 ]=

```
nm
N
```
```
+ n ( n − 1 )
```
```
m
N
```
```
m − 1
N − 1
Consequently,
```
```
Var( X )=
```
```
nm
N
```
```
+ n ( n − 1 )
```
```
m
N
```
```
m − 1
N − 1
```
##### −

##### (

```
nm
N
```
##### ) 2

```
which, as shown in Example 8j, can be simplified to yield
```
```
Var( X )= np ( 1 − p )
```
##### (

##### 1 −

```
n − 1
N − 1
```
##### )

```
where p = m / N..
```
### 4.10 Properties of the Cumulative Distribution Function

```
Recall that, for the distribution function F of X , F ( b )denotes the probability that the
random variable X takes on a value that is less than or equal to b. Following are some
properties of the cumulative distribution function (c.d.f.) F :
```
1. _F_ is a nondecreasing function; that is, if _a_ < _b_ ,then _F_ ( _a_ )... _F_ ( _b_ ).
2. lim
    _b_ →q

```
F ( b )=1.
```
3. lim
    _b_ →−q

```
F ( b )=0.
```
4. _F_ is right continuous. That is, for any _b_ and any decreasing sequence _bn_ , _n_ Ú1,
    that converges to _b_ , lim
       _n_ →q
          _F_ ( _bn_ )= _F_ ( _b_ ).

```
Property 1 follows, as was noted in Section 4.1, because, for a < b , the event
{ X ... a }is contained in the event{ X ... b }and so cannot have a larger probabil-
ity. Properties 2, 3, and 4 all follow from the continuity property of probabilities
```

```
Section 4.10 Properties of the Cumulative Distribution Function 169
```
(Section 2.6). For instance, to prove property 2, we note that if _bn_ increases toq,then
the events{ _X_ ... _bn_ }, _n_ Ú1, are increasing events whose union is the event{ _X_ <q}.
Hence, by the continuity property of probabilities,

```
lim
n →q
P { X ... bn }= P { X <q}= 1
```
which proves property 2.
The proof of property 3 is similar and is left as an exercise. To prove property 4,
we note that if _bn_ decreases to _b_ ,then{ _X_ ... _bn_ }, _n_ Ú1, are decreasing events whose
intersection is{ _X_ ... _b_ }. The continuity property then, yields

```
lim
n
```
```
P { X ... bn }= P { X ... b }
```
which verifies property 4.
All probability questions about _X_ can be answered in terms of the c.d.f., _F_ .For
example,
_P_ { _a_ < _X_ ... _b_ }= _F_ ( _b_ )− _F_ ( _a_ ) for all _a_ < _b_ (8.1)

This equation can best be seen to hold if we write the event{ _X_ ... _b_ }as the union of
the mutually exclusive events{ _X_ ... _a_ }and{ _a_ < _X_ ... _b_ }. That is,

```
{ X ... b }={ X ... a }∪{ a < X ... b }
```
so
_P_ { _X_ ... _b_ }= _P_ { _X_ ... _a_ }+ _P_ { _a_ < _X_ ... _b_ }

which establishes Equation (9.1).
If we want to compute the probability that _X_ is strictly less than _b_ , we can again
apply the continuity property to obtain

```
P { X < b }= P
```
##### (

```
lim
n →q
```
##### {

```
X ... b −
```
##### 1

```
n
```
##### })

```
= lim
n →q
```
##### P

##### (

```
X ... b −
```
##### 1

```
n
```
##### )

```
= lim
n →q
```
##### F

##### (

```
b −
```
##### 1

```
n
```
##### )

Note that _P_ { _X_ < _b_ }does not necessarily equal _F_ ( _b_ ), since _F_ ( _b_ )also includes the
probability that _X_ equals _b_.

**_EXAMPLE 10a_**

The distribution function of the random variable _X_ is given by

```
F ( x )=
```
##### ⎧

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎨

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎩

```
0 x < 0
x
2
```
```
0 ... x < 1
```
```
2
3
```
```
1 ... x < 2
```
```
11
12
```
```
2 ... x < 3
```
```
13 ... x
```

**170** Chapter 4 Random Variables

(^1) –
2
(^2) –
3
1
(^11) —
12
123
_x
F_ ( _x_ )
**FIGURE 4.8:** Graph of _F_ ( _x_ ).
A graph of _F_ ( _x_ )is presented in Figure 4.8. Compute (a) _P_ { _X_ < 3 },(b) _P_ { _X_ = 1 }, (c)
_P_ { _X_ >^12 },and(d) _P_ { 2 < _X_ ... 4 }.
**_Solution._** (a) _P_ { _X_ < 3 }=lim
_n_

##### P

##### {

##### X ... 3 −

##### 1

```
n
```
##### }

```
=lim
n
```
##### F

##### (

##### 3 −

##### 1

```
n
```
##### )

##### =

##### 11

##### 12

```
(b)
```
```
P { X = 1 }= P { X ... 1 }− P { X < 1 }
```
```
= F ( 1 )−lim
n
```
##### F

##### (

##### 1 −

##### 1

```
n
```
##### )

##### =

##### 2

##### 3

##### −

##### 1

##### 2

##### =

##### 1

##### 6

```
(c)
```
##### P

##### {

##### X >

##### 1

##### 2

##### }

##### = 1 − P

##### {

##### X ...

##### 1

##### 2

##### }

##### = 1 − F

##### (

##### 1

##### 2

##### )

##### =

##### 3

##### 4

```
(d)
```
```
P { 2 < X ... 4 }= F ( 4 )− F ( 2 )
```
```
=
```
##### 1

##### 12.

#### Summary

```
A real-valued function defined on the outcome of a probability experiment is called
a random variable.
If X is a random variable, then the function F ( x )defined by
```
```
F ( x )= P { X ... x }
```
```
is called the distribution function of X. All probabilities concerning X can be stated
in terms of F.
```

```
Summary 171
```
A random variable whose set of possible values is either finite or countably infinite
is called _discrete_ .If _X_ is a discrete random variable, then the function

```
p ( x )= P { X = x }
```
is called the _probability mass function_ of _X_. Also, the quantity _E_ [ _X_ ] defined by

```
E [ X ]=
```
##### ∑

```
x : p ( x )> 0
```
```
xp ( x )
```
is called the _expected value_ of _X_. _E_ [ _X_ ] is also commonly called the _mean_ or the _expec-
tation_ of _X_.
A useful identity states that, for a function _g_ ,

```
E [ g ( X )]=
```
##### ∑

```
x : p ( x )> 0
```
```
g ( x ) p ( x )
```
The _variance_ of a random variable _X_ , denoted by Var( _X_ ), is defined by

```
Var( X )= E [( X − E [ X ])^2 ]
```
The variance, which is equal to the expected square of the difference between _X_
and its expected value, is a measure of the spread of the possible values of _X_. A useful
identity is
Var( _X_ )= _E_ [ _X_^2 ]−( _E_ [ _X_ ])^2

The quantity

##### √

Var( _X_ )is called the _standard deviation_ of _X_.
We now note some common types of discrete random variables. The random vari-
able _X_ whose probability mass function is given by

```
p ( i )=
```
##### (

```
n
i
```
##### )

```
pi ( 1 − p ) n − i i =0,..., n
```
is said to be a binomial random variable with parameters _n_ and _p_. Such a random
variable can be interpreted as being the number of successes that occur when _n_ inde-
pendent trials, each of which results in a success with probability _p_ , are performed.
Its mean and variance are given by

```
E [ X ]= np Var( X )= np ( 1 − p )
```
The random variable _X_ whose probability mass function is given by

```
p ( i )=
```
```
e −λλ i
i!
```
```
i Ú 0
```
is said to be a _Poisson_ random variable with parameterλ. If a large number of (approx-
imately) independent trials are performed, each having a small probability of being
successful, then the number of successful trials that result will have a distribution
which is approximately that of a Poisson random variable. The mean and variance of
a Poisson random variable are both equal to its parameterλ. That is,

```
E [ X ]=Var( X )=λ
```
The random variable _X_ whose probability mass function is given by

```
p ( i )= p ( 1 − p ) i −^1 i =1, 2,...
```

**172** Chapter 4 Random Variables

```
is said to be a geometric random variable with parameter p. Such a random variable
represents the trial number of the first success when each trial is independently a
success with probability p. Its mean and variance are given by
```
##### E [ X ]=

##### 1

```
p
```
```
Var( X )=
```
```
1 − p
p^2
```
```
The random variable X whose probability mass function is given by
```
```
p ( i )=
```
##### (

```
i − 1
r − 1
```
##### )

```
pr ( 1 − p ) i − r i Ú r
```
```
is said to be a negative binomial random variable with parameters r and p. Such a
random variable represents the trial number of the r th success when each trial is
independently a success with probability p. Its mean and variance are given by
```
##### E [ X ]=

```
r
p
```
```
Var( X )=
```
```
r ( 1 − p )
p^2
```
```
A hypergeometric random variable X with parameters n , N ,and m represents the
number of white balls selected when n balls are randomly chosen from an urn that
contains N balls of which m are white. The probability mass function of this random
variable is given by
```
```
p ( i )=
```
##### (

```
m
i
```
##### )(

```
N − m
n − i
```
##### )

##### (

##### N

```
n
```
```
) i =0,..., m
```
```
With p = m / N , its mean and variance are
```
```
E [ X ]= np Var( X )=
```
```
N − n
N − 1
```
```
np ( 1 − p )
```
```
An important property of the expected value is that the expected value of a sum of
random variables is equal to the sum of their expected values. That is,
```
##### E

##### ⎡

##### ⎣

```
∑ n
```
```
i = 1
```
```
Xi
```
##### ⎤

##### ⎦=

```
∑ n
```
```
i = 1
```
```
E [ Xi ]
```
#### Problems...................................

```
4.1. Two balls are chosen randomly from an urn con-
taining 8 white, 4 black, and 2 orange balls. Sup-
pose that we win $2 for each black ball selected
and we lose $1 for each white ball selected. Let
X denote our winnings. What are the possible val-
ues of X , and what are the probabilities associated
with each value?
4.2. Two fair dice are rolled. Let X equal the
product of the 2 dice. Compute P { X = i }for
i =1,..., 36.
```
```
4.3. Three dice are rolled. By assuming that each of
the 6^3 =216 possible outcomes is equally likely,
find the probabilities attached to the possible val-
ues that X can take on, where X is the sum of
the 3 dice.
4.4. Five men and 5 women are ranked according to
their scores on an examination. Assume that no
two scores are alike and all 10! possible rankings
are equally likely. Let X denote the highest rank-
ing achieved by a woman. (For instance, X = 1
```

```
Problems 173
```
if the top-ranked person is female.) Find P{X=i},
_i_ =1, 2, 3,...,8,9,10.
**4.5.** Let _X_ represent the difference between the num-
ber of heads and the number of tails obtained
when a coin is tossed _n_ times. What are the pos-
sible values of _X_?
**4.6.** In Problem 5, for _n_ =3, if the coin is assumed fair,
what are the probabilities associated with the val-
ues that _X_ can take on?
**4.7.** Suppose that a die is rolled twice. What are the
possible values that the following random vari-
ables can take on:
**(a)** the maximum value to appear in the two rolls;
**(b)** the minimum value to appear in the two rolls;
**(c)** the sum of the two rolls;
**(d)** the value of the first roll minus the value of
the second roll?
**4.8.** If the die in Problem 7 is assumed fair, calculate
the probabilities associated with the random vari-
ables in parts (a) through (d).
**4.9.** Repeat Example 1b when the balls are selected
with replacement.
**4.10.** In Example 1d, compute the conditional probabil-
ity that we win _i_ dollars, given that we win some-
thing; compute it for _i_ =1, 2, 3.
**4.11. (a)** An integer _N_ is to be selected at random from
{1, 2,...,( 10 )^3 }in the sense that each integer
has the same probability of being selected.
What is the probability that _N_ will be divis-
ible by 3? by 5? by 7? by 15? by 105? How
would your answer change if( 10 )^3 is replaced
by( 10 ) _k_ as _k_ became larger and larger?
**(b)** An important function in number theory—
one whose properties can be shown to be
related to what is probably the most impor-
tant unsolved problem of mathematics, the
Riemann hypothesis—is the Mobius function ̈
μ( _n_ ), defined for all positive integral values _n_
as follows: Factor _n_ into its prime factors. If
there is a repeated prime factor, as in 12 =
2 · 2 ·3or49= 7 ·7, thenμ( _n_ )is defined
to equal 0. Now let _N_ be chosen at random
from{1, 2,...( 10 ) _k_ },where _k_ is large. Deter-
mine _P_ {μ( _N_ )= 0 }as _k_ →q.
_Hint_ : To compute _P_ {μ( _N_ )Z 0 }, use the identity

```
∏q
```
```
i = 1
```
```
P^2 i − 1
P^2 i
```
```
=
```
```
(
3
4
```
```
)(
8
9
```
```
)(
24
25
```
```
)(
48
49
```
```
)
···=
```
```
6
π^2
```
where _Pi_ is the _i_ th-smallest prime. (The number 1
is not a prime.)
**4.12.** In the game of Two-Finger Morra, 2 players show
1 or 2 fingers and simultaneously guess the number
of fingers their opponent will show. If only one of
the players guesses correctly, he wins an amount

```
(in dollars) equal to the sum of the fingers shown
by him and his opponent. If both players guess
correctly or if neither guesses correctly, then no
money is exchanged. Consider a specified player,
and denote by X the amount of money he wins in
a single game of Two-Finger Morra.
(a) If each player acts independently of the other,
and if each player makes his choice of the
number of fingers he will hold up and the
number he will guess that his opponent will
hold up in such a way that each of the 4 pos-
sibilities is equally likely, what are the possi-
ble values of X and what are their associated
probabilities?
(b) Suppose that each player acts independently
of the other. If each player decides to hold up
the same number of fingers that he guesses his
opponent will hold up, and if each player is
equally likely to hold up 1 or 2 fingers, what
are the possible values of X and their associ-
ated probabilities?
4.13. A salesman has scheduled two appointments to
sell encyclopedias. His first appointment will lead
to a sale with probability .3, and his second will
lead independently to a sale with probability .6.
Any sale made is equally likely to be either for the
deluxe model, which costs $1000, or the standard
model, which costs $500. Determine the probabil-
ity mass function of X , the total dollar value of all
sales.
4.14. Five distinct numbers are randomly distributed
to players numbered 1 through 5. Whenever two
players compare their numbers, the one with the
higher one is declared the winner. Initially, players
1 and 2 compare their numbers; the winner then
compares her number with that of player 3, and so
on. Let X denote the number of times player 1 is a
winner. Find P { X = i }, i =0, 1, 2, 3, 4.
4.15. The National Basketball Association (NBA) draft
lottery involves the 11 teams that had the worst
won–lost records during the year. A total of 66
balls are placed in an urn. Each of these balls is
inscribed with the name of a team: Eleven have
the name of the team with the worst record, 10
have the name of the team with the second-worst
record, 9 have the name of the team with the third-
worst record, and so on (with 1 ball having the
name of the team with the 11th-worst record).
A ball is then chosen at random, and the team
whose name is on the ball is given the first pick
in the draft of players about to enter the league.
Another ball is then chosen, and if it “belongs”
to a team different from the one that received the
first draft pick, then the team to which it belongs
receives the second draft pick. (If the ball belongs
```

**174** Chapter 4 Random Variables

```
to the team receiving the first pick, then it is dis-
carded and another one is chosen; this continues
until the ball of another team is chosen.) Finally,
another ball is chosen, and the team named on
the ball (provided that it is different from the
previous two teams) receives the third draft pick.
The remaining draft picks 4 through 11 are then
awarded to the 8 teams that did not “win the lot-
tery,” in inverse order of their won–lost records.
For instance, if the team with the worst record did
not receive any of the 3 lottery picks, then that
team would receive the fourth draft pick. Let X
denote the draft pick of the team with the worst
record. Find the probability mass function of X.
4.16. In Problem 15, let team number 1 be the team
with the worst record, let team number 2 be the
team with the second-worst record, and so on. Let
Yi denote the team that gets draft pick number i.
(Thus, Y 1 =3 if the first ball chosen belongs to
team number 3.) Find the probability mass func-
tion of (a) Y 1 ,(b) Y 2 ,and(c) Y 3.
4.17. Suppose that the distribution function of X is
given by
```
```
F ( b )=
```
```
⎧
⎪⎪⎪
⎪⎪
⎪⎪⎪
⎪⎪
⎪⎪
⎪⎨
```
```
⎪⎪
⎪⎪
⎪⎪⎪
⎪⎪
⎪⎪
⎪⎪⎩
```
```
0 b < 0
b
4
0 ... b < 1
```
```
1
2
```
```
+
```
```
b − 1
4
```
```
1 ... b < 2
```
```
11
12
```
```
2 ... b < 3
```
```
13 ... b
```
```
(a) Find P { X = i }, i =1, 2, 3.
(b) Find P {^12 < X <^32 }.
4.18. Four independent flips of a fair coin are made. Let
X denote the number of heads obtained. Plot the
probability mass function of the random variable
X −2.
4.19. If the distribution function of X is given by
```
```
F ( b )=
```
```
⎧
⎪⎪
⎪⎪⎪
⎪⎪
⎪⎪
⎪⎪⎪
⎪⎪
⎪⎪
⎪⎨
```
```
⎪⎪
⎪⎪
⎪⎪⎪
⎪⎪
⎪⎪
⎪⎪⎪
⎪⎪
⎪⎩
```
```
0 b < 0
1
2
```
```
0 ... b < 1
```
```
3
5
```
```
1 ... b < 2
```
```
4
5
```
```
2 ... b < 3
```
```
9
10
```
```
3 ... b < 3. 5
```
```
1 b Ú 3. 5
```
```
calculate the probability mass function of X.
```
```
4.20. A gambling book recommends the following “win-
ning strategy” for the game of roulette: Bet $1 on
red. If red appears
```
```
(
which has probability^1838
```
```
)
,then
take the $1 profit and quit. If red does not appear
and you lose this bet
```
```
(
which has probability^2038 of
occurring
```
```
)
, make additional $1 bets on red on each
of the next two spins of the roulette wheel and then
quit. Let X denote your winnings when you quit.
(a) Find P { X > 0 }.
(b) Are you convinced that the strategy is indeed
a “winning” strategy? Explain your answer!
(c) Find E [ X ].
4.21. Four buses carrying 148 students from the same
school arrive at a football stadium. The buses
carry, respectively, 40, 33, 25, and 50 students. One
of the students is randomly selected. Let X denote
the number of students that were on the bus car-
rying the randomly selected student. One of the 4
bus drivers is also randomly selected. Let Y denote
the number of students on her bus.
(a) Which of E [ X ]or E [ Y ] do you think is larger?
Why?
(b) Compute E [ X ]and E [ Y ].
4.22. Suppose that two teams play a series of games that
ends when one of them has won i games. Suppose
that each game played is, independently, won by
team A with probability p. Find the expected num-
ber of games that are played when (a) i =2and(b)
i =3. Also, show in both cases that this number is
maximized when p =^12.
4.23. You have $1000, and a certain commodity
presently sells for $2 per ounce. Suppose that after
one week the commodity will sell for either $1
or $4 an ounce, with these two possibilities being
equally likely.
(a) If your objective is to maximize the expected
amount of money that you possess at the
end of the week, what strategy should you
employ?
(b) If your objective is to maximize the expected
amount of the commodity that you possess at
the end of the week, what strategy should you
employ?
4.24. A and B play the following game: A writes down
either number 1 or number 2, and B must guess
which one. If the number that A has written down
is i and B has guessed correctly, B receives i units
from A .If B makes a wrong guess, B pays^34 unit to
A .If B randomizes his decision by guessing 1 with
probability p and 2 with probability 1− p , deter-
mine his expected gain if (a) A has written down
number 1 and (b) A has written down number 2.
What value of p maximizes the minimum pos-
sible value of B ’s expected gain, and what is
this maximin value? (Note that B ’s expected
```

```
Problems 175
```
gain depends not only on _p_ , but also on what
_A_ does.)
Consider now player _A_. Suppose that she also
randomizes her decision, writing down number 1
with probability _q_. What is _A_ ’s expected loss if (c)
_B_ chooses number 1 and (d) _B_ chooses number 2?
What value of _q_ minimizes _A_ ’s maximum
expected loss? Show that the minimum of _A_ ’s max-
imum expected loss is equal to the maximum of _B_ ’s
minimum expected gain. This result, known as the
minimax theorem, was first established in general-
ity by the mathematician John von Neumann and
is the fundamental result in the mathematical disci-
pline known as the theory of games. The common
value is called the value of the game to player _B_.
**4.25.** Two coins are to be flipped. The first coin will land
on heads with probability .6, the second with prob-
ability .7. Assume that the results of the flips are
independent, and let _X_ equal the total number of
heads that result.
**(a)** Find _P_ { _X_ = 1 }.
**(b)** Determine _E_ [ _X_ ].
**4.26.** One of the numbers 1 through 10 is randomly cho-
sen. You are to try to guess the number chosen by
asking questions with “yes–no” answers. Compute
the expected number of questions you will need to
ask in each of the following two cases:
**(a)** Your _i_ thquestionistobe“Isit _i_ ?” _i_ =
1, 2, 3, 4, 5, 6, 7, 8, 9, 10.
**(b)** With each question you try to eliminate one-
half of the remaining numbers, as nearly as
possible.
**4.27.** An insurance company writes a policy to the effect
that an amount of money _A_ must be paid if some
event _E_ occurs within a year. If the company esti-
mates that _E_ will occur within a year with probabil-
ity _p_ , what should it charge the customer in order
that its expected profit will be 10 percent of _A_?
**4.28.** A sample of 3 items is selected at random from a
box containing 20 items of which 4 are defective.
Find the expected number of defective items in the
sample.
**4.29.** There are two possible causes for a breakdown of
a machine. To check the first possibility would cost
_C_ 1 dollars, and, if that were the cause of the break-
down, the trouble could be repaired at a cost of _R_ 1
dollars. Similarly, there are costs _C_ 2 and _R_ 2 asso-
ciated with the second possibility. Let _p_ and 1 −
_p_ denote, respectively, the probabilities that the
breakdown is caused by the first and second possi-
bilities. Under what conditions on _p_ , _Ci_ , _Ri_ , _i_ =1, 2,
should we check the first possible cause of break-
down and then the second, as opposed to reversing
the checking order, so as to minimize the expected
cost involved in returning the machine to working
order?

```
Note : If the first check is negative, we must still
check the other possibility.
4.30. A person tosses a fair coin until a tail appears for
the first time. If the tail appears on the n th flip, the
person wins 2 n dollars. Let X denote the player’s
winnings. Show that E [ X ]=+q. This problem is
known as the St. Petersburg paradox.
(a) Would you be willing to pay $1 million to play
this game once?
(b) Would you be willing to pay $1 million for
each game if you could play for as long as
you liked and only had to settle up when you
stopped playing?
4.31. Each night different meteorologists give us the
probability that it will rain the next day. To judge
how well these people predict, we will score each
of them as follows: If a meteorologist says that it
will rain with probability p , then he or she will
receive a score of
1 −( 1 − p )^2 if it does rain
1 − p^2 if it does not rain
```
```
We will then keep track of scores over a cer-
tain time span and conclude that the meteorologist
with the highest average score is the best predictor
of weather. Suppose now that a given meteorolo-
gist is aware of our scoring mechanism and wants
to maximize his or her expected score. If this per-
son truly believes that it will rain tomorrow with
probability p ∗, what value of p should he or she
assert so as to maximize the expected score?
4.32. To determine whether they have a certain dis-
ease, 100 people are to have their blood tested.
However, rather than testing each individual sepa-
rately, it has been decided first to place the peo-
ple into groups of 10. The blood samples of the
10 people in each group will be pooled and ana-
lyzed together. If the test is negative, one test will
suffice for the 10 people, whereas if the test is posi-
tive, each of the 10 people will also be individually
tested and, in all, 11 tests will be made on this
group. Assume that the probability that a person
has the disease is .1 for all people, independently
of each other, and compute the expected number
of tests necessary for each group. (Note that we are
assuming that the pooled test will be positive if at
least one person in the pool has the disease.)
4.33. A newsboy purchases papers at 10 cents and sells
them at 15 cents. However, he is not allowed to
return unsold papers. If his daily demand is a bino-
mial random variable with n =10, p =^13 , approxi-
mately how many papers should he purchase so as
to maximize his expected profit?
4.34. In Example 4b, suppose that the department store
incurs an additional cost of c for each unit of unmet
```

**176** Chapter 4 Random Variables

```
demand. (This type of cost is often referred to as
a goodwill cost because the store loses the good-
will of those customers whose demands it can-
not meet.) Compute the expected profit when the
store stocks s units, and determine the value of s
that maximizes the expected profit.
4.35. A box contains 5 red and 5 blue marbles. Two mar-
bles are withdrawn randomly. If they are the same
color, then you win $1.10; if they are different col-
ors, then you win−$1.00. (That is, you lose $1.00.)
Calculate
(a) the expected value of the amount you win;
(b) the variance of the amount you win.
4.36. Consider Problem 22 with i =2. Find the variance
of the number of games played, and show that this
number is maximized when p =^12.
4.37. Find Var( X )and Var( Y )for X and Y as given in
Problem 21.
4.38. If E [ X ]=1andVar( X )=5, find
(a) E [( 2 + X )^2 ];
(b) Var( 4 + 3 X ).
4.39. A ball is drawn from an urn containing 3 white and
3 black balls. After the ball is drawn, it is replaced
and another ball is drawn. This process goes on
indefinitely. What is the probability that, of the
first 4 balls drawn, exactly 2 are white?
4.40. On a multiple-choice exam with 3 possible answers
for each of the 5 questions, what is the probability
that a student will get 4 or more correct answers
just by guessing?
4.41. A man claims to have extrasensory perception. As
a test, a fair coin is flipped 10 times and the man is
asked to predict the outcome in advance. He gets
7 out of 10 correct. What is the probability that
he would have done at least this well if he had no
ESP?
4.42. Suppose that, in flight, airplane engines will fail
with probability 1− p , independently from engine
to engine. If an airplane needs a majority of its
engines operative to complete a successful flight,
for what values of p is a 5-engine plane preferable
to a 3-engine plane?
4.43. A communications channel transmits the digits 0
and 1. However, due to static, the digit transmitted
is incorrectly received with probability .2. Suppose
that we want to transmit an important message
consisting of one binary digit. To reduce the
chance of error, we transmit 00000 instead of 0 and
11111 instead of 1. If the receiver of the message
uses “majority” decoding, what is the probability
that the message will be wrong when decoded?
What independence assumptions are you making?
4.44. A satellite system consists of n components and
functions on any given day if at least k of the n
components function on that day. On a rainy day
```
```
each of the components independently functions
with probability p 1 , whereas on a dry day they each
independently function with probability p 2 .Ifthe
probability of rain tomorrow isα, what is the prob-
ability that the satellite system will function?
4.45. A student is getting ready to take an important
oral examination and is concerned about the pos-
sibility of having an “on” day or an “off” day. He
figures that if he has an on day, then each of his
examiners will pass him, independently of each
other, with probability .8, whereas if he has an off
day, this probability will be reduced to .4. Sup-
pose that the student will pass the examination if a
majority of the examiners pass him. If the student
feels that he is twice as likely to have an off day as
he is to have an on day, should he request an exam-
ination with 3 examiners or with 5 examiners?
4.46. Suppose that it takes at least 9 votes from a 12-
member jury to convict a defendant. Suppose also
that the probability that a juror votes a guilty per-
son innocent is .2, whereas the probability that the
juror votes an innocent person guilty is .1. If each
juror acts independently and if 65 percent of the
defendants are guilty, find the probability that the
jury renders a correct decision. What percentage
of defendants is convicted?
4.47. In some military courts, 9 judges are appointed.
However, both the prosecution and the defense
attorneys are entitled to a peremptory challenge
of any judge, in which case that judge is removed
from the case and is not replaced. A defendant is
declared guilty if the majority of judges cast votes
of guilty, and he or she is declared innocent other-
wise. Suppose that when the defendant is, in fact,
guilty, each judge will (independently) vote guilty
with probability .7, whereas when the defendant is,
in fact, innocent, this probability drops to .3.
(a) What is the probability that a guilty defendant
is declared guilty when there are (i) 9, (ii) 8,
and (iii) 7 judges?
(b) Repeat part (a) for an innocent defendant.
(c) If the prosecution attorney does not exercise
the right to a peremptory challenge of a judge,
and if the defense is limited to at most two
such challenges, how many challenges should
the defense attorney make if he or she is 60
percent certain that the client is guilty?
4.48. It is known that diskettes produced by a cer-
tain company will be defective with probability
.01, independently of each other. The company
sells the diskettes in packages of size 10 and
offers a money-back guarantee that at most 1 of
the 10 diskettes in the package will be defective.
The guarantee is that the customer can return the
entire package of diskettes if he or she finds more
```

```
Problems 177
```
```
than one defective diskette in it. If someone buys
3 packages, what is the probability that he or she
will return exactly 1 of them?
```
**4.49.** When coin 1 is flipped, it lands on heads with prob-
ability.4; when coin 2 is flipped, it lands on heads
with probability.7. One of these coins is randomly
chosen and flipped 10 times.
**(a)** What is the probability that the coin lands on
heads on exactly 7 of the 10 flips?
**(b)** Given that the first of these ten flips lands
heads, what is the conditional probability that
exactly 7 of the 10 flips land on heads?

**4.50.** Suppose that a biased coin that lands on heads with
probability _p_ is flipped 10 times. Given that a total
of 6 heads results, find the conditional probability
that the first 3 outcomes are
**(a)** _h_ , _t_ , _t_ (meaning that the first flip results in
heads, the second in tails, and the third in
tails);
**(b)** _t_ , _h_ , _t_.

**4.51.** The expected number of typographical errors on a
page of a certain magazine is .2. What is the prob-
ability that the next page you read contains (a) 0
and (b) 2 or more typographical errors? Explain
your reasoning!

**4.52.** The monthly worldwide average number of air-
plane crashes of commercial airlines is 3.5. What
is the probability that there will be
**(a)** at least 2 such accidents in the next month;
**(b)** at most 1 accident in the next month?
Explain your reasoning!

**4.53.** Approximately 80,000 marriages took place in the
state of New York last year. Estimate the proba-
bility that, for at least one of these couples,
**(a)** both partners were born on April 30;
**(b)** both partners celebrated their birthday on the
same day of the year.
State your assumptions.

**4.54.** Suppose that the average number of cars aban-
doned weekly on a certain highway is 2.2. Approx-
imate the probability that there will be
**(a)** no abandoned cars in the next week;
**(b)** at least 2 abandoned cars in the next week.

**4.55.** A certain typing agency employs 2 typists. The
average number of errors per article is 3 when
typed by the first typist and 4.2 when typed by the
second. If your article is equally likely to be typed
by either typist, approximate the probability that it
will have no errors.

**4.56.** How many people are needed so that the probabil-
ity that at least one of them has the same birthday
as you is greater than^12?

```
4.57. Suppose that the number of accidents occurring on
a highway each day is a Poisson random variable
with parameterλ=3.
(a) Find the probability that 3 or more accidents
occur today.
(b) Repeat part (a) under the assumption that at
least 1 accident occurs today.
4.58. Compare the Poisson approximation with the cor-
rect binomial probability for the following cases:
(a) P { X = 2 }when n =8, p =.1;
(b) P { X = 9 }when n =10, p =.95;
(c) P { X = 0 }when n =10, p =.1;
(d) P { X = 4 }when n =9, p =.2.
4.59. If you buy a lottery ticket in 50 lotteries, in each of
which your chance of winning a prize is 1001 ,what
is the (approximate) probability that you will win
aprize
(a) at least once?
(b) exactly once?
(c) at least twice?
4.60. The number of times that a person contracts a cold
in a given year is a Poisson random variable with
parameterλ=5. Suppose that a new wonder drug
(based on large quantities of vitamin C) has just
been marketed that reduces the Poisson parame-
ter toλ=3 for 75 percent of the population. For
the other 25 percent of the population, the drug
has no appreciable effect on colds. If an individ-
ual tries the drug for a year and has 2 colds in that
time, how likely is it that the drug is beneficial for
him or her?
4.61. The probability of being dealt a full house in a
hand of poker is approximately .0014. Find an
approximation for the probability that, in 1000
hands of poker, you will be dealt at least 2 full
houses.
4.62. Consider n independent trials, each of which
results in one of the outcomes 1,..., k with respec-
tive probabilities p 1 ,..., pk ,
```
```
∑ k
i = 1 pi =^1 .Show
that if all the pi are small, then the probability that
no trial outcome occurs more than once is approx-
imately equal to exp(− n ( n − 1 )
```
```
∑
ip
```
```
2
i /^2 ).
4.63. People enter a gambling casino at a rate of 1 every
2 minutes.
(a) What is the probability that no one enters
between 12:00 and 12:05?
(b) What is the probability that at least 4 people
enter the casino during that time?
4.64. The suicide rate in a certain state is 1 suicide per
100,000 inhabitants per month.
(a) Find the probability that, in a city of 400,000
inhabitants within this state, there will be 8 or
more suicides in a given month.
```

**178** Chapter 4 Random Variables

```
(b) What is the probability that there will be at
least 2 months during the year that will have 8
or more suicides?
(c) Counting the present month as month num-
ber 1, what is the probability that the first
month to have 8 or more suicides will be
month number i , i Ú1?
What assumptions are you making?
4.65. Each of 500 soldiers in an army company indepen-
dently has a certain disease with probability 1/ 103.
This disease will show up in a blood test, and to
facilitate matters, blood samples from all 500 sol-
diers are pooled and tested.
(a) What is the (approximate) probability that
the blood test will be positive (that is, at least
one person has the disease)?
Suppose now that the blood test yields a positive
result.
(b) What is the probability, under this circum-
stance, that more than one person has the dis-
ease?
One of the 500 people is Jones, who knows that he
has the disease.
(c) What does Jones think is the probability that
more than one person has the disease?
Because the pooled test was positive, the author-
ities have decided to test each individual sepa-
rately. The first i −1 of these tests were negative,
and the i th one—which was on Jones—was posi-
tive.
(d) Given the preceding, scenario, what is the
probability, as a function of i , that any of the
remaining people have the disease?
4.66. A total of 2 n people, consisting of n married cou-
ples, are randomly seated (all possible orderings
being equally likely) at a round table. Let Ci
denote the event that the members of couple i are
seated next to each other, i =1,..., n.
(a) Find P ( Ci ).
(b) For j Z i , find P ( Cj | Ci ).
(c) Approximate the probability, for n large, that
there are no married couples who are seated
next to each other.
4.67. Repeat the preceding problem when the seating is
random but subject to the constraint that the men
and women alternate.
4.68. In response to an attack of 10 missiles, 500 antibal-
listic missiles are launched. The missile targets of
the antiballistic missiles are independent, and each
antiballstic missile is equally likely to go towards
any of the target missiles. If each antiballistic mis-
sile independently hits its target with probability
.1, use the Poisson paradigm to approximate the
probability that all missiles are hit.
```
```
4.69. A fair coin is flipped 10 times. Find the probability
that there is a string of 4 consecutive heads by
(a) using the formula derived in the text;
(b) using the recursive equations derived in the
text.
(c) Compare your answer with that given by the
Poisson approximation.
4.70. At time 0, a coin that comes up heads with prob-
ability p is flipped and falls to the ground. Sup-
pose it lands on heads. At times chosen accord-
ing to a Poisson process with rateλ, the coin is
picked up and flipped. (Between these times the
coin remains on the ground.) What is the proba-
bility that the coin is on its head side at time t?
Hint What would be the conditional probability
if there were no additional flips by time t, and
what would it be if there were additional flips by
time t?
4.71. Consider a roulette wheel consisting of 38 num-
bers 1 through 36, 0, and double 0. If Smith always
bets that the outcome will be one of the numbers 1
through 12, what is the probability that
(a) Smith will lose his first 5 bets;
(b) his first win will occur on his fourth bet?
4.72. Two athletic teams play a series of games; the first
team to win 4 games is declared the overall win-
ner. Suppose that one of the teams is stronger than
the other and wins each game with probability .6,
independently of the outcomes of the other games.
Find the probability, for i =4, 5, 6, 7, that the
stronger team wins the series in exactly i games.
Compare the probability that the stronger team
wins with the probability that it would win a 2-out-
of-3 series.
4.73. Suppose in Problem 72 that the two teams are
evenly matched and each has probability^12 of win-
ning each game. Find the expected number of
games played.
4.74. An interviewer is given a list of people she can
interview. If the interviewer needs to interview 5
people, and if each person (independently) agrees
to be interviewed with probability^23 , what is the
probability that her list of people will enable her
to obtain her necessary number of interviews if
the list consists of (a) 5 people and (b) 8 people?
For part (b), what is the probability that the inter-
viewer will speak to exactly (c) 6 people and (d) 7
people on the list?
4.75. A fair coin is continually flipped until heads
appears for the 10th time. Let X denote the num-
ber of tails that occur. Compute the probability
mass function of X.
4.76. Solve the Banach match problem (Example 8e)
when the left-hand matchbox originally contained
```

```
Theoretical Exercises 179
```
_N_ 1 matches and the right-hand box contained _N_ 2
matches.
**4.77.** In the Banach matchbox problem, find the prob-
ability that, at the moment when the first box is
emptied (as opposed to being found empty), the
other box contains exactly _k_ matches.
**4.78.** An urn contains 4 white and 4 black balls. We ran-
domly choose 4 balls. If 2 of them are white and
2 are black, we stop. If not, we replace the balls
in the urn and again randomly select 4 balls. This
continues until exactly 2 of the 4 chosen are white.
What is the probability that we shall make exactly
_n_ selections?
**4.79.** Suppose that a batch of 100 items contains 6 that
are defective and 94 that are not defective. If _X_
is the number of defective items in a randomly
drawn sample of 10 items from the batch, find (a)
_P_ { _X_ = 0 }and (b) _P_ { _X_ > 2 }.
**4.80.** A game popular in Nevada gambling casinos is
Keno, which is played as follows: Twenty num-
bers are selected at random by the casino from the
set of numbers 1 through 80. A player can select
from 1 to 15 numbers; a win occurs if some frac-
tion of the player’s chosen subset matches any of
the 20 numbers drawn by the house. The payoff is a
function of the number of elements in the player’s
selection and the number of matches. For instance,
if the player selects only 1 number, then he or she
wins if this number is among the set of 20, and
the payoff is $2.2 won for every dollar bet. (As
the player’s probability of winning in this case is
1
4 , it is clear that the “fair” payoff should be $3
won for every $1 bet.) When the player selects 2
numbers, a payoff (of odds) of $12 won for every
$1 bet is made when both numbers are among
the 20,
**(a)** What would be the fair payoff in this case?
Let _Pn_ , _k_ denote the probability that exactly
_k_ of the _n_ numbers chosen by the player are
among the 20 selected by the house.
**(b)** Compute _Pn_ , _k_
**(c)** The most typical wager at Keno consists of
selecting 10 numbers. For such a bet the
casino pays off as shown in the following
table. Compute the expected payoff:

```
Keno Payoffs in 10 Number Bets
```
```
Number of matches Dollars won for each $1 bet
```
```
0–4 -1
51
617
7 179
8 1, 299
9 2, 599
10 24, 999
```
```
4.81. In Example 8i, what percentage of i defective lots
does the purchaser reject? Find it for i = 1, 4.
Given that a lot is rejected, what is the condi-
tional probability that it contained 4 defective
components?
4.82. A purchaser of transistors buys them in lots of 20.
It is his policy to randomly inspect 4 components
from a lot and to accept the lot only if all 4 are
nondefective. If each component in a lot is, inde-
pendently, defective with probability .1, what pro-
portion of lots is rejected?
4.83. There are three highways in the county. The num-
ber of daily accidents that occur on these high-
ways are Poisson random variables with respective
parameters.3,.5, and. 7 .Find the expected num-
ber of accidents that will happen on any of these
highways today.
4.84. Suppose that 10 balls are put into 5 boxes, with
each ball independently being put in box i with
probability pi ,
```
```
∑ 5
i = 1 pi =^1.
(a) Find the expected number of boxes that do
not have any balls.
(b) Find the expected number of boxes that have
exactly 1 ball.
4.85. There are k types of coupons. Independently of
the types of previously collected coupons, each
new coupon collected is of type i with probability
pi ,
```
```
∑ k
i = 1 pi =^1 .If n coupons are collected, find
the expected number of distinct types that appear
in this set. (That is, find the expected number of
types of coupons that appear at least once in the
set of n coupons.)
```
#### Theoretical Exercises

```
4.1. There are N distinct types of coupons, and each
time one is obtained it will, independently of
past choices, be of type i with probability Pi , i =
1,..., N .Let T denote the number one need select
```
```
to obtain at least one of each type. Compute
P { T = n }.
Hint : Use an argument similar to the one used in
Example 1e.
```

**180** Chapter 4 Random Variables

```
4.2. If X has distribution function F , what is the distri-
bution function of eX?
4.3. If X has distribution function F , what is the distri-
bution function of the random variableα X + β,
whereαandβare constants,αZ0?
4.4. For a nonnegative integer-valued random vari-
able N , show that
```
```
E [ N ]=
```
```
∑q
```
```
i = 1
```
```
P { N Ú i }
```
```
Hint :
```
```
∑q
i = 1
```
```
P { N Ú i }=
```
```
∑q
i = 1
```
```
∑q
k = i
```
```
P { N = k }.Nowinter-
change the order of summation.
4.5. For a nonnegative integer-valued random variable
N , show that
∑q
```
```
i = 0
```
```
iP { N > i }=
```
```
1
2
( E [ N^2 ]− E [ N ])
```
```
Hint :
```
```
∑q
i = 0
```
```
iP { N > i }=
```
```
∑q
i = 0
```
```
i
```
```
∑q
k = i + 1
```
```
P { N = k }.Now
interchange the order of summation.
4.6. Let X be such that
```
```
P { X = 1 }= p = 1 − P { X =− 1 }
```
```
Find c Z1 such that E [ cX ]=1.
4.7. Let X be a random variable having expected value
μand varianceσ^2. Find the expected value and
variance of
Y =
```
```
X −μ
σ
4.8. Find Var( X )if
```
```
P ( X = a )= p = 1 − P ( X = b )
```
```
4.9. Show how the derivation of the binomial probabil-
ities
```
```
P { X = i }=
```
```
(
n
i
```
```
)
pi ( 1 − p ) n − i , i =0,..., n
```
```
leads to a proof of the binomial theorem
```
```
( x + y ) n =
```
```
∑ n
```
```
i = 0
```
```
(
n
i
```
```
)
xiyn − i
```
```
when x and y are nonnegative.
Hint: Let p = x + xy.
4.10. Let X be a binomial random variable with param-
eters n and p. Show that
```
```
E
```
```
[
1
X + 1
```
```
]
=
```
```
1 −( 1 − p ) n +^1
( n + 1 ) p
```
```
4.11. Consider n independent sequential trials, each of
which is successful with probability p .Ifthere
is a total of k successes, show that each of the
n !/[ k !( n − k )!] possible arrangements of the k suc-
cesses and n − k failures is equally likely.
4.12. There are n components lined up in a linear
arrangement. Suppose that each component inde-
pendently functions with probability p. What is the
probability that no 2 neighboring components are
both nonfunctional?
Hint : Condition on the number of defective com-
ponents and use the results of Example 4c of
Chapter 1.
4.13. Let X be a binomial random variable with param-
eters ( n , p ). What value of p maximizes P { X =
k }, k = 0, 1,..., n? This is an example of a sta-
tistical method used to estimate p when a bino-
mial ( n , p ) random variable is observed to equal
k. If we assume that n is known, then we estimate
p by choosing that value of p which maximizes
P { X = k }. This is known as the method of maxi-
mum likelihood estimation.
4.14. A family has n children with probabilityα pn , n Ú1,
whereα...( 1 − p )/ p.
(a) What proportion of families has no children?
(b) If each child is equally likely to be a boy or a
girl (independently of each other), what pro-
portion of families consists of k boys (and any
number of girls)?
4.15. Suppose that n independent tosses of a coin having
probability p of coming up heads are made. Show
that the probability that an even number of heads
results is^12 [1+( q − p ) n ], where q = 1 − p .Do
this by proving and then utilizing the identity
```
```
[∑ n /2]
```
```
i = 0
```
```
(
n
2 i
```
```
)
p^2 iqn −^2 i =
```
```
1
2
```
```
[
( p + q ) n +( q − p ) n
```
```
]
```
```
where [ n /2] is the largest integer less than or equal
to n /2. Compare this exercise with Theoretical
Exercise 3.5 of Chapter 3.
4.16. Let X be a Poisson random variable with parame-
terλ. Show that P { X = i }increases monotonically
and then decreases monotonically as i increases,
reaching its maximum when i is the largest integer
not exceedingλ.
Hint : Consider P { X = i }/ P { X = i − 1 }.
4.17. Let X be a Poisson random variable with
parameterλ.
(a) Show that
```
```
P { X is even}=
1
2
```
```
[
1 + e −^2 λ
```
```
]
```

```
Theoretical Exercises 181
```
by using the result of Theoretical Exercise
15 and the relationship between Poisson and
binomial random variables.
**(b)** Verify the formula in part (a) directly by mak-
ing use of the expansion of _e_ −λ+ _e_ λ.
**4.18.** Let _X_ be a Poisson random variable with parame-
terλ. What value ofλmaximizes _P_ { _X_ = _k_ }, _k_ Ú0?
**4.19.** Show that _X_ is a Poisson random variable with
parameterλ,then

```
E [ Xn ]=λ E [( X + 1 ) n −^1 ]
```
Now use this result to compute _E_ [ _X_^3 ].
**4.20.** Consider _n_ coins, each of which independently
comes up heads with probability _p_. Suppose that
_n_ is large and _p_ is small, and letλ= _np_. Suppose
that all _n_ coins are tossed; if at least one comes
up heads, the experiment ends; if not, we again
toss all _n_ coins, and so on. That is, we stop the
first time that at least one of the _n_ coins come up
heads. Let _X_ denote the total number of heads that
appear. Which of the following reasonings con-
cerned with approximating _P_ { _X_ = 1 }is correct
(in all cases, _Y_ is a Poisson random variable with
parameterλ)?
**(a)** Because the total number of heads that occur
when all _n_ coins are rolled is approximately a
Poisson random variable with parameterλ,

```
P { X = 1 }L P { Y = 1 }=λ e −λ
```
```
(b) Because the total number of heads that occur
when all n coins are rolled is approximately
a Poisson random variable with parameterλ,
and because we stop only when this number is
positive,
```
```
P { X = 1 }L P { Y = 1 | Y > 0 }=
```
```
λ e −λ
1 − e −λ
(c) Because at least one coin comes up heads, X
will equal 1 if none of the other n −1 coins
come up heads. Because the number of heads
resulting from these n −1 coins is approxi-
mately Poisson with mean( n − 1 ) p Lλ,
```
```
P { X = 1 }L P { Y = 0 }= e −λ
```
**4.21.** From a set of _n_ randomly chosen people, let _Eij_
denote the event that persons _i_ and _j_ have the same
birthday. Assume that each person is equally likely
to have any of the 365 days of the year as his or her
birthday. Find
**(a)** _P_ ( _E_ 3,4| _E_ 1,2);
**(b)** _P_ ( _E_ 1,3| _E_ 1,2);
**(c)** _P_ ( _E_ 2,3| _E_ 1,2∩ _E_ 1,3).

```
What can you conclude from your answers to
parts (a)–(c) about the independence of the
```
```
(
n
2
```
```
)
```
```
events Eij?
4.22. An urn contains 2 n balls, of which 2 are numbered
1, 2 are numbered 2,..., and 2 are numbered n.
Balls are successively withdrawn 2 at a time with-
out replacement. Let T denote the first selection
in which the balls withdrawn have the same num-
ber (and let it equal infinity if none of the pairs
withdrawn has the same number). We want to
show that, for 0<α<1,
```
```
lim
n
P { T >α n }= e −α/^2
```
```
To verify the preceding formula, let Mk denote the
number of pairs withdrawn in the first k selections,
k =1,..., n.
(a) Argue that when n is large, Mk can be
regarded as the number of successes in k
(approximately) independent trials.
(b) Approximate P { Mk = 0 }when n is large.
(c) Write the event{ T >α n }in terms of the value
of one of the variables Mk.
(d) Verify the limiting probability given for
P { T >α n }.
4.23. Consider a random collection of n individuals. In
approximating the probability that no 3 of these
individuals share the same birthday, a better Pois-
son approximation than that obtained in the text
(at least for values of n between 80 and 90) is
obtained by letting Ei be the event that there are
at least 3 birthdays on day i , i =1,..., 365.
(a) Find P ( Ei ).
(b) Give an approximation for the probability
that no 3 individuals share the same birthday.
(c) Evaluate the preceding when n =88 (which
can be shown to be the smallest value of n for
which the probability exceeds.5).
4.24. Here is another way to obtain a set of recur-
sive equations for determining Pn , the probability
that there is a string of k consecutive heads in a
sequence of n flips of a fair coin that comes up
heads with probability p :
(a) Argue that, for k < n , there will be a string of
k consecutive heads if either
```
1. there is a string of _k_ consecutive heads
    within the first _n_ −1flips,or
2. there is no string of _k_ consecutive heads
    within the first _n_ − _k_ −1flips,flip _n_ − _k_
    is a tail, and flips _n_ − _k_ +1,..., _n_ are
    all heads.
**(b)** Using the preceding, relate _Pn_ to _Pn_ − 1 .Start-
ing with _Pk_ = _pk_ , the recursion can be used to
obtain _Pk_ + 1 ,then _Pk_ + 1 , and so on, up to _Pn_.


**182** Chapter 4 Random Variables

```
4.25. Suppose that the number of events that occur
in a specified time is a Poisson random variable
with parameterλ. If each event is counted with
probability p , independently of every other event,
show that the number of events that are counted
is a Poisson random variable with parameterλ p.
Also, give an intuitive argument as to why this
should be so. As an application of the preceding
result, suppose that the number of distinct ura-
nium deposits in a given area is a Poisson random
variable with parameterλ = 10. If, in a fixed
period of time, each deposit is discovered inde-
pendently with probability 501 , find the probability
that (a) exactly 1, (b) at least 1, and (c) at most 1
deposit is discovered during that time.
4.26. Prove
∑ n
```
```
i = 0
```
```
e −λ
```
```
λ i
i!
```
```
=
```
```
1
n!
```
```
∫q
```
```
λ
```
```
e − xxndx
```
```
Hint : Use integration by parts.
4.27. If X is a geometric random variable, show analyti-
cally that
```
```
P { X = n + k | X > n }= P { X = k }
```
```
Using the interpretation of a geometric random
variable, give a verbal argument as to why the pre-
ceding equation is true.
4.28. Let X be a negative binomial random variable with
parameters r and p ,andlet Y be a binomial ran-
dom variable with parameters n and p. Show that
```
```
P { X > n }= P { Y < r }
```
```
Hint : Either one could attempt an analytical proof
of the preceding equation, which is equivalent to
proving the identity
```
```
∑q
```
```
i = n + 1
```
```
(
i − 1
r − 1
```
```
)
pr ( 1 − p ) i − r =
```
```
r ∑− 1
```
```
i = 0
```
```
(
n
i
```
```
)
```
```
* pi ( 1 − p ) n − i
```
```
or one could attempt a proof that uses the prob-
abilistic interpretation of these random variables.
That is, in the latter case, start by considering a
sequence of independent trials having a common
probability p of success. Then try to express the
events{ X > n }and{ Y < r }in terms of the out-
comes of this sequence.
4.29. For a hypergeometric random variable, determine
```
```
P { X = k + 1 }/ P { X = k }
```
```
4.30. Balls numbered 1 through N are in an urn. Sup-
pose that n , n ... N , of them are randomly selected
```
```
without replacement. Let Y denote the largest
number selected.
(a) Find the probability mass function of Y.
(b) Derive an expression for E [ Y ] and then use
Fermat’s combinatorial identity (see Theoret-
ical Exercise 11 of Chapter 1) to simplify the
expression.
4.31. A jar contains m + n chips, numbered
1, 2,..., n + m .Asetofsize n is drawn. If we
let X denote the number of chips drawn having
numbers that exceed each of the numbers of those
remaining, compute the probability mass function
of X.
4.32. A jar contains n chips. Suppose that a boy succes-
sively draws a chip from the jar, each time replac-
ing the one drawn before drawing another. The
process continues until the boy draws a chip that
he has previously drawn. Let X denote the num-
ber of draws, and compute its probability mass
function.
4.33. Show that Equation (8.6) follows from Equation
(8.5).
4.34. From a set of n elements, a nonempty subset is
chosen at random in the sense that all of the
nonempty subsets are equally likely to be selected.
Let X denote the number of elements in the cho-
sen subset. Using the identities given in Theoreti-
cal Exercise 12 of Chapter 1, show that
```
```
E [ X ]=
n
```
```
2 −
```
```
(
1
2
```
```
) n − 1
```
```
Var( X )=
n · 22 n −^2 − n ( n + 1 ) 2 n −^2
( 2 n − 1 )^2
```
```
Show also that, for n large,
```
```
Var( X )
```
```
n
4
in the sense that the ratio Var( X )to n /4
approaches 1 as n approachesq. Compare this
formula with the limiting form of Var( Y )when
P { Y = i }= 1 / n , i =1,..., n.
4.35. An urn initially contains one red and one blue ball.
At each stage, a ball is randomly chosen and then
replaced along with another of the same color. Let
X denote the selection number of the first chosen
ball that is blue. For instance, if the first selec-
tion is red and the second blue, then X is equal
to 2.
(a) Find P { X > i }, i Ú1.
(b) Show that, with probability 1, a blue ball is
eventually chosen. (That is, show that P { X <
q}=1.)
(c) Find E [ X ].
```

```
Self-Test Problems and Exercises 183
```
**4.36.** Suppose the possible values of _X_ are{ _xi_ }, the pos-
sible values of _Y_ are{ _yj_ }, and the possible values
of _X_ + _Y_ are{ _zk_ }.Let _Ak_ denote the set of all
pairs of indices( _i_ , _j_ )such that _xi_ + _yj_ = _zk_ ;thatis,
_Ak_ ={( _i_ , _j_ ): _xi_ + _yj_ = _zk_ }.
**(a)** Argue that

```
P { X + Y = zk }=
```
```
∑
```
```
( i , j )∈ Ak
```
```
P { X = xi , Y = yj }
```
```
(b) Show that
```
```
E [ X + Y ]=
```
```
∑
```
```
k
```
```
∑
```
```
( i , j )∈ Ak
```
```
( xi + yj ) P { X = xi ,
```
```
Y = yj }
```
```
(c) Using the formula from part (b), argue that
```
```
E [ X + Y ]=
```
```
∑
```
```
i
```
```
∑
```
```
j
```
```
( xi + yj ) P { X = xi ,
```
```
Y = yj }
```
```
(d) Show that
```
```
P ( X = xi )=
```
```
∑
```
```
j
```
```
P ( X = xi , Y = yj ),
```
```
P ( Y = yj )=
```
```
∑
```
```
i
```
```
P { X = xi , Y = yj }
```
```
(e) Prove that
```
```
E [ X + Y ]= E [ X ]+ E [ Y ]
```
#### Self-Test Problems and Exercises

```
4.1. Suppose that the random variable X is equal to
the number of hits obtained by a certain base-
ball player in his next 3 at bats. If P { X = 1 }=
.3, P { X = 2 }=.2, and P { X = 0 }= 3 P { X = 3 },
find E [ X ].
4.2. Suppose that X takes on one of the values 0, 1,
and 2. If for some constant c , P { X = i }= cP { X =
i − 1 }, i =1, 2, find E [ X ].
4.3. A coin that, when flipped, comes up heads with
probability p is flipped until either heads or tails
has occurred twice. Find the expected number of
flips.
4.4. A certain community is composed of m families,
ni of which have i children,
```
```
∑ r
i = 1
```
```
ni = m. If one of
the families is randomly chosen, let X denote the
number of children in that family. If one of the
∑ r
i = 1
```
```
ini children is randomly chosen, let Y denote
the total number of children in the family of that
child. Show that E [ Y ]Ú E [ X ].
4.5. Suppose that P { X = 0 }= 1 − P { X = 1 }.If
E [ X ]=3Var( X ), find P { X = 0 }.
4.6. There are 2 coins in a bin. When one of them is
flipped, it lands on heads with probability .6, and
when the other is flipped, it lands on heads with
probability .3. One of these coins is to be randomly
chosen and then flipped. Without knowing which
coin is chosen, you can bet any amount up to 10
dollars, and you then either win that amount if the
coincomesupheadsorloseitifitcomesuptails.
Suppose, however, that an insider is willing to sell
you, for an amount C , the information as to which
coin was selected. What is your expected payoff
if you buy this information? Note that if you buy
```
```
itandthenbet x , you will end up either winning
x − C or− x − C (that is, losing x + C in the lat-
ter case). Also, for what values of C does it pay to
purchase the information?
4.7. A philanthropist writes a positive number x on a
piece of red paper, shows the paper to an impar-
tial observer, and then turns it face down on the
table. The observer then flips a fair coin. If it shows
heads, she writes the value 2 x and, if tails, the value
x /2, on a piece of blue paper, which she then turns
face down on the table. Without knowing either
the value x or the result of the coin flip, you have
the option of turning over either the red or the
blue piece of paper. After doing so and observing
the number written on that paper, you may elect
to receive as a reward either that amount or the
(unknown) amount written on the other piece of
paper. For instance, if you elect to turn over the
blue paper and observe the value 100, then you
can elect either to accept 100 as your reward or
to take the amount (either 200 or 50) on the red
paper. Suppose that you would like your expected
reward to be large.
(a) Argue that there is no reason to turn over the
red paper first, because if you do so, then no
matter what value you observe, it is always
better to switch to the blue paper.
(b) Let y be a fixed nonnegative value, and con-
sider the following strategy: Turn over the
blue paper, and if its value is at least y ,then
accept that amount. If it is less than y ,then
switch to the red paper. Let Ry ( x )denote the
reward obtained if the philanthropist writes
the amount x and you employ this strat-
egy. Find E [ Ry ( x )]. Note that E [ R 0 ( x )]isthe
```

**184** Chapter 4 Random Variables

```
expected reward if the philanthropist writes
the amount x when you employ the strategy
of always choosing the blue paper.
4.8. Let B ( n , p ) represent a binomial random variable
with parameters n and p .Arguethat
```
```
P { B ( n , p )... i }= 1 − P { B ( n ,1− p )... n − i − 1 }
```
```
Hint : The number of successes less than or equal to
i is equivalent to what statement about the number
of failures?
4.9. If X is a binomial random variable with expected
value 6 and variance 2.4, find P { X = 5 }.
4.10. An urn contains n balls numbered 1 through n .If
you withdraw m balls randomly in sequence, each
time replacing the ball selected previously, find
P { X = k }, k =1,..., m ,where X is the maximum
of the m chosen numbers.
Hint : First find P { X ... k }.
4.11. Teams A and B play a series of games, with the
first team to win 3 games being declared the winner
of the series. Suppose that team A independently
wins each game with probability p. Find the condi-
tional probability that team A wins
(a) the series given that it wins the first game;
(b) the first game given that it wins the series.
4.12. A local soccer team has 5 more games left to play.
If it wins its game this weekend, then it will play
its final 4 games in the upper bracket of its league,
and if it loses, then it will play its final games in
the lower bracket. If it plays in the upper bracket,
then it will independently win each of its games in
this bracket with probability .4, and if it plays in
the lower bracket, then it will independently win
each of its games with probability .7. If the proba-
bility that the team wins its game this weekend is
.5, what is the probability that it wins at least 3 of
its final 4 games?
4.13. Each of the members of a 7-judge panel inde-
pendently makes a correct decision with probabil-
ity.7. If the panel’s decision is made by majority
rule, what is the probability that the panel makes
the correct decision? Given that 4 of the judges
agreed, what is the probability that the panel made
the correct decision?
4.14. On average, 5.2 hurricanes hit a certain region in a
year. What is the probability that there will be 3 or
fewer hurricanes hitting this year?
4.15. The number of eggs laid on a tree leaf by an insect
of a certain type is a Poisson random variable with
parameterλ. However, such a random variable
can be observed only if it is positive, since if it is
0 then we cannot know that such an insect was on
the leaf. If we let Y denote the observed number
of eggs, then
```
```
P { Y = i }= P { X = i | X > 0 }
```
```
where X is Poisson with parameterλ.Find E [ Y ].
4.16. Each of n boys and n girls, independently and ran-
domly, chooses a member of the other sex. If a
boy and girl choose each other, they become a
couple. Number the girls, and let Gi be the event
that girl number i is part of a couple. Let P 0 =
1 − P (∪ ni = 1 Gi )be the probability that no couples
are formed.
(a) What is P ( Gi )?
(b) What is P ( Gi | Gj )?
(c) When n is large, approximate P 0.
(d) When n is large, approximate Pk , the proba-
bility that exactly k couples are formed.
(e) Use the inclusion–exclusion identity to evalu-
ate P 0.
4.17. A total of 2 n people, consisting of n married cou-
ples, are randomly divided into n pairs. Arbitrarily
number the women, and let Wi denote the event
that woman i is paired with her husband.
(a) Find P ( Wi ).
(b) For i Z j , find P ( Wi | Wj ).
(c) When n is large, approximate the probability
that no wife is paired with her husband.
(d) If each pairing must consist of a man and a
woman, what does the problem reduce to?
4.18. A casino patron will continue to make $5 bets on
red in roulette until she has won 4 of these bets.
(a) What is the probability that she places a total
of 9 bets?
(b) What is her expected winnings when she
stops?
Remark : On each bet, she will either win $5 with
probability^1838 or lose $5 with probability^2038.
4.19. When three friends go for coffee, they decide who
will pay the check by each flipping a coin and then
letting the “odd person” pay. If all three flips pro-
duce the same result (so that there is no odd per-
son), then they make a second round of flips, and
they continue to do so until there is an odd person.
What is the probability that
(a) exactly 3 rounds of flips are made?
(b) more than 4 rounds are needed?
4.20. Show that if X is a geometric random variable with
parameter p ,then
```
```
E [1/ X ]=
− p log( p )
1 − p
Hint : You will need to evaluate an expression of
the form
```
```
∑q
i = 1
```
```
ai / i .Todoso,write ai / i =
```
```
∫ a
0 x
```
_i_ − (^1) _dx_ ,
and then interchange the sum and the integral.
**4.21.** Suppose that
_P_ { _X_ = _a_ }= _p_ , _P_ { _X_ = _b_ }= 1 − _p_


```
Self-Test Problems and Exercises 185
```
**(a)** Show that _Xa_ −− _bb_ is a Bernoulli random vari-
able.
**(b)** Find Var( _X_ ).
**4.22.** Each game you play is a win with probability _p_.
You plan to play 5 games, but if you win the fifth
game, then you will keep on playing until you
lose.
**(a)** Find the expected number of games that
you play.
**(b)** Find the expected number of games that
you lose.
**4.23.** Balls are randomly withdrawn, one at a time with-
out replacement, from an urn that initially has
_N_ white and _M_ black balls. Find the probability
that _n_ white balls are drawn before _m_ black balls,
_n_ ... _N_ , _m_ ... _M_.
**4.24.** Ten balls are to be distributed among 5 urns,
with each ball going into urn _i_ with probabil-
ity _pi_ ,

```
∑ 5
i = 1 pi =^1 .Let Xi denote the number of
```
```
balls that go into urn i. Assume that events cor-
responding to the locations of different balls are
independent.
(a) What type of random variable is Xi ?Beas
specific as possible.
(b) For i Z j , what type of random variable is
Xi + Xj?
(c) Find P { X 1 + X 2 + X 3 = 7 }.
4.25. For the match problem (Example 5m in
Chapter 2), find
(a) the expected number of matches.
(b) the variance of the number of matches.
4.26. Letαbe the probability that a geometric random
variable X with parameter p is an even number.
(a) Findα by using the identityα =
```
```
∑q
i = 1
P{X=2i}.
(b) Findαby conditioning on whether X =1or
X > 1.
```

## CHAPTER 5

# Continuous Random Variables

### 5.1 Introduction

**5.2 EXPECTATION AND VARIANCE OF CONTINUOUS RANDOM VARIABLES
5.3 THE UNIFORM RANDOM VARIABLE
5.4 NORMAL RANDOM VARIABLES
5.5 EXPONENTIAL RANDOM VARIABLES
5.6 OTHER CONTINUOUS DISTRIBUTIONS
5.7 THE DISTRIBUTION OF A FUNCTION OF A RANDOM VARIABLE**

##### 5.1 INTRODUCTION

```
In Chapter 4, we considered discrete random variables—that is, random variables
whose set of possible values is either finite or countably infinite. However, there also
exist random variables whose set of possible values is uncountable. Two examples are
the time that a train arrives at a specified stop and the lifetime of a transistor. Let X
be such a random variable. We say that X is a continuous †random variable if there
exists a nonnegative function f , defined for all real x ∈(−q,q), having the property
that, for any set B of real numbers,‡
```
##### P { X ∈ B }=

##### ∫

```
B
```
```
f ( x ) dx (1.1)
```
```
The function f is called the probability density function of the random variable X.
(See Figure 5.1.)
In words, Equation (1.1) states that the probability that X will be in B may be
obtained by integrating the probability density function over the set B. Since X must
assume some value, f must satisfy
```
```
1 = P { X ∈(−q,q)}=
```
```
∫q
```
```
−q
```
```
f ( x ) dx
```
```
All probability statements about X can be answered in terms of f. For instance, from
Equation (1.1), letting B =[ a , b ], we obtain
```
```
P { a ... X ... b }=
```
```
∫ b
```
```
a
```
```
f ( x ) dx (1.2)
```
```
†Sometimes called absolutely continuous.
‡Actually, for technical reasons Equation (1.1) is true only for the measurable sets B ,which,
fortunately, include all sets of practical interest.
```
**186**


```
Section 5.1 Introduction 187
```
```
x
a b
```
```
f
```
```
P ( a  X  b ) = area of shaded region
```
```
FIGURE 5.1: Probability density function f.
```
If we let _a_ = _b_ in Equation (1.2), we get

```
P { X = a }=
```
```
∫ a
```
```
a
```
```
f ( x ) dx = 0
```
In words, this equation states that the probability that a continuous random variable
will assume any fixed value is zero. Hence, for a continuous random variable,

```
P { X < a }= P { X ... a }= F ( a )=
```
```
∫ a
```
```
−q
```
```
f ( x ) dx
```
**_EXAMPLE 1a_**

Suppose that _X_ is a continuous random variable whose probability density function
is given by

```
f ( x )=
```
##### {

```
C ( 4 x − 2 x^2 ) 0 < x < 2
0 otherwise
```
```
(a) What is the value of C?
(b) Find P { X > 1 }.
```
**_Solution._** **(a)** Since _f_ is a probability density function, we must have

∫q
−q _f_ ( _x_ ) _dx_ =1,
implying that

```
C
```
##### ∫ 2

```
0
```
```
( 4 x − 2 x^2 ) dx = 1
```
or

```
C
```
##### [

```
2 x^2 −
```
```
2 x^3
3
```
##### ]∣

##### ∣

##### ∣

##### ∣

##### ∣

```
x = 2
```
```
x = 0
```
##### = 1

or

```
C =
```
##### 3

##### 8

Hence,

```
(b) P { X > 1 }=
```
```
∫q
1 f ( x ) dx =
```
```
3
8
```
##### ∫ 2

```
1 (^4 x −^2 x
```
(^2) ) _dx_ = 1
(^2).


**188** Chapter 5 Continuous Random Variables

```
EXAMPLE 1b
The amount of time in hours that a computer functions before breaking down is a
continuous random variable with probability density function given by
```
```
f ( x )=
```
##### {

```
λ e − x /^100 x Ú 0
0 x < 0
```
```
What is the probability that
(a) a computer will function between 50 and 150 hours before breaking down?
(b) it will function for fewer than 100 hours?
```
```
Solution. (a) Since
```
##### 1 =

```
∫q
```
```
−q
```
```
f ( x ) dx =λ
```
```
∫q
```
```
0
```
```
e − x /^100 dx
```
```
we obtain
```
```
1 =−λ( 100 ) e − x /^100
```
##### ∣

```
∣q
0 =^100 λ or λ=
```
##### 1

##### 100

```
Hence, the probability that a computer will function between 50 and 150 hours before
breaking down is given by
```
##### P { 50 < X < 150 }=

##### ∫ 150

```
50
```
##### 1

##### 100

```
e − x /^100 dx =− e − x /^100
```
##### ∣

##### ∣^150

```
50
= e −^1 /^2 − e −^3 /^2 L. 384
```
```
(b) Similarly,
```
##### P { X < 100 }=

##### ∫ 100

```
0
```
##### 1

##### 100

```
e − x /^100 dx =− e − x /^100
```
##### ∣

##### ∣^100

```
0 =^1 − e
```
− (^1) L. 633
In other words, approximately 63.3 percent of the time, a computer will fail before
registering 100 hours of use..
**_EXAMPLE 1c_**
The lifetime in hours of a certain kind of radio tube is a random variable having a
probability density function given by
_f_ ( _x_ )=

##### ⎧

##### ⎪⎨

##### ⎪⎩

```
0 x ... 100
100
x^2
```
```
x > 100
```
```
What is the probability that exactly 2 of 5 such tubes in a radio set will have to be
replaced within the first 150 hours of operation? Assume that the events Ei , i =
1, 2, 3, 4, 5, that the i th such tube will have to be replaced within this time are
independent.
```

```
Section 5.1 Introduction 189
```
**_Solution._** From the statement of the problem, we have

```
P ( Ei )=
```
##### ∫ 150

```
0
```
```
f ( x ) dx
```
##### = 100

##### ∫ 150

```
100
```
```
x −^2 dx
```
##### =

##### 1

##### 3

Hence, from the independence of the events _Ei_ , it follows that the desired probabil-
ity is
(
5
2

##### )(

##### 1

##### 3

##### ) 2 (

##### 2

##### 3

##### ) 3

##### =

##### 80

##### 243.

The relationship between the cumulative distribution _F_ and the probability density
_f_ is expressed by

```
F ( a )= P { X ∈(−q, a ]}=
```
```
∫ a
```
```
−q
```
```
f ( x ) dx
```
Differentiating both sides of the preceding equation yields

```
d
da
```
```
F ( a )= f ( a )
```
That is, the density is the derivative of the cumulative distribution function. A some-
what more intuitive interpretation of the density function may be obtained from
Equation (1.2) as follows:

##### P

##### {

```
a −
```
```
ε
2
```
```
... X ... a +
```
```
ε
2
```
##### }

##### =

```
∫ a +ε/ 2
```
```
a −ε/ 2
```
```
f ( x ) dx Lε f ( a )
```
whenεis small and when _f_ (·)is continuous at _x_ = _a_. In other words, the probability
that _X_ will be contained in an interval of lengthεaround the point _a_ is approximately
ε _f_ ( _a_ ). From this result we see that _f_ ( _a_ )is a measure of how likely it is that the random
variable will be near _a_.

**_EXAMPLE 1d_**

If _X_ is continuous with distribution function _FX_ and density function _fX_ , find the
density function of _Y_ = 2 _X_.

**_Solution._** We will determine _fY_ in two ways. The first way is to derive, and then
differentiate, the distribution function of _Y_ :

```
FY ( a )= P { Y ... a }
= P { 2 X ... a }
= P { X ... a / 2 }
= FX ( a / 2 )
```
Differentiation gives

```
fY ( a )=
```
##### 1

##### 2

```
fX ( a / 2 )
```

**190** Chapter 5 Continuous Random Variables

```
Another way to determine fY is to note that
```
```
fY ( a )L P { a −
2
```
```
... Y ... a +
2
```
##### }

```
= P { a −
2
```
```
... 2 X ... a +
2
```
##### }

##### = P {

```
a
2
```
##### −

##### 4

##### ... X ...

```
a
2
```
##### +

##### 4

##### }

##### L

##### 2

```
fX ( a / 2 )
```
```
Dividing through by gives the same result as before..
```
### 5.2 Expectation and Variance of Continuous Random Variables

```
In Chapter 4, we defined the expected value of a discrete random variable X by
```
```
E [ X ]=
```
##### ∑

```
x
```
```
xP { X = x }
```
```
If X is a continuous random variable having probability density function f ( x ), then,
because
f ( x ) dx L P { x ... X ... x + dx } for dx small
```
```
it is easy to see that the analogous definition is to define the expected value of X by
```
##### E [ X ]=

```
∫q
```
```
−q
```
```
xf ( x ) dx
```
```
EXAMPLE 2a
Find E [ X ] when the density function of X is
```
```
f ( x )=
```
##### {

```
2 x if 0... x ... 1
0 otherwise
```
```
Solution.
```
##### E [ X ]=

##### ∫

```
xf ( x ) dx
```
##### =

##### ∫ 1

```
0
```
```
2 x^2 dx
```
##### =

##### 2

(^3).
**_EXAMPLE 2b_**
The density function of _X_ is given by
_f_ ( _x_ )=

##### {

```
1if 0... x ... 1
0 otherwise
```
```
Find E [ eX ].
```

```
Section 5.2 Expectation and Variance of Continuous Random Variables 191
```
**_Solution._** Let _Y_ = _eX_. We start by determining _FY_ , the probability distribution func-
tion of _Y_. Now, for 1... _x_ ... _e_ ,

```
FY ( x )= P { Y ... x }
= P { eX ... x }
= P { X ...log( x )}
```
```
=
```
```
∫log( x )
```
```
0
```
```
f ( y ) dy
```
```
=log( x )
```
By differentiating _FY_ ( _x_ ), we can conclude that the probability density function of _Y_
is given by

```
fY ( x )=
```
##### 1

```
x
```
```
1 ... x ... e
```
Hence,

```
E [ eX ]= E [ Y ]=
```
```
∫q
```
```
−q
```
```
xfY ( x ) dx
```
##### =

```
∫ e
```
```
1
```
```
dx
```
```
= e − 1
.
```
Although the method employed in Example 2b to compute the expected value of
a function of _X_ is always applicable, there is, as in the discrete case, an alternative
way of proceeding. The following is a direct analog of Proposition 4.1. of Chapter 4.

**Proposition 2.1.** If _X_ is a continuous random variable with probability density func-
tion _f_ ( _x_ ), then, for any real-valued function _g_ ,

```
E [ g ( X )]=
```
```
∫q
```
```
−q
```
```
g ( x ) f ( x ) dx
```
```
An application of Proposition 2.1 to Example 2b yields
```
```
E [ eX ]=
```
##### ∫ 1

```
0
```
```
exdx since f ( x )=1, 0< x < 1
```
```
= e − 1
```
which is in accord with the result obtained in that example.
The proof of Proposition 2.1 is more involved than that of its discrete random
variable analog. We will present such a proof under the provision that the random
variable _g_ ( _X_ )is nonnegative. (The general proof, which follows the argument in the
case we present, is indicated in Theoretical Exercises 2 and 3.) We will need the fol-
lowing lemma, which is of independent interest.

```
Lemma 2.1
For a nonnegative random variable Y ,
```
##### E [ Y ]=

```
∫q
```
```
0
```
```
P { Y > y } dy
```

**192** Chapter 5 Continuous Random Variables

```
Proof. We present a proof when Y is a continuous random variable with probabil-
ity density function fY. We have
∫q
```
```
0
```
```
P { Y > y } dy =
```
```
∫q
```
```
0
```
```
∫q
```
```
y
```
```
fY ( x ) dx dy
```
```
where we have used the fact that P { Y > y }=
```
```
∫q
y fY ( x ) dx. Interchanging the order
of integration in the preceding equation yields
∫q
```
```
0
```
```
P { Y > y } dy =
```
```
∫q
```
```
0
```
```
(∫ x
```
```
0
```
```
dy
```
##### )

```
fY ( x ) dx
```
##### =

```
∫q
```
```
0
```
```
xfY ( x ) dx
```
```
= E [ Y ].
```
```
Proof of Proposition 2.1. From Lemma 2.1, for any function g for which g ( x )Ú0,
```
```
E [ g ( X )]=
```
```
∫q
```
```
0
```
```
P { g ( X )> y } dy
```
##### =

```
∫q
```
```
0
```
##### ∫

```
x : g ( x )> y
```
```
f ( x ) dx dy
```
##### =

##### ∫

```
x : g ( x )> 0
```
```
∫ g ( x )
```
```
0
```
```
dy f ( x ) dx
```
##### =

##### ∫

```
x : g ( x )> 0
```
```
g ( x ) f ( x ) dx
```
```
which completes the proof.
```
```
EXAMPLE 2c
A stick of length 1 is split at a point U that is uniformly distributed over (0, 1). Deter-
mine the expected length of the piece that contains the point p ,0... p ...1.
```
```
Solution. Let Lp ( U )denote the length of the substick that contains the point p ,and
note that
```
```
Lp ( U )=
```
##### {

```
1 − UU < p
UU > p
```
```
(See Figure 5.2.) Hence, from Proposition 2.1,
```
```
E [ Lp ( U )]=
```
##### ∫ 1

```
0
```
```
Lp ( u ) du
```
##### =

```
∫ p
```
```
0
```
```
( 1 − u ) du +
```
##### ∫ 1

```
p
```
```
udu
```
##### =

##### 1

##### 2

##### −

```
( 1 − p )^2
2
```
##### +

##### 1

##### 2

##### −

```
p^2
2
=
```
##### 1

##### 2

```
+ p ( 1 − p )
```

```
Section 5.2 Expectation and Variance of Continuous Random Variables 193
```
```
0 Up 1
(a)
```
```
0 p U 1
(b)
```
```
1 – U
```
```
U
```
```
FIGURE 5.2: Substick containing point p :(a) U < p ;(b) U > p.
```
Since _p_ ( 1 − _p_ )is maximized when _p_ =^12 , it is interesting to note that the expected
length of the substick containing the point _p_ is maximized when _p_ is the midpoint of
the original stick..

**_EXAMPLE 2d_**

Suppose that if you are _s_ minutes early for an appointment, then you incur the cost _cs_ ,
and if you are _s_ minutes late, then you incur the cost _ks_. Suppose also that the travel
time from where you presently are to the location of your appointment is a continuous
random variable having probability density function _f_. Determine the time at which
you should depart if you want to minimize your expected cost.

**_Solution._** Let _X_ denote the travel time. If you leave _t_ minutes before your appoint-
ment, then your cost—call it _Ct_ ( _X_ )—is given by

```
Ct ( X )=
```
##### {

```
c ( t − X ) if X ... t
k ( X − t ) if X Ú t
```
Therefore,

```
E [ Ct ( X )]=
```
```
∫q
```
```
0
```
```
Ct ( x ) f ( x ) dx
```
##### =

```
∫ t
```
```
0
```
```
c ( t − x ) f ( x ) dx +
```
```
∫q
```
```
t
```
```
k ( x − t ) f ( x ) dx
```
```
= ct
```
```
∫ t
```
```
0
```
```
f ( x ) dx − c
```
```
∫ t
```
```
0
```
```
xf ( x ) dx + k
```
```
∫q
```
```
t
```
```
xf ( x ) dx − kt
```
```
∫q
```
```
t
```
```
f ( x ) dx
```
The value of _t_ that minimizes _E_ [ _Ct_ ( _X_ )] can now be obtained by calculus. Differentia-
tion yields

```
d
dt
```
```
E [ Ct ( X )]= ct f ( t )+ cF ( t )− ct f ( t )− kt f ( t )+ kt f ( t )− k [1− F ( t )]
```
```
=( k + c ) F ( t )− k
```
Equating the rightmost side to zero shows that the minimal expected cost is obtained
when you leave _t_ ∗minutes before your appointment, where _t_ ∗satisfies

```
F ( t ∗)=
```
```
k
k + c.
As in Chapter 4, we can use Proposition 2.1 to show the following.
```
**Corollary 2.1.** If _a_ and _b_ are constants, then

```
E [ aX + b ]= aE [ X ]+ b
```

**194** Chapter 5 Continuous Random Variables

```
The proof of Corollary 2.1 for a continuous random variable X is the same as the
one given for a discrete random variable. The only modification is that the sum is
replaced by an integral and the probability mass function by a probability density
function.
The variance of a continuous random variable is defined exactly as it is for a dis-
crete random variable, namely, if X is a random variable with expected valueμ,then
the variance of X is defined (for any type of random variable) by
```
```
Var( X )= E [( X −μ)^2 ]
```
```
The alternative formula,
```
```
Var( X )= E [ X^2 ]−( E [ X ])^2
```
```
is established in a manner similar to its counterpart in the discrete case.
```
```
EXAMPLE 2e
Find Var( X )for X as given in Example 2a.
```
```
Solution. We first compute E [ X^2 ].
```
##### E [ X^2 ]=

```
∫q
```
```
−q
```
```
x^2 f ( x ) dx
```
##### =

##### ∫ 1

```
0
```
```
2 x^3 dx
```
##### =

##### 1

##### 2

```
Hence, since E [ X ]=^23 , we obtain
```
```
Var( X )=
```
##### 1

##### 2

##### −

##### (

##### 2

##### 3

##### ) 2

##### =

##### 1

##### 18.

```
It can be shown that, for constants a and b ,
```
```
Var( aX + b )= a^2 Var( X )
```
```
The proof mimics the one given for discrete random variables.
There are several important classes of continuous random variables that appear
frequently in applications of probability; the next few sections are devoted to a study
of some of them.
```
### 5.3 The Uniform Random Variable

```
A random variable is said to be uniformly distributed over the interval (0, 1) if its
probability density function is given by
```
```
f ( x )=
```
##### {

```
10 < x < 1
0 otherwise
```
##### (3.1)

```
Note that Equation (3.1) is a density function, since f ( x ) Ú 0and
```
```
∫q
∫ −q f ( x ) dx =
1
0 dx =1. Because f ( x )>0 only when x ∈(0, 1), it follows that X must assume
a value in interval (0, 1). Also, since f ( x )is constant for x ∈(0, 1), X is just as likely to
```

```
Section 5.3 The Uniform Random Variable 195
```
```

```
```
a
```
```
f ( a )
```
```

```
```
——–^1
```
_-_

```
(a)
```
```

```
```
a
```
```
F ( a )
```
```

(b)
```
```
1
```
```

```
```
FIGURE 5.3: Graph of (a) f ( a )and (b) F ( a )for a uniform(α,β)random variable.
```
be near any value in (0, 1) as it is to be near any other value. To verify this statement,
note that, for any 0< _a_ < _b_ <1,

```
P { a ... X ... b }=
```
```
∫ b
```
```
a
```
```
f ( x ) dx = b − a
```
In other words, the probability that _X_ is in any particular subinterval of (0, 1) equals
the length of that subinterval.
In general, we say that _X_ is a uniform random variable on the interval(α,β)if the
probability density function of _X_ is given by

```
f ( x )=
```
##### ⎧

##### ⎪⎨

##### ⎪⎩

##### 1

```
β−α
```
```
ifα< x <β
```
```
0 otherwise
```
##### (3.2)

Since _F_ ( _a_ )=

∫ _a_
−q _f_ ( _x_ ) _dx_ , it follows from Equation (3.2) that the distribution function
of a uniform random variable on the interval(α,β)is given by

```
F ( a )=
```
##### ⎧

##### ⎪⎪

##### ⎪⎨

##### ⎪⎪

##### ⎪⎩

```
0 a ...α
a −α
β −α
```
```
α< a <β
```
```
1 a Úβ
```
Figure 5.3 presents a graph of _f_ ( _a_ )and _F_ ( _a_ ).

**_EXAMPLE 3a_**

Let _X_ be uniformly distributed over(α,β). Find (a) _E_ [ _X_ ] and (b) Var( _X_ ).

**_Solution._** (a)

##### E [ X ]=

```
∫q
```
```
−q
```
```
xf ( x ) dx
```
##### =

```
∫β
```
```
α
```
```
x
β−α
```
```
dx
```
##### =

```
β^2 −α^2
2 (β−α)
```
```
=
```
```
β+α
2
```

**196** Chapter 5 Continuous Random Variables

```
In words, the expected value of a random variable that is uniformly distributed
over some interval is equal to the midpoint of that interval.
(b) To find Var( X ), we first calculate E [ X^2 ].
```
##### E [ X^2 ]=

```
∫β
```
```
α
```
##### 1

```
β−α
```
```
x^2 dx
```
##### =

```
β^3 −α^3
3 (β−α)
```
```
=
```
```
β^2 +αβ +α^2
3
Hence,
```
```
Var( X )=
```
```
β^2 +αβ +α^2
3
```
##### −

```
(α+β)^2
4
```
```
=
```
```
(β−α)^2
12
Therefore, the variance of a random variable that is uniformly distributed over
some interval is the square of the length of that interval divided by 12..
```
```
EXAMPLE 3b
If X is uniformly distributed over (0, 10), calculate the probability that (a) X <3, (b)
X >6, and (c) 3< X <8.
```
```
Solution. (a) P { X < 3 }=
```
##### ∫ 3

```
0
```
##### 1

##### 10

```
dx =
```
##### 3

##### 10

```
(b) P { X > 6 }=
```
##### ∫ 10

```
6
```
##### 1

##### 10

```
dx =
```
##### 4

##### 10

```
(c) P { 3 < X < 8 }=
```
##### ∫ 8

```
3
```
##### 1

##### 10

```
dx =
```
##### 1

##### 2.

```
EXAMPLE 3c
Buses arrive at a specified stop at 15-minute intervals starting at 7A.M. That is, they
arrive at 7, 7:15, 7:30, 7:45, and so on. If a passenger arrives at the stop at a time that
is uniformly distributed between 7 and 7:30, find the probability that he waits
(a) less than 5 minutes for a bus;
(b) more than 10 minutes for a bus.
```
```
Solution. Let X denote the number of minutes past 7 that the passenger arrives at
the stop. Since X is a uniform random variable over the interval (0, 30), it follows that
the passenger will have to wait less than 5 minutes if (and only if) he arrives between
7:10 and 7:15 or between 7:25 and 7:30. Hence, the desired probability for part (a) is
```
##### P { 10 < X < 15 }+ P { 25 < X < 30 }=

##### ∫ 15

```
10
```
##### 1

##### 30

```
dx +
```
##### ∫ 30

```
25
```
##### 1

##### 30

```
dx =
```
##### 1

##### 3

```
Similarly, he would have to wait more than 10 minutes if he arrives between 7 and
7:05 or between 7:15 and 7:20, so the probability for part (b) is
```
##### P { 0 < X < 5 }+ P { 15 < X < 20 }=

##### 1

##### 3

##### .


```
Section 5.3 The Uniform Random Variable 197
```
The next example was first considered by the French mathematician Joseph
L. F. Bertrand in 1889 and is often referred to as _Bertrand’s paradox_. It represents
our initial introduction to a subject commonly referred to as geometrical probability.

**_EXAMPLE 3d_**

Consider a random chord of a circle. What is the probability that the length of the
chord will be greater than the side of the equilateral triangle inscribed in that circle?

**_Solution._** As stated, the problem is incapable of solution because it is not clear what
is meant by a random chord. To give meaning to this phrase, we shall reformulate the
problem in two distinct ways.
The first formulation is as follows: The position of the chord can be determined
by its distance from the center of the circle. This distance can vary between 0 and
_r_ , the radius of the circle. Now, the length of the chord will be greater than the side
of the equilateral triangle inscribed in the circle if the distance from the chord to the
center of the circle is less than _r_ /2. Hence, by assuming that a random chord is a chord
whose distance _D_ from the center of the circle is uniformly distributed between 0 and
_r_ , we see that the probability that the length of the chord is greater than the side of
an inscribed equilateral triangle is

##### P

##### {

##### D <

```
r
2
```
##### }

##### =

```
r / 2
r
```
##### =

##### 1

##### 2

For our second formulation of the problem, consider an arbitrary chord of the cir-
cle; through one end of the chord, draw a tangent. The angleθbetween the chord and
the tangent, which can vary from 0◦to 180◦, determines the position of the chord. (See
Figure 5.4.) Furthermore, the length of the chord will be greater than the side of the
inscribed equilateral triangle if the angleθis between 60◦and 120◦. Hence, assuming
that a random chord is a chord whose angleθis uniformly distributed between 0◦and
180 ◦, we see that the desired answer in this formulation is

```
P { 60 <θ < 120 }=
```
##### 120 − 60

##### 180

##### =

##### 1

##### 3

Note that random experiments could be performed in such a way that^12 or^13 would
be the correct probability. For instance, if a circular disk of radius _r_ is thrown on a
table ruled with parallel lines a distance 2 _r_ apart, then one and only one of these lines
would cross the disk and form a chord. All distances from this chord to the center of
the disk would be equally likely, so that the desired probability that the chord’s length
will be greater than the side of an inscribed equilateral triangle is^12. In contrast, if the

```
A
```
```

```
```
FIGURE 5.4
```

**198** Chapter 5 Continuous Random Variables

```
experiment consisted of rotating a needle freely about a point A on the edge (see
Figure 5.4) of the circle, the desired answer would be^13..
```
### 5.4 Normal Random Variables

```
We say that X is a normal random variable, or simply that X is normally distributed,
with parametersμandσ^2 if the density of X is given by
```
```
f ( x )=
```
##### 1

##### √

```
2 πσ
```
```
e −( x −μ)
```
(^2) / 2 σ 2
−q< _x_ <q
This density function is a bell-shaped curve that is symmetric aboutμ. (See Figure 5.5.)
(b)

- 2

```
3
(a)
```
```
–3 –2 –1 0 1 2
```
```
.399
```
```
——–.399
```
```
+ 2
```
- +

```
FIGURE 5.5: Normal density function: (a)μ=0,σ=1; (b) arbitraryμ,σ^2.
```
```
The normal distribution was introduced by the French mathematician Abraham
DeMoivre in 1733, who used it to approximate probabilities associated with bino-
mial random variables when the binomial parameter n is large. This result was later
extended by Laplace and others and is now encompassed in a probability theorem
known as the central limit theorem, which is discussed in Chapter 8. The central limit
theorem, one of the two most important results in probability theory,†gives a theo-
retical base to the often noted empirical observation that, in practice, many random
phenomena obey, at least approximately, a normal probability distribution. Some
examples of random phenomena obeying this behavior are the height of a man, the
velocity in any direction of a molecule in gas, and the error made in measuring a
physical quantity.
To prove that f ( x )is indeed a probability density function, we need to show that
```
```
1
√
2 πσ
```
```
∫q
```
```
−q
```
```
e −( x −μ)
```
(^2) / 2 σ 2
_dx_ = 1
†The other is the strong law of large numbers.


```
Section 5.4 Normal Random Variables 199
```
Making the substitution _y_ =( _x_ −μ)/σ, we see that

```
1
√
2 πσ
```
```
∫q
```
```
−q
```
```
e −( x −μ)
```
(^2) / 2 σ 2
_dx_ =

##### 1

##### √

```
2 π
```
```
∫q
```
```
−q
```
```
e − y
```
(^2) / 2
_dy_
Hence, we must show that ∫
q
−q
_e_ − _y_
(^2) / 2
_dy_ =

##### √

```
2 π
```
Toward this end, let _I_ =

```
∫q
−q e
```
− _y_^2 / (^2) _dy_. Then

##### I^2 =

```
∫q
```
```
−q
```
```
e − y
```
(^2) / 2
_dy_
∫q
−q
_e_ − _x_
(^2) / 2
_dx_

##### =

```
∫q
```
```
−q
```
```
∫q
```
```
−q
```
```
e −( y
```
(^2) + _x_ (^2) )/ 2
_dy dx_
We now evaluate the double integral by means of a change of variables to polar
coordinates. (That is, let _x_ = _r_ cosθ, _y_ = _r_ sinθ,and _dy dx_ = _rd_ θ _dr_ .) Thus,

##### I^2 =

```
∫q
```
```
0
```
```
∫ 2 π
```
```
0
```
```
e − r
```
(^2) / 2
_rd_ θ _dr_
= 2 π
∫q
0
_re_ − _r_
(^2) / 2
_dr_
=− 2 π _e_ − _r_
(^2) / 2 ∣∣q
0
= 2 π
Hence, _I_ =

##### √

2 π, and the result is proved.
An important fact about normal random variables is that if _X_ is normally dis-
tributed with parametersμandσ^2 ,then _Y_ = _aX_ + _b_ is normally distributed with
parameters _a_ μ+ _b_ and _a_^2 σ^2. To prove this statement, suppose that _a_ >0. (The proof
when _a_ <0 is similar.) Let _FY_ denote the cumulative distribution function of _Y_. Then

```
FY ( x )= P { Y ... x }
= P { aX + b ... x }
```
```
= P { X ...
```
```
x − b
a
```
##### }

##### = FX (

```
x − b
a
```
##### )

where _FX_ is the cumulative distribution function of _X_. By differentiation, the density
function of _Y_ is then

```
fY ( x )=
```
##### 1

```
a
```
```
fX (
```
```
x − b
a
```
##### )

##### =

##### 1

##### √

```
2 π a σ
```
```
exp{−(
```
```
x − b
a
```
```
−μ)^2 / 2 σ^2 }
```
##### =

##### 1

##### √

```
2 π a σ
```
```
exp{−( x − b − a μ)^2 / 2 ( a σ)^2 }
```
which shows that _Y_ is normal with parameters _a_ μ+ _b_ and _a_^2 σ^2.


**200** Chapter 5 Continuous Random Variables

```
An important implication of the preceding result is that if X is normally distributed
with parametersμandσ^2 ,then Z =( X −μ)/σis normally distributed with parame-
ters 0 and 1. Such a random variable is said to be a standard ,ora unit , normal random
variable.
We now show that the parametersμandσ^2 of a normal random variable represent,
respectively, its expected value and variance.
```
```
EXAMPLE 4a
Find E [ X ] and Var( X )when X is a normal random variable with parametersμandσ^2.
```
```
Solution. Let us start by finding the mean and variance of the standard normal ran-
dom variable Z =( X −μ)/σ. We have
```
##### E [ Z ]=

```
∫q
```
```
−q
```
```
xfZ ( x ) dx
```
##### =

##### 1

##### √

```
2 π
```
```
∫q
```
```
−q
```
```
xe − x
```
(^2) / 2
_dx_

##### =−

##### 1

##### √

```
2 π
```
```
e − x
```
(^2) / 2
|q−q
= 0
Thus,
Var( _Z_ )= _E_ [ _Z_^2 ]
=

##### 1

##### √

```
2 π
```
```
∫q
```
```
−q
```
```
x^2 e − x
```
(^2) / 2
_dx_
Integration by parts (with _u_ = _x_ and _dv_ = _xe_ − _x_
(^2) / 2
)now gives
Var( _Z_ )=

##### 1

##### √

```
2 π
```
```
(− xe − x
```
(^2) / 2
|q−q+
∫q
−q
_e_ − _x_
(^2) / 2
_dx_ )

##### =

##### 1

##### √

```
2 π
```
```
∫q
```
```
−q
```
```
e − x
```
(^2) / 2
_dx_
= 1
Because _X_ =μ+σ _Z_ , the preceding yields the results
_E_ [ _X_ ]=μ+σ _E_ [ _Z_ ]=μ
and
Var( _X_ )=σ^2 Var( _Z_ )=σ^2.
It is customary to denote the cumulative distribution function of a standard normal
random variable by
( _x_ ). That is,

( _x_ )=

##### 1

##### √

```
2 π
```
```
∫ x
```
```
−q
```
```
e − y
```
(^2) / 2
_dy_
The values of
( _x_ )for nonnegative _x_ are given in Table 5.1. For negative values of _x_ ,

( _x_ )can be obtained from the relationship

(− _x_ )= 1 −
( _x_ ) −q< _x_ <q (4.1)


```
Section 5.4 Normal Random Variables 201
```
```
TABLE 5.1: AREA
( x )UNDER THE STANDARD NORMAL CURVE TO THE LEFT OF X
```
_X_ .00 .01 .02 .03 .04 .05 .06 .07 .08 .09

.0 .5000 .5040 .5080 .5120 .5160 .5199 .5239 .5279 .5319 .5359
.1 .5398 .5438 .5478 .5517 .5557 .5596 .5636 .5675 .5714 .5753
.2 .5793 .5832 .5871 .5910 .5948 .5987 .6026 .6064 .6103 .6141
.3 .6179 .6217 .6255 .6293 .6331 .6368 .6406 .6443 .6480 .6517
.4 .6554 .6591 .6628 .6664 .6700 .6736 .6772 .6808 .6844 .6879
.5 .6915 .6950 .6985 .7019 .7054 .7088 .7123 .7157 .7190 .7224
.6 .7257 .7291 .7324 .7357 .7389 .7422 .7454 .7486 .7517 .7549
.7 .7580 .7611 .7642 .7673 .7704 .7734 .7764 .7794 .7823 .7852
.8 .7881 .7910 .7939 .7967 .7995 .8023 .8051 .8078 .8106 .8133
.9 .8159 .8186 .8212 .8238 .8264 .8289 .8315 .8340 .8365 .8389
1.0 .8413 .8438 .8461 .8485 .8508 .8531 .8554 .8577 .8599 .8621
1.1 .8643 .8665 .8686 .8708 .8729 .8749 .8770 .8790 .8810 .8830
1.2 .8849 .8869 .8888 .8907 .8925 .8944 .8962 .8980 .8997 .9015
1.3 .9032 .9049 .9066 .9082 .9099 .9115 .9131 .9147 .9162 .9177
1.4 .9192 .9207 .9222 .9236 .9251 .9265 .9279 .9292 .9306 .9319
1.5 .9332 .9345 .9357 .9370 .9382 .9394 .9406 .9418 .9429 .9441
1.6 .9452 .9463 .9474 .9484 .9495 .9505 .9515 .9525 .9535 .9545
1.7 .9554 .9564 .9573 .9582 .9591 .9599 .9608 .9616 .9625 .9633
1.8 .9641 .9649 .9656 .9664 .9671 .9678 .9686 .9693 .9699 .9706
1.9 .9713 .9719 .9726 .9732 .9738 .9744 .9750 .9756 .9761 .9767
2.0 .9772 .9778 .9783 .9788 .9793 .9798 .9803 .9808 .9812 .9817
2.1 .9821 .9826 .9830 .9834 .9838 .9842 .9846 .9850 .9854 .9857
2.2 .9861 .9864 .9868 .9871 .9875 .9878 .9881 .9884 .9887 .9890
2.3 .9893 .9896 .9898 .9901 .9904 .9906 .9909 .9911 .9913 .9916
2.4 .9918 .9920 .9922 .9925 .9927 .9929 .9931 .9932 .9934 .9936
2.5 .9938 .9940 .9941 .9943 .9945 .9946 .9948 .9949 .9951 .9952
2.6 .9953 .9955 .9956 .9957 .9959 .9960 .9961 .9962 .9963 .9964
2.7 .9965 .9966 .9967 .9968 .9969 .9970 .9971 .9972 .9973 .9974
2.8 .9974 .9975 .9976 .9977 .9977 .9978 .9979 .9979 .9980 .9981
2.9 .9981 .9982 .9982 .9983 .9984 .9984 .9985 .9985 .9986 .9986
3.0 .9987 .9987 .9987 .9988 .9988 .9989 .9989 .9989 .9990 .9990
3.1 .9990 .9991 .9991 .9991 .9992 .9992 .9992 .9992 .9993 .9993
3.2 .9993 .9993 .9994 .9994 .9994 .9994 .9994 .9995 .9995 .9995
3.3 .9995 .9995 .9995 .9996 .9996 .9996 .9996 .9996 .9996 .9997
3.4 .9997 .9997 .9997 .9997 .9997 .9997 .9997 .9997 .9997 .9998

The proof of Equation (4.1), which follows from the symmetry of the standard nor-
mal density, is left as an exercise. This equation states that if _Z_ is a standard normal
random variable, then

```
P { Z ...− x }= P { Z > x }−q< x <q
```
Since _Z_ =( _X_ −μ)/σis a standard normal random variable whenever _X_ is normally
distributed with parametersμandσ^2 , it follows that the distribution function of _X_
can be expressed as

```
FX ( a )= P { X ... a }= P
```
##### (

```
X −μ
σ
```
##### ...

```
a −μ
σ
```
##### )

##### =

##### (

```
a −μ
σ
```
##### )


**202** Chapter 5 Continuous Random Variables

```
EXAMPLE 4b
If X is a normal random variable with parametersμ=3andσ^2 =9, find (a) P { 2 <
X < 5 };(b) P { X > 0 }; (c) P {| X − 3 |> 6 }.
```
```
Solution. (a)
```
##### P { 2 < X < 5 }= P

##### {

##### 2 − 3

##### 3

##### <

##### X − 3

##### 3

##### <

##### 5 − 3

##### 3

##### }

##### = P

##### {

##### −

##### 1

##### 3

##### < Z <

##### 2

##### 3

##### }

##### =

##### (

##### 2

##### 3

##### )

##### −

##### (

##### −

##### 1

##### 3

##### )

##### =

##### (

##### 2

##### 3

##### )

##### −

##### [

##### 1 −

##### (

##### 1

##### 3

##### )]

##### L. 3779

```
(b)
```
##### P { X > 0 }= P

##### {

##### X − 3

##### 3

##### >

##### 0 − 3

##### 3

##### }

##### = P { Z >− 1 }

##### = 1 −
(− 1 )

##### =
( 1 )

##### L. 8413

```
(c)
```
```
P {| X − 3 |> 6 }= P { X > 9 }+ P { X <− 3 }
```
```
= P
```
##### {

##### X − 3

##### 3

##### >

##### 9 − 3

##### 3

##### }

##### + P

##### {

##### X − 3

##### 3

##### <

##### − 3 − 3

##### 3

##### }

##### = P { Z > 2 }+ P { Z <− 2 }

##### = 1 −
( 2 )+
(− 2 )

##### =2[1−
( 2 )]

##### L. 0456

##### .

```
EXAMPLE 4c
An examination is frequently regarded as being good (in the sense of determining
a valid grade spread for those taking it) if the test scores of those taking the exami-
nation can be approximated by a normal density function. (In other words, a graph
of the frequency of grade scores should have approximately the bell-shaped form of
the normal density.) The instructor often uses the test scores to estimate the normal
parametersμandσ^2 and then assigns the letter grade A to those whose test score
is greater thanμ+σ, B to those whose score is betweenμandμ+σ, C to those
whose score is betweenμ− σandμ, D to those whose score is betweenμ− 2 σ
andμ−σ, and F to those getting a score belowμ− 2 σ. (This strategy is sometimes
referred to as grading “on the curve.”) Since
```

```
Section 5.4 Normal Random Variables 203
```
```
P { X >μ+σ}= P
```
##### {

```
X −μ
σ
```
##### > 1

##### }

##### = 1 −
( 1 )L. 1587

```
P {μ< X <μ+σ}= P
```
##### {

##### 0 <

```
X −μ
σ
```
##### < 1

##### }

##### =
( 1 )−
( 0 )L. 3413

```
P {μ−σ< X <μ}= P
```
##### {

##### − 1 <

```
X −μ
σ
```
##### < 0

##### }

##### =
( 0 )−
(− 1 )L. 3413

```
P {μ− 2 σ< X <μ−σ}= P
```
##### {

##### − 2 <

```
X −μ
σ
```
##### <− 1

##### }

##### =
( 2 )−
( 1 )L. 1359

```
P { X <μ− 2 σ}= P
```
##### {

```
X −μ
σ
```
##### <− 2

##### }

##### =
(− 2 )L. 0228

it follows that approximately 16 percent of the class will receive an A grade on the
examination, 34 percent a B grade, 34 percent a C grade, and 14 percent a D grade; 2
percent will fail..

**_EXAMPLE 4d_**

An expert witness in a paternity suit testifies that the length (in days) of human ges-
tation is approximately normally distributed with parametersμ=270 andσ^2 =100.
The defendant in the suit is able to prove that he was out of the country during a
period that began 290 days before the birth of the child and ended 240 days before
the birth. If the defendant was, in fact, the father of the child, what is the probability
that the mother could have had the very long or very short gestation indicated by the
testimony?

**_Solution._** Let _X_ denote the length of the gestation, and assume that the defendant
is the father. Then the probability that the birth could occur within the indicated
period is

```
P { X >290or X < 240 }= P { X > 290 }+ P { X < 240 }
```
```
= P
```
##### {

##### X − 270

##### 10

##### > 2

##### }

##### + P

##### {

##### X − 270

##### 10

##### <− 3

##### }

##### = 1 −
( 2 )+ 1 −
( 3 )

##### L. 0241

##### .

**_EXAMPLE 4e_**

Suppose that a binary message—either 0 or 1—must be transmitted by wire from
location _A_ to location _B_. However, the data sent over the wire are subject to a channel
noise disturbance, so, to reduce the possibility of error, the value 2 is sent over the
wire when the message is 1 and the value−2 is sent when the message is 0. If _x_ , _x_ =;2,
is the value sent at location _A_ ,then _R_ , the value received at location _B_ , is given by
_R_ = _x_ + _N_ , where _N_ is the channel noise disturbance. When the message is received
at location _B_ , the receiver decodes it according to the following rule:

```
If R Ú.5, then 1 is concluded.
If R <.5, then 0 is concluded.
```

**204** Chapter 5 Continuous Random Variables

```
Because the channel noise is often normally distributed, we will determine the error
probabilities when N is a standard normal random variable.
Two types of errors can occur: One is that the message 1 can be incorrectly deter-
mined to be 0, and the other is that 0 can be incorrectly determined to be 1. The first
type of error will occur if the message is 1 and 2+ N <.5, whereas the second will
occur if the message is 0 and− 2 + N Ú.5. Hence,
```
```
P {error|message is 1}= P { N <− 1. 5 }
= 1 −
( 1. 5 )L. 0668
```
```
and
```
```
P {error|message is 0}= P { N Ú 2. 5 }
= 1 −
( 2. 5 )L. 0062
```
#### 5.4.1 The Normal Approximation to the Binomial Distribution

```
An important result in probability theory known as the DeMoivre–Laplace limit the-
orem states that when n is large, a binomial random variable with parameters n and p
will have approximately the same distribution as a normal random variable with the
same mean and variance as the binomial. This result was proved originally for the spe-
cial case of p =^12 by DeMoivre in 1733 and was then extended to general p by Laplace
in 1812. It formally states that if we “standardize” the binomial by first subtracting its
mean np and then dividing the result by its standard deviation
```
##### √

```
np ( 1 − p ), then the
distribution function of this standardized random variable (which has mean 0 and
variance 1) will converge to the standard normal distribution function as n →q.
```
```
The DeMoivre–Laplace limit theorem
```
```
If Sn denotes the number of successes that occur when n independent trials, each
resulting in a success with probability p , are performed, then, for any a < b ,
```
##### P

##### {

```
a ...
```
```
Sn − np
√
np ( 1 − p )
```
```
... b
```
##### }

```
→
( b )−
( a )
```
```
as n →q.
```
```
Because the preceding theorem is only a special case of the central limit theorem,
which is presented in Chapter 8, we shall not present a proof.
Note that we now have two possible approximations to binomial probabilities: the
Poisson approximation, which is good when n is large and p is small, and the normal
approximation, which can be shown to be quite good when np ( 1 − p )is large. (See
Figure 5.6.) [The normal approximation will, in general, be quite good for values of n
satisfying np ( 1 − p )Ú10.]
```
```
EXAMPLE 4f
Let X be the number of times that a fair coin that is flipped 40 times lands on heads.
Find the probability that X =20. Use the normal approximation and then compare
it with the exact solution.
```

```
Section 5.4 Normal Random Variables 205
```
```
0246
```
```
(10, 0.7)
```
```
810 0
```
```
0.0 05
```
```
0.02
```
```
0.04
```
```
0.06
```
```
0.08
```
```
0.10
```
```
0.12
```
```
0.14
```
```
0.16
```
```
0.0
```
```
0.14
0.12
0.10
0.08
0.06
0.04
0.02
```
```
0.0
```
```
0.30
0.25
0.20
0.15
0.10
0.05
0.0
```
```
0.20
```
```
0.15
```
```
0.10
```
```
0.05
```
```
10 15
```
```
(30, 0.7)
```
```
20 25 30 0 10 20
```
```
(50, 0.7)
```
```
30 40 50
```
```
510
```
```
(20, 0.7)
```
```
x
```
```
xx
```
```
x
```
```
15 20
```
**FIGURE 5.6:** The probability mass function of a binomial ( _n_ , _p_ ) random variable becomes more and more
“normal” as _n_ becomes larger and larger.

**_Solution._** To employ the normal approximation, note that because the binomial is
a discrete integer-valued random variable, whereas the normal is a continuous ran-
dom variable, it is best to write _P_ { _X_ = _i_ }as _P_ { _i_ − 1 / 2 < _X_ < _i_ + 1 / 2 }before
applying the normal approximation (this is called the _continuity correction_ ). Doing
so gives

```
P { X = 20 }= P { 19. 5 ... X < 20. 5 }
```
##### = P

##### {

##### 19. 5 − 20

##### √

##### 10

##### <

##### X − 20

##### √

##### 10

##### <

##### 20. 5 − 20

##### √

##### 10

##### }

##### L P

##### {

##### −. 16 <

##### X − 20

##### √

##### 10

##### <. 16

##### }

##### L
(. 16 )−
(−. 16 )L. 1272

The exact result is

```
P { X = 20 }=
```
##### (

##### 40

##### 20

##### )(

##### 1

##### 2

##### ) 40

L. (^1254).
**_EXAMPLE 4g_**
The ideal size of a first-year class at a particular college is 150 students. The college,
knowing from past experience that, on the average, only 30 percent of those accepted
for admission will actually attend, uses a policy of approving the applications of 450
students. Compute the probability that more than 150 first-year students attend this
college.
**_Solution._** If _X_ denotes the number of students that attend, then _X_ is a binomial ran-
dom variable with parameters _n_ =450 and _p_ =.3. Using the continuity correction,


**206** Chapter 5 Continuous Random Variables

```
we see that the normal approximation yields
```
##### P { X Ú 150. 5 }= P

##### {

##### X −( 450 )(. 3 )

##### √

##### 450 (. 3 )(. 7 )

##### Ú

##### 150. 5 −( 450 )(. 3 )

##### √

##### 450 (. 3 )(. 7 )

##### }

##### L 1 −
( 1. 59 )

##### L. 0559

```
Hence, less than 6 percent of the time do more than 150 of the first 450 accepted
actually attend. (What independence assumptions have we made?).
```
```
EXAMPLE 4h
To determine the effectiveness of a certain diet in reducing the amount of cholesterol
in the bloodstream, 100 people are put on the diet. After they have been on the diet
for a sufficient length of time, their cholesterol count will be taken. The nutritionist
running this experiment has decided to endorse the diet if at least 65 percent of the
people have a lower cholesterol count after going on the diet. What is the probability
that the nutritionist endorses the new diet if, in fact, it has no effect on the cholesterol
level?
```
```
Solution. Let us assume that if the diet has no effect on the cholesterol count, then,
strictly by chance, each person’s count will be lower than it was before the diet with
probability^12. Hence, if X is the number of people whose count is lowered, then the
probability that the nutritionist will endorse the diet when it actually has no effect on
the cholesterol count is
∑^100
```
```
i = 65
```
##### (

##### 100

```
i
```
##### )(

##### 1

##### 2

##### ) 100

##### = P { X Ú 64. 5 }

##### = P

##### ⎧

##### ⎪⎨

##### ⎪⎩

##### X −( 100 )(^12 )

##### √

##### 100 (^12 )(^12 )

##### Ú 2. 9

##### ⎫

##### ⎪⎬

##### ⎪⎭

##### L 1 −
( 2. 9 )

##### L. 0019.

```
EXAMPLE 4i
Fifty-two percent of the residents of New York City are in favor of outlawing cigarette
smoking in publicly owned areas. Approximate the probability that more than 50
percent of a random sample of n people from New York are in favor of this prohibi-
tion when
(a) n = 11
(b) n = 101
(c) n = 1001
How large would n have to be to make this probability exceed .95?
```
```
Solution. Let N denote the number of residents of New York City. To answer the
preceding question, we must first understand that a random sample of size n is a
sample such that the n people were chosen in such a manner that each of the
```
##### (

##### N

```
n
```
##### )

```
subsets of n people had the same chance of being the chosen subset. Consequently,
```

```
Section 5.4 Normal Random Variables 207
```
_Sn_ , the number of people in the sample who are in favor of the smoking prohibition,
is a hypergeometric random variable. That is, _Sn_ has the same distribution as the
number of white balls obtained when _n_ balls are chosen from an urn of _N_ balls, of
which .52 _N_ are white. But because _N_ and .52 _N_ are both large in comparison with the
sample size _n_ , it follows from the binomial approximation to the hypergeometric (see
Section 4.8.3) that the distribution of _Sn_ is closely approximated by a binomial dis-
tribution with parameters _n_ and _p_ =.52. The normal approximation to the binomial
distribution then shows that

```
P { Sn >. 5 n }= P
```
##### {

```
Sn −. 52 n
√
n (. 52 )(. 48 )
```
##### >

. 5 _n_ −. 52 _n_
√
_n_ (. 52 )(. 48 )

##### }

##### = P

##### {

```
Sn −. 52 n
√
n (. 52 )(. 48 )
```
##### >−. 04

##### √

```
n
```
##### }

##### L
(. 04

##### √

```
n )
```
```
Thus,
```
```
P { Sn >. 5 n }L
```
##### ⎧

##### ⎨

##### ⎩

```

(. 1328 )=.5528, if n = 11

(. 4020 )=.6562, if n = 101

( 1. 2665 )=.8973, if n = 1001
```
In order for this probability to be at least .95, we would need
(. 04

##### √

_n_ )>.95. Because

( _x_ )is an increasing function and
( 1. 645 )=.95, this means that

. 04

##### √

```
n > 1. 645
```
or
_n_ Ú 1691. 266

That is, the sample size would have to be at least 1692..

```
Historical Notes Concerning the Normal Distribution
```
```
The normal distribution was introduced by the French mathematician Abraham
DeMoivre in 1733. DeMoivre, who used this distribution to approximate proba-
bilities connected with coin tossing, called it the exponential bell-shaped curve. Its
usefulness, however, became truly apparent only in 1809, when the famous German
mathematician Karl Friedrich Gauss used it as an integral part of his approach to
predicting the location of astronomical entities. As a result, it became common after
this time to call it the Gaussian distribution.
During the mid- to late 19th century, however, most statisticians started to
believe that the majority of data sets would have histograms conforming to the
Gaussian bell-shaped form. Indeed, it came to be accepted that it was “normal”
for any well-behaved data set to follow this curve. As a result, following the lead of
the British statistician Karl Pearson, people began referring to the Gaussian curve
by calling it simply the normal curve. (A partial explanation as to why so many data
sets conform to the normal curve is provided by the central limit theorem, which is
presented in Chapter 8.)
```
```
Abraham DeMoivre (1667–1754)
Today there is no shortage of statistical consultants, many of whom ply their trade
in the most elegant of settings. However, the first of their breed worked, in the early
```

**208** Chapter 5 Continuous Random Variables

```
years of the 18th century, out of a dark, grubby betting shop in Long Acres, London,
known as Slaughter’s Coffee House. He was Abraham DeMoivre, a Protestant
refugee from Catholic France, and, for a price, he would compute the probability of
gambling bets in all types of games of chance.
Although DeMoivre, the discoverer of the normal curve, made his living at the
coffee shop, he was a mathematician of recognized abilities. Indeed, he was a mem-
ber of the Royal Society and was reported to be an intimate of Isaac Newton.
Listen to Karl Pearson imagining DeMoivre at work at Slaughter’s Coffee
House: “ I picture DeMoivre working at a dirty table in the coffee house with a broken-
down gambler beside him and Isaac Newton walking through the crowd to his corner
to fetch out his friend. It would make a great picture for an inspired artist .”
```
```
Karl Friedrich Gauss
Karl Friedrich Gauss (1777–1855), one of the earliest users of the normal curve,
was one of the greatest mathematicians of all time. Listen to the words of the
well-known mathematical historian E. T. Bell, as expressed in his 1954 book Men
of Mathematics : In a chapter entitled “The Prince of Mathematicians,” he writes,
“ Archimedes, Newton, and Gauss; these three are in a class by themselves among
the great mathematicians, and it is not for ordinary mortals to attempt to rank them
in order of merit. All three started tidal waves in both pure and applied mathemat-
ics. Archimedes esteemed his pure mathematics more highly than its applications;
Newton appears to have found the chief justification for his mathematical inventions
in the scientific uses to which he put them; while Gauss declared it was all one to him
whether he worked on the pure or on the applied side .”‡
```
### 5.5 Exponential Random Variables

```
A continuous random variable whose probability density function is given, for some
λ>0, by
```
```
f ( x )=
```
##### {

```
λ e −λ x if x Ú 0
0if x < 0
```
```
is said to be an exponential random variable (or, more simply, is said to be exponen-
tially distributed) with parameterλ. The cumulative distribution function F ( a )of an
exponential random variable is given by
```
```
F ( a )= P { X ... a }
```
```
=
```
```
∫ a
```
```
0
```
```
λ e −λ xdx
```
```
=− e −λ x
```
##### ∣

```
∣ a
0
= 1 − e −λ a a Ú 0
```
```
Note that F (q)=
```
```
∫q
0 λ e
```
```
−λ xdx =1, as, of course, it must. The parameterλwill now
be shown to equal the reciprocal of the expected value.
```
```
EXAMPLE 5a
Let X be an exponential random variable with parameterλ. Calculate (a) E [ X ]and
(b) Var( X ).
```

```
Section 5.5 Exponential Random Variables 209
```
**_Solution._** (a) Since the density function is given by

```
f ( x )=
```
##### {

```
λ e −λ x x Ú 0
0 x < 0
```
we obtain, for _n_ >0,

```
E [ Xn ]=
```
```
∫q
```
```
0
```
```
xn λ e −λ xdx
```
Integrating by parts (withλ _e_ −λ _x_ = _dv_ and _u_ = _xn_ ) yields

```
E [ Xn ]=− xne −λ x |q 0 +
```
```
∫q
```
```
0
```
```
e −λ xnxn −^1 dx
```
##### = 0 +

```
n
λ
```
```
∫q
```
```
0
```
```
λ e −λ xxn −^1 dx
```
##### =

```
n
λ
```
```
E [ Xn −^1 ]
```
Letting _n_ =1andthen _n_ =2 gives

##### E [ X ]=

##### 1

```
λ
E [ X^2 ]=
```
##### 2

```
λ
```
##### E [ X ]=

##### 2

```
λ^2
```
(b) Hence,

```
Var( X )=
```
##### 2

```
λ^2
```
##### −

##### (

##### 1

```
λ
```
##### ) 2

##### =

##### 1

```
λ^2
```
Thus, the mean of the exponential is the reciprocal of its parameterλ, and the vari-
ance is the mean squared..

In practice, the exponential distribution often arises as the distribution of the
amount of time until some specific event occurs. For instance, the amount of time
(starting from now) until an earthquake occurs, or until a new war breaks out, or
until a telephone call you receive turns out to be a wrong number are all random
variables that tend in practice to have exponential distributions. (For a theoretical
explanation of this phenomenon, see Section 4.7.)

**_EXAMPLE 5b_**

Suppose that the length of a phone call in minutes is an exponential random variable
with parameterλ= 101. If someone arrives immediately ahead of you at a public
telephone booth, find the probability that you will have to wait

```
(a) more than 10 minutes;
(b) between 10 and 20 minutes.
```
**_Solution._** Let _X_ denote the length of the call made by the person in the booth. Then
the desired probabilities are

```
(a)
```
```
P { X > 10 }= 1 − F ( 10 )
= e −^1 L. 368
```

**210** Chapter 5 Continuous Random Variables

```
(b)
```
```
P { 10 < X < 20 }= F ( 20 )− F ( 10 )
```
= _e_ −^1 − _e_ −^2 L. (^233).
We say that a nonnegative random variable _X_ is _memoryless_ if
_P_ { _X_ > _s_ + _t_ | _X_ > _t_ }= _P_ { _X_ > _s_ } for all _s_ , _t_ Ú 0 (5.1)
If we think of _X_ as being the lifetime of some instrument, Equation (5.1) states that
the probability that the instrument survives for at least _s_ + _t_ hours, given that it has
survived _t_ hours, is the same as the initial probability that it survives for at least _s_
hours. In other words, if the instrument is alive at age _t_ , the distribution of the remain-
ing amount of time that it survives is the same as the original lifetime distribution.
(That is, it is as if the instrument does not “remember” that it has already been in use
foratime _t_ .)
Equation (5.1) is equivalent to
_P_ { _X_ > _s_ + _t_ , _X_ > _t_ }
_P_ { _X_ > _t_ }
= _P_ { _X_ > _s_ }
or
_P_ { _X_ > _s_ + _t_ }= _P_ { _X_ > _s_ } _P_ { _X_ > _t_ } (5.2)
Since Equation (5.2) is satisfied when _X_ is exponentially distributed (for _e_ −λ( _s_ + _t_ )=
_e_ −λ _se_ −λ _t_ ), it follows that exponentially distributed random variables are memoryless.
**_EXAMPLE 5c_**
Consider a post office that is staffed by two clerks. Suppose that when Mr. Smith
enters the system, he discovers that Ms. Jones is being served by one of the clerks
and Mr. Brown by the other. Suppose also that Mr. Smith is told that his service will
begin as soon as either Ms. Jones or Mr. Brown leaves. If the amount of time that
a clerk spends with a customer is exponentially distributed with parameterλ, what
is the probability that, of the three customers, Mr. Smith is the last to leave the post
office?
**_Solution._** The answer is obtained by reasoning as follows: Consider the time at which
Mr. Smith first finds a free clerk. At this point, either Ms. Jones or Mr. Brown would
have just left, and the other one would still be in service. However, because the expo-
nential is memoryless, it follows that the additional amount of time that this other
person (either Ms. Jones or Mr. Brown) would still have to spend in the post office is
exponentially distributed with parameterλ. That is, it is the same as if service for that
person were just starting at this point. Hence, by symmetry, the probability that the
remaining person finishes before Smith leaves must equal^12..
It turns out that not only is the exponential distribution memoryless, but it is also
the unique distribution possessing this property. To see this, suppose that _X_ is mem-
oryless and let _F_ ( _x_ )= _P_ { _X_ > _x_ }. Then, by Equation (5.2),
_F_ ( _s_ + _t_ )= _F_ ( _s_ ) _F_ ( _t_ )
That is, _F_ (·)satisfies the functional equation
_g_ ( _s_ + _t_ )= _g_ ( _s_ ) _g_ ( _t_ )


```
Section 5.5 Exponential Random Variables 211
```
However, it turns out that the only right continuous solution of this functional
equation is†
_g_ ( _x_ )= _e_ −λ _x_ (5.3)

and, since a distribution function is always right continuous, we must have

```
F ( x )= e −λ x or F ( x )= P { X ... x }= 1 − e −λ x
```
which shows that _X_ is exponentially distributed.

**_EXAMPLE 5d_**

Suppose that the number of miles that a car can run before its battery wears out is
exponentially distributed with an average value of 10,000 miles. If a person desires to
take a 5000-mile trip, what is the probability that he or she will be able to complete the
trip without having to replace the car battery? What can be said when the distribution
is not exponential?

**_Solution._** It follows by the memoryless property of the exponential distribution that
the remaining lifetime (in thousands of miles) of the battery is exponential with
parameterλ= 101. Hence, the desired probability is

```
P {remaining lifetime> 5 }= 1 − F ( 5 )= e −^5 λ= e −^1 /^2 L. 604
```
However, if the lifetime distribution _F_ is not exponential, then the relevant probabil-
ity is

```
P {lifetime> t + 5 |lifetime> t }=
```
```
1 − F ( t + 5 )
1 − F ( t )
```
where _t_ is the number of miles that the battery had been in use prior to the start of
the trip. Therefore, if the distribution is not exponential, additional information is
needed (namely, the value of _t_ ) before the desired probability can be calculated..

A variation of the exponential distribution is the distribution of a random variable
that is equally likely to be either positive or negative and whose absolute value is
exponentially distributed with parameterλ,λ# Ú0. Such a random variable is said to
have a _Laplace_ distribution,‡and its density is given by

```
f ( x )=
```
##### 1

##### 2

```
λ e −λ| x | −q< x <q
```
```
†One can prove Equation (5.3) as follows: If g ( s + t )= g ( s ) g ( t ),then
```
```
g
```
```
(
2
n
```
```
)
= g
```
```
(
1
n
```
```
+
1
n
```
```
)
= g^2
```
```
(
1
n
```
```
)
```
and repeating this yields _g_ ( _m_ / _n_ )= _gm_ ( 1 / _n_ ).Also,

```
g ( 1 )= g
```
```
(
1
n
+
```
```
1
n
+ ··· +
```
```
1
n
```
```
)
= gn
```
```
(
1
n
```
```
)
or g
```
```
(
1
n
```
```
)
=( g ( 1 ))^1 / n
```
```
Hence, g ( m / n ) =( g ( 1 )) m / n ,which,since g is right continuous, implies that g ( x ) =( g ( 1 )) x.
```
Because _g_ ( 1 )=

```
(
g
```
```
(
1
2
```
```
)) 2
Ú0, we obtain g ( x )= e −λ x ,whereλ=−log( g ( 1 )).
‡It also is sometimes called the double exponential random variable.
```

**212** Chapter 5 Continuous Random Variables

```
Its distribution function is given by
```
```
F ( x )=
```
##### ⎧

##### ⎪⎪

##### ⎪⎪

##### ⎨

##### ⎪⎪

##### ⎪⎪

##### ⎩

```
1
2
```
```
∫ x
```
```
−q
```
```
λ e λ xdx x < 0
```
```
1
2
```
##### ∫ 0

```
−q
```
```
λ e λ xdx +
```
##### 1

##### 2

```
∫ x
```
```
0
```
```
λ e −λ xdx x > 0
```
##### =

##### ⎧

##### ⎨

##### ⎩

```
1
2 e
```
```
λ x x < 0
```
```
1 −^12 e −λ x x > 0
```
```
EXAMPLE 5e
Consider again Example 4e, which supposes that a binary message is to be transmit-
ted from A to B , with the value 2 being sent when the message is 1 and−2 when it is
```
0. However, suppose now that, rather than being a standard normal random variable,
the channel noise _N_ is a Laplacian random variable with parameterλ=1. Suppose
again that if _R_ is the value received at location _B_ , then the message is decoded as
follows:
    If _R_ Ú.5, then 1 is concluded.
    If _R_ <.5, then 0 is concluded.
In this case, where the noise is Laplacian with parameterλ=1, the two types of
errors will have probabilities given by

```
P {error|message 1 is sent}= P { N <− 1. 5 }
```
```
=
```
##### 1

##### 2

```
e −^1.^5
```
```
L. 1116
P {error|message 0 is sent}= P { N Ú 2. 5 }
```
```
=
```
##### 1

##### 2

```
e −^2.^5
```
```
L. 041
```
```
On comparing this with the results of Example 4e, we see that the error probabilities
are higher when the noise is Laplacian withλ=1 than when it is a standard normal
variable.
```
#### 5.5.1 Hazard Rate Functions.......................

```
Consider a positive continuous random variable X that we interpret as being the
lifetime of some item. Let X have distribution function F and density f. The hazard
rate (sometimes called the failure rate ) functionλ( t )of F is defined by
```
```
λ( t )=
```
```
f ( t )
F ( t )
```
```
, where F = 1 − F
```
```
To interpretλ( t ), suppose that the item has survived for a time t and we desire the
probability that it will not survive for an additional time dt. That is, consider P { X ∈
( t , t + dt )| X > t }. Now,
```

```
Section 5.5 Exponential Random Variables 213
```
```
P { X ∈( t , t + dt )| X > t }=
```
```
P { X ∈( t , t + dt ), X > t }
P { X > t }
```
```
=
```
```
P { X ∈( t , t + dt )}
P { X > t }
```
```
L
```
```
f ( t )
F ( t )
```
```
dt
```
Thus,λ( _t_ )represents the conditional probability intensity that a _t_ -unit-old item will fail.
Suppose now that the lifetime distribution is exponential. Then, by the memoryless
property, it follows that the distribution of remaining life for a _t_ -year-old item is the
same as that for a new item. Hence,λ( _t_ )should be constant. In fact, this checks out,
since

```
λ( t )=
```
```
f ( t )
F ( t )
```
```
=
```
```
λ e −λ t
e −λ t
=λ
```
Thus, the failure rate function for the exponential distribution is constant. The param-
eterλis often referred to as the _rate_ of the distribution.
It turns out that the failure rate functionλ( _t_ )uniquely determines the distribu-
tion _F_. To prove this, note that, by definition,

```
λ( t )=
```
```
d
dtF ( t )
1 − F ( t )
```
Integrating both sides yields

```
log( 1 − F ( t ))=−
```
```
∫ t
```
```
0
```
```
λ( t ) dt + k
```
or

```
1 − F ( t )= ek exp
```
##### {

##### −

```
∫ t
```
```
0
```
```
λ( t ) dt
```
##### }

Letting _t_ =0 shows that _k_ =0; thus,

```
F ( t )= 1 −exp
```
##### {

##### −

```
∫ t
```
```
0
```
```
λ( t ) dt
```
##### }

##### (5.4)

Hence, a distribution function of a positive continuous random variable can be
specified by giving its hazard rate function. For instance, if a random variable has a
linear hazard rate function—that is, if

```
λ( t )= a + bt
```
then its distribution function is given by

```
F ( t )= 1 − e − at − bt
```
(^2) / 2
and differentiation yields its density, namely,


**214** Chapter 5 Continuous Random Variables

```
f ( t )=( a + bt ) e −( at + bt
```
(^2) / 2 )
_t_ Ú 0
When _a_ =0, the preceding equation is known as the _Rayleigh density function_.
**_EXAMPLE 5f_**
One often hears that the death rate of a person who smokes is, at each age, twice that
of a nonsmoker. What does this mean? Does it mean that a nonsmoker has twice the
probability of surviving a given number of years as does a smoker of the same age?
**_Solution._** Ifλ _s_ ( _t_ )denotes the hazard rate of a smoker of age _t_ andλ _n_ ( _t_ )that of a
nonsmoker of age _t_ , then the statement at issue is equivalent to the statement that
λ _s_ ( _t_ )= 2 λ _n_ ( _t_ )
The probability that an _A_ -year-old nonsmoker will survive until age _B_ , _A_ < _B_ ,is
_P_ { _A_ -year-old nonsmoker reaches age _B_ }
= _P_ {nonsmoker’s lifetime> _B_ |nonsmoker’s lifetime> _A_ }
=
1 − _F_ non( _B_ )
1 − _F_ non( _A_ )

##### =

```
exp
```
##### {

##### −

##### ∫ B

```
0
```
```
λ n ( t ) dt
```
##### }

```
exp
```
##### {

##### −

##### ∫ A

```
0
```
```
λ n ( t ) dt
```
```
} from( 5. 4 )
```
```
=exp
```
##### {

##### −

##### ∫ B

```
A
```
```
λ n ( t ) dt
```
##### }

```
whereas the corresponding probability for a smoker is, by the same reasoning,
```
```
P { A -year-old smoker reaches age B }=exp
```
##### {

##### −

##### ∫ B

```
A
```
```
λ s ( t ) dt
```
##### }

```
=exp
```
##### {

##### − 2

##### ∫ B

```
A
```
```
λ n ( t ) dt
```
##### }

##### =

##### ⎡

```
⎣exp
```
##### {

##### −

##### ∫ B

```
A
```
```
λ n ( t ) dt
```
##### }⎤

##### ⎦

```
2
```
```
In other words, for two people of the same age, one of whom is a smoker and
the other a nonsmoker, the probability that the smoker survives to any given age
is the square (not one-half) of the corresponding probability for a nonsmoker. For
instance, ifλ n ( t )= 301 ,50... t ...60, then the probability that a 50-year-old nonsmoker
reaches age 60 is e −^1 /^3 L.7165, whereas the corresponding probability for a smoker
is e −^2 /^3 L.5134..
```

```
Section 5.6 Other Continuous Distributions 215
```
### 5.6 Other Continuous Distributions

#### 5.6.1 TheGammaDistribution

```
A random variable is said to have a gamma distribution with parameters(α,λ),λ>0,
α>0, if its density function is given by
```
```
f ( x )=
```
##### ⎧

##### ⎪⎨

##### ⎪⎩

```
λ e −λ x (λ x )α−^1
(α)
```
```
x Ú 0
0 x < 0
```
```
where(α), called the gamma function , is defined as
```
```
(α)=
```
```
∫q
```
```
0
```
```
e − yy α−^1 dy
```
```
Integration of(α)by parts yields
```
```
(α)=− e − yy α−^1
```
##### ∣

##### ∣

##### ∣

```
q
0
```
##### +

```
∫q
```
```
0
```
```
e − y (α− 1 ) y α−^2 dy
```
```
=(α− 1 )
```
```
∫q
```
```
0
```
```
e − yy α−^2 dy (6.1)
```
```
=(α− 1 )(α− 1 )
```
```
For integral values ofα, say,α= n , we obtain, by applying Equation (6.1) repeatedly,
```
```
( n )=( n − 1 )( n − 1 )
=( n − 1 )( n − 2 )( n − 2 )
=···
=( n − 1 )( n − 2 )··· 3 · 2 ( 1 )
```
```
Since( 1 )=
```
```
∫q
0 e
```
```
− xdx =1, it follows that, for integral values of n ,
```
```
( n )=( n − 1 )!
```
```
Whenαis a positive integer, say,α= n , the gamma distribution with parameters
(α,λ)often arises, in practice as the distribution of the amount of time one has to
wait until a total of n events has occurred. More specifically, if events are occurring
randomly and in accordance with the three axioms of Section 4.7, then it turns out
that the amount of time one has to wait until a total of n events has occurred will be a
gamma random variable with parameters( n ,λ). To prove this, let Tn denote the time
at which the n th event occurs, and note that Tn is less than or equal to t if and only
if the number of events that have occurred by time t is at least n. That is, with N ( t )
equal to the number of events in [0, t ],
```
```
P { Tn ... t }= P { N ( t )Ú n }
```
##### =

```
∑q
```
```
j = n
```
```
P { N ( t )= j }
```
##### =

```
∑q
```
```
j = n
```
```
e −λ t (λ t ) j
j!
```

**216** Chapter 5 Continuous Random Variables

```
where the final identity follows because the number of events in [0, t ]hasa
Poisson distribution with parameterλ t. Differentiation of the preceding now yields
the density function of Tn :
```
```
f ( t )=
```
```
∑q
```
```
j = n
```
```
e −λ tj (λ t ) j −^1 λ
j!
```
##### −

```
∑q
```
```
j = n
```
```
λ e −λ t (λ t ) j
j!
```
##### =

```
∑q
```
```
j = n
```
```
λ e −λ t (λ t ) j −^1
( j − 1 )!
```
##### −

```
∑q
```
```
j = n
```
```
λ e −λ t (λ t ) j
j!
```
##### =

```
λ e −λ t (λ t ) n −^1
( n − 1 )!
```
```
Hence, Tn has the gamma distribution with parameters( n ,λ). (This distribution is
often referred to in the literature as the n-Erlang distribution .) Note that when n =1,
this distribution reduces to the exponential distribution.
The gamma distribution withλ=^12 andα= n /2, n a positive integer, is called the
χ n^2 (read “chi-squared”) distribution with n degrees of freedom. The chi-squared dis-
tribution often arises in practice as the distribution of the error involved in attempt-
ing to hit a target in n -dimensional space when each coordinate error is normally
distributed. This distribution will be studied in Chapter 6, where its relation to the
normal distribution is detailed.
```
```
EXAMPLE 6a
Let X be a gamma random variable with parametersαandλ. Calculate (a) E [ X ]and
(b) Var( X ).
```
```
Solution. (a)
```
##### E [ X ]=

##### 1

```
(α)
```
```
∫q
```
```
0
```
```
λ xe −λ x (λ x )α−^1 dx
```
##### =

##### 1

```
λ(α)
```
```
∫q
```
```
0
```
```
λ e −λ x (λ x )α dx
```
##### =

```
(α+ 1 )
λ(α)
=
```
```
α
λ
```
```
by Equation( 6. 1 )
```
```
(b) By first calculating E [ X^2 ], we can show that
```
```
Var( X )=
```
```
α
λ^2
The details are left as an exercise..
```
#### 5.6.2 TheWeibullDistribution

```
The Weibull distribution is widely used in engineering practice due to its versatility. It
was originally proposed for the interpretation of fatigue data, but now its use has been
extended to many other engineering problems. In particular, it is widely used in the
field of life phenomena as the distribution of the lifetime of some object, especially
when the “weakest link” model is appropriate for the object. That is, consider an
```

```
Section 5.6 Other Continuous Distributions 217
```
object consisting of many parts, and suppose that the object experiences death (fail-
ure) when any of its parts fail. It has been shown (both theoretically and empirically)
that under these conditions a Weibull distribution provides a close approximation to
the distribution of the lifetime of the item.
The Weibull distribution function has the form

```
F ( x )=
```
##### ⎧

##### ⎪⎪

##### ⎨

##### ⎪⎪

##### ⎩

```
0 x ...ν
```
```
1 −exp
```
##### {

##### −

##### (

```
x −ν
α
```
```
)β}
x >ν
```
##### (6.2)

A random variable whose cumulative distribution function is given by Equation (6.2)
is said to be a _Weibull random variable_ with parametersν,α,andβ. Differentiation
yields the density:

```
f ( x )=
```
##### ⎧

##### ⎪⎪

##### ⎨

##### ⎪⎪

##### ⎩

```
0 x ...ν
```
```
β
α
```
##### (

```
x −ν
α
```
```
)β− 1
exp
```
##### {

##### −

##### (

```
x −ν
α
```
```
)β}
x >ν
```
#### 5.6.3 TheCauchyDistribution......................

A random variable is said to have a Cauchy distribution with parameterθ,−q<θ <
q, if its density is given by

```
f ( x )=
```
##### 1

```
π
```
##### 1

```
1 +( x −θ)^2
```
```
−q< x <q
```
**_EXAMPLE 6b_**
Suppose that a narrow-beam flashlight is spun around its center, which is located a
unit distance from the _x_ -axis. (See Figure 5.7.) Consider the point _X_ at which the
beam intersects the _x_ -axis when the flashlight has stopped spinning. (If the beam is
not pointing toward the _x_ -axis, repeat the experiment.)

```

```
```
1
```
```
0 Xx -axis
```
```
FIGURE 5.7
```
As indicated in Figure 5.7, the point _X_ is determined by the angleθbetween the
flashlight and the _y_ -axis, which, from the physical situation, appears to be uniformly
distributed between−π/2andπ/2. The distribution function of _X_ is thus given by

```
F ( x )= P { X ... x }
= P {tanθ... x }
= P {θ ...tan−^1 x }
```
```
=
```
##### 1

##### 2

##### +

##### 1

```
π
```
```
tan−^1 x
```

**218** Chapter 5 Continuous Random Variables

```
where the last equality follows since θ, being uniform over (−π/2,π/ 2 ),has
distribution
```
```
P {θ... a }=
```
```
a −(−π/ 2 )
π
```
##### =

##### 1

##### 2

##### +

```
a
π
```
##### −

```
π
2
```
```
< a <
```
```
π
2
Hence, the density function of X is given by
```
```
f ( x )=
```
```
d
dx
```
```
F ( x )=
```
##### 1

```
π( 1 + x^2 )
```
```
−q< x <q
```
```
and we see that X has the Cauchy distribution.†.
```
#### 5.6.4 TheBetaDistribution

```
A random variable is said to have a beta distribution if its density is given by
```
```
f ( x )=
```
##### ⎧

##### ⎪⎨

##### ⎪⎩

##### 1

```
B ( a , b )
```
```
xa −^1 ( 1 − x ) b −^10 < x < 1
```
```
0 otherwise
```
```
where
```
```
B ( a , b )=
```
##### ∫ 1

```
0
```
```
xa −^1 ( 1 − x ) b −^1 dx
```
```
The beta distribution can be used to model a random phenomenon whose set of
possible values is some finite interval [ c , d ]—which, by letting c denote the origin and
taking d − c as a unit measurement, can be transformed into the interval [0, 1].
When a = b , the beta density is symmetric about^12 , giving more and more weight
to regions about^12 as the common value a increases. (See Figure 5.8.) When b > a ,
the density is skewed to the left (in the sense that smaller values become more likely);
and it is skewed to the right when a > b. (See Figure 5.9.)
The relationship
```
```
B ( a , b )=
```
```
( a )( b )
( a + b )
```
##### (6.3)

```
can be shown to exist between
```
```
B ( a , b )=
```
##### ∫ 1

```
0
```
```
xa −^1 ( 1 − x ) b −^1 dx
```
```
and the gamma function.
```
```
†That d
dx (tan
```
− (^1) _x_ )= 1 /( 1 + _x_ (^2) )can be seen as follows: If _y_ =tan− (^1) _x_ ,thentan _y_ = _x_ ,so
1 =
_d
dx_
(tan _y_ )=
_d
dy_
(tan _y_ )
_dy
dx_
=
_d
dy_
(
sin _y_
cos _y_
)
_dy
dx_
=
(
cos^2 _y_ +sin^2 _y_
cos^2 _y_
)
_dy
dx_
or
_dy
dx_
=
cos^2 _y_
sin^2 _y_ +cos^2 _y_
=
1
tan^2 _y_ + 1
=
1
_x_^2 + 1


```
Section 5.7 The Distribution of a Function of a Random Variable 219
```
```
f ( x )
```
```
x
```
(^1) –
(^012)
(^1) –
_a_ = 4
_a_ = 3
_a_ = 10
_a_ = 1
**FIGURE 5.8:** Beta densities with parameters ( _a_ , _b_ )when _a_ = _b_.
_f_ ( _x_ )
_x_
(^3) –
_a_ = 2
_a_ = 6
**FIGURE 5.9:** Beta densities with parameters ( _a_ , _b_ )when _a_ /( _a_ + _b_ )= 1 /20.
Upon using Equation (6.1) along with the identity (6.3), it is an easy matter to show
that if _X_ is a beta random variable with parameters _a_ and _b_ ,then
_E_ [ _X_ ]=
_a
a_ + _b_
Var( _X_ )=
_ab_
( _a_ + _b_ )^2 ( _a_ + _b_ + 1 )
**Remark.** A verification of Equation (6.3) appears in Example 7c of Chapter 6..

### 5.7 The Distribution of a Function of a Random Variable

```
Often, we know the probability distribution of a random variable and are interested
in determining the distribution of some function of it. For instance, suppose that we
know the distribution of X and want to find the distribution of g ( X ).Todoso,itis
```

**220** Chapter 5 Continuous Random Variables

```
necessary to express the event that g ( X )... y in terms of X being in some set. We
illustrate with the following examples.
```
```
EXAMPLE 7a
Let X be uniformly distributed over (0, 1). We obtain the distribution of the random
variable Y , defined by Y = Xn , as follows: For 0... y ...1,
```
```
FY ( y )= P { Y ... y }
= P { Xn ... y }
= P { X ... y^1 / n }
= FX ( y^1 / n )
= y^1 / n
```
```
For instance, the density function of Y is given by
```
```
fY ( y )=
```
##### ⎧

##### ⎪⎨

##### ⎪⎩

##### 1

```
n
```
```
y^1 / n −^10 ... y ... 1
```
```
0 otherwise
```
##### .

```
EXAMPLE 7b
If X is a continuous random variable with probability density fX , then the distribution
of Y = X^2 is obtained as follows: For y Ú0,
```
```
FY ( y )= P { Y ... y }
= P { X^2 ... y }
= P {−
```
##### √

```
y ... X ...
```
##### √

```
y }
= FX (
```
##### √

```
y )− FX (−
```
##### √

```
y )
```
```
Differentiation yields
```
```
fY ( y )=
```
##### 1

##### 2

##### √

```
y
```
```
[ fX (
```
##### √

```
y )+ fX (−
```
##### √

```
y )].
```
```
EXAMPLE 7c
If X has a probability density fX ,then Y =| X |has a density function that is obtained
as follows: For y Ú0,
```
```
FY ( y )= P { Y ... y }
= P {| X |... y }
= P {− y ... X ... y }
= FX ( y )− FX (− y )
```
```
Hence, on differentiation, we obtain
```
```
fY ( y )= fX ( y )+ fX (− y ) y Ú 0
```
```
.
```

```
Section 5.7 The Distribution of a Function of a Random Variable 221
```
The method employed in Examples 7a through 7c can be used to prove
Theorem 7.1.

**Theorem 7.1.** _Let X be a continuous random variable having probability density func-
tion fX. Suppose that g_ ( _x_ ) _is a strictly monotonic (increasing or decreasing), differen-
tiable (and thus continuous) function of x. Then the random variable Y defined by
Y_ = _g_ ( _X_ ) _has a probability density function given by_

```
fY ( y )=
```
##### ⎧

##### ⎪⎨

##### ⎪⎩

```
fX [ g −^1 ( y )]
```
##### ∣

##### ∣

##### ∣

##### ∣

```
d
dy
```
```
g −^1 ( y )
```
##### ∣

##### ∣

##### ∣

```
∣ if y = g ( x ) for some x
```
```
0 if y Z g ( x ) for all x
```
where _g_ −^1 ( _y_ )is defined to equal that value of _x_ such that _g_ ( _x_ )= _y_.
We shall prove Theorem 7.1 when _g_ ( _x_ )is an increasing function.

```
Proof. Suppose that y = g ( x )for some x. Then, with Y = g ( X ),
```
```
FY ( y )= P { g ( X )... y }
= P { X ... g −^1 ( y )}
= FX ( g −^1 ( y ))
```
```
Differentiation gives
```
```
fY ( y )= fX ( g −^1 ( y ))
```
```
d
dy
```
```
g −^1 ( y ).
```
which agrees with Theorem 7.1, since _g_ −^1 ( _y_ )is nondecreasing, so its derivative is non-
negative.
When _y_ Z _g_ ( _x_ )for any _x_ ,then _FY_ ( _y_ )is either 0 or 1, and in either case _fY_ ( _y_ )=0.

**_EXAMPLE 7d_**

Let _X_ be a continuous nonnegative random variable with density function _f_ , and let
_Y_ = _Xn_. Find _fY_ , the probability density function of _Y_.

**_Solution._** If _g_ ( _x_ )= _xn_ ,then

```
g −^1 ( y )= y^1 / n
```
and
_d
dy_

```
{ g −^1 ( y )}=
```
##### 1

```
n
```
```
y^1 / n −^1
```
Hence, from Theorem 7.1, we obtain

```
fY ( y )=
```
##### 1

```
n
```
```
y^1 / n −^1 f ( y^1 / n )
```
For _n_ =2, this gives

```
fY ( y )=
```
##### 1

##### 2

##### √

```
y
```
```
f (
```
##### √

```
y )
```
which (since _X_ Ú0) is in agreement with the result of Example 7b..


**222** Chapter 5 Continuous Random Variables

#### Summary

```
A random variable X is continuous if there is a nonnegative function f , called the
probability density function of X , such that, for any set B ,
```
##### P { X ∈ B }=

##### ∫

```
B
```
```
f ( x ) dx
```
```
If X is continuous, then its distribution function F will be differentiable and
```
```
d
dx
```
```
F ( x )= f ( x )
```
```
The expected value of a continuous random variable X is defined by
```
##### E [ X ]=

```
∫q
```
```
−q
```
```
xf ( x ) dx
```
```
A useful identity is that, for any function g ,
```
```
E [ g ( X )]=
```
```
∫q
```
```
−q
```
```
g ( x ) f ( x ) dx
```
```
As in the case of a discrete random variable, the variance of X is defined by
```
```
Var( X )= E [( X − E [ X ])^2 ]
```
```
A random variable X is said to be uniform over the interval ( a , b ) if its probability
density function is given by
```
```
f ( x )=
```
##### ⎧

##### ⎪⎨

##### ⎪⎩

##### 1

```
b − a
```
```
a ... x ... b
```
```
0 otherwise
```
```
Its expected value and variance are
```
##### E [ X ]=

```
a + b
2
```
```
Var( X )=
```
```
( b − a )^2
12
A random variable X is said to be normal with parametersμandσ^2 if its probability
density function is given by
```
```
f ( x )=
```
##### 1

##### √

```
2 πσ
```
```
e −( x −μ)
```
(^2) / 2 σ 2
−q< _x_ <q
It can be shown that
μ= _E_ [ _X_ ] σ^2 =Var( _X_ )
If _X_ is normal with meanμand varianceσ^2 ,then _Z_ , defined by

##### Z =

```
X −μ
σ
is normal with mean 0 and variance 1. Such a random variable is said to be a standard
normal random variable. Probabilities about X can be expressed in terms of proba-
bilities about the standard normal variable Z , whose probability distribution function
can be obtained either from Table 5.1 or from a website.
```

```
Summary 223
```
When _n_ is large, the probability distribution function of a binomial random vari-
able with parameters _n_ and _p_ can be approximated by that of a normal random
variable having mean _np_ and variance _np_ ( 1 − _p_ ).
A random variable whose probability density function is of the form

```
f ( x )=
```
##### {

```
λ e −λ x x Ú 0
0 otherwise
```
is said to be an _exponential_ random variable with parameterλ. Its expected value and
variance are, respectively,

##### E [ X ]=

##### 1

```
λ
```
```
Var( X )=
```
##### 1

```
λ^2
```
A key property possessed only by exponential random variables is that they are _mem-
oryless_ , in the sense that, for positive _s_ and _t_ ,

```
P { X > s + t | X > t }= P { X > s }
```
If _X_ represents the life of an item, then the memoryless property states that, for any
_t_ , the remaining life of a _t_ -year-old item has the same probability distribution as the
life of a new item. Thus, one need not remember the age of an item to know its
distribution of remaining life.
Let _X_ be a nonnegative continuous random variable with distribution function _F_
and density function _f_. The function

```
λ( t )=
```
```
f ( t )
1 − F ( t )
```
```
t Ú 0
```
is called the _hazard rate_ ,or _failure rate_ , function of _F_. If we interpret _X_ as being the
life of an item, then, for small values of _dt_ ,λ( _t_ ) _dt_ is approximately the probability
that a _t_ -unit-old item will fail within an additional time _dt_ .If _F_ is the exponential
distribution with parameterλ,then

```
λ( t )=λ t Ú 0
```
In addition, the exponential is the unique distribution having a constant failure rate.
A random variable is said to have a _gamma_ distribution with parametersαandλ
if its probability density function is equal to

```
f ( x )=
```
```
λ e −λ x (λ x )α−^1
(α)
```
```
x Ú 0
```
and is 0 otherwise. The quantity(α)is called the gamma function and is defined by

```
(α)=
```
```
∫q
```
```
0
```
```
e − xx α−^1 dx
```
The expected value and variance of a gamma random variable are, respectively,

##### E [ X ]=

```
α
λ
```
```
Var( X )=
```
```
α
λ^2
```

**224** Chapter 5 Continuous Random Variables

```
A random variable is said to have a beta distribution with parameters ( a , b )ifits
probability density function is equal to
```
```
f ( x )=
```
##### 1

```
B ( a , b )
```
```
xa −^1 ( 1 − x ) b −^10 ... x ... 1
```
```
and is equal to 0 otherwise. The constant B ( a , b ) is given by
```
```
B ( a , b )=
```
##### ∫ 1

```
0
```
```
xa −^1 ( 1 − x ) b −^1 dx
```
```
The mean and variance of such a random variable are, respectively,
```
##### E [ X ]=

```
a
a + b
```
```
Var( X )=
```
```
ab
( a + b )^2 ( a + b + 1 )
```
#### Problems...................................

```
5.1. Let X be a random variable with probability den-
sity function
```
```
f ( x )=
```
```
{
c ( 1 − x^2 ) − 1 < x < 1
0 otherwise
```
```
(a) What is the value of c?
(b) What is the cumulative distribution function
of X?
5.2. A system consisting of one original unit plus a
spare can function for a random amount of time X.
If the density of X is given (in units of months) by
```
```
f ( x )=
```
```
{
Cxe − x /^2 x > 0
0 x ... 0
```
```
what is the probability that the system functions
for at least 5 months?
5.3. Consider the function
```
```
f ( x )=
```
```
{
C ( 2 x − x^3 ) 0 < x <^52
0 otherwise
```
```
Could f be a probability density function? If so,
determine C. Repeat if f ( x )were given by
```
```
f ( x )=
```
```
{
C ( 2 x − x^2 ) 0 < x <^52
0 otherwise
```
```
5.4. The probability density function of X , the lifetime
of a certain type of electronic device (measured in
hours), is given by
```
```
f ( x )=
```
```
⎧
⎪⎨
```
```
⎪⎩
```
```
10
x^2
```
```
x > 10
0 x ... 10
```
```
(a) Find P { X > 20 }.
(b) What is the cumulative distribution function
of X?
(c) What is the probability that, of 6 such types of
devices, at least 3 will function for at least 15
hours? What assumptions are you making?
5.5. A filling station is supplied with gasoline once a
week. If its weekly volume of sales in thousands of
gallons is a random variable with probability den-
sity function
```
```
f ( x )=
```
```
{
5 ( 1 − x )^40 < x < 1
0 otherwise
```
```
what must the capacity of the tank be so that the
probability of the supply’s being exhausted in a
given week is .01?
5.6. Compute E [ X ]if X has a density function given by
```
```
(a) f ( x )=
```
```
⎧
⎪⎨
```
```
⎪⎩
```
```
1
4
```
```
xe − x /^2 x > 0
```
```
0 otherwise
```
```
;
```
```
(b) f ( x )=
```
```
{
c ( 1 − x^2 ) − 1 < x < 1
0 otherwise ;
```
```
(c) f ( x )=
```
```
⎧
⎪⎨
```
```
⎪⎩
```
```
5
x^2
```
```
x > 5
```
```
0 x ... 5
```
```
.
```

```
Problems 225
```
```
5.7. The density function of X is given by
```
```
f ( x )=
```
```
{
a + bx^20 ... x ... 1
0 otherwise
```
```
If E [ X ]=^35 , find a and b.
5.8. The lifetime in hours of an electronic tube is a ran-
dom variable having a probability density function
given by
f ( x )= xe − x x Ú 0
```
```
Compute the expected lifetime of such a tube.
5.9. Consider Example 4b of Chapter 4, but now sup-
pose that the seasonal demand is a continuous ran-
dom variable having probability density function f.
Show that the optimal amount to stock is the value
s ∗that satisfies
```
```
F ( s ∗)=
b
b +
where b is net profit per unit sale,is the net loss
per unit unsold, and F is the cumulative distribu-
tion function of the seasonal demand.
```
**5.10.** Trains headed for destination _A_ arrive at the train
station at 15-minute intervals starting at 7A.M.,
whereas trains headed for destination _B_ arrive at
15-minute intervals starting at 7:05A.M.
**(a)** If a certain passenger arrives at the station at
a time uniformly distributed between 7 and
8 A.M. and then gets on the first train that
arrives, what proportion of time does he or
she go to destination _A_?
**(b)** What if the passenger arrives at a time uni-
formly distributed between 7:10 and 8:10
A.M.?

**5.11.** A point is chosen at random on a line segment
of length _L_. Interpret this statement, and find the
probability that the ratio of the shorter to the
longer segment is less than^14.

**5.12.** A bus travels between the two cities _A_ and _B_ ,
which are 100 miles apart. If the bus has a break-
down, the distance from the breakdown to city _A_
has a uniform distribution over (0, 100). There is a
bus service station in city _A_ ,in _B_ ,andinthecen-
ter of the route between _A_ and _B_. It is suggested
that it would be more efficient to have the three
stations located 25, 50, and 75 miles, respectively,
from _A_. Do you agree? Why?

**5.13.** You arrive at a bus stop at 10 o’clock, knowing
that the bus will arrive at some time uniformly dis-
tributed between 10 and 10:30.
**(a)** What is the probability that you will have to
wait longer than 10 minutes?

```
(b) If, at 10:15, the bus has not yet arrived, what
is the probability that you will have to wait at
least an additional 10 minutes?
5.14. Let X be a uniform (0, 1) random variable. Com-
pute E [ Xn ] by using Proposition 2.1, and then
check the result by using the definition of expec-
tation.
5.15. If X is a normal random variable with parameters
μ=10 andσ^2 =36, compute
(a) P { X > 5 };
(b) P { 4 < X < 16 };
(c) P { X < 8 };
(d) P { X < 20 };
(e) P { X > 16 }.
5.16. The annual rainfall (in inches) in a certain region is
normally distributed withμ=40 andσ=4. What
is the probability that, starting with this year, it will
take over 10 years before a year occurs having a
rainfall of over 50 inches? What assumptions are
you making?
5.17. A man aiming at a target receives 10 points if his
shot is within 1 inch of the target, 5 points if it is
between 1 and 3 inches of the target, and 3 points if
it is between 3 and 5 inches of the target. Find the
expected number of points scored if the distance
from the shot to the target is uniformly distributed
between 0 and 10.
5.18. Suppose that X is a normal random variable with
mean 5. If P { X > 9 }=.2, approximately what is
Var( X )?
5.19. Let X be a normal random variable with mean
12 and variance 4. Find the value of c such that
P { X > c }=.10.
5.20. If 65 percent of the population of a large commu-
nity is in favor of a proposed rise in school taxes,
approximate the probability that a random sample
of 100 people will contain
(a) at least 50 who are in favor of the proposition;
(b) between 60 and 70 inclusive who are in favor;
(c) fewer than 75 in favor.
5.21. Suppose that the height, in inches, of a 25-year-old
man is a normal random variable with parameters
μ =71 andσ^2 = 6 .25. What percentage of 25-
year-old men are over 6 feet, 2 inches tall? What
percentage of men in the 6-footer club are over 6
feet, 5 inches?
5.22. The width of a slot of a duralumin forging is (in
inches) normally distributed withμ=.9000 and
σ =.0030. The specification limits were given as
```
. 9000 ;.0050.
**(a)** What percentage of forgings will be defec-
    tive?


**226** Chapter 5 Continuous Random Variables

```
(b) What is the maximum allowable value ofσ
that will permit no more than 1 in 100 defec-
tives when the widths are normally distributed
withμ=.9000 andσ?
5.23. One thousand independent rolls of a fair die will
be made. Compute an approximation to the prob-
ability that the number 6 will appear between 150
and 200 times inclusively. If the number 6 appears
exactly 200 times, find the probability that the
number 5 will appear less than 150 times.
5.24. The lifetimes of interactive computer chips pro-
duced by a certain semiconductor manufacturer
are normally distributed with parametersμ =
1. 4 * 106 hours andσ= 3 * 105 hours. What is the
approximate probability that a batch of 100 chips
will contain at least 20 whose lifetimes are less than
1. 8 * 106?
5.25. Each item produced by a certain manufacturer is,
independently, of acceptable quality with proba-
bility .95. Approximate the probability that at most
10 of the next 150 items produced are unaccept-
able.
5.26. Two types of coins are produced at a factory: a fair
coin and a biased one that comes up heads 55 per-
cent of the time. We have one of these coins, but
do not know whether it is a fair coin or a biased
one. In order to ascertain which type of coin we
have, we shall perform the following statistical test:
We shall toss the coin 1000 times. If the coin lands
on heads 525 or more times, then we shall conclude
that it is a biased coin, whereas if it lands on heads
less than 525 times, then we shall conclude that it
is a fair coin. If the coin is actually fair, what is the
probability that we shall reach a false conclusion?
What would it be if the coin were biased?
5.27. In 10,000 independent tosses of a coin, the coin
landed on heads 5800 times. Is it reasonable to
assume that the coin is not fair? Explain.
5.28. Twelve percent of the population is left handed.
Approximate the probability that there are at least
20 left-handers in a school of 200 students. State
your assumptions.
5.29. A model for the movement of a stock supposes
that if the present price of the stock is s , then, after
one period, it will be either us with probability p
or ds with probability 1− p. Assuming that suc-
cessive movements are independent, approximate
the probability that the stock’s price will be up
at least 30 percent after the next 1000 periods if
u = 1 .012, d = 0 .990, and p =.52.
5.30. An image is partitioned into two regions, one
white and the other black. A reading taken from
a randomly chosen point in the white section will
give a reading that is normally distributed withμ=
4andσ^2 =4, whereas one taken from a randomly
```
```
chosen point in the black region will have a nor-
mally distributed reading with parameters (6, 9).
A point is randomly chosen on the image and has
a reading of 5. If the fraction of the image that is
black isα, for what value ofαwould the probabil-
ity of making an error be the same, regardless of
whether one concluded that the point was in the
black region or in the white region?
5.31. (a) A fire station is to be located along a road of
length A , A <q. If fires occur at points uni-
formly chosen on (0, A ), where should the sta-
tion be located so as to minimize the expected
distance from the fire? That is, choose a so
as to
minimize E [| X − a |]
```
```
when X is uniformly distributed over (0, A ).
(b) Now suppose that the road is of infinite
length—stretching from point 0 outward toq.
If the distance of a fire from point 0 is expo-
nentially distributed with rateλ, where should
the fire station now be located? That is, we
want to minimize E [| X − a |], where X is now
exponential with rateλ.
5.32. The time (in hours) required to repair a machine is
an exponentially distributed random variable with
parameterλ=^12. What is
(a) the probability that a repair time exceeds 2
hours?
(b) the conditional probability that a repair takes
at least 10 hours, given that its duration
exceeds 9 hours?
5.33. The number of years a radio functions is exponen-
tially distributed with parameterλ=^18. If Jones
buys a used radio, what is the probability that it
will be working after an additional 8 years?
5.34. Jones figures that the total number of thousands
of miles that an auto can be driven before it would
need to be junked is an exponential random vari-
able with parameter 201. Smith has a used car that
he claims has been driven only 10,000 miles. If
Jones purchases the car, what is the probability
that she would get at least 20,000 additional miles
out of it? Repeat under the assumption that the
lifetime mileage of the car is not exponentially dis-
tributed, but rather is (in thousands of miles) uni-
formly distributed over (0, 40).
5.35. The lung cancer hazard rateλ( t )of a t -year-old
male smoker is such that
```
```
λ( t )=. 027 +. 00025 ( t − 40 )^2 t Ú 40
```
```
Assuming that a 40-year-old male smoker survives
all other hazards, what is the probability that he
survives to (a) age 50 and (b) age 60 without con-
tracting lung cancer?
```

```
Theoretical Exercises 227
```
**5.36.** Suppose that the life distribution of an item has the
hazard rate functionλ( _t_ )= _t_^3 , _t_ >0. What is the
probability that
**(a)** the item survives to age 2?
**(b)** the item’s lifetime is between .4 and 1.4?
**(c)** a 1-year-old item will survive to age 2?

**5.37.** If _X_ is uniformly distributed over(−1, 1), find
**(a)** _P_ {| _X_ |>^12 };
**(b)** the density function of the random variable
| _X_ |.

**5.38.** If _Y_ is uniformly distributed over (0, 5), what
is the probability that the roots of the equation
4 _x_^2 + 4 _xY_ + _Y_ + 2 =0 are both real?

```
5.39. If X is an exponential random variable with
parameterλ = 1, compute the probability den-
sity function of the random variable Y defined by
Y =log X.
5.40. If X is uniformly distributed over (0, 1), find the
density function of Y = eX.
5.41. Find the distribution of R = A sinθ,where A is
a fixed constant andθis uniformly distributed on
(−π/2,π/ 2 ). Such a random variable R arises in
the theory of ballistics. If a projectile is fired from
the origin at an angleαfrom the earth with a speed
ν, then the point R at which it returns to the earth
can be expressed as R =( v^2 / g )sin 2α,where g is
the gravitational constant, equal to 980 centime-
ters per second squared.
```
#### Theoretical Exercises

```
5.1. The speed of a molecule in a uniform gas at equi-
librium is a random variable whose probability
density function is given by
```
```
f ( x )=
```
```
{
ax^2 e − bx
2
x Ú 0
0 x < 0
```
```
where b = m / 2 kT and k , T ,and m denote, respec-
tively, Boltzmann’s constant, the absolute temper-
ature of the gas, and the mass of the molecule.
Evaluate a in terms of b.
5.2. Show that
```
```
E [ Y ]=
```
```
∫q
```
```
0
```
```
P { Y > y } dy −
```
```
∫q
```
```
0
```
```
P { Y <− y } dy
```
```
Hint : Show that
∫q
```
```
0
```
```
P { Y <− y } dy =−
```
```
∫ 0
```
```
−q
```
```
xfY ( x ) dx
∫q
```
```
0
```
```
P { Y > y } dy =
```
```
∫q
```
```
0
```
```
xfY ( x ) dx
```
```
5.3. Show that if X has density function f ,then
```
```
E [ g ( X )]=
```
```
∫q
```
```
−q
```
```
g ( x ) f ( x ) dx
```
```
Hint : Using Theoretical Exercise 2, start with
```
```
E [ g ( X )]=
```
```
∫q
```
```
0
```
```
P { g ( X )> y } dy −
```
```
∫q
```
```
0
```
```
P { g ( X )<− y } dy
```
```
and then proceed as in the proof given in the text
when g ( X )Ú0.
5.4. Prove Corollary 2.1.
```
```
5.5. Use the result that, for a nonnegative random vari-
able Y ,
E [ Y ]=
```
```
∫q
```
```
0
```
```
P { Y > t } dt
```
```
to show that, for a nonnegative random vari-
able X ,
```
```
E [ Xn ]=
```
```
∫q
```
```
0
```
```
nxn −^1 P { X > x } dx
```
```
Hint : Start with
```
```
E [ Xn ]=
```
```
∫q
```
```
0
```
```
P { Xn > t } dt
```
```
and make the change of variables t = xn.
5.6. Define a collection of events Ea ,0< a <1, hav-
ing the property that P ( Ea ) = 1forall a but
```
```
P
```
```
(
⋂
a
```
```
Ea
```
```
)
=0.
```
```
Hint :Let X be uniform over (0, 1) and define each
Ea in terms of X.
5.7. The standard deviation of X , denoted SD ( X ),is
given by
SD( X )=
```
```
√
Var( X )
```
```
Find SD ( aX + b )if X has varianceσ^2.
5.8. Let X be a random variable that takes on values
between 0 and c .Thatis, P { 0 ... X ... c }=1.
Show that
Var( X )...
```
```
c^2
4
Hint : One approach is to first argue that
```
```
E [ X^2 ]... cE [ X ]
```

**228** Chapter 5 Continuous Random Variables

```
and then use this inequality to show that
```
```
Var( X )... c^2 [α( 1 −α)]whereα=
E [ X ]
c
5.9. Show that Z is a standard normal random variable,
then, for x >0,
(a) P { Z > x }= P { Z <− x };
(b) P {| Z |> x }= 2 P { Z > x };
(c) P {| Z |< x }= 2 P { Z < x }−1.
5.10. Let f ( x )denote the probability density function of
a normal random variable with meanμand vari-
anceσ^2. Show thatμ−σandμ+σare points
of inflection of this function. That is, show that
f ′′( x )=0when x =μ−σor x =μ+σ.
5.11. Let Z be a standard normal random variable Z ,
and let g be a differentiable function with deriva-
tive g ′.
(a) Show that E [ g ′( Z )]= E [ Zg ( Z )]
(b) Show that E [ Zn +^1 ]= nE [ Zn −^1 ]
(c) Find E [ Z^4 ].
5.12. Use the identity of Theoretical Exercise 5 to derive
E [ X^2 ]when X is an exponential random variable
with parameterλ.
5.13. The median of a continuous random variable hav-
ing distribution function F is that value m such that
F ( m )=^12. That is, a random variable is just as
likely to be larger than its median as it is to be
smaller. Find the median of X if X is
(a) uniformly distributed over ( a , b );
(b) normal with parametersμ,σ^2 ;
(c) exponential with rateλ.
5.14. The mode of a continuous random variable having
density f is the value of x for which f ( x )attains its
maximum. Compute the mode of X in cases (a),
(b), and (c) of Theoretical Exercise 5.13.
5.15. If X is an exponential random variable with
parameterλ,and c >0, show that cX is exponen-
tial with parameterλ/ c.
5.16. Compute the hazard rate function of X when X is
uniformly distributed over (0, a ).
5.17. If X has hazard rate functionλ X ( t ), compute the
hazard rate function of aX where a is a positive
constant.
5.18. Verify that the gamma density function integrates
to 1.
5.19. If X is an exponential random variable with mean
1 /λ, show that
```
```
E [ Xk ]=
k!
λ k
```
```
k =1, 2,...
```
```
Hint : Make use of the gamma density function to
evaluate the preceding.
5.20. Verify that
Var( X )=
```
```
α
λ^2
```
```
when X is a gamma random variable with param-
etersαandλ.
5.21. Show that
```
```
(
1
2
```
```
)
=
√
π.
Hint :
```
```
(
1
2
```
```
)
=
```
```
∫q
0 e
```
− _xx_ − 1 / (^2) _dx_. Make the change
of variables _y_ =
√
2 _x_ and then relate the resulting
expression to the normal distribution.
**5.22.** Compute the hazard rate function of a gamma ran-
dom variable with parameters(α,λ)and show it is
increasing whenαÚ1 and decreasing whenα...1.
**5.23.** Compute the hazard rate function of a Weibull
random variable and show it is increasing when
β Ú1 and decreasing whenβ...1.
**5.24.** Show that a plot of log(log( 1 − _F_ ( _x_ ))−^1 )against
log _x_ will be a straight line with slopeβ when
_F_ (·)is a Weibull distribution function. Show also
that approximately 63.2 percent of all observa-
tions from such a distribution will be less thanα.
Assume that _v_ =0.
**5.25.** Let
_Y_ =
(
_X_ −ν
α
)β
Show that if _X_ is a Weibull random variable with
parametersν,α,andβ,then _Y_ is an exponential
random variable with parameterλ= 1andvice
versa.
**5.26.** If _X_ is a beta random variable with parameters _a_
and _b_ , show that
_E_ [ _X_ ]=
_a
a_ + _b_
Var( _X_ )=
_ab_
( _a_ + _b_ )^2 ( _a_ + _b_ + 1 )
**5.27.** If _X_ is uniformly distributed over ( _a_ , _b_ ), what ran-
dom variable, having a linear relation with _X_ ,is
uniformly distributed over (0, 1)?
**5.28.** Consider the beta distribution with parameters
( _a_ , _b_ ). Show that
**(a)** when _a_ > 1and _b_ > 1, the density is uni-
modal (that is, it has a unique mode) with
mode equal to( _a_ − 1 )/( _a_ + _b_ − 2 );
**(b)** when _a_ ...1, _b_ ...1, and _a_ + _b_ <2, the den-
sity is either unimodal with mode at 0 or 1 or
U-shaped with modes at both 0 and 1;
**(c)** when _a_ = 1 = _b_ , all points in [0, 1] are modes.
**5.29.** Let _X_ be a continuous random variable having
cumulative distribution function _F_. Define the ran-
dom variable _Y_ by _Y_ = _F_ ( _X_ ). Show that _Y_ is
uniformly distributed over (0, 1).
**5.30.** Let _X_ have probability density _fX_. Find the prob-
ability density function of the random variable _Y_
defined by _Y_ = _aX_ + _b_.


```
Self-Test Problems and Exercises 229
```
**5.31.** Find the probability density function of _Y_ = _eX_
when _X_ is normally distributed with parametersμ
andσ^2. The random variable _Y_ is said to have a
_lognormal distribution_ (since log _Y_ has a normal
distribution) with parametersμandσ^2.
**5.32.** Let _X_ and _Y_ be independent random vari-
ables that are both equally likely to be either
1, 2,...,( 10 ) _N_ ,where _N_ is very large. Let _D_ denote
the greatest common divisor of _X_ and _Y_ ,andlet
_Qk_ = _P_ { _D_ = _k_ }.
**(a)** Give a heuristic argument that _Qk_ = _k_^12 _Q_ 1.
_Hint_ : Note that in order for _D_ to equal _k_ , _k_
must divide both _X_ and _Y_ and also _X_ / _k_ ,and
_Y_ / _k_ must be relatively prime. (That is, _X_ / _k_ ,
and _Y_ / _k_ must have a greatest common divisor
equal to 1.)
**(b)** Use part (a) to show that

```
Q 1 = P { X and Y are relatively prime}
```
```
=
```
```
1
∑q
```
```
k = 1
```
```
1 / k^2
```
```
It is a well-known identity that
```
```
∑q
1
```
```
1 / k^2 =
```
```
π^2 /6, so Q 1 = 6 /π^2. (In number theory, this
is known as the Legendre theorem.)
(c) Now argue that
```
```
Q 1 =
```
```
∏q
```
```
i = 1
```
```
(
P^2 i − 1
P^2 i
```
```
)
```
```
where Pi is the i th-smallest prime greater
than 1.
Hint : X and Y will be relatively prime if they
have no common prime factors. Hence, from
part (b), we see that
```
```
∏q
```
```
i = 1
```
```
(
P^2 i − 1
P^2 i
```
```
)
=
6
π^2
```
```
which was noted without explanation in
Problem 11 of Chapter 4. (The relationship
between this problem and Problem 11 of
Chapter 4 is that X and Y are relatively prime
if XY has no multiple prime factors.)
5.33. Prove Theorem 7.1 when g ( x )is a decreasing func-
tion.
```
#### Self-Test Problems and Exercises

```
5.1. The number of minutes of playing time of a certain
high school basketball player in a randomly cho-
sen game is a random variable whose probability
density function is given in the following figure:
```
```
.025
```
```
.050
```
```
10 20 30 40
```
```
Find the probability that the player plays
(a) over 15 minutes;
(b) between 20 and 35 minutes;
(c) less than 30 minutes;
(d) more than 36 minutes.
5.2. For some constant c , the random variable X has
the probability density function
```
```
f ( x )=
```
```
{
cxn 0 < x < 1
0 otherwise
```
```
Find (a) c and (b) P { X > x },0< x <1.
```
```
5.3. For some constant c , the random variable X has
the probability density function
```
```
f ( x )=
```
```
{
cx^40 < x < 2
0 otherwise
```
```
Find (a) E [ X ]and(b)Var( X ).
5.4. The random variable X has the probability density
function
```
```
f ( x )=
```
```
{
ax + bx^20 < x < 1
0 otherwise
```
```
If E [ X ]=.6, find (a) P { X <^12 }and (b) Var( X ).
5.5. The random variable X is said to be a discrete uni-
form random variable on the integers 1, 2,..., n if
```
```
P { X = i }=
```
```
1
n
i =1, 2,..., n
```
```
For any nonnegative real number x ,letInt( x )
(sometimes written as [ x ]) be the largest inte-
ger that is less than or equal to x. Show that
U is a uniform random variable on (0, 1), fain
```

**230** Chapter 5 Continuous Random Variables

```
X =Int( nU )+1 is a discrete uniform random
variable on 1,..., n.
5.6. Your company must make a sealed bid for a con-
struction project. If you succeed in winning the
contract (by having the lowest bid), then you plan
to pay another firm 100 thousand dollars to do
the work. If you believe that the minimum bid
(in thousands of dollars) of the other participating
companies can be modeled as the value of a ran-
dom variable that is uniformly distributed on (70,
140), how much should you bid to maximize your
expected profit?
5.7. To be a winner in a certain game, you must be
successful in three successive rounds. The game
depends on the value of U , a uniform random vari-
able on (0, 1). If U >.1, then you are successful
in round 1; if U >.2, then you are successful in
round 2; and if U >.3, then you are successful in
round 3.
(a) Find the probability that you are successful in
round 1.
(b) Find the conditional probability that you are
successful in round 2 given that you were suc-
cessful in round 1.
(c) Find the conditional probability that you are
successful in round 3 given that you were suc-
cessful in rounds 1 and 2.
(d) Find the probability that you are a winner.
5.8. A randomly chosen IQ test taker obtains a score
that is approximately a normal random variable
with mean 100 and standard deviation 15. What is
the probability that the score of such a person is
(a) above 125; (b) between 90 and 110?
5.9. Suppose that the travel time from your home to
your office is normally distributed with mean 40
minutes and standard deviation 7 minutes. If you
want to be 95 percent certain that you will not be
late for an office appointment at 1P.M., what is the
latest time that you should leave home?
5.10. The life of a certain type of automobile tire is nor-
mally distributed with mean 34,000 miles and stan-
dard deviation 4000 miles.
(a) What is the probability that such a tire lasts
over 40,000 miles?
(b) What is the probability that it lasts between
30,000 and 35,000 miles?
(c) Given that it has survived 30,000 miles, what
is the conditional probability that the tire sur-
vives another 10,000 miles?
5.11. The annual rainfall in Cleveland, Ohio is approx-
imately a normal random variable with mean 40.2
inches and standard deviation 8.4 inches. What is
the probability that
(a) next year’s rainfall will exceed 44 inches?
(b) the yearly rainfalls in exactly 3 of the next 7
years will exceed 44 inches?
```
```
Assume that if Ai is the event that the rainfall
exceeds 44 inches in year i (from now), then the
events Ai , i Ú1, are independent.
5.12. The following table uses 1992 data concerning the
percentages of male and female full-time workers
whose annual salaries fall into different ranges:
```
```
Earnings range Percentage Percentage
of females of males
```
```
... 9999 8.6 4.4
10,000–19,999 38.0 21.1
20,000–24,999 19.4 15.8
25,000–49,999 29.2 41.5
Ú50,000 4.8 17.2
```
```
Suppose that random samples of 200 male and 200
female full-time workers are chosen. Approximate
the probability that
(a) at least 70 of the women earn $25,000 or more;
(b) at most 60 percent of the men earn $25,000
or more;
(c) at least three-fourths of the men and at least
half the women earn $20,000 or more.
5.13. At a certain bank, the amount of time that a cus-
tomer spends being served by a teller is an expo-
nential random variable with mean 5 minutes. If
there is a customer in service when you enter the
bank, what is the probability that he or she will still
be with the teller after an additional 4 minutes?
5.14. Suppose that the cumulative distribution function
of the random variable X is given by
```
```
F ( x )= 1 − e − x
```
```
2
x > 0
```
```
Evaluate (a) P { X > 2 };(b) P { 1 < X < 3 };(c)the
hazard rate function of F ;(d) E [ X ]; (e) Var( X ).
Hint : For parts (d) and (e), you might want to
make use of the results of Theoretical Exercise 5.
5.15. The number of years that a washing machine func-
tions is a random variable whose hazard rate func-
tion is given by
```
```
λ( t )=
```
```
⎧
⎨
⎩
```
. 20 < _t_ < 2
. 2 +. 3 ( _t_ − 2 ) 2 ... _t_ < 5
1. 1 _t_ > 5

```
(a) What is the probability that the machine will
still be working 6 years after being purchased?
(b) If it is still working 6 years after being pur-
chased, what is the conditional probability
that it will fail within the next 2 years?
5.16. A standard Cauchy random variable has density
function
```
```
f ( x )=
1
π( 1 + x^2 )
```
```
−q< x <q
```

```
Self-Test Problems and Exercises 231
```
Show that _X_ is a standard Cauchy random
variable, then 1/ _X_ is also a standard Cauchy ran-
dom variable.
**5.17.** A roulette wheel has 38 slots, numbered 0, 00, and
1 through 36. If you bet 1 on a specified num-
ber then you either win 35 if the roulette ball
lands on that number or lose 1 if it does not.
If you continually make such bets, approximate
the probability that
**(a)** you are winning after 34 bets;
**(b)** you are winning after 1000 bets;
**(c)** you are winning after 100,000 bets.
Assume that each roll of the roulette ball is equally
likely to land on any of the 38 numbers.
**5.18.** There are two types of batteries in a bin. When in
use, type _i_ batteries last (in hours) an exponentially
distributed time with rateλ _i_ , _i_ = 1, 2. A battery
that is randomly chosen from the bin will be a type
_i_ battery with probability _pi_ ,

```
∑^2
i = 1
```
_pi_ = 1. If a ran-
domly chosen battery is still operating after _t_ hours
of use, what is the probability that it will still be
operating after an additional _s_ hours?
**5.19.** Evidence concerning the guilt or innocence of a
defendant in a criminal investigation can be sum-
marized by the value of an exponential random

```
variable X whose meanμdepends on whether the
defendant is guilty. If innocent,μ=1; if guilty,
μ = 2. The deciding judge will rule the defen-
dant guilty if X > c for some suitably chosen
value of c.
(a) If the judge wants to be 95 percent certain
that an innocent man will not be convicted,
what should be the value of c?
(b) Using the value of c found in part (a), what is
the probability that a guilty defendant will be
convicted?
5.20. For any real number y , define y +by
```
```
y +=
y ,if y Ú 0
0, if y < 0
```
```
Let c be a constant.
(a) Show that
```
```
E [( Z − c )+]=
```
```
1
√
2 π
```
```
e − c
```
(^2) / 2
− _c_ ( 1 −
( _c_ ))
when _Z_ is a standard normal random variable.
**(b)** Find _E_ [( _X_ − _c_ )+]when _X_ is normal with
meanμand varianceσ^2.


## CHAPTER 6

# Jointly Distributed Random Variables

### 6.1 JointDistributionFunctions

**6.2 INDEPENDENT RANDOM VARIABLES
6.3 SUMS OF INDEPENDENT RANDOM VARIABLES
6.4 CONDITIONAL DISTRIBUTIONS: DISCRETE CASE
6.5 CONDITIONAL DISTRIBUTIONS: CONTINUOUS CASE
6.6 ORDER STATISTICS
6.7 JOINT PROBABILITY DISTRIBUTION OF FUNCTIONS OF RANDOM VARIABLES
6.8 EXCHANGEABLE RANDOM VARIABLES**

##### 6.1 JOINT DISTRIBUTION FUNCTIONS

```
Thus far, we have concerned ourselves only with probability distributions for single
random variables. However, we are often interested in probability statements con-
cerning two or more random variables. In order to deal with such probabilities, we
define, for any two random variables X and Y ,the joint cumulative probability distri-
bution function of X and Y by
```
```
F ( a , b )= P { X ... a , Y ... b }−q< a , b <q
```
```
The distribution of X can be obtained from the joint distribution of X and Y as
follows:
```
```
FX ( a )= P { X ... a }
= P { X ... a , Y <q}
```
```
= P
```
##### (

```
lim
b →q
```
```
{ X ... a , Y ... b }
```
##### )

```
= lim
b →q
```
```
P { X ... a , Y ... b }
```
```
= lim
b →q
```
```
F ( a , b )
```
```
K F ( a ,q)
```
```
Note that, in the preceding set of equalities, we have once again made use of the fact
that probability is a continuous set (that is, event) function. Similarly, the cumulative
distribution function of Y is given by
```
```
FY ( b )= P { Y ... b }
= lim
a →q
F ( a , b )
```
```
K F (q, b )
```
**232**


```
Section 6.1 Joint Distribution Functions 233
```
The distribution functions _FX_ and _FY_ are sometimes referred to as the _marginal_ dis-
tributions of _X_ and _Y_.
All joint probability statements about _X_ and _Y_ can, in theory, be answered in terms
of their joint distribution function. For instance, suppose we wanted to compute the
joint probability that _X_ is greater than _a_ and _Y_ is greater than _b_. This could be done
as follows:

```
P { X > a , Y > b }= 1 − P ({ X > a , Y > b } c )
= 1 − P ({ X > a } c ∪{ Y > b } c )
= 1 − P ({ X ... a }∪{ Y ... b }) (1.1)
= 1 −[ P { X ... a }+ P { Y ... b }− P { X ... a , Y ... b }]
= 1 − FX ( a )− FY ( b )+ F ( a , b )
```
Equation (1.1) is a special case of the following equation, whose verification is left as
an exercise:

```
P { a 1 < X ... a 2 , b 1 < Y ... b 2 }
= F ( a 2 , b 2 )+ F ( a 1 , b 1 )− F ( a 1 , b 2 )− F ( a 2 , b 1 ) (1.2)
```
whenever _a_ 1 < _a_ 2 , _b_ 1 < _b_ 2.
In the case when _X_ and _Y_ are both discrete random variables, it is convenient to
define the _joint probability mass function_ of _X_ and _Y_ by

```
p ( x , y )= P { X = x , Y = y }
```
The probability mass function of _X_ can be obtained from _p_ ( _x_ , _y_ )by

```
pX ( x )= P { X = x }
=
```
##### ∑

```
y : p ( x , y )> 0
```
```
p ( x , y )
```
Similarly,

```
pY ( y )=
```
##### ∑

```
x : p ( x , y )> 0
```
```
p ( x , y )
```
**_EXAMPLE 1a_**

Suppose that 3 balls are randomly selected from an urn containing 3 red, 4 white, and
5 blue balls. If we let _X_ and _Y_ denote, respectively, the number of red and white balls
chosen, then the joint probability mass function of _X_ and _Y_ , _p_ ( _i_ , _j_ )= _P_ { _X_ = _i_ , _Y_ = _j_ },
is given by

```
p (0, 0)=
```
##### (

##### 5

##### 3

##### )/(

##### 12

##### 3

##### )

##### =

##### 10

##### 220

```
p (0, 1)=
```
##### (

##### 4

##### 1

##### )(

##### 5

##### 2

##### )/(

##### 12

##### 3

##### )

##### =

##### 40

##### 220

```
p (0, 2)=
```
##### (

##### 4

##### 2

##### )(

##### 5

##### 1

##### )/(

##### 12

##### 3

##### )

##### =

##### 30

##### 220

```
p (0, 3)=
```
##### (

##### 4

##### 3

##### )/(

##### 12

##### 3

##### )

##### =

##### 4

##### 220


**234** Chapter 6 Jointly Distributed Random Variables

```
p (1, 0)=
```
##### (

##### 3

##### 1

##### )(

##### 5

##### 2

##### )/(

##### 12

##### 3

##### )

##### =

##### 30

##### 220

```
p (1, 1)=
```
##### (

##### 3

##### 1

##### )(

##### 4

##### 1

##### )(

##### 5

##### 1

##### )/(

##### 12

##### 3

##### )

##### =

##### 60

##### 220

```
p (1, 2)=
```
##### (

##### 3

##### 1

##### )(

##### 4

##### 2

##### )/(

##### 12

##### 3

##### )

##### =

##### 18

##### 220

```
p (2, 0)=
```
##### (

##### 3

##### 2

##### )(

##### 5

##### 1

##### )/(

##### 12

##### 3

##### )

##### =

##### 15

##### 220

```
p (2, 1)=
```
##### (

##### 3

##### 2

##### )(

##### 4

##### 1

##### )/(

##### 12

##### 3

##### )

##### =

##### 12

##### 220

```
p (3, 0)=
```
##### (

##### 3

##### 3

##### )/(

##### 12

##### 3

##### )

##### =

##### 1

##### 220

```
These probabilities can most easily be expressed in tabular form, as in Table 6.1. The
reader should note that the probability mass function of X is obtained by computing
the row sums, whereas the probability mass function of Y is obtained by comput-
ing the column sums. Because the individual probability mass functions of X and Y
thus appear in the margin of such a table, they are often referred to as the marginal
probability mass functions of X and Y , respectively..
```
```
TABLE 6.1: P { X = i , Y = j }
j
i 0123Rowsum= P { X = i }
```
```
0
```
```
10
220
```
```
40
220
```
```
30
220
```
```
4
220
```
```
84
220
```
```
1
30
220
```
```
60
220
```
```
18
220
```
```
0
108
220
```
```
2
```
```
15
220
```
```
12
220
```
```
00
```
```
27
220
```
```
3
```
```
1
220
000
```
```
1
220
```
```
Column sum= P { Y = j }
```
```
56
220
```
```
112
220
```
```
48
220
```
```
4
220
```
```
EXAMPLE 1b
Suppose that 15 percent of the families in a certain community have no children, 20
percent have 1 child, 35 percent have 2 children, and 30 percent have 3. Suppose
further that in each family each child is equally likely (independently) to be a boy or
a girl. If a family is chosen at random from this community, then B , the number of
boys, and G , the number of girls, in this family will have the joint probability mass
function shown in Table 6.2.
```

```
Section 6.1 Joint Distribution Functions 235
```
```
TABLE 6.2: P { B = i , G = j }
```
```
j
i 0123Rowsum= P { B = i }
```
```
0 .15 .10 .0875 .0375 .3750
1 .10 .175 .1125 0 .3875
2 .0875 .1125 0 0 .2000
3 .0375 0 0 0 .0375
```
Columnsum= _P_ { _G_ = _j_ } .3750 .3875 .2000 .0375

```
The probabilities shown in Table 6.2 are obtained as follows:
```
```
P { B =0, G = 0 }= P {no children}=. 15
P { B =0, G = 1 }= P {1 girl and total of 1 child}
```
```
= P {1 child} P {1 girl|1 child}=(. 20 )
```
##### (

##### 1

##### 2

##### )

```
P { B =0, G = 2 }= P {2 girls and total of 2 children}
```
```
= P {2 children} P {2 girls|2 children}=(. 35 )
```
##### (

##### 1

##### 2

##### ) 2

We leave the verification of the remaining probabilities in the table to the reader..

We say that _X_ and _Y_ are _jointly continuous_ if there exists a function _f_ ( _x_ , _y_ ), defined
for all real _x_ and _y_ , having the property that, for every set _C_ of pairs of real numbers
(that is, _C_ is a set in the two-dimensional plane),

##### P {( X , Y )∈ C }=

##### ∫∫

```
( x , y )∈ C
```
```
f ( x , y ) dx dy (1.3)
```
The function _f_ ( _x_ , _y_ )is called the _joint probability density function_ of _X_ and _Y_ .If _A_
and _B_ are any sets of real numbers, then, by defining _C_ ={( _x_ , _y_ ): _x_ ∈ _A_ , _y_ ∈ _B_ },we
see from Equation (1.3) that

##### P { X ∈ A , Y ∈ B }=

##### ∫

```
B
```
##### ∫

```
A
```
```
f ( x , y ) dx dy (1.4)
```
Because

```
F ( a , b )= P { X ∈(−q, a ], Y ∈(−q, b ]}
```
```
=
```
```
∫ b
```
```
−q
```
```
∫ a
```
```
−q
```
```
f ( x , y ) dx dy
```
it follows, upon differentiation, that

```
f ( a , b )=
```
##### ∂^2

```
∂ a ∂ b
```
```
F ( a , b )
```
wherever the partial derivatives are defined. Another interpretation of the joint den-
sity function, obtained from Equation (1.4), is


**236** Chapter 6 Jointly Distributed Random Variables

```
P { a < X < a + da , b < Y < b + db }=
```
```
∫ d + db
```
```
b
```
```
∫ a + da
```
```
a
```
```
f ( x , y ) dx dy
```
```
L f ( a , b ) da db
```
```
when da and db are small and f ( x , y )is continuous at a , b. Hence, f ( a , b )is a measure
of how likely it is that the random vector ( X , Y ) will be near ( a , b ).
If X and Y are jointly continuous, they are individually continuous, and their prob-
ability density functions can be obtained as follows:
```
```
P { X ∈ A }= P { X ∈ A , Y ∈(−q,q)}
```
```
=
```
##### ∫

```
A
```
```
∫q
```
```
−q
```
```
f ( x , y ) dy dx
```
##### =

##### ∫

```
A
```
```
fX ( x ) dx
```
```
where
fX ( x )=
```
```
∫q
```
```
−q
```
```
f ( x , y ) dy
```
```
is thus the probability density function of X. Similarly, the probability density func-
tion of Y is given by
fY ( y )=
```
```
∫q
```
```
−q
```
```
f ( x , y ) dx
```
```
EXAMPLE 1c
The joint density function of X and Y is given by
```
```
f ( x , y )=
```
##### {

```
2 e − xe −^2 y 0 < x <q,0< y <q
0 otherwise
```
```
Compute (a) P { X >1, Y < 1 },(b) P { X < Y }, and (c) P { X < a }.
```
```
Solution. (a)
```
##### P { X >1, Y < 1 }=

##### ∫ 1

```
0
```
```
∫q
```
```
1
```
```
2 e − xe −^2 ydx dy
```
##### =

##### ∫ 1

```
0
```
```
2 e −^2 y
```
##### (

```
− e − x
```
##### ∣

```
∣q
1
```
##### )

```
dy
```
```
= e −^1
```
##### ∫ 1

```
0
```
```
2 e −^2 ydy
```
```
= e −^1 ( 1 − e −^2 )
```
```
(b)
```
##### P { X < Y }=

##### ∫∫

```
( x , y ): x < y
```
```
2 e − xe −^2 ydx dy
```
##### =

```
∫q
```
```
0
```
```
∫ y
```
```
0
```
```
2 e − xe −^2 ydx dy
```

```
Section 6.1 Joint Distribution Functions 237
```
##### =

```
∫q
```
```
0
```
```
2 e −^2 y ( 1 − e − y ) dy
```
##### =

```
∫q
```
```
0
```
```
2 e −^2 ydy −
```
```
∫q
```
```
0
```
```
2 e −^3 ydy
```
##### = 1 −

##### 2

##### 3

##### =

##### 1

##### 3

```
(c)
```
```
P { X < a }=
```
```
∫ a
```
```
0
```
```
∫q
```
```
0
```
```
2 e −^2 ye − xdy dx
```
##### =

```
∫ a
```
```
0
```
```
e − xdx
```
```
= 1 − e − a.
```
**_EXAMPLE 1d_**

Consider a circle of radius _R_ , and suppose that a point within the circle is randomly
chosen in such a manner that all regions within the circle of equal area are equally
likely to contain the point. (In other words, the point is uniformly distributed within
the circle.) If we let the center of the circle denote the origin and define _X_ and _Y_ to be
the coordinates of the point chosen (Figure 6.1), then, since ( _X_ , _Y_ ) is equally likely
to be near each point in the circle, it follows that the joint density function of _X_ and
_Y_ is given by

```
f ( x , y )=
```
##### {

```
c if x^2 + y^2 ... R^2
0if x^2 + y^2 > R^2
```
for some value of _c_.

```
(a) Determine c.
(b) Find the marginal density functions of X and Y.
(c) Compute the probability that D , the distance from the origin of the point selected,
is less than or equal to a.
(d) Find E [ D ].
```
```
(0, 0)
```
```
( X , Y )
```
```
R
```
```
x
```
```
y
```
```
FIGURE 6.1: Joint probability distribution.
```

**238** Chapter 6 Jointly Distributed Random Variables

```
Solution. (a) Because ∫
q
```
```
−q
```
```
∫q
```
```
−q
```
```
f ( x , y ) dy dx = 1
```
```
it follows that
c
```
##### ∫∫

```
x^2 + y^2 ... R^2
```
```
dy dx = 1
```
```
We can evaluate
```
##### ∫∫

```
x^2 + y^2 ... R^2 dy dx either by using polar coordinates or,
more simply, by noting that it represents the area of the circle and is thus equal
toπ R^2. Hence,
c =
```
##### 1

```
π R^2
```
```
(b)
```
```
fX ( x )=
```
```
∫q
```
```
−q
```
```
f ( x , y ) dy
```
##### =

##### 1

```
π R^2
```
##### ∫

```
x^2 + y^2 ... R^2
```
```
dy
```
##### =

##### 1

```
π R^2
```
```
∫ c
```
```
− c
```
```
dy , where c =
```
##### √

```
R^2 − x^2
```
##### =

##### 2

```
π R^2
```
##### √

```
R^2 − x^2 x^2 ... R^2
```
```
and it equals 0 when x^2 > R^2. By symmetry, the marginal density of Y is given by
```
```
fY ( y )=
```
##### 2

```
π R^2
```
##### √

```
R^2 − y^2 y^2 ... R^2
```
```
= 0 y^2 > R^2
```
```
(c) The distribution function of D =
```
##### √

```
X^2 + Y^2 , the distance from the origin, is
obtained as follows: For 0... a ... R ,
```
```
FD ( a )= P {
```
##### √

```
X^2 + Y^2 ... a }
= P { X^2 + Y^2 ... a^2 }
```
```
=
```
##### ∫∫

```
x^2 + y^2 ... a^2
```
```
f ( x , y ) dy dx
```
##### =

##### 1

```
π R^2
```
##### ∫∫

```
x^2 + y^2 ... a^2
```
```
dy dx
```
##### =

```
π a^2
π R^2
```
```
=
```
```
a^2
R^2
where we have used the fact that
```
##### ∫∫

```
x^2 + y^2 ... a^2 dy dx is the area of a circle of radius
a and thus is equal toπ a^2.
```

```
Section 6.1 Joint Distribution Functions 239
```
```
(d) From part (c), the density function of D is
```
```
fD ( a )=
```
```
2 a
R^2
```
```
0 ... a ... R
```
```
Hence,
```
```
E [ D ]=
```
##### 2

##### R^2

##### ∫ R

```
0
```
```
a^2 da =
```
##### 2 R

(^3).
**_EXAMPLE 1e_**
The joint density of _X_ and _Y_ is given by
_f_ ( _x_ , _y_ )=

##### {

```
e −( x + y ) 0 < x <q,0< y <q
0 otherwise
```
Find the density function of the random variable _X_ / _Y_.

**_Solution._** We start by computing the distribution function of _X_ / _Y_ .For _a_ >0,

```
FX / Y ( a )= P
```
##### {

##### X

##### Y

```
... a
```
##### }

##### =

##### ∫∫

```
x / y ... a
```
```
e −( x + y ) dx dy
```
##### =

```
∫q
```
```
0
```
```
∫ ay
```
```
0
```
```
e −( x + y ) dx dy
```
##### =

```
∫q
```
```
0
```
```
( 1 − e − ay ) e − ydy
```
##### =

##### {

```
− e − y +
```
```
e −( a +^1 ) y
a + 1
```
##### }∣∣

##### ∣

##### ∣

##### ∣

##### ∣

```
q
```
```
0
= 1 −
```
##### 1

```
a + 1
```
Differentiation shows that the density function of _X_ / _Y_ is given by _fX_ / _Y_ ( _a_ ) = 1 /
( _a_ + 1 )^2 ,0< _a_ <q..

We can also define joint probability distributions for _n_ random variables in exactly
thesamemanneraswedidfor _n_ =2. For instance, the joint cumulative probabil-
ity distribution function _F_ ( _a_ 1 , _a_ 2 ,..., _an_ )of the _n_ random variables _X_ 1 , _X_ 2 ,..., _Xn_ is
defined by

```
F ( a 1 , a 2 ,..., an )= P { X 1 ... a 1 , X 2 ... a 2 ,..., Xn ... an }
```
Further, the _n_ random variables are said to be _jointly continuous_ if there exists a
function _f_ ( _x_ 1 , _x_ 2 ,..., _xn_ ), called the _joint probability density function_ , such that, for
any set _C_ in _n_ -space,

```
P {( X 1 , X 2 ,..., Xn )∈ C }=
```
##### ∫∫

##### ···

##### ∫

```
( x 1 ,..., xn )∈ C
```
```
f ( x 1 ,..., xn ) dx 1 dx 2 ··· dxn
```

**240** Chapter 6 Jointly Distributed Random Variables

```
In particular, for any n sets of real numbers A 1 , A 2 ,..., An ,
```
```
P { X 1 ∈ A 1 , X 2 ,∈ A 2 ,..., Xn ∈ An }
```
```
=
```
##### ∫

```
An
```
##### ∫

```
An − 1
```
##### ···

##### ∫

```
A 1
```
```
f ( x 1 ,..., xn ) dx 1 dx 2 ··· dxn
```
```
EXAMPLE 1f The multinomial distribution
One of the most important joint distributions is the multinomial distribution, which
arises when a sequence of n independent and identical experiments is performed.
Suppose that each experiment can result in any one of r possible outcomes, with
respective probabilities p 1 , p 2 ,..., pr ,
```
```
∑ r
i = 1
```
```
pi =1. If we let Xi denote the number of the
```
```
n experiments that result in outcome number i ,then
```
```
P { X 1 = n 1 , X 2 = n 2 ,..., Xr = nr }=
```
```
n!
n 1! n 2 !··· nr!
```
```
pn 11 pn 22 ··· pnrr (1.5)
```
```
whenever
```
```
∑ r
i = 1
```
```
ni = n.
```
```
Equation (1.5) is verified by noting that any sequence of outcomes for the n experi-
ments that leads to outcome i occurring ni times for i =1, 2,..., r will, by the assumed
independence of experiments, have probability pn 11 pn 22 ... pnrr of occurring. Because
there are n !/( n 1! n 2 !... nr !)such sequences of outcomes (there are n !/ n 1 !... nr !dif-
ferent permutations of n things of which n 1 are alike, n 2 are alike,..., nr are alike),
Equation (1.5) is established. The joint distribution whose joint probability mass func-
tion is specified by Equation (1.5) is called the multinomial distribution. Note that
when r =2, the multinomial reduces to the binomial distribution.
Note also that any sum of a fixed set of the Xi ′ s will have a binomial distribution.
That is, if N ({1, 2,..., r },then
```
##### ∑

```
i ∈ NXi will be a binomial random variable with
parameters n and p =
```
##### ∑

```
i ∈ Npi .This follows because
```
##### ∑

```
i ∈ NXi represents the number
of the n experiments whose outcome is in N , and each experiment will independently
have such an outcome with probability
```
##### ∑

```
i ∈ Npi.
As an application of the multinomial distribution, suppose that a fair die is rolled
9 times. The probability that 1 appears three times, 2 and 3 twice each, 4 and 5 once
each, and 6 not at all is
```
```
9!
3!2!2!1!1!0!
```
##### (

##### 1

##### 6

##### ) 3 (

##### 1

##### 6

##### ) 2 (

##### 1

##### 6

##### ) 2 (

##### 1

##### 6

##### ) 1 (

##### 1

##### 6

##### ) 1 (

##### 1

##### 6

##### ) 0

##### =

##### 9!

##### 3!2!2!

##### (

##### 1

##### 6

##### ) 9

### 6.2 Independent Random Variables

```
The random variables X and Y are said to be independent if, for any two sets of real
numbers A and B ,
```
##### P { X ∈ A , Y ∈ B }= P { X ∈ A } P { Y ∈ B } (2.1)

```
In other words, X and Y are independent if, for all A and B , the events EA ={ X ∈ A }
and FB ={ Y ∈ B }are independent.
It can be shown by using the three axioms of probability that Equation (2.1) will
follow if and only if, for all a , b ,
```
```
P { X ... a , Y ... b }= P { X ... a } P { Y ... b }
```

```
Section 6.2 Independent Random Variables 241
```
Hence, in terms of the joint distribution function _F_ of _X_ and _Y_ , _X_ and _Y_ are inde-
pendent if
_F_ ( _a_ , _b_ )= _FX_ ( _a_ ) _FY_ ( _b_ ) for all _a_ , _b_

When _X_ and _Y_ are discrete random variables, the condition of independence (2.1) is
equivalent to
_p_ ( _x_ , _y_ )= _pX_ ( _x_ ) _pY_ ( _y_ ) for all _x_ , _y_ (2.2)

The equivalence follows because, if Equation (2.1) is satisfied, then we obtain Equa-
tion (2.2) by letting _A_ and _B_ be, respectively, the one-point sets _A_ ={ _x_ }and _B_ ={ _y_ }.
Furthermore, if Equation (2.2) is valid, then, for any sets _A_ , _B_ ,

```
P { X ∈ A , Y ∈ B }=
```
##### ∑

```
y ∈ B
```
##### ∑

```
x ∈ A
```
```
p ( x , y )
```
##### =

##### ∑

```
y ∈ B
```
##### ∑

```
x ∈ A
```
```
pX ( x ) pY ( y )
```
##### =

##### ∑

```
y ∈ B
```
```
pY ( y )
```
##### ∑

```
x ∈ A
```
```
pX ( x )
```
##### = P { Y ∈ B } P { X ∈ A }

and Equation (2.1) is established.
In the jointly continuous case, the condition of independence is equivalent to

```
f ( x , y )= fX ( x ) fY ( y ) for all x , y
```
Thus, loosely speaking, _X_ and _Y_ are independent if knowing the value of one does
not change the distribution of the other. Random variables that are not independent
are said to be _dependent_.

**_EXAMPLE 2a_**

Suppose that _n_ + _m_ independent trials having a common probability of success _p_ are
performed. If _X_ is the number of successes in the first _n_ trials, and _Y_ is the number
of successes in the final _m_ trials, then _X_ and _Y_ are independent, since knowing the
number of successes in the first _n_ trials does not affect the distribution of the number
of successes in the final _m_ trials (by the assumption of independent trials). In fact, for
integral _x_ and _y_ ,

```
P { X = x , Y = y }=
```
##### (

```
n
x
```
##### )

```
px ( 1 − p ) n − x
```
##### (

```
m
y
```
##### )

```
py ( 1 − p ) m − y
0 ... x ... n ,
0 ... y ... m
= P { X = x } P { Y = y }
```
In contrast, _X_ and _Z_ will be dependent, where _Z_ is the total number of successes in
the _n_ + _m_ trials. (Why?).

**_EXAMPLE 2b_**

Suppose that the number of people who enter a post office on a given day is a Poisson
random variable with parameterλ. Show that if each person who enters the post office
is a male with probability _p_ and a female with probability 1− _p_ , then the number of
males and females entering the post office are independent Poisson random variables
with respective parametersλ _p_ andλ( 1 − _p_ ).


**242** Chapter 6 Jointly Distributed Random Variables

```
Solution. Let X and Y denote, respectively, the number of males and females that
enter the post office. We shall show the independence of X and Y by establishing
Equation (2.2). To obtain an expression for P { X = i , Y = j }, we condition on X + Y
as follows:
```
```
P { X = i , Y = j }= P { X = i , Y = j | X + Y = i + j } P { X + Y = i + j }
+ P { X = i , Y = j | X + Y Z i + j } P { X + Y Z i + j }
```
```
[Note that this equation is merely a special case of the formula P ( E )= P ( E | F ) P ( F )+
P ( E | Fc ) P ( Fc ).]
Since P { X = i , Y = j | X + Y Z i + j }is clearly 0, we obtain
```
```
P { X = i , Y = j }= P { X = i , Y = j | X + Y = i + j } P { X + Y = i + j } (2.3)
```
```
Now, because X + Y is the total number of people who enter the post office, it
follows, by assumption, that
```
```
P { X + Y = i + j }= e −λ
```
```
λ i + j
( i + j )!
```
##### (2.4)

```
Furthermore, given that i + j people do enter the post office, since each person
entering will be male with probability p , it follows that the probability that exactly
i (of them will be male (and thus j of them female) is just the binomial probability
i + j
i
```
##### )

```
pi ( 1 − p ) j. That is,
```
```
P { X = i , Y = j | X + Y = i + j }=
```
##### (

```
i + j
i
```
##### )

```
pi ( 1 − p ) j (2.5)
```
```
Substituting Equations (2.4) and (2.5) into Equation (2.3) yields
```
```
P { X = i , Y = j }=
```
##### (

```
i + j
i
```
##### )

```
pi ( 1 − p ) je −λ
```
```
λ i + j
( i + j )!
```
```
= e −λ
```
```
(λ p ) i
i! j!
```
```
[λ( 1 − p )] j
```
##### =

```
e −λ p (λ p ) i
i!
```
```
e −λ(^1 − p )
```
```
[λ( 1 − p )] j
j!
```
##### (2.6)

```
Hence,
```
```
P { X = i }= e −λ p
```
```
(λ p ) i
i!
```
##### ∑

```
j
```
```
e −λ(^1 − p )
```
```
[λ( 1 − p )] j
j!
```
```
= e −λ p
```
```
(λ p ) i
i!
```
##### (2.7)

```
and similarly,
```
```
P { Y = j }= e −λ(^1 − p )
```
```
[λ( 1 − p )] j
j!
```
##### (2.8)

```
Equations (2.6), (2.7), and (2.8) establish the desired result..
```

```
Section 6.2 Independent Random Variables 243
```
**_EXAMPLE 2c_**

A man and a woman decide to meet at a certain location. If each of them indepen-
dently arrives at a time uniformly distributed between 12 noon and 1P.M., find the
probability that the first to arrive has to wait longer than 10 minutes.

**_Solution._** If we let _X_ and _Y_ denote, respectively, the time past 12 that the man and
the woman arrive, then _X_ and _Y_ are independent random variables, each of which is
uniformly distributed over (0, 60). The desired probability, _P_ { _X_ + 10 < _Y_ }+ _P_ { _Y_ +
10 < _X_ }, which, by symmetry, equals 2 _P_ { _X_ + 10 < _Y_ }, is obtained as follows:

##### 2 P { X + 10 < Y }= 2

##### ∫∫

```
x + 10 < y
```
```
f ( x , y ) dx dy
```
##### = 2

##### ∫∫

```
x + 10 < y
```
```
fX ( x ) fY ( y ) dx dy
```
##### = 2

##### ∫ 60

```
10
```
```
∫ y − 10
```
```
0
```
##### (

##### 1

##### 60

##### ) 2

```
dx dy
```
##### =

##### 2

##### ( 60 )^2

##### ∫ 60

```
10
```
```
( y − 10 ) dy
```
##### =

##### 25

(^36).
Our next example presents the oldest problem dealing with geometrical probabil-
ities. It was first considered and solved by Buffon, a French naturalist of the 18th
century, and is usually referred to as _Buffon’s needle problem_.
**_EXAMPLE 2d Buffon’s needle problem_**
A table is ruled with equidistant parallel lines a distance _D_ apart. A needle of length _L_ ,
where _L_ ... _D_ , is randomly thrown on the table. What is the probability that the nee-
dle will intersect one of the lines (the other possibility being that the needle will be
completely contained in the strip between two lines)?
**_Solution._** Let us determine the position of the needle by specifying (1) the distance _X_
from the middle point of the needle to the nearest parallel line and (2) the angleθ
between the needle and the projected line of length _X_. (See Figure 6.2.) The needle
will intersect a line if the hypotenuse of the right triangle in Figure 6.2 is less than
_L_ /2—that is, if
_X_
cosθ

##### <

##### L

##### 2

```
or X <
```
##### L

##### 2

```
cosθ
```
```
X 
```
```
FIGURE 6.2
```

**244** Chapter 6 Jointly Distributed Random Variables

```
As X varies between 0 and D /2andθbetween 0 andπ/2, it is reasonable to assume
that they are independent, uniformly distributed random variables over these respec-
tive ranges. Hence,
```
##### P

##### {

##### X <

##### L

##### 2

```
cosθ
```
##### }

##### =

##### ∫∫

```
x < L /2 cos y
```
```
fX ( x ) f θ( y ) dx dy
```
##### =

##### 4

```
π D
```
```
∫π/ 2
```
```
0
```
```
∫ L /2 cos y
```
```
0
```
```
dx dy
```
##### =

##### 4

```
π D
```
```
∫π/ 2
```
```
0
```
##### L

##### 2

```
cos ydy
```
##### =

##### 2 L

```
π D.
```
```
∗ EXAMPLE 2e Characterization of the normal distribution
```
```
Let X and Y denote the horizontal and vertical miss distances when a bullet is fired
at a target, and assume that
```
1. _X_ and _Y_ are independent continuous random variables having differentiable
    density functions.
2. The joint density _f_ ( _x_ , _y_ )= _fX_ ( _x_ ) _fY_ ( _y_ )of _X_ and _Y_ depends on ( _x_ , _y_ ) only through
    _x_^2 + _y_^2.
Loosely put, assumption 2 states that the probability of the bullet landing on any
point of the _x_ – _y_ plane depends only on the distance of the point from the target and
not on its angle of orientation. An equivalent way of phrasing this assumption is to
say that the joint density function is rotation invariant.
It is a rather interesting fact that assumptions 1 and 2 imply that _X_ and _Y_ are
normally distributed random variables. To prove this, note first that the assumptions
yield the relation
_f_ ( _x_ , _y_ )= _fX_ ( _x_ ) _fY_ ( _y_ )= _g_ ( _x_^2 + _y_^2 ) (2.9)

```
for some function g. Differentiating Equation (2.9) with respect to x yields
```
```
fX ′( x ) fY ( y )= 2 xg ′( x^2 + y^2 ) (2.10)
```
```
Dividing Equation (2.10) by Equation (2.9) gives
```
```
fX ′( x )
fX ( x )
```
##### =

```
2 xg ′( x^2 + y^2 )
g ( x^2 + y^2 )
or
fX ′( x )
2 xfX ( x )
```
##### =

```
g ′( x^2 + y^2 )
g ( x^2 + y^2 )
```
##### (2.11)

```
Because the value of the left-hand side of Equation (2.11) depends only on x ,
whereas the value of the right-hand side depends on x^2 + y^2 , it follows that the
left-hand side must be the same for all x. To see this, consider any x 1 , x 2 and let y 1 , y 2
be such that x^21 + y^21 = x^22 + y^22. Then, from Equation (2.11), we obtain
```
```
fX ′( x 1 )
2 x 1 fX ( x 1 )
```
##### =

```
g ′( x^21 + y^21 )
g ( x^21 + y^21 )
```
##### =

```
g ′( x^22 + y^22 )
g ( x^22 + y^22 )
```
##### =

```
fX ′( x 2 )
2 x 2 fX ( x 2 )
```

```
Section 6.2 Independent Random Variables 245
```
Hence,
_fX_ ′( _x_ )
_xfX_ ( _x_ )

```
= c or
```
```
d
dx
```
```
(log fX ( x ))= cx
```
which implies, upon integration of both sides, that

```
log fX ( x )= a +
```
```
cx^2
2
```
```
or fX ( x )= kecx
```
(^2) / 2
Since
∫q
−q _fX_ ( _x_ ) _dx_ =1, it follows that _c_ is necessarily negative, and we may write
_c_ =− 1 /σ^2. Thus,
_fX_ ( _x_ )= _ke_ − _x_
(^2) / 2 σ 2
That is, _X_ is a normal random variable with parametersμ =0andσ^2. A similar
argument can be applied to _fY_ ( _y_ )to show that
_fY_ ( _y_ )=

##### 1

##### √

```
2 πσ
```
```
e − y
```
(^2) / 2 σ 2
Furthermore, it follows from assumption 2 thatσ^2 =σ^2 and that _X_ and _Y_ are thus
independent, identically distributed normal random variables with parametersμ= 0
andσ^2..
A necessary and sufficient condition for the random variables _X_ and _Y_ to be
independent is for their joint probability density function (or joint probability mass
function in the discrete case) _f_ ( _x_ , _y_ ) to factor into two terms, one depending only on
_x_ and the other depending only on _y_.
**Proposition 2.1.** The continuous (discrete) random variables _X_ and _Y_ are indepen-
dent if and only if their joint probability density (mass) function can be expressed as
_fX_ , _Y_ ( _x_ , _y_ )= _h_ ( _x_ ) _g_ ( _y_ ) −q< _x_ <q,−q< _y_ <q
**_Proof._** Let us give the proof in the continuous case. First, note that independence
implies that the joint density is the product of the marginal densities of _X_ and _Y_ ,so
the preceding factorization will hold when the random variables are independent.
Now, suppose that
_fX_ , _Y_ ( _x_ , _y_ )= _h_ ( _x_ ) _g_ ( _y_ )
Then
1 =
∫q
−q
∫q
−q
_fX_ , _Y_ ( _x_ , _y_ ) _dx dy_

##### =

```
∫q
```
```
−q
```
```
h ( x ) dx
```
```
∫q
```
```
−q
```
```
g ( y ) dy
```
```
= C 1 C 2
```
```
where C 1 =
```
```
∫q
−q h ( x ) dx and C^2 =
```
```
∫q
−q g ( y ) dy. Also,
```
```
fX ( x )=
```
```
∫q
```
```
−q
```
```
fX , Y ( x , y ) dy = C 2 h ( x )
```
```
fY ( y )=
```
```
∫q
```
```
−q
```
```
fX , Y ( x , y ) dx = C 1 g ( y )
```

**246** Chapter 6 Jointly Distributed Random Variables

```
Since C 1 C 2 =1, it follows that
```
```
fX , Y ( x , y )= fX ( x ) fY ( y )
```
```
and the proof is complete.
```
```
EXAMPLE 2f
If the joint density function of X and Y is
```
```
f ( x , y )= 6 e −^2 xe −^3 y 0 < x <q,0< y <q
```
```
and is equal to 0 outside this region, are the random variables independent? What if
the joint density function is
```
```
f ( x , y )= 24 xy 0 < x <1, 0< y <1, 0< x + y < 1
```
```
and is equal to 0 otherwise?
```
```
Solution. In the first instance, the joint density function factors, and thus the random
variables, are independent (with one being exponential with rate 2 and the other
exponential with rate 3). In the second instance, because the region in which the joint
density is nonzero cannot be expressed in the form x ∈ A , y ∈ B , the joint density does
not factor, so the random variables are not independent. This can be seen clearly by
letting
```
```
I ( x , y )=
```
##### {

```
1if0< x <1, 0< y <1, 0< x + y < 1
0 otherwise
```
```
and writing
f ( x , y )= 24 xy I ( x , y )
```
```
which clearly does not factor into a part depending only on x and another depending
only on y..
```
```
The concept of independence may, of course, be defined for more than two random
variables. In general, the n random variables X 1 , X 2 ,..., Xn are said to be indepen-
dent if, for all sets of real numbers A 1 , A 2 ,..., An ,
```
```
P { X 1 ∈ A 1 , X 2 ∈ A 2 ,..., Xn ∈ An }=
```
```
∏ n
```
```
i = 1
```
```
P { Xi ∈ Ai }
```
```
As before, it can be shown that this condition is equivalent to
```
```
P { X 1 ... a 1 , X 2 ... a 2 ,..., Xn ... an }
```
##### =

```
∏ n
```
```
i = 1
```
```
P { Xi ... ai } for all a 1 , a 2 ,..., an
```
```
Finally, we say that an infinite collection of random variables is independent if every
finite subcollection of them is independent.
```
```
EXAMPLE 2g How can a computer choose a random subset?
Most computers are able to generate the value of, or simulate , a uniform (0, 1) random
variable by means of a built-in subroutine that (to a high degree of approximation)
```

```
Section 6.2 Independent Random Variables 247
```
produces such “random numbers.” As a result, it is quite easy for a computer to sim-
ulate an indicator (that is, a Bernoulli) random variable. Suppose _I_ is an indicator
variable such that

```
P { I = 1 }= p = 1 − P { I = 0 }
```
The computer can simulate _I_ by choosing a uniform (0, 1) random number _U_ and
then letting

##### I =

```
1if U < p
0if U Ú p
```
Suppose that we are interested in having the computer select _k_ , _k_ ... _n_ , of the num-

bers 1, 2,..., _n_ in such a way that each of the

##### (

```
n
k
```
##### )

```
subsets of size k is equally likely
```
to be chosen. We now present a method that will enable the computer to solve this
task. To generate such a subset, we will first simulate, in sequence, _n_ indicator vari-
ables _I_ 1 , _I_ 2 ,..., _In_ , of which exactly _k_ will equal 1. Those _i_ for which _Ii_ =1 will then
constitute the desired subset.
To generate the random variables _I_ 1 ,..., _In_ , start by simulating _n_ independent uni-
form (0, 1) random variables _U_ 1 , _U_ 2 ,..., _Un_. Now define

##### I 1 =

##### ⎧

##### ⎪⎨

##### ⎪⎩

```
1if U 1 <
```
```
k
n
0 otherwise
```
and then, once _I_ 1 ,..., _Ii_ are determined, recursively set

```
Ii + 1 =
```
##### ⎧

##### ⎪⎨

##### ⎪⎩

```
1if Ui + 1 <
```
```
k −( I 1 + ··· + Ii )
n − i
0 otherwise
```
In words, at the ( _i_ +1)th stage we set _Ii_ + 1 equal to 1 (and thus put _i_ + 1 into the
desired subset) with a probability equal to the remaining number of places in the sub-

set

##### ⎛

```
⎝namely, k −
∑ i
j = 1
```
```
Ij
```
##### ⎞

```
⎠, divided by the remaining number of possibilities (namely,
```
_n_ − _i_ ). Hence, the joint distribution of _I_ 1 , _I_ 2 ,..., _In_ is determined from

##### P { I 1 = 1 }=

```
k
n
```
```
P { Ii + 1 = 1 | I 1 ,..., Ii }=
```
```
k −
```
```
∑ i
```
```
j = 1
```
```
Ij
```
```
n − i
```
```
1 < i < n
```
The proof that the preceding formula results in all subsets of size _k_ being equally
likely to be chosen is by induction on _k_ + _n_. It is immediate when _k_ + _n_ =2(that
is, when _k_ =1, _n_ =1), so assume it to be true whenever _k_ + _n_ ... _l_. Now, suppose
that _k_ + _n_ = _l_ +1, and consider any subset of size _k_ —say, _i_ 1 ... _i_ 2 ...···... _ik_ —and
consider the following two cases.


**248** Chapter 6 Jointly Distributed Random Variables

```
Case 1: i 1 = 1
```
```
P { I 1 = Ii 2 =···= Iik =1, Ij =0 otherwise}
= P { I 1 = 1 } P { Ii 2 =···= Iik =1, Ij =0 otherwise| I 1 = 1 }
```
```
Now given that I 1 =1, the remaining elements of the subset are chosen as if a
subset of size k − 1 were to be chosen from the n −1 elements 2, 3,..., n. Hence,
by the induction hypothesis, the conditional probability that this will result in a given
subset of size k −1 being selected is 1/
```
##### (

```
n − 1
k − 1
```
##### )

. Hence,

```
P { I 1 = Ii 2 =···= Iik =1, Ij =0 otherwise}
```
```
=
```
```
k
n
```
##### 1

##### (

```
n − 1
k − 1
```
##### )=

##### 1

##### (

```
n
k
```
##### )

```
Case 2: i 1 Z 1
```
```
P { Ii 1 = Ii 2 =···= Iik =1, Ij =0 otherwise}
= P { Ii 1 =···= Iik =1, Ij =0 otherwise| I 1 = 0 } P { I 1 = 0 }
```
```
=
```
##### 1

##### (

```
n − 1
k
```
##### )

##### (

##### 1 −

```
k
n
```
##### )

##### =

##### 1

##### (

```
n
k
```
##### )

```
where the induction hypothesis was used to evaluate the preceding conditional prob-
ability.
Thus, in all cases, the probability that a given subset of size k will be the subset
chosen is 1
```
##### /

##### (

```
n
k
```
##### )

##### ..

```
Remark. The foregoing method for generating a random subset has a very low
memory requirement. A faster algorithm that requires somewhat more memory is
presented in Section 10.1. (The latter algorithm uses the last k elements of a random
permutation of 1, 2,..., n .).
```
```
EXAMPLE 2h
Let X , Y , Z be independent and uniformly distributed over (0, 1). Compute P { X Ú
YZ }.
```
```
Solution. Since
```
```
fX , Y , Z ( x , y , z )= fX ( x ) fY ( y ) fZ ( z )= 10 ... x ...1, 0... y ...1, 0... z ... 1
```
```
we have
```
##### P { X Ú YZ }=

##### ∫∫∫

```
x Ú yz
```
```
fX , Y , Z ( x , y , z ) dx dy dz
```
##### =

##### ∫ 1

```
0
```
##### ∫ 1

```
0
```
##### ∫ 1

```
yz
```
```
dx dy dz
```

```
Section 6.2 Independent Random Variables 249
```
##### =

##### ∫ 1

```
0
```
##### ∫ 1

```
0
```
```
( 1 − yz ) dy dz
```
##### =

##### ∫ 1

```
0
```
##### (

##### 1 −

```
z
2
```
##### )

```
dz
```
##### =

##### 3

##### 4.

**_EXAMPLE 2i Probabilistic interpretation of half-life_**

Let _N_ ( _t_ )denote the number of nuclei contained in a radioactive mass of material at
time _t_. The concept of half-life is often defined in a deterministic fashion by stating
this it is an empirical fact that, for some value _h_ , called the _half-life_ ,

```
N ( t )= 2 − t / hN ( 0 ) t > 0
```
[Note that _N_ ( _h_ )= _N_ ( 0 )/2.] Since the preceding implies that, for any nonnegative _s_
and _t_ ,
_N_ ( _t_ + _s_ )= 2 −( _s_ + _t_ )/ _hN_ ( 0 )= 2 − _t_ / _hN_ ( _s_ )

it follows that no matter how much time _s_ has already elapsed, in an additional time _t_
the number of existing nuclei will decrease by the factor 2− _t_ / _h_.
Because the deterministic relationship just given results from observations of radio-
active masses containing huge numbers of nuclei, it would seem that it might be
consistent with a probabilistic interpretation. The clue to deriving the appropriate
probability model for half-life resides in the empirical observation that the propor-
tion of decay in any time interval depends neither on the total number of nuclei at
the beginning at the interval nor on the location of this interval (since _N_ ( _t_ + _s_ )/ _N_ ( _s_ )
depends neither on _N_ ( _s_ )nor on _s_ ). Thus, it appears that the individual nuclei act inde-
pendently and with a memoryless life distribution. Consequently, since the unique life
distribution that is memoryless is the exponential distribution, and since exactly one-
half of a given amount of mass decays every _h_ time units, we propose the following
probabilistic model for radioactive decay.

**Probabilistic interpretation of the half-life** **_h_** **:** The lifetimes of the individual nuclei
are independent random variables having a life distribution that is exponential with
median equal to _h_. That is, if _L_ represents the lifetime of a given nucleus, then

```
P { L < t }= 1 − 2 − t / h
```
(Because _P_ { _L_ < _h_ }=^12 and the preceding can be written as

```
P { L < t }= 1 −exp
```
##### {

```
− t
```
```
log 2
h
```
##### }

it can be seen that _L_ indeed has an exponential distribution with median _h_ .)
Note that, under the probabilistic interpretation of half-life just given, if one starts
with _N_ (0) nuclei at time 0, then _N_ ( _t_ ), the number of nuclei that remain at time _t_ ,
will have a binomial distribution with parameters _n_ = _N_ ( 0 )and _p_ = 2 − _t_ / _h_. Results of
Chapter 8 will show that this interpretation of half-life is consistent with the determin-
istic model when considering the proportion of a large number of nuclei that decay
over a given time frame. However, the difference between the deterministic and prob-
abilistic interpretation becomes apparent when one considers the actual number of


**250** Chapter 6 Jointly Distributed Random Variables

```
decayed nuclei. We will now indicate this with regard to the question of whether
protons decay.
There is some controversy over whether or not protons decay. Indeed, one theory
predicts that protons should decay with a half-life of about h = 1030 years. To check
this prediction empirically, it has been suggested that one follow a large number of
protons for, say, one or two years and determine whether any of them decay within
that period. (Clearly, it would not be feasible to follow a mass of protons for 10^30
years to see whether one-half of it decays.) Let us suppose that we are able to keep
track of N ( 0 )= 1030 protons for c years. The number of decays predicted by the
deterministic model would then be given by
```
```
N ( 0 )− N ( c )= h ( 1 − 2 − c / h )
```
```
=
```
```
1 − 2 − c / h
1 / h
```
```
L lim
x → 0
```
```
1 − 2 − cx
x
```
```
since
```
##### 1

```
h
```
##### = 10 −^30 L 0

```
=lim
x → 0
```
```
( c 2 − cx log 2) by L’Hopital’s ruleˆ
```
```
= c log 2L. 6931 c
```
```
For instance, the deterministic model predicts that in 2 years there should be 1.3863
decays, and it would thus appear to be a serious blow to the hypothesis that protons
decay with a half-life of 10^30 years if no decays are observed over those 2 years.
Let us now contrast the conclusions just drawn with those obtained from the prob-
abilistic model. Again, let us consider the hypothesis that the half-life of protons is
h = 1030 years, and suppose that we follow h protons for c years. Since there is a
huge number of independent protons, each of which will have a very small probabil-
ity of decaying within this time period, it follows that the number of protons which
decay will have (to a very strong approximation) a Poisson distribution with parame-
ter equal to h ( 1 − 2 − c / h )L c log 2. Thus,
```
```
P {0 decays}= e − c log 2
```
```
= e −log(^2
```
```
c )
=
```
##### 1

```
2 c
and, in general,
```
```
P { n decays}=
```
```
2 − c [ c log 2] n
n!
```
```
n Ú 0
```
```
Thus we see that even though the average number of decays over 2 years is (as pre-
dicted by the deterministic model) 1.3863, there is 1 chance in 4 that there will not
be any decays, thereby indicating that such a result in no way invalidates the original
hypothesis of proton decay..
```
```
Remark. Independence is a symmetric relation. The random variables X and Y
are independent if their joint density function (or mass function in the discrete case)
is the product of their individual density (or mass) functions. Therefore, to say that
X is independent of Y is equivalent to saying that Y is independent of X —or just
that X and Y are independent. As a result, in considering whether X is independent
of Y in situations where it is not at all intuitive that knowing the value of Y will not
change the probabilities concerning X , it can be beneficial to interchange the roles of
```

```
Section 6.2 Independent Random Variables 251
```
_X_ and _Y_ and ask instead whether _Y_ is independent of _X_. The next example illustrates
this point..

**_EXAMPLE 2j_**

If the initial throw of the dice in the game of craps results in the sum of the dice
equaling 4, then the player will continue to throw the dice until the sum is either 4 or

7. If this sum is 4, then the player wins, and if it is 7, then the player loses. Let _N_ denote
the number of throws needed until either 4 or 7 appears, and let _X_ denote the value
(either 4 or 7) of the final throw. Is _N_ independent of _X_? That is, does knowing which
of 4 or 7 occurs first affect the distribution of the number of throws needed until that
number appears? Most people do not find the answer to this question to be intuitively
obvious. However, suppose that we turn it around and ask whether _X_ is independent
of _N_. That is, does knowing how many throws it takes to obtain a sum of either 4 or
7 affect the probability that that sum is equal to 4? For instance, suppose we know
that it takes _n_ throws of the dice to obtain a sum of either 4 or 7. Does this affect the
probability distribution of the final sum? Clearly not, since all that is important is that
its value is either 4 or 7, and the fact that none of the first _n_ −1 throws were either 4
or 7 does not change the probabilities for the _n_ th throw. Thus, we can conclude that
_X_ is independent of _N_ , or equivalently, that _N_ is independent of _X_.
    As another example, let _X_ 1 , _X_ 2 ,...be a sequence of independent and identically
distributed continuous random variables, and suppose that we observe these random
variables in sequence. If _Xn_ > _Xi_ for each _i_ =1,..., _n_ − 1, then we say that _Xn_ is
a _record value_. That is, each random variable that is larger than all those preceding
it is called a record value. Let _An_ denote the event that _Xn_ is a record value. Is _An_ + 1
independent of _An_? That is, does knowing that the _n_ th random variable is the largest
of the first _n_ change the probability that the( _n_ + 1 )st random variable is the largest
of the first _n_ +1? While it is true that _An_ + 1 is independent of _An_ , this may not be
intuitively obvious. However, if we turn the question around and ask whether _An_ is
independent of _An_ + 1 , then the result is more easily understood. For knowing that
the( _n_ + 1 )st value is larger than _X_ 1 ,..., _Xn_ clearly gives us no information about
the relative size of _Xn_ among the first _n_ random variables. Indeed, by symmetry, it is
clear that each of these _n_ random variables is equally likely to be the largest of this
set, so _P_ ( _An_ | _An_ + 1 )= _P_ ( _An_ )= 1 / _n_. Hence, we can conclude that _An_ and _An_ + 1 are
independent events..

```
Remark. It follows from the identity
```
```
P { X 1 ... a 1 ,..., Xn ... an }
= P { X 1 ... a 1 } P { X 2 ... a 2 | X 1 ... a 1 }··· P { Xn ... an | X 1 ... a 1 ,..., Xn − 1 ... an − 1 }
```
that the independence of _X_ 1 ,..., _Xn_ can be established sequentially. That is, we can
show that these random variables are independent by showing that

```
X 2 is independent of X 1
X 3 is independent of X 1 , X 2
X 4 is independent of X 1 , X 2 , X 3
#
#
#
Xn is independent of X 1 ,..., Xn − 1
```

**252** Chapter 6 Jointly Distributed Random Variables

### 6.3 Sums of Independent Random Variables

```
It is often important to be able to calculate the distribution of X + Y from the dis-
tributions of X and Y when X and Y are independent. Suppose that X and Y are
independent, continuous random variables having probability density functions fX
and fY. The cumulative distribution function of X + Y is obtained as follows:
```
```
FX + Y ( a )= P { X + Y ... a }
```
```
=
```
##### ∫∫

```
x + y ... a
```
```
fX ( x ) fY ( y ) dx dy
```
##### =

```
∫q
```
```
−q
```
```
∫ a − y
```
```
−q
```
```
fX ( x ) fY ( y ) dx dy (3.1)
```
##### =

```
∫q
```
```
−q
```
```
∫ a − y
```
```
−q
```
```
fX ( x ) dxfY ( y ) dy
```
##### =

```
∫q
```
```
−q
```
```
FX ( a − y ) fY ( y ) dy
```
```
The cumulative distribution function FX + Y is called the convolution of the distribu-
tions FX and FY (the cumulative distribution functions of X and Y , respectively).
By differentiating Equation (3.1), we find that the probability density function
fX + Y of X + Y is given by
```
```
fX + Y ( a )=
```
```
d
da
```
```
∫q
```
```
−q
```
```
FX ( a − y ) fY ( y ) dy
```
##### =

```
∫q
```
```
−q
```
```
d
da
```
```
FX ( a − y ) fY ( y ) dy (3.2)
```
##### =

```
∫q
```
```
−q
```
```
fX ( a − y ) fY ( y ) dy
```
#### 6.3.1 Identically Distributed Uniform Random Variables

```
It is not difficult to determine the density function of the sum of two independent
uniform(0, 1)random variables.
```
```
EXAMPLE 3a Sum of two independent uniform random variables
If X and Y are independent random variables, both uniformly distributed on (0, 1),
calculate the probability density of X + Y.
```
```
Solution. From Equation (3.2), since
```
```
fX ( a )= fY ( a )=
```
##### {

```
10 < a < 1
0 otherwise
```
```
we obtain
fX + Y ( a )=
```
##### ∫ 1

```
0
```
```
fX ( a − y ) dy
```
```
For 0... a ...1, this yields
```
```
fX + Y ( a )=
```
```
∫ a
```
```
0
```
```
dy = a
```

```
Section 6.3 Sums of Independent Random Variables 253
```
```
1
```
```
12
```
```
x
```
```
f ( x )
```
```
0
```
```
FIGURE 6.3: Triangular density function.
```
For 1< _a_ <2, we get

```
fX + Y ( a )=
```
##### ∫ 1

```
a − 1
```
```
dy = 2 − a
```
Hence,

```
fX + Y ( a )=
```
##### ⎧

##### ⎨

##### ⎩

```
a 0 ... a ... 1
2 − a 1 < a < 2
0 otherwise
```
Because of the shape of its density function (see Figure 6.3), the random variable
_X_ + _Y_ is said to have a _triangular_ distribution..

Now, suppose that _X_ 1 , _X_ 2 ,..., _Xn_ are independent uniform(0, 1)random variables,
and let

```
Fn ( x )= P { X 1 +...+ Xn ... x }
```
Whereas a general formula for _Fn_ ( _x_ )is messy, it has a particularly nice form when
_x_ ... 1 .Indeed, we now use mathematical induction to prove that

```
Fn ( x )= xn / n !, 0 ... x ... 1
```
Because the proceeding equation is true for _n_ =1, assume that

```
Fn − 1 ( x )= xn −^1 /( n − 1 )!, 0... x ... 1
```
Now, writing

```
∑ n
```
```
i = 1
```
```
Xi =
```
```
n ∑− 1
```
```
i = 1
```
```
Xi + Xn
```
and using the fact that the _Xi_ are all nonnegative, we see from Equation 3.1 that, for
0 ... _x_ ...1,

```
Fn ( x )=
```
##### ∫ 1

```
0
```
```
Fn − 1 ( x − y ) fXn ( y ) dy
```
##### =

##### 1

```
( n − 1 )!
```
```
∫ x
```
```
0
```
```
( x − y ) n −^1 dy by the induction hypothesis
```
```
= xn / n!
```
which completes the proof.


**254** Chapter 6 Jointly Distributed Random Variables

```
For an interesting application of the preceding formula, let us use it to determine
the expected number of independent uniform(0, 1)random variables that need to
be summed to exceed 1. That is, with X 1 , X 2 ,...being independent uniform(0, 1)
random variables, we want to determine E [ N ], where
```
```
N =min{ n : X 1 +...+ Xn > 1 }
```
```
Noting that N is greater than n >0 if and only if X 1 +...+ Xn ...1, we see that
```
```
P { N > n }= Fn ( 1 )= 1 / n !, n > 0
```
```
Because
P { N > 0 }= 1 = 1 /0!
```
```
we see that, for n >0,
```
```
P { N = n }= P { N > n − 1 }− P { N > n }=
```
##### 1

```
( n − 1 )!
```
##### −

##### 1

```
n!
```
##### =

```
n − 1
n!
Therefore,
```
##### E [ N ]=

```
∑q
```
```
n = 1
```
```
n ( n − 1 )
n!
```
##### =

```
∑q
```
```
n = 2
```
##### 1

```
( n − 2 )!
= e
```
```
That is, the mean number of independent uniform(0, 1)random variables that must
be summed for the sum to exceed 1 is equal to e.
```
#### 6.3.2 Gamma Random Variables

```
Recall that a gamma random variable has a density of the form
```
```
f ( y )=
```
```
λ e −λ y (λ y ) t −^1
( t )
```
```
0 < y <q
```
```
An important property of this family of distributions is that, for a fixed value ofλ,it
is closed under convolutions.
Proposition 3.1. If X and Y are independent gamma random variables with respec-
tive parameters( s ,λ)and( t ,λ),then X + Y is a gamma random variable with param-
eters( s + t ,λ).
```
```
Proof. Using Equation (3.2), we obtain
```
```
fX + Y ( a )=
```
##### 1

```
( s )( t )
```
```
∫ a
```
```
0
```
```
λ e −λ( a − y )[λ( a − y )] s −^1 λ e −λ y (λ y ) t −^1 dy
```
```
= Ke −λ a
```
```
∫ a
```
```
0
```
```
( a − y ) s −^1 yt −^1 dy
```
```
= Ke −λ aas + t −^1
```
##### ∫ 1

```
0
```
```
( 1 − x ) s −^1 xt −^1 dx by letting x =
```
```
y
a
= Ce −λ aas + t −^1
```

```
Section 6.3 Sums of Independent Random Variables 255
```
```
where C is a constant that does not depend on a. But, as the preceding is a density
function and thus must integrate to 1, the value of C is determined, and we have
```
```
fX + Y ( a )=
```
```
λ e −λ a (λ a ) s + t −^1
( s + t )
```
```
Hence, the result is proved.
```
It is now a simple matter to establish, by using Proposition 3.1 and induction, that if
_Xi_ , _i_ =1,..., _n_ are independent gamma random variables with respective parameters

( _ti_ ,λ), _i_ =1,..., _n_ ,then

```
∑ n
i = 1
```
```
Xi is gamma with parameters
```
##### (

```
∑ n
i = 1
```
```
ti ,λ
```
##### )

. We leave the

proof of this statement as an exercise.

**_EXAMPLE 3b_**
Let _X_ 1 , _X_ 2 ,..., _Xn_ be _n_ independent exponential random variables, each having param-
eterλ. Then, since an exponential random variable with parameterλis the same as
a gamma random variable with parameters(1,λ), it follows from Proposition 3.1 that
_X_ 1 + _X_ 2 + ··· + _Xn_ is a gamma random variable with parameters( _n_ ,λ)..

```
If Z 1 , Z 2 ,..., Zn are independent standard normal random variables, then Y K
∑ n
```
_i_ = 1

```
Z^2 i is said to have the chi-squared (sometimes seen asχ^2 ) distribution with n
```
degrees of freedom. Let us compute the density function of _Y_ .When _n_ =1, _Y_ = _Z_^21 ,
and from Example 7b of Chapter 5, we see that its probability density function is
given by

```
fZ 2 ( y )=
```
##### 1

##### 2

##### √

```
y
```
```
[ fZ (
```
##### √

```
y )+ fZ (−
```
##### √

```
y )]
```
##### =

##### 1

##### 2

##### √

```
y
```
##### 2

##### √

```
2 π
```
```
e − y /^2
```
##### =

```
1
2 e
```
− _y_ / (^2) ( _y_ / 2 ) 1 / 2 − 1
√
π
But we recognize the preceding as the gamma distribution with parameters

##### (

```
1
2 ,
```
```
1
2
```
##### )

##### .

[A by-product of this analysis is that

##### (

```
1
2
```
##### )

##### =

##### √

π.] But since each _Z_^2 _i_ is gamma
(
1
2 ,

```
1
2
```
##### )

```
, it follows from Proposition 3.1 that theχ^2 distribution with n degrees of
```
freedom is just the gamma distribution with parameters

##### (

```
n /2,^12
```
##### )

```
and hence has a
```
probability density function given by

```
f χ 2 ( y )=
```
##### 1

##### 2

```
e − y /^2
```
##### (

```
y
2
```
```
) n / 2 − 1
```
##### 

##### (

```
n
2
```
```
) y > 0
```
##### =

```
e − y /^2 yn /^2 −^1
```
```
2 n /^2 
```
##### (

```
n
2
```
```
) y > 0
```

**256** Chapter 6 Jointly Distributed Random Variables

```
When n is an even integer,( n / 2 )=[( n / 2 )−1]!, whereas when n is odd,( n / 2 )can
be obtained from iterating the relationship( t )=( t − 1 )( t − 1 )and then using
the previously obtained result that
```
##### (

```
1
2
```
##### )

##### =

##### √

```
π. [For instance,
```
##### (

```
5
2
```
##### )

##### =^32 

##### (

```
3
2
```
##### )

##### =

```
3
2
```
```
1
2 
```
##### (

```
1
2
```
##### )

##### =^34

##### √

```
π.]
In practice, the chi-squared distribution often arises as the distribution of the square
of the error involved when one attempts to hit a target in n -dimensional space when
the coordinate errors are taken to be independent standard normal random variables.
It is also important in statistical analysis.
```
#### 6.3.3 Normal Random Variables

```
We can also use Equation (3.2) to prove the following important result about normal
random variables.
Proposition 3.2. If Xi , i =1,..., n , are independent random variables that are nor-
mally distributed with respective parametersμ i ,σ i^2 , i =1,..., n ,then
```
```
∑ n
i = 1
```
```
Xi is normally
```
```
distributed with parameters
```
```
∑ n
i = 1
```
```
μ i and
```
```
∑ n
i = 1
```
```
σ i^2.
```
```
Proof of Proposition 3.2: To begin, let X and Y be independent normal random
variables with X having mean 0 and varianceσ^2 and Y having mean 0 and vari-
ance 1. We will determine the density function of X + Y by utilizing Equation (3.2).
Now, with
```
```
c =
```
##### 1

```
2 σ^2
```
##### +

##### 1

##### 2

##### =

```
1 +σ^2
2 σ^2
we have
```
```
fX ( a − y ) fY ( y )=
```
##### 1

##### √

```
2 πσ
```
```
exp
```
##### {

##### −

```
( a − y )^2
2 σ^2
```
##### }

##### 1

##### √

```
2 π
```
```
exp
```
##### {

##### −

```
y^2
2
```
##### }

##### =

##### 1

```
2 πσ
```
```
exp
```
##### {

##### −

```
a^2
2 σ^2
```
##### }

```
exp
```
##### {

```
− c
```
##### (

```
y^2 − 2 y
```
```
a
1 +σ^2
```
##### )}

```
Hence, from Equation (3.2),
```
```
fX + Y ( a )=
```
##### 1

```
2 πσ
```
```
exp
```
##### {

##### −

```
a^2
2 σ^2
```
##### }

```
exp
```
##### {

```
a^2
2 σ^2 ( 1 +σ^2 )
```
##### }

##### *

```
∫q
```
```
−q
```
```
exp
```
##### {

```
− c
```
##### (

```
y −
```
```
a
1 +σ^2
```
##### ) 2 }

```
dy
```
##### =

##### 1

```
2 πσ
```
```
exp
```
##### {

##### −

```
a^2
2 ( 1 +σ^2 )
```
##### }∫

```
q
```
```
−q
```
```
exp{− cx^2 } dx
```
```
= C exp
```
##### {

##### −

```
a^2
2 ( 1 +σ^2 )
```
##### }

```
where C does not depend on a. But this implies that X + Y is normal with mean 0
and variance 1+σ^2.
```

```
Section 6.3 Sums of Independent Random Variables 257
```
Now, suppose that _X_ 1 and _X_ 2 are independent normal random variables with _Xi_
having meanμ _i_ and varianceσ _i_^2 , _i_ =1, 2. Then

```
X 1 + X 2 =σ 2
```
##### (

```
X 1 −μ 1
σ 2
```
##### +

```
X 2 −μ 2
σ 2
```
##### )

```
+μ 1 +μ 2
```
But since( _X_ 1 −μ 1 )/σ 2 is normal with mean 0 and varianceσ 12 /σ 22 ,and( _X_ 2 −μ 2 )/σ 2
is normal with mean 0 and variance 1, it follows from our previous result that( _X_ 1 −
μ 1 )/σ 2 +( _X_ 2 −μ 2 )/σ 2 is normal with mean 0 and variance 1 +σ 12 /σ 22 , implying

that _X_ 1 + _X_ 2 is normal with meanμ 1 +μ 2 and varianceσ 22 ( 1 +σ 12 /σ 22 )=σ 12 +σ 22.
Thus, Proposition 3.2 is established when _n_ =2. The general case now follows by
induction. That is, assume that Proposition 3.2 is true when there are _n_ −1 random
variables. Now consider the case of _n_ , and write

```
∑ n
```
```
i = 1
```
```
Xi =
```
```
n ∑− 1
```
```
i = 1
```
```
Xi + Xn
```
By the induction hypothesis,

```
n ∑− 1
```
```
i = 1
```
```
Xi is normal with mean
```
```
n ∑− 1
```
```
i = 1
```
```
μ i and variance
```
```
n ∑− 1
```
```
i = 1
```
```
σ i^2.
```
Therefore, by the result for _n_ = 2,

```
∑ n
i = 1
```
```
Xi is normal with mean
```
```
∑ n
i = 1
```
```
μ i and variance
∑ n
```
_i_ = 1

```
σ i^2.
```
**_EXAMPLE 3c_**

A basketball team will play a 44-game season. Twenty-six of these games are against
class A teams and 18 are against class B teams. Suppose that the team will win each
game against a class A team with probability .4 and will win each game against a class
B team with probability .7. Suppose also that the results of the different games are
independent. Approximate the probability that

```
(a) the team wins 25 games or more;
(b) the team wins more games against class A teams than it does against class B
teams.
```
**_Solution._** (a) Let _XA_ and _XB_ respectively denote the number of games the team
wins against class A and against class B teams. Note that _XA_ and _XB_ are independent
binomial random variables and

```
E [ XA ]= 26 (. 4 )= 10 .4Var( XA )= 26 (. 4 )(. 6 )= 6. 24
E [ XB ]= 18 (. 7 )= 12 .6Var( XB )= 18 (. 7 )(. 3 )= 3. 78
```
By the normal approximation to the binomial, _XA_ and _XB_ will have approximately
the same distribution as would independent normal random variables with the pre-
ceding expected values and variances. Hence, by Proposition 3.2, _XA_ + _XB_ will have


**258** Chapter 6 Jointly Distributed Random Variables

```
approximately a normal distribution with mean 23 and variance 10.02. Therefore,
letting Z denote a standard normal random variable, we have
```
```
P { XA + XB Ú 25 }= P { XA + XB Ú 24. 5 }
```
##### = P

##### {

##### XA + XB − 23

##### √

##### 10. 02

##### Ú

##### 24. 5 − 23

##### √

##### 10. 02

##### }

##### L P

##### {

##### Z Ú

##### 1. 5

##### √

##### 10. 02

##### }

##### L 1 − P { Z <. 4739 }

##### L. 3178

```
(b)Wenotethat XA − XB will have approximately a normal distribution with
mean−2.2 and variance 10.02. Hence,
```
```
P { XA − XB Ú 1 }= P { XA − XB Ú. 5 }
```
##### = P

##### {

##### XA − XB + 2. 2

##### √

##### 10. 02

##### Ú

##### . 5 + 2. 2

##### √

##### 10. 02

##### }

##### L P

##### {

##### Z Ú

##### 2. 7

##### √

##### 10. 02

##### }

##### L 1 − P { Z <. 8530 }

##### L. 1968

```
Therefore, there is approximately a 31.78 percent chance that the team will win at
least 25 games and approximately a 19.68 percent chance that it will win more games
against class A teams than against class B teams..
```
```
The random variable Y is said to be a lognormal random variable with parame-
tersμandσif log( Y )is a normal random variable with meanμand varianceσ^2.
That is, Y is lognormal if it can be expressed as
```
```
Y = eX
```
```
where X is a normal random variable.
```
```
EXAMPLE 3d
Starting at some fixed time, let S ( n )denote the price of a certain security at the end
of n additional weeks, n Ú1. A popular model for the evolution of these prices
assumes that the price ratios S ( n )/ S ( n − 1 ), n Ú 1, are independent and identi-
cally distributed lognormal random variables. Assuming this model, with parameters
μ=.0165,σ=.0730, what is the probability that
(a) the price of the security increases over each of the next two weeks?
(b) the price at the end of two weeks is higher than it is today?
```
```
Solution. Let Z be a standard normal random variable. To solve part (a), we use the
fact that log( x )increases in x to conclude that x >1 if and only if log( x )>log( 1 )=0.
As a result, we have
```

```
Section 6.3 Sums of Independent Random Variables 259
```
##### P

##### {

##### S ( 1 )

##### S ( 0 )

##### > 1

##### }

##### = P

##### {

```
log
```
##### (

##### S ( 1 )

##### S ( 0 )

##### )

##### > 0

##### }

##### = P

##### {

##### Z >

##### −. 0165

##### . 0730

##### }

##### = P { Z <. 2260 }

##### =. 5894

In other words, the probability that the price is up after one week is .5894. Since the
successive price ratios are independent, the probability that the price increases over
each of the next two weeks is(. 5894 )^2 =.3474.
To solve part (b), we reason as follows:

##### P

##### {

##### S ( 2 )

##### S ( 0 )

##### > 1

##### }

##### = P

##### {

##### S ( 2 )

##### S ( 1 )

##### S ( 1 )

##### S ( 0 )

##### > 1

##### }

##### = P

##### {

```
log
```
##### (

##### S ( 2 )

##### S ( 1 )

##### )

```
+log
```
##### (

##### S ( 1 )

##### S ( 0 )

##### )

##### > 0

##### }

However, log

##### (

```
S ( 2 )
S ( 1 )
```
##### )

```
+log
```
##### (

```
S ( 1 )
S ( 0 )
```
##### )

```
, being the sum of two independent normal random
```
variables with a common mean .0165 and a common standard deviation .0730, is a
normal random variable with mean .0330 and variance 2(. 0730 )^2. Consequently,

##### P

##### {

##### S ( 2 )

##### S ( 0 )

##### > 1

##### }

##### = P

##### {

##### Z >

##### −. 0330

##### . 0730

##### √

##### 2

##### }

##### = P { Z <. 31965 }

##### =. 6254.

#### 6.3.4 Poisson and Binomial Random Variables

Rather than attempt to derive a general expression for the distribution of _X_ + _Y_ in
the discrete case, we shall consider some examples.

**_EXAMPLE 3e Sums of independent Poisson random variables_**

If _X_ and _Y_ are independent Poisson random variables with respective parametersλ 1
andλ 2 , compute the distribution of _X_ + _Y_.

**_Solution._** Because the event{ _X_ + _Y_ = _n_ }may be written as the union of the disjoint
events{ _X_ = _k_ , _Y_ = _n_ − _k_ },0... _k_ ... _n_ , we have

```
P { X + Y = n }=
```
```
∑ n
```
```
k = 0
```
```
P { X = k , Y = n − k }
```
##### =

```
∑ n
```
```
k = 0
```
```
P { X = k } P { Y = n − k }
```
##### =

```
∑ n
```
```
k = 0
```
```
e −λ^1
```
```
λ k 1
k!
```
```
e −λ^2
```
```
λ n 2 − k
( n − k )!
```

**260** Chapter 6 Jointly Distributed Random Variables

```
= e −(λ^1 +λ^2 )
```
```
∑ n
```
```
k = 0
```
```
λ k 1 λ n 2 − k
k !( n − k )!
```
##### =

```
e −(λ^1 +λ^2 )
n!
```
```
∑ n
```
```
k = 0
```
```
n!
k !( n − k )!
```
```
λ k 1 λ n 2 − k
```
##### =

```
e −(λ^1 +λ^2 )
n!
```
```
(λ 1 +λ 2 ) n
```
```
Thus, X 1 + X 2 has a Poisson distribution with parameterλ 1 +λ 2..
```
```
EXAMPLE 3f Sums of independent binomial random variables
Let X and Y be independent binomial random variables with respective parameters
( n , p )and( m , p ). Calculate the distribution of X + Y.
```
```
Solution. Recalling the interpretation of a binomial random variable, and without
any computation at all, we can immediately conclude that X + Y is binomial with
parameters( n + m , p ). This follows because X represents the number of successes in
n independent trials, each of which results in a success with probability p ; similarly,
Y represents the number of successes in m independent trials, each of which results
in a success with probability p. Hence, given that X and Y are assumed independent,
it follows that X + Y represents the number of successes in n + m independent
trials when each trial has a probability p of resulting in a success. Therefore, X + Y
is a binomial random variable with parameters( n + m , p ). To check this conclusion
analytically, note that
```
```
P { X + Y = k }=
```
```
∑ n
```
```
i = 0
```
```
P { X = i , Y = k − i }
```
##### =

```
∑ n
```
```
i = 0
```
```
P { X = i } P { Y = k − i }
```
##### =

```
∑ n
```
```
i = 0
```
##### (

```
n
i
```
##### )

```
piqn − i
```
##### (

```
m
k − i
```
##### )

```
pk − iqm − k + i
```
```
where q = 1 − p and where
```
##### (

```
r
j
```
##### )

```
=0 when j <0. Thus,
```
```
P { X + Y = k }= pkqn + m − k
```
```
∑ n
```
```
i = 0
```
##### (

```
n
i
```
##### )(

```
m
k − i
```
##### )

```
and the conclusion follows upon application of the combinatorial identity
(
n + m
k
```
##### )

##### =

```
∑ n
```
```
i = 0
```
##### (

```
n
i
```
##### )(

```
m
k − i
```
##### )

#### 6.3.5 Geometric Random Variables...................

```
Let X 1 ,..., Xn be independent geometric random variables, with Xi having parame-
ter pi for i =1,..., n. We are interested in computing the probability mass function
```

```
Section 6.3 Sums of Independent Random Variables 261
```
of their sum _Sn_ =

∑ _n
i_ = 1 _Xi_. For an application, consider _n_ coins, with coin _i_ having
probability _pi_ of coming up heads when flipped, _i_ =1,..., _n_. Suppose that coin 1 is
flipped until heads appears, at which point coin 2 is flipped until it shows heads, and
then coin 3 is flipped until it shows heads, and so on. If we let _Xi_ denote the number
of flips made with coin _i_ ,then _X_ 1 , _X_ 2 ,..., _Xn_ will be independent geometric random
variables with respective parameters _p_ 1 , _p_ 2 ,..., _pn_ ,and _Sn_ =

∑ _n
i_ = 1 _Xi_ will represent
the total number of flips. If all the _pi_ are equal—say, all _pi_ = _p_ —then _Sn_ has the same
distribution as the number of flips of a coin having probability _p_ of coming up heads
that are needed to obtain a total of _n_ heads, and so _Sn_ is a negative binomial random
variable with probability mass function

```
P { Sn = k }=
```
##### (

```
k − 1
n − 1
```
##### )

```
pn ( 1 − p ) k − n , k Ú n
```
As a prelude to determining the probability mass function of _Sn_ when the _pi_ are all
distinct, let us first consider the case _n_ = 2 .Letting _qj_ = 1 − _pj_ , _j_ =1, 2, we obtain

```
P ( S 2 = k )=
```
```
∑ k −^1
```
```
j = 1
```
```
P { X 1 = j , X 2 = k − j }
```
##### =

```
∑ k −^1
```
```
j = 1
```
```
P { X 1 = j } P { X 2 = k − j } (by independence)
```
##### =

```
∑ k −^1
```
```
j = 1
```
```
p 1 q
j − 1
1 p^2 q
```
```
k − j − 1
2
```
```
= p 1 p 2 qk 2 −^2
```
```
k ∑− 1
```
```
j = 1
```
```
( q 1 / q 2 ) j −^1
```
```
= p 1 p 2 qk 2 −^2
```
```
1 −( q 1 / q 2 ) k −^1
1 − q 1 / q 2
```
```
=
```
```
p 1 p 2 qk 2 −^1
q 2 − q 1
```
##### −

```
p 1 p 2 qk 1 −^1
q 2 − q 1
= p 2 qk 2 −^1
```
```
p 1
p 1 − p 2
```
```
+ p 1 qk 1 −^1
```
```
p 2
p 2 − p 1
```
If we now let _n_ =3 and compute _P_ { _S_ 3 = _k_ }by starting with the identity

```
P { S 3 = k }=
```
```
k ∑− 1
```
```
j = 1
```
```
P { S 2 = j , X 3 = k − j }=
```
```
k ∑− 1
```
```
j = 1
```
```
P { S 2 = j } P { X 3 = k − j }
```
and then substituting the derived formula for the mass function of _S_ 2 , we would
obtain, after some computations,

```
P { S 3 = k }= p 1 qk 1 −^1
```
```
p 2
p 2 − p 1
```
```
p 3
p 3 − p 1
```
```
+ p 2 qk 2 −^1
```
```
p 1
p 1 − p 2
```
```
p 3
p 3 − p 2
+ p 3 qk 3 −^1
```
```
p 1
p 1 − p 3
```
```
p 2
p 2 − p 3
```

**262** Chapter 6 Jointly Distributed Random Variables

```
The mass functions of S 2 and S 3 lead to the following conjecture for the mass function
of Sn.
```
```
Proposition 3.3. Let X 1 ,..., Xn be independent geometric random variables, with Xi
having parameter pi for i =1,..., n. If all the pi are distinct, then, for k Ú n ,
```
```
P { Sn = k }=
```
```
∑ n
```
```
i = 1
```
```
piqki −^1
```
##### ∏

```
j Z i
```
```
pj
pj − pi
```
```
Proof of Proposition 3.3: We will prove this proposition by induction on the value
of n + k. Because the proposition is true when n =2, k =2, take as the induction
hypothesis that it is true for any k Ú n for which n + k ... r. Now, suppose k Ú n are
such that n + k = r +1. To compute P { Sn = k }, we condition on whether Xn =1.
This gives
```
```
P { Sn = k }= P { Sn = k | Xn = 1 } P { Xn = 1 }+ P { Sn = k | Xn > 1 } P { Xn > 1 }
= P { Sn = k | Xn = 1 } pn + P { Sn = k | Xn > 1 } qn
```
```
Now,
```
```
P { Sn = k | Xn = 1 }= P { Sn − 1 = k − 1 | Xn = 1 }
= P { Sn − 1 = k − 1 } (by independence)
```
##### =

```
n ∑− 1
```
```
i = 1
```
```
piqki −^2
```
##### ∏

```
i Z j ... n − 1
```
```
pj
pj − pi
```
```
(by the induction hypothesis)
```
```
Now, if X is geometric with parameter p , then the conditional distribution of X given
that it is larger than 1 is the same as the distribution of 1 (the first failed trial) plus
a geometric with parameter p (the number of additional trials after the first until a
success occurs). Consequently,
```
```
P { Sn = k | Xn > 1 }= P { X 1 +...+ Xn − 1 + Xn + 1 = k }
= P { Sn = k − 1 }
```
```
=
```
```
∑ n
```
```
i = 1
```
```
piqki −^2
```
##### ∏

```
i Z j ... n
```
```
pj
pj − pi
```
```
where the final equality follows from the induction hypothesis. Thus, from the pre-
ceding, we obtain
```
```
P { Sn = k }= pn
```
```
∑ n −^1
```
```
i = 1
```
```
piqki −^2
```
##### ∏

```
i Z j ... n − 1
```
```
pj
pj − pi
```
```
+ qn
```
```
∑ n
```
```
i = 1
```
```
piqki −^2
```
##### ∏

```
i Z j ... n
```
```
pj
pj − pi
```
```
= pn
```
```
∑ n −^1
```
```
i = 1
```
```
piqki −^2
```
##### ∏

```
i Z j ... n − 1
```
```
pj
pj − pi
```
```
+ qn
```
```
n ∑− 1
```
```
i = 1
```
```
piqki −^2
```
##### ∏

```
i Z j ... n
```
```
pj
pj − pi
```
```
+ qnpnqkn −^2
```
##### ∏

```
j < n
```
```
pj
pj − pn
```
##### =

```
n ∑− 1
```
```
i = 1
```
```
piqki −^2 pn ( 1 +
```
```
qn
pn − pi
```
##### )

##### ∏

```
i Z j ... n − 1
```
```
pj
pj − pi
```
```
+ pnqkn −^1
```
##### ∏

```
j < n
```
```
pj
pj − pn
```

```
Section 6.4 Conditional Distributions: Discrete Case 263
```
```
Now, using that
```
```
1 +
```
```
qn
pn − pi
```
##### =

```
pn − pi + qn
pn − pi
```
##### =

```
qi
pn − pi
```
```
the preceding gives
```
```
P { Sn = k }=
```
```
n ∑− 1
```
```
i = 1
```
```
piqki −^1
```
##### ∏

```
i Z j ... n
```
```
pj
pj − pi
```
```
+ pnqkn −^1
```
##### ∏

```
j < n
```
```
pj
pj − pn
```
##### =

```
∑ n
```
```
i = 1
```
```
piqki −^1
```
##### ∏

```
j Z i
```
```
pj
pj − pi
```
```
and the proof by induction is complete..
```
### 6.4 Conditional Distributions: Discrete Case

```
Recall that, for any two events E and F , the conditional probability of E given F is
defined, provided that P ( F )>0, by
```
##### P ( E | F )=

##### P ( EF )

##### P ( F )

```
Hence, if X and Y are discrete random variables, it is natural to define the conditional
probability mass function of X given that Y = y ,by
```
```
pX | Y ( x | y )= P { X = x | Y = y }
```
```
=
```
```
P { X = x , Y = y }
P { Y = y }
```
```
=
```
```
p ( x , y )
pY ( y )
```
```
for all values of y such that pY ( y )>0. Similarly, the conditional probability distribu-
tion function of X given that Y = y is defined, for all y such that pY ( y )>0, by
```
```
FX | Y ( x | y )= P { X ... x | Y = y }
=
```
##### ∑

```
a ... x
```
```
pX | Y ( a | y )
```
```
In other words, the definitions are exactly the same as in the unconditional case,
except that everything is now conditional on the event that Y = y .If X is indepen-
dent of Y , then the conditional mass function and the distribution function are the
same as the respective unconditional ones. This follows because if X is independent
of Y ,then
```
```
pX | Y ( x | y )= P { X = x | Y = y }
```
```
=
```
```
P { X = x , Y = y }
P { Y = y }
```
```
=
```
```
P { X = x } P { Y = y }
P { Y = y }
= P { X = x }
```

**264** Chapter 6 Jointly Distributed Random Variables

```
EXAMPLE 4a
Suppose that p ( x , y ), the joint probability mass function of X and Y , is given by
```
```
p (0, 0)=. 4 p (0, 1)=. 2 p (1, 0)=. 1 p (1, 1)=. 3
```
```
Calculate the conditional probability mass function of X given that Y =1.
```
```
Solution. We first note that
```
```
pY ( 1 )=
```
##### ∑

```
x
```
```
p ( x ,1)= p (0, 1)+ p (1, 1)=. 5
```
```
Hence,
```
```
pX | Y ( 0 | 1 )=
```
```
p (0, 1)
pY ( 1 )
```
##### =

##### 2

##### 5

```
and
```
```
pX | Y ( 1 | 1 )=
```
```
p (1, 1)
pY ( 1 )
```
##### =

##### 3

##### 5.

```
EXAMPLE 4b
If X and Y are independent Poisson random variables with respective parametersλ 1
andλ 2 , calculate the conditional distribution of X given that X + Y = n.
```
```
Solution. We calculate the conditional probability mass function of X given that X +
Y = n as follows:
```
```
P { X = k | X + Y = n }=
```
```
P { X = k , X + Y = n }
P { X + Y = n }
```
```
=
```
```
P { X = k , Y = n − k }
P { X + Y = n }
```
```
=
```
```
P { X = k } P { Y = n − k }
P { X + Y = n }
```
```
where the last equality follows from the assumed independence of X and Y. Recalling
(Example 3e) that X + Y has a Poisson distribution with parameterλ 1 +λ 2 , we see
that the preceding equals
```
```
P { X = k | X + Y = n }=
```
```
e −λ^1 λ k 1
k!
```
```
e −λ^2 λ n 2 − k
( n − k )!
```
##### [

```
e −(λ^1 +λ^2 )(λ 1 +λ 2 ) n
n!
```
##### ]− 1

##### =

```
n!
( n − k )! k!
```
```
λ k 1 λ n 2 − k
(λ 1 +λ 2 ) n
```
```
=
```
##### (

```
n
k
```
##### )(

```
λ 1
λ 1 +λ 2
```
```
) k (
λ 2
λ 1 +λ 2
```
```
) n − k
```
```
In other words, the conditional distribution of X given that X + Y = n is the binomial
distribution with parameters n andλ 1 /(λ 1 +λ 2 )..
```
```
We can also talk about joint conditional distributions, as is indicated in the next
two examples.
```

```
Section 6.4 Conditional Distributions: Discrete Case 265
```
**_EXAMPLE 4c_**

Consider the multinomial distribution with joint probability mass function

```
P { Xi = ni , i =1,..., k }=
```
```
n!
n 1 !··· nk!
```
```
p
n 1
1 ··· p
```
```
nk
k , ni Ú0,
```
```
∑ k
```
```
i = 1
```
```
ni = n
```
Such a mass function results when _n_ independent trials are performed, with each

trial resulting in outcome _i_ with probability _pi_ ,

∑ _k
i_ = 1 _pi_ =1. The random variables
_Xi_ , _i_ =1,..., _k_ , represent, respectively, the number of trials that result in outcome _i_ ,
_i_ =1,..., _k_. Suppose we are given that _nj_ of the trials resulted in outcome _j_ ,for _j_ =

_r_ +1,..., _k_ , where

∑ _k
j_ = _r_ + 1 _nj_ = _m_ ... _n_. Then, because each of the other _n_ − _m_ trials
must have resulted in one of the trials 1,..., _r_ , it would seem that the conditional dis-
tribution of _X_ 1 ,..., _Xr_ is the multinomial distribution on _n_ − _m_ trials with respective
trial outcome probabilities

```
P {outcome i |outcome is not any of r +1,..., k }=
```
```
pi
Fr
```
```
, i =1,..., r
```
where _Fr_ =

∑ _r
i_ = 1 _pi_ is the probability that a trial results in one of the outcomes
1,..., _r_.

**_Solution._** To verify this intuition, let _n_ 1 ,..., _nr_ ,besuchthat

```
∑ r
i = 1 ni = n − m. Then
```
```
P { X 1 = n 1 ,..., Xr = nr | Xr + 1 = nr + 1 ,... Xk = nk }
```
```
=
```
```
P { X 1 = n 1 ,..., Xk = nk }
P { Xr + 1 = nr + 1 ,... Xk = nk }
```
##### =

```
n!
n 1 !··· nk! p
```
```
n 1
1 ··· p
```
```
nr
rp
```
```
nr + 1
r + 1 ··· p
```
```
nk
k
n!
( n − m )! nr + 1 !··· nk! F
```
```
n − m
r p
```
```
nr + 1
r + 1 ··· p
```
```
nk
k
```
where the probability in the denominator was obtained by regarding outcomes 1,..., _r_
as a single outcome having probability _Fr_ , thus showing that the probability is a multi-
nomial probability on∑ _n_ trials with outcome probabilities _Fr_ , _pr_ + 1 ,..., _pk_. Because
_r
i_ = 1 _ni_ = _n_ − _m_ , the preceding can be written as

```
P { X 1 = n 1 ,..., Xr = nr | Xr + 1 = nr + 1 ,... Xk = nk }
```
```
=
```
```
( n − m )!
n 1 !··· nr!
```
##### (

```
p 1
Fr
```
```
) n^1 ···(
```
```
pr
Fr
```
```
) nr
```
and our intuition is upheld..

**_EXAMPLE 4d_**

Consider _n_ independent trials, with each trial being a success with probability _p_.
Given a total of _k_ successes, show that all possible orderings of the _k_ successes and
_n_ − _k_ failures are equally likely.

**_Solution._** We want to show that, given a total of _k_ successes, each of the

```
( n
k
```
##### )

possible
orderings of _k_ successes and _n_ − _k_ failures is equally likely. Let _X_ denote the number
of successes, and consider any ordering of _k_ successes and _n_ − _k_ failures, say, **o** =
( _s_ , _s_ , _f_ , _f_ ,..., _f_ ).Then


**266** Chapter 6 Jointly Distributed Random Variables

```
P ( o | X = k )=
```
```
P ( o , X = k )
P ( X = k )
```
```
=
```
```
P ( o )
P ( X = k )
```
```
=
```
```
pk ( 1 − p ) n − k
( n
k
```
##### )

```
pk ( 1 − p ) n − k
```
```
=
```
##### 1

```
( n
k
```
##### )

### 6.5 Conditional Distributions: Continuous Case

```
If X and Y have a joint probability density function f ( x , y ), then the conditional prob-
ability density function of X given that Y = y is defined, for all values of y such that
fY ( y )>0, by
fX | Y ( x | y )=
```
```
f ( x , y )
fY ( y )
To motivate this definition, multiply the left-hand side by dx and the right-hand side
by( dx dy )/ dy to obtain
```
```
fX | Y ( x | y ) dx =
```
```
f ( x , y ) dx dy
fY ( y ) dy
```
```
L
```
```
P { x ... X ... x + dx , y ... Y ... y + dy }
P { y ... Y ... y + dy }
= P { x ... X ... x + dx | y ... Y ... y + dy }
```
```
In other words, for small values of dx and dy , fX | Y ( x | y ) dx represents the conditional
probability that X is between x and x + dx given that Y is between y and y + dy.
The use of conditional densities allows us to define conditional probabilities of
events associated with one random variable when we are given the value of a second
random variable. That is, if X and Y are jointly continuous, then, for any set A ,
```
```
P { X ∈ A | Y = y }=
```
##### ∫

```
A
```
```
fX | Y ( x | y ) dx
```
```
In particular, by letting A =(−q, a ], we can define the conditional cumulative distri-
bution function of X given that Y = y by
```
```
FX | Y ( a | y )K P { X ... a | Y = y }=
```
```
∫ a
```
```
−q
```
```
fX | Y ( x | y ) dx
```
```
The reader should note that, by using the ideas presented in the preceding discussion,
we have been able to give workable expressions for conditional probabilities, even
though the event on which we are conditioning (namely, the event{ Y = y })has
probability 0.
```
```
EXAMPLE 5a
The joint density of X and Y is given by
```
```
f ( x , y )=
```
##### {

```
12
5 x (^2 − x − y )^0 < x <1, 0< y <^1
0 otherwise
```
```
Compute the conditional density of X given that Y = y , where 0< y <1.
```

```
Section 6.5 Conditional Distributions: Continuous Case 267
```
**_Solution._** For 0< _x_ <1, 0< _y_ <1, we have

```
fX | Y ( x | y )=
```
```
f ( x , y )
fY ( y )
```
```
=
```
```
f ( x , y )
∫q
−q f ( x , y ) dx
```
```
=
```
```
x ( 2 − x − y )
∫ 1
0 x (^2 − x − y ) dx
```
```
=
```
```
x ( 2 − x − y )
2
3 − y /^2
=
```
```
6 x ( 2 − x − y )
4 − 3 y.
```
**_EXAMPLE 5b_**

Suppose that the joint density of _X_ and _Y_ is given by

```
f ( x , y )=
```
##### ⎧

##### ⎪⎨

##### ⎪⎩

```
e − x / ye − y
y
```
```
0 < x <q,0< y <q
```
```
0 otherwise
```
Find _P_ { _X_ > 1 | _Y_ = _y_ }.

**_Solution._** We first obtain the conditional density of _X_ given that _Y_ = _y_.

```
fX | Y ( x | y )=
```
```
f ( x , y )
fY ( y )
```
```
=
```
```
e − x / ye − y / y
e − y
```
```
∫q
0 (^1 / y ) e
```
```
− x / ydx
```
##### =

##### 1

```
y
```
```
e − x / y
```
Hence,

```
P { X > 1 | Y = y }=
```
```
∫q
```
```
1
```
##### 1

```
y
```
```
e − x / ydx
```
```
=− e − x / y
```
##### ∣

##### ∣

##### ∣

```
q
1
= e −^1 / y.
```
If _X_ and _Y_ are independent continuous random variables, the conditional density
of _X_ given that _Y_ = _y_ is just the unconditional density of _X_. This is so because, in the
independent case,

```
fX | Y ( x | y )=
```
```
f ( x , y )
fY ( y )
```
##### =

```
fX ( x ) fY ( y )
fY ( y )
```
```
= fX ( x )
```
We can also talk about conditional distributions when the random variables are nei-
ther jointly continuous nor jointly discrete. For example, suppose that _X_ is a continu-
ous random variable having probability density function _f_ and _N_ is a discrete random
variable, and consider the conditional distribution of _X_ given that _N_ = _n_. Then


**268** Chapter 6 Jointly Distributed Random Variables

```
P { x < X < x + dx | N = n }
dx
=
```
```
P { N = n | x < X < x + dx }
P { N = n }
```
```
P { x < X < x + dx }
dx
and letting dx approach 0 gives
```
```
lim
dx → 0
```
```
P { x < X < x + dx | N = n }
dx
```
##### =

```
P { N = n | X = x }
P { N = n }
```
```
f ( x )
```
```
thus showing that the conditional density of X given that N = n is given by
```
```
fX | N ( x | n )=
```
```
P { N = n | X = x }
P { N = n }
```
```
f ( x )
```
```
EXAMPLE 5c The Bivariate Normal Distribution
One of the most important joint distributions is the bivariate normal distribution.
We say that the random variables X , Y have a bivariate normal distribution if, for
constantsμ x ,μ y ,σ x >0,σ y >0,− 1 <ρ<1, their joint density function is given,
for all−q< x , y <q,by
```
```
f ( x , y )=
```
##### 1

```
2 πσ x σ y
```
##### √

```
1 −ρ^2
```
```
exp
```
##### ⎧

##### ⎨

##### ⎩

##### −

##### 1

```
2 ( 1 −ρ^2 )
```
##### [(

```
x −μ x
σ x
```
##### ) 2

##### +

##### (

```
y −μ y
σ y
```
##### ) 2

```
− 2 ρ
```
```
( x −μ x )( y −μ y )
σ x σ y
```
##### ⎤

##### ⎦

##### ⎫

##### ⎪⎬

##### ⎪⎭

```
We now determine the conditional density of X given that Y = y. In doing so, we
will continually collect all factors that do not depend on x and represent them by the
constants Ci. The final constant will then be found by using that
```
```
∫q
−q fX | Y ( x | y ) dx =1.
We have
```
```
fX | Y ( x | y )=
```
```
f ( x , y )
fY ( y )
= C 1 f ( x , y )
```
```
= C 2 exp
```
##### ⎧

##### ⎨

##### ⎩

##### −

##### 1

```
2 ( 1 −ρ^2 )
```
##### [(

```
x −μ x
σ x
```
##### ) 2

```
− 2 ρ
```
```
x ( y −μ y )
σ x σ y
```
##### ]⎫

##### ⎬

##### ⎭

```
= C 3 exp
```
##### ⎧

##### ⎪⎨

##### ⎪⎩

##### −

##### 1

```
2 σ x^2 ( 1 −ρ^2 )
```
##### ⎡

```
⎣ x^2 − 2 x
```
##### (

```
μ x +ρ
```
```
σ x
σ y
```
```
( y −μ y )
```
##### )⎤

##### ⎦

##### ⎫

##### ⎪⎬

##### ⎪⎭

```
= C 4 exp
```
##### ⎧

##### ⎪⎨

##### ⎪⎩

##### −

##### 1

```
2 σ x^2 ( 1 −ρ^2 )
```
##### ⎡

```
⎣ x −
```
##### (

```
μ x +ρ
```
```
σ x
σ y
```
```
( y −μ y )
```
##### )⎤

##### ⎦

```
2
```
##### ⎫

##### ⎪⎬

##### ⎪⎭

```
Recognizing the preceding equation as a normal density, we can conclude that, given
Y = y , the random variable X is normally distributed with meanμ x +ρσσ xy ( y −μ y )
and varianceσ x^2 ( 1 −ρ^2 ).Also, because the joint density of Y , X is exactly the same as
that of X , Y , except thatμ x ,σ x are interchanged withμ y ,σ y , it similarly follows that
```

```
Section 6.5 Conditional Distributions: Continuous Case 269
```
the conditional distribution of _Y_ given _X_ = _x_ is the normal distribution with mean
μ _y_ + ρ
σ _y_
σ _x_ ( _x_ − μ _x_ )and varianceσ

```
2
y (^1 −ρ
```
(^2) ).It follows from these results that the
necessary and sufficient condition for the bivariate normal random variables _X_ and
_Y_ to be independent is thatρ=0 (a result that also follows directly from their joint
density, because it is only whenρ=0 that the joint density factors into two terms,
one depending only on _x_ and the other only on _y_ ).
With _C_ =^1
2 πσ _x_ σ _y_

##### √

```
1 −ρ^2
```
```
, the marginal density of X can be obtained from
```
```
fX ( x )=
```
```
∫q
```
```
−q
```
```
f ( x , y ) dy
```
##### = C

```
∫q
```
```
−q
```
```
exp
```
##### ⎧

##### ⎪⎨

##### ⎪⎩

##### −

##### 1

```
2 ( 1 −ρ^2 )
```
##### ⎡

##### ⎣

##### (

```
x −μ x
σ x
```
##### ) 2

##### +

##### (

```
y −μ y
σ y
```
##### ) 2

```
− 2 ρ
```
```
( x −μ x )( y −μ y )
σ x σ y
```
##### ]⎫

##### ⎬

##### ⎭

```
dy
```
Making the change of variables _w_ =
_y_ −μ _y_
σ _y_ gives

```
fX ( x )= C σ y exp
```
##### {

##### −

##### 1

```
2 ( 1 −ρ^2 )
```
##### (

```
x −μ x
σ x
```
##### ) 2 }

##### *

```
∫q
```
```
−q
```
```
exp
```
##### {

##### −

##### 1

```
2 ( 1 −ρ^2 )
```
##### [

```
w^2 − 2 ρ
```
```
x −μ x
σ x
```
```
w
```
##### ]}

```
dw
```
```
= C σ y exp
```
##### {

##### −

##### 1

```
2 ( 1 −ρ^2 )
```
##### (

```
x −μ x
σ x
```
##### ) 2

```
( 1 −ρ^2 )
```
##### }

##### *

```
∫q
```
```
−q
```
```
exp
```
##### {

##### −

##### 1

```
2 ( 1 −ρ^2 )
```
##### [

```
w −ρ
```
```
x −μ x
σ x
```
##### ] 2 }

```
dw
```
Because

```
1
√
2 π( 1 −ρ^2 )
```
```
∫q
```
```
−q
```
```
exp
```
##### {

##### −

##### 1

```
2 ( 1 −ρ^2 )
```
##### [

```
w −
```
```
ρ
σ x
```
```
( x −μ x )
```
##### ] 2 }

```
dw = 1
```
we see that

```
fX ( x )= C σ y
```
##### √

```
2 π( 1 −ρ^2 ) e −( x −μ x )
```
(^2) / 2 σ _x_ 2

##### =

##### 1

##### √

```
2 πσ x
```
```
e −( x −μ x )
```
(^2) / 2 σ _x_ 2
That is, _X_ is normal with meanμ _x_ and varianceσ _x_^2. Similarly, _Y_ is normal with
meanμ _y_ and varianceσ _y_^2..
**_EXAMPLE 5d_**
Consider _n_ + _m_ trials having a common probability of success. Suppose, however,
that this success probability is not fixed in advance but is chosen from a uniform (0, 1)


```
270 Chapter 6 Jointly Distributed Random Variables
```
```
population. What is the conditional distribution of the success probability given that
the n + m trials result in n successes?
```
```
Solution. If we let X denote the probability that a given trial is a success, then X
is a uniform (0, 1) random variable. Also, given that X = x ,the n + m trials are
independent with common probability of success x ,so N , the number of successes,
is a binomial random variable with parameters( n + m , x ). Hence, the conditional
density of X given that N = n is
```
```
fX | N ( x | n )=
```
```
P { N = n | X = x } fX ( x )
P { N = n }
```
##### =

##### (

```
n + m
n
```
##### )

```
xn ( 1 − x ) m
```
```
P { N = n }
```
```
0 < x < 1
```
```
= cxn ( 1 − x ) m
```
```
where c does not depend on x. Thus, the conditional density is that of a beta random
variable with parameters n +1, m +1.
The preceding result is quite interesting, for it states that if the original or prior
(to the collection of data) distribution of a trial success probability is uniformly dis-
tributed over (0, 1) [or, equivalently, is beta with parameters (1, 1)] then the posterior
(or conditional) distribution given a total of n successes in n + m trials is beta with
parameters( 1 + n ,1+ m ). This is valuable, for it enhances our intuition as to what
it means to assume that a random variable has a beta distribution..
```
∗ **6.6 ORDER STATISTICS**

```
Let X 1 , X 2 ,..., Xn be n independent and identically distributed continuous random
variables having a common density f and distribution function F. Define
```
```
X ( 1 )=smallest of X 1 , X 2 ,..., Xn
X ( 2 )=second smallest of X 1 , X 2 ,..., Xn
```
```
#
#
#
X ( j )= j th smallest of X 1 , X 2 ,..., Xn
```
```
#
#
#
X ( n )=largest of X 1 , X 2 ,..., Xn
```
```
The ordered values X ( 1 )... X ( 2 ) ...···... X ( n )are known as the order statistics cor-
responding to the random variables X 1 , X 2 ,..., Xn. In other words, X ( 1 ),..., X ( n )are
the ordered values of X 1 ,..., Xn.
The joint density function of the order statistics is obtained by noting that the order
statistics X ( 1 ),..., X ( n )will take on the values x 1 ... x 2 ...···... xn if and only if, for
some permutation( i 1 , i 2 ,..., in )of(1, 2,..., n ),
```
```
X 1 = xi 1 , X 2 = xi 2 ,..., Xn = xin
```

```
Section 6.6 Order Statistics 271
```
Since, for any permutation( _i_ 1 ,..., _in_ )of(1, 2,..., _n_ ),

##### P

##### {

```
xi 1 −
```
```
ε
2
```
```
< X 1 < xi 1 +
```
```
ε
2
```
```
,..., xin −
```
```
ε
2
```
```
< Xn < xin +
```
```
ε
2
```
##### }

```
Lε nfX 1 ,···, Xn ( xi 1 ,..., xin )
=ε nf ( xi 1 )··· f ( xin )
=ε nf ( x 1 )··· f ( xn )
```
it follows that, for _x_ 1 < _x_ 2 <···< _xn_ ,

##### P

##### {

```
x 1 −
```
```
ε
2
```
```
< X ( 1 )< x 1 +
```
```
ε
2
```
```
,..., xn −
```
```
ε
2
```
```
< X ( n )< xn +
```
```
ε
2
```
##### }

```
L n !ε nf ( x 1 )··· f ( xn )
```
Dividing byε _n_ and lettingε→0 yields

```
fX ( 1 ),..., X ( n )( x 1 , x 2 ,..., xn )= n! f ( x 1 )··· f ( xn ) x 1 < x 2 <···< xn (6.1)
```
Equation (6.1) is most simply explained by arguing that, in order for the vector
〈 _X_ ( 1 ),..., _X_ ( _n_ )〉to equal〈 _x_ 1 ,..., _xn_ 〉, it is necessary and sufficient for〈 _X_ 1 ,..., _Xn_ 〉to
equal one of the _n_! permutations of〈 _x_ 1 ,..., _xn_ 〉. Since the probability (density) that
〈 _X_ 1 ,..., _Xn_ 〉equals any given permutation of〈 _x_ 1 ,..., _xn_ 〉is just _f_ ( _x_ 1 )··· _f_ ( _xn_ ), Equa-
tion (6.1) follows.

**_EXAMPLE 6a_**

Along a road 1 mile long are 3 people “distributed at random.” Find the probability
that no 2 people are less than a distance of _d_ miles apart when _d_ ...^12.

**_Solution._** Let us assume that “distributed at random” means that the positions of the
3 people are independent and uniformly distributed over the road. If _Xi_ denotes the
position of the _i_ th person, then the desired probability is _P_ { _X_ ( _i_ )> _X_ ( _i_ − 1 ) + _d_ , _i_ =
2, 3}. Because

```
fX ( 1 ), X ( 2 ), X ( 3 )( x 1 , x 2 , x 3 )=3! 0 < x 1 < x 2 < x 3 < 1
```
it follows that

```
P { X ( i )> X ( i − 1 )+ d , i =2, 3}=
```
##### ∫∫∫

```
xi > xj − 1 + d
```
```
fX ( 1 ), X ( 2 ), X ( 3 )( x 1 , x 2 , x 3 ) dx 1 dx 2 dx 3
```
##### =3!

```
∫ 1 − 2 d
```
```
0
```
```
∫ 1 − d
```
```
x 1 + d
```
##### ∫ 1

```
x 2 + d
```
```
dx 3 dx 2 dx 1
```
##### = 6

```
∫ 1 − 2 d
```
```
0
```
```
∫ 1 − d
```
```
x 1 + d
```
```
( 1 − d − x 2 ) dx 2 dx 1
```
##### = 6

```
∫ 1 − 2 d
```
```
0
```
```
∫ 1 − 2 d − x 1
```
```
0
```
```
y 2 dy 2 dx 1
```

**272** Chapter 6 Jointly Distributed Random Variables

```
where we have made the change of variables y 2 = 1 − d − x 2. Continuing the string
of equalities yields
```
##### = 3

```
∫ 1 − 2 d
```
```
0
```
```
( 1 − 2 d − x 1 )^2 dx 1
```
##### = 3

```
∫ 1 − 2 d
```
```
0
```
```
y^21 dy 1
```
```
=( 1 − 2 d )^3
```
```
Hence, the desired probability that no 2 people are within a distance d of each other
when 3 people are uniformly and independently distributed over an interval of size
1is( 1 − 2 d )^3 when d ...^12. In fact, the same method can be used to prove that
when n people are distributed at random over the unit interval, the desired
probability is
```
```
[1−( n − 1 ) d ] n when d ...
```
##### 1

```
n − 1
```
```
The proof is left as an exercise..
```
```
The density function of the j th-order statistic X ( j )can be obtained either by inte-
grating the joint density function (6.1) or by direct reasoning as follows: In order for
X ( j )to equal x , it is necessary for j − 1ofthe n values X 1 ,..., Xn to be less than
x , n − j of them to be greater than x , and 1 of them to equal x. Now, the probability
density that any given set of j − 1ofthe Xi ’s are less than x , another given set of
n − j are all greater than x , and the remaining value is equal to x equals
```
```
[ F ( x )] j −^1 [1− F ( x )] n − jf ( x )
```
```
Hence, since there are
(
n
j −1, n − j ,1
```
##### )

##### =

```
n!
( n − j )!( j − 1 )!
```
```
different partitions of the n random variables X 1 ,..., Xn into the preceding three
groups, it follows that the density function of X ( j )is given by
```
```
fX ( j )( x )=
```
```
n!
( n − j )!( j − 1 )!
```
```
[ F ( x )] j −^1 [1− F ( x )] n − jf ( x ) (6.2)
```
```
EXAMPLE 6b
When a sample of 2 n +1 random variables (that is, when 2 n +1 independent and
identically distributed random variables) is observed, the( n + 1 )st smallest is called
the sample median. If a sample of size 3 from a uniform distribution over (0, 1) is
observed, find the probability that the sample median is between^14 and^34.
```
```
Solution. From Equation (6.2), the density of X ( 2 )is given by
```
```
fX ( 2 )( x )=
```
##### 3!

##### 1!1!

```
x ( 1 − x ) 0 < x < 1
```

```
Section 6.6 Order Statistics 273
```
Hence,

##### P

##### {

##### 1

##### 4

##### < X ( 2 )<

##### 3

##### 4

##### }

##### = 6

##### ∫ 3 / 4

```
1 / 4
```
```
x ( 1 − x ) dx
```
##### = 6

##### {

```
x^2
2
```
##### −

```
x^3
3
```
##### }∣∣

##### ∣

##### ∣

##### ∣

##### ∣

```
x = 3 / 4
```
```
x = 1 / 4
```
##### =

##### 11

##### 16

##### .

The cumulative distribution function of _X_ ( _j_ )can be found by integrating Equa-
tion (6.2). That is,

```
FX ( j )( y )=
```
```
n!
( n − j )!( j − 1 )!
```
```
∫ y
```
```
−q
```
```
[ F ( x )] j −^1 [1− F ( x )] n − jf ( x ) dx (6.3)
```
However, _FX_ ( _j_ )( _y_ )could also have been derived directly by noting that the _j_ th order
statistic is less than or equal to _y_ if and only if there are _j_ or more of the _Xi_ ’s that are
less than or equal to _y_. Thus, because the number of _Xi_ ’s that are less than or equal
to _y_ is a binomial random variable with parameters _n_ , _p_ = _F_ ( _y_ ), it follows that

```
FX ( j )( y )= P { X ( j )... y }= P { j or more of the Xi ’s are ... y }
```
##### =

```
∑ n
```
```
k = j
```
##### (

```
n
k
```
##### )

```
[ F ( y )] k [1− F ( y )] n − k (6.4)
```
If, in Equations (6.3) and (6.4), we take _F_ to be the uniform (0, 1) distribution [that
is, _f_ ( _x_ )=1, 0< _x_ <1], then we obtain the interesting analytical identity

```
∑ n
```
```
k = j
```
##### (

```
n
k
```
##### )

```
yk ( 1 − y ) n − k =
```
```
n!
( n − j )!( j − 1 )!
```
```
∫ y
```
```
0
```
```
xj −^1 ( 1 − x ) n − jdx 0 ... y ...1 (6.5)
```
By employing the same type of argument that we used in establishing
Equation (6.2), we can show that the joint density function of the order statistics _X_ ( _i_ )
and _X_ ( _j_ )when _i_ < _j_ is

```
fX ( i ), X ( j )( xi , xj )=
```
```
n!
( i − 1 )!( j − i − 1 )!( n − j )!
```
```
[ F ( xi )] i −^1 (6.6)
```
```
*[ F ( xj )− F ( xi )] j − i −^1 [1− F ( xj )] n − jf ( xi ) f ( xj )
```
for all _xi_ < _xj_.

**_EXAMPLE 6c Distribution of the range of a random sample_**

Suppose that _n_ independent and identically distributed random variables _X_ 1 , _X_ 2 ,...,
_Xn_ are observed. The random variable _R_ defined by _R_ = _X_ ( _n_ ) − _X_ ( 1 )is called the
_range_ of the observed random variables. If the random variables _Xi_ have distribution
function _F_ and density function _f_ , then the distribution of _R_ can be obtained from
Equation (6.6) as follows: For _a_ Ú0,


**274** Chapter 6 Jointly Distributed Random Variables

```
P { R ... a }= P { X ( n )− X ( 1 )... a }
```
```
=
```
##### ∫∫

```
xn − x 1 ... a
```
```
fX ( 1 ), X ( n )( x 1 , xn ) dx 1 dxn
```
##### =

```
∫q
```
```
−q
```
```
∫ x 1 + a
```
```
x 1
```
```
n!
( n − 2 )!
```
```
[ F ( xn )− F ( x 1 )] n −^2 f ( x 1 ) f ( xn ) dxndx 1
```
```
Making the change of variable y = F ( xn )− F ( x 1 ), dy = f ( xn ) dxn yields
∫ x 1 + a
```
```
x 1
```
```
[ F ( xn )− F ( x 1 )] n −^2 f ( xn ) dxn =
```
```
∫ F ( x 1 + a )− F ( x 1 )
```
```
0
```
```
yn −^2 dy
```
##### =

##### 1

```
n − 1
```
```
[ F ( x 1 + a )− F ( x 1 )] n −^1
```
```
Thus,
```
```
P { R ... a }= n
```
```
∫q
```
```
−q
```
```
[ F ( x 1 + a )− F ( x 1 )] n −^1 f ( x 1 ) dx 1 (6.7)
```
```
Equation (6.7) can be evaluated explicitly only in a few special cases. One such case
is when the Xi ’s are all uniformly distributed on (0, 1). In this case, we obtain, from
Equation (6.7), that for 0< a <1,
```
```
P { R < a }= n
```
##### ∫ 1

```
0
```
```
[ F ( x 1 + a )− F ( x 1 )] n −^1 f ( x 1 ) dx 1
```
```
= n
```
```
∫ 1 − a
```
```
0
```
```
an −^1 dx 1 + n
```
##### ∫ 1

```
1 − a
```
```
( 1 − x 1 ) n −^1 dx 1
```
```
= n ( 1 − a ) an −^1 + an
```
```
Differentiation yields the density function of the range: given in this case by
```
```
fR ( a )=
```
##### {

```
n ( n − 1 ) an −^2 ( 1 − a ) 0 ... a ... 1
0 otherwise
```
```
That is, the range of n independent uniform (0, 1) random variables is a beta random
variable with parameters n −1, 2..
```
### 6.7 Joint Probability Distribution of Functions of Random Variables

```
Let X 1 and X 2 be jointly continuous random variables with joint probability density
function fX 1 , X 2. It is sometimes necessary to obtain the joint distribution of the ran-
dom variables Y 1 and Y 2 , which arise as functions of X 1 and X 2. Specifically, suppose
that Y 1 = g 1 ( X 1 , X 2 )and Y 2 = g 2 ( X 1 , X 2 )for some functions g 1 and g 2.
Assume that the functions g 1 and g 2 satisfy the following conditions:
```
1. The equations _y_ 1 = _g_ 1 ( _x_ 1 , _x_ 2 )and _y_ 2 = _g_ 2 ( _x_ 1 , _x_ 2 )can be uniquely solved for _x_ 1
    and _x_ 2 in terms of _y_ 1 and _y_ 2 , with solutions given by, say, _x_ 1 = _h_ 1 ( _y_ 1 , _y_ 2 ), _x_ 2 =
    _h_ 2 ( _y_ 1 , _y_ 2 ).
2. The functions _g_ 1 and _g_ 2 have continuous partial derivatives at all points( _x_ 1 , _x_ 2 )
    and are such that the 2*2 determinant


```
Section 6.7 Joint Distribution of Functions of Random Variables 275
```
```
J ( x 1 , x 2 )=
```
##### ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣

```
∂ g 1
∂ x 1
```
```
∂ g 1
∂ x 2
∂ g 2
∂ x 1
```
```
∂ g 2
∂ x 2
```
##### ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣

##### K

```
∂ g 1
∂ x 1
```
```
∂ g 2
∂ x 2
```
##### −

```
∂ g 1
∂ x 2
```
```
∂ g 2
∂ x 1
```
##### Z 0

```
at all points( x 1 , x 2 ).
```
Under these two conditions, it can be shown that the random variables _Y_ 1 and _Y_ 2
are jointly continuous with joint density function given by

```
fY 1 Y 2 ( y 1 , y 2 )= fX 1 , X 2 ( x 1 , x 2 )| J ( x 1 , x 2 )|−^1 (7.1)
```
where _x_ 1 = _h_ 1 ( _y_ 1 , _y_ 2 ), _x_ 2 = _h_ 2 ( _y_ 1 , _y_ 2 ).
A proof of Equation (7.1) would proceed along the following lines:

```
P { Y 1 ... y 1 , Y 2 ... y 2 }=
```
##### ∫∫

```
( x 1 , x 2 ):
g 1 ( x 1 , x 2 )... y 1
g 2 ( x 1 , x 2 )... y 2
```
```
fX 1 , X 2 ( x 1 , x 2 ) dx 1 dx 2 (7.2)
```
The joint density function can now be obtained by differentiating Equation (7.2) with
respect to _y_ 1 and _y_ 2. That the result of this differentiation will be equal to the right-
hand side of Equation (7.1) is an exercise in advanced calculus whose proof will not
be presented in this book.

**_EXAMPLE 7a_**

Let _X_ 1 and _X_ 2 be jointly continuous random variables with probability density func-
tion _fX_ 1 , _X_ 2 .Let _Y_ 1 = _X_ 1 + _X_ 2 , _Y_ 2 = _X_ 1 − _X_ 2. Find the joint density function of _Y_ 1
and _Y_ 2 in terms of _fX_ 1 , _X_ 2.

**_Solution._** Let _g_ 1 ( _x_ 1 , _x_ 2 )= _x_ 1 + _x_ 2 and _g_ 2 ( _x_ 1 , _x_ 2 )= _x_ 1 − _x_ 2. Then

```
J ( x 1 , x 2 )=
```
##### ∣

##### ∣

##### ∣

##### ∣

##### 11

##### 1 − 1

##### ∣

##### ∣

##### ∣

##### ∣=−^2

Also, since the equations _y_ 1 = _x_ 1 + _x_ 2 and _y_ 2 = _x_ 1 − _x_ 2 have _x_ 1 =( _y_ 1 + _y_ 2 )/2, _x_ 2 =
( _y_ 1 − _y_ 2 )/2 as their solution, it follows from Equation (7.1) that the desired density is

```
fY 1 , Y 2 ( y 1 , y 2 )=
```
##### 1

##### 2

```
fX 1 , X 2
```
##### (

```
y 1 + y 2
2
```
##### ,

```
y 1 − y 2
2
```
##### )

For instance, if _X_ 1 and _X_ 2 are independent uniform (0, 1) random variables, then

```
fY 1 , Y 2 ( y 1 , y 2 )=
```
##### {

```
1
2 0 ... y^1 + y^2 ...2, 0 ... y^1 − y^2 ...^2
0 otherwise
```

**276** Chapter 6 Jointly Distributed Random Variables

```
or if X 1 and X 2 are independent exponential random variables with respective param-
etersλ 1 andλ 2 ,then
```
```
fY 1 , Y 2 ( y 1 , y 2 )
```
##### =

##### ⎧

##### ⎪⎪

##### ⎨

##### ⎪⎪

##### ⎩

```
λ 1 λ 2
2
```
```
exp
```
##### {

```
−λ 1
```
##### (

```
y 1 + y 2
2
```
##### )

```
−λ 2
```
##### (

```
y 1 − y 2
2
```
##### )}

```
y 1 + y 2 Ú0, y 1 − y 2 Ú 0
```
```
0 otherwise
```
```
Y
```
```
X
```
```
R
```
```
FIGURE 6.4: •=Random point.( X , Y )=( R ,Θ).
```
```
Finally, if X 1 and X 2 are independent standard normal random variables, then
```
```
fY 1 , Y 2 ( y 1 , y 2 )=
```
##### 1

```
4 π
```
```
e −[( y^1 + y^2 )
```
(^2) / 8 +( _y_ 1 − _y_ 2 ) (^2) /8]

##### =

##### 1

```
4 π
```
```
e −( y
```
```
2
1 + y
2
2 )/^4
```
##### =

##### 1

##### √

```
4 π
```
```
e − y
```
```
2
1 /^4
```
##### 1

##### √

```
4 π
```
```
e − y
```
```
2
2 /^4
```
```
Thus, not only do we obtain (in agreement with Proposition 3.2) that both X 1 + X 2
and X 1 − X 2 are normal with mean 0 and variance 2, but we also conclude that these
two random variables are independent. (In fact, it can be shown that if X 1 and X 2
are independent random variables having a common distribution function F ,then
X 1 + X 2 will be independent of X 1 − X 2 if and only if F is a normal distribution
function.).
```
```
EXAMPLE 7b
Let ( X , Y ) denote a random point in the plane, and assume that the rectangular
coordinates X and Y are independent standard normal random variables. We are
interested in the joint distribution of R ,Θ, the polar coordinate representation of
( x , y ). (See Figure 6.4.)
Suppose first that X and Y are both positive. For x and y positive, letting r =
g 1 ( x , y )=
```
##### √

```
x^2 + y^2 andθ= g 2 ( x , y )=tan−^1 y / x , we see that
∂ g 1
∂ x
```
##### =

```
x
√
x^2 + y^2
∂ g 1
∂ y
```
##### =

```
y
√
x^2 + y^2
```

```
Section 6.7 Joint Distribution of Functions of Random Variables 277
```
```
∂ g 2
∂ x
```
##### =

##### 1

```
1 +( y / x )^2
```
##### (

```
− y
x^2
```
##### )

##### =

```
− y
x^2 + y^2
∂ g 2
∂ y
```
##### =

##### 1

```
x [1+( y / x )^2 ]
```
##### =

```
x
x^2 + y^2
```
Hence,

```
J ( x , y )=
```
```
x^2
( x^2 + y^2 )^3 /^2
```
##### +

```
y^2
( x^2 + y^2 )^3 /^2
```
##### =

##### 1

##### √

```
x^2 + y^2
```
##### =

##### 1

```
r
```
Because the conditional joint density function of _X_ , _Y_ given that they are both
positive is

```
f ( x , y | X >0, Y > 0 )=
```
```
f ( x , y )
P ( X >0, Y > 0 )
```
##### =

##### 2

```
π
```
```
e −( x
```
(^2) + _y_ (^2) )/ 2
, _x_ >0, _y_ > 0
we see that the conditional joint density function of _R_ =

##### √

_X_^2 + _Y_^2 and =
tan−^1 ( _Y_ / _X_ ), given that _X_ and _Y_ are both positive, is

```
f ( r ,θ| X >0, Y > 0 )=
```
##### 2

```
π
```
```
re − r
```
```
2 / 2
,0<θ <π/2, 0 < r <q
```
Similarly, we can show that

```
f ( r ,θ| X <0, Y > 0 )=
```
##### 2

```
π
```
```
re − r
```
```
2 / 2
, π/ 2 <θ <π,0< r <q
```
```
f ( r ,θ| X <0, Y < 0 )=
```
##### 2

```
π
```
```
re − r
```
```
2 / 2
, π<θ< 3 π/2, 0 < r <q
```
```
f ( r ,θ| X >0, Y < 0 )=
```
##### 2

```
π
```
```
re − r
```
```
2 / 2
,3π/ 2 <θ < 2 π,0< r <q
```
As the joint density is an equally weighted average of these 4 conditional joint densi-
ties, we obtain that the joint density of _R_ ,Θis given by

```
f ( r ,θ)=
```
##### 1

```
2 π
```
```
re − r
```
(^2) / 2
0 <θ < 2 π,0< _r_ <q
Now, this joint density factors into the marginal densities for _R_ andΘ,so _R_ andΘ
are independent random variables, withΘbeing uniformly distributed over(0, 2π)
and _R_ having the Rayleigh distribution with density
_f_ ( _r_ )= _re_ − _r_
(^2) / 2
0 < _r_ <q
(For instance, when one is aiming at a target in the plane, if the horizontal and vertical
miss distances are independent standard normals, then the absolute value of the error
has the preceding Rayleigh distribution.)
This result is quite interesting, for it certainly is not evident a priori that a ran-
dom vector whose coordinates are independent standard normal random variables
will have an angle of orientation that not only is uniformly distributed, but also is
independent of the vector’s distance from the origin.


**278** Chapter 6 Jointly Distributed Random Variables

```
If we wanted the joint distribution of R^2 andΘ, then, since the transformation
d = g 1 ( x , y )= x^2 + y^2 andθ= g 2 ( x , y )=tan−^1 y / x has the Jacobian
```
##### J =

##### ∣ ∣ ∣ ∣ ∣ ∣ ∣

```
2 x 2 y
− y
x^2 + y^2
```
```
x
x^2 + y^2
```
##### ∣ ∣ ∣ ∣ ∣ ∣ ∣

##### = 2

```
it follows that
```
```
f ( d ,θ)=
```
##### 1

##### 2

```
e − d /^2
```
##### 1

```
2 π
```
```
0 < d <q,0<θ < 2 π
```
```
Therefore, R^2 andΘare independent, with R^2 having an exponential distribution
with parameter^12. But because R^2 = X^2 + Y^2 , it follows by definition that R^2 has
a chi-squared distribution with 2 degrees of freedom. Hence, we have a verification
of the result that the exponential distribution with parameter^12 is the same as the
chi-squared distribution with 2 degrees of freedom.
The preceding result can be used to simulate (or generate) normal random vari-
ables by making a suitable transformation on uniform random variables. Let U 1 and
U 2 be independent random variables, each uniformly distributed over (0, 1). We will
transform U 1 , U 2 into two independent unit normal random variables X 1 and X 2
by first considering the polar coordinate representation( R ,Θ)of the random vec-
tor( X 1 , X 2 ). From the preceding, R^2 andΘwill be independent, and, in addition,
R^2 = X 12 + X^22 will have an exponential distribution with parameterλ=^12. But
−2log U 1 has such a distribution, since, for x >0,
```
```
P {−2log U 1 < x }= P
```
##### {

```
log U 1 >−
```
```
x
2
```
##### }

```
= P { U 1 > e − x /^2 }
= 1 − e − x /^2
```
```
Also, because 2π U 2 is a uniform(0, 2π)random variable, we can use it to generateΘ.
That is, if we let
```
```
R^2 =−2log U 1
Θ= 2 π U 2
```
```
then R^2 can be taken to be the square of the distance from the origin andθcan be
taken to be the angle of orientation of( X 1 , X 2 ). Now, since X 1 = R cosΘ, X 2 =
R sinΘ, it follows that
```
```
X 1 =
```
##### √

```
−2log U 1 cos( 2 π U 2 )
X 2 =
```
##### √

```
−2log U 1 sin( 2 π U 2 )
```
```
are independent standard normal random variables..
```
```
EXAMPLE 7c
If X and Y are independent gamma random variables with parameters(α,λ)and
(β,λ), respectively, compute the joint density of U = X + Y and V = X /( X + Y ).
```

```
Section 6.7 Joint Distribution of Functions of Random Variables 279
```
**_Solution._** The joint density of _X_ and _Y_ is given by

```
fX , Y ( x , y )=
```
```
λ e −λ x (λ x )α−^1
(α)
```
```
λ e −λ y (λ y )β−^1
(β)
```
```
=
```
```
λα+β
(α)(β)
```
```
e −λ( x + y ) x α−^1 y β−^1
```
Now, if _g_ 1 ( _x_ , _y_ )= _x_ + _y_ , _g_ 2 ( _x_ , _y_ )= _x_ /( _x_ + _y_ ),then

```
∂ g 1
∂ x
```
##### =

```
∂ g 1
∂ y
```
##### = 1

```
∂ g 2
∂ x
```
##### =

```
y
( x + y )^2
```
```
∂ g 2
∂ y
```
##### =−

```
x
( x + y )^2
```
so

```
J ( x , y )=
```
##### ∣ ∣ ∣ ∣ ∣ ∣ ∣

##### 11

```
y
( x + y )^2
```
```
− x
( x + y )^2
```
##### ∣ ∣ ∣ ∣ ∣ ∣ ∣

##### =−

##### 1

```
x + y
```
Finally, as the equations _u_ = _x_ + _y_ , _v_ = _x_ /( _x_ + _y_ )have as their solutions _x_ = _uv_ , _y_ =
_u_ ( 1 − _v_ ), we see that

```
fU , V ( u , v )= fX , Y [ uv , u ( 1 − v )] u
```
```
=
```
```
λ e −λ u (λ u )α+β−^1
(α+β)
```
```
v α−^1 ( 1 − v )β−^1 (α+β)
(α)(β)
```
Hence, _X_ + _Y_ and _X_ /( _X_ + _Y_ )are independent, with _X_ + _Y_ having a gamma dis-
tribution with parameters(α+β,λ)and _X_ /( _X_ + _Y_ )having a beta distribution with
parameters(α,β). The preceding reasoning also shows that _B_ (α,β), the normalizing
factor in the beta density, is such that

```
B (α,β)K
```
##### ∫ 1

```
0
```
```
v α−^1 ( 1 − v )β−^1 dv
```
##### =

```
(α)(β)
(α+β)
```
This entire result is quite interesting. For suppose there are _n_ + _m_ jobs to be per-
formed, each (independently) taking an exponential amount of time with rateλto be
completed and suppose that we have two workers to perform these jobs. Worker I
will do jobs 1, 2,..., _n_ , and worker II will do the remaining _m_ jobs. If we let _X_ and _Y_
denote the total working times of workers I and II, respectively, then (either from the
foregoing result or from Example 3b) _X_ and _Y_ will be independent gamma random
variables having parameters( _n_ ,λ)and( _m_ ,λ), respectively. It then follows that, inde-
pendently of the working time needed to complete all _n_ + _m_ jobs (that is, of _X_ + _Y_ ),
the proportion of this work that will be performed by worker I has a beta distribution
with parameters ( _n_ , _m_ )..

When the joint density function of the _n_ random variables _X_ 1 , _X_ 2 ,..., _Xn_ is given
and we want to compute the joint density function of _Y_ 1 , _Y_ 2 ,..., _Yn_ , where

```
Y 1 = g 1 ( X 1 ,..., Xn ) Y 2 = g 2 ( X 1 ,..., Xn ),... Yn = gn ( X 1 ,..., Xn )
```

**280** Chapter 6 Jointly Distributed Random Variables

```
the approach is the same—namely, we assume that the functions gi have continuous
partial derivatives and that the Jacobian determinant.
```
```
J ( x 1 ,..., xn )=
```
##### ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣

```
∂ g 1
∂ x 1
```
```
∂ g 1
∂ x 2
```
##### ···

```
∂ g 1
∂ xn
∂ g 2
∂ x 1
```
```
∂ g 2
∂ x 2
```
##### ···

```
∂ g 2
∂ xn
∂ gn
∂ x 1
```
```
∂ gn
∂ x 2
```
##### ···

```
∂ gn
∂ xn
```
##### ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣

##### Z 0

```
at all points ( x 1 ,..., xn ). Furthermore, we suppose that the equations y 1 =
g 1 ( x 1 ,..., xn ), y 2 = g 2 ( x 1 ,..., xn ),..., yn = gn ( x 1 ,..., xn )have a unique solution, say,
x 1 = h 1 ( y 1 ,..., yn ),..., xn = hn ( y 1 ,..., yn ). Under these assumptions, the joint den-
sity function of the random variables Yi is given by
```
```
fY 1 ,..., Yn ( y 1 ,..., yn )= fX 1 ,..., Xn ( x 1 ,..., xn )| J ( x 1 ,..., xn )|−^1 (7.3)
```
```
where xi = hi ( y 1 ,..., yn ), i =1, 2,..., n.
```
```
EXAMPLE 7d
Let X 1 , X 2 ,and X 3 be independent standard normal random variables. If Y 1 = X 1 +
X 2 + X 3 , Y 2 = X 1 − X 2 ,and Y 3 = X 1 − X 3 , compute the joint density function of
Y 1 , Y 2 , Y 3.
```
```
Solution. Letting Y 1 = X 1 + X 2 + X 3 , Y 2 = X 1 − X 2 , Y 3 = X 1 − X 3 , the Jacobian
of these transformations is given by
```
##### J =

##### ∣ ∣ ∣ ∣ ∣ ∣

##### 111

##### 1 − 10

##### 10 − 1

##### ∣ ∣ ∣ ∣ ∣ ∣

##### = 3

```
As the preceding transformations yield that
```
##### X 1 =

##### Y 1 + Y 2 + Y 3

##### 3

##### X 2 =

##### Y 1 − 2 Y 2 + Y 3

##### 3

##### X 3 =

##### Y 1 + Y 2 − 2 Y 3

##### 3

```
we see from Equation (7.3) that
```
```
fY 1 , Y 2 , Y 3 ( y 1 , y 2 , y 3 )
```
```
=
```
##### 1

##### 3

```
fX 1 , X 2 , X 3
```
##### (

```
y 1 + y 2 + y 3
3
```
##### ,

```
y 1 − 2 y 2 + y 3
3
```
##### ,

```
y 1 + y 2 − 2 y 3
3
```
##### )

```
Hence, as
```
```
fX 1 , X 2 , X 3 ( x 1 , x 2 , x 3 )=
```
##### 1

```
( 2 π)^3 /^2
```
```
e −
```
```
∑ 3
i = 1 x^2 i /^2
```
```
we see that
```
```
fY 1 , Y 2 , Y 3 ( y 1 , y 2 , y 3 )=
```
##### 1

```
3 ( 2 π)^3 /^2
```
```
e − Q ( y^1 , y^2 , y^3 )/^2
```

```
Section 6.7 Joint Distribution of Functions of Random Variables 281
```
where

```
Q ( y 1 , y 2 , y 3 )
```
##### =

##### (

```
y 1 + y 2 + y 3
3
```
##### ) 2

##### +

##### (

```
y 1 − 2 y 2 + y 3
3
```
##### ) 2

##### +

##### (

```
y 1 + y 2 − 2 y 3
3
```
##### ) 2

##### =

```
y^21
3
```
##### +

##### 2

##### 3

```
y^22 +
```
##### 2

##### 3

```
y^23 −
```
##### 2

##### 3

```
y 2 y 3
.
```
**_EXAMPLE 7e_**

Let _X_ 1 , _X_ 2 ,..., _Xn_ be independent and identically distributed exponential random
variables with rateλ.Let

```
Yi = X 1 + ··· + Xi i =1,..., n
```
```
(a) Find the joint density function of Y 1 ,..., Yn.
(b) Use the result of part (a) to find the density of Yn.
```
**_Solution._** (a) The Jacobian of the transformations _Y_ 1 = _X_ 1 , _Y_ 2 = _X_ 1 + _X_ 2 ,...,
_Yn_ = _X_ 1 + ··· + _Xn_ is

##### J =

##### ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣

##### 1000 ··· 0

##### 1100 ··· 0

##### 1110 ··· 0

##### ··· ···

##### ··· ···

##### 1111 ··· 1

##### ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣

```
Since only the first term of the determinant will be nonzero, we have J =1.
Now, the joint density function of X 1 ,..., Xn is given by
```
```
fX 1 ,..., Xn ( x 1 ,..., xn )=
```
```
∏ n
```
```
i = 1
```
```
λ e −λ xi 0 < xi <q, i =1,..., n
```
```
Hence, because the preceding transformations yield
```
```
X 1 = Y 1 , X 2 = Y 2 − Y 1 ,..., Xi = Yi − Yi − 1 ,..., Xn = Yn − Yn − 1
```
```
it follows from Equation (7.3) that the joint density function of Y 1 ,..., Yn is
fY 1 ,..., Yn ( y 1 , y 2 ,..., yn )
```
```
= fX 1 ,..., Xn ( y 1 , y 2 − y 1 ,..., yi − yi − 1 ,..., yn − yn − 1 )
```
```
=λ n exp
```
##### ⎧

##### ⎪⎨

##### ⎪⎩

```
−λ
```
##### ⎡

```
⎣ y 1 +
```
```
∑ n
```
```
i = 2
```
```
( yi − yi − 1 )
```
##### ⎤

##### ⎦

##### ⎫

##### ⎪⎬

##### ⎪⎭

```
=λ ne −λ yn 0 < y 1 ,0< yi − yi − 1 , i =2,..., n
=λ ne −λ yn 0 < y 1 < y 2 <···< yn
```

```
282 Chapter 6 Jointly Distributed Random Variables
```
```
(b) To obtain the marginal density of Yn , let us integrate out the other variables one
at a time. Doing this gives
```
```
fY 2 ,..., Yn ( y 2 ,..., yn )=
```
```
∫ y 2
```
```
0
```
```
λ ne −λ yndy 1
```
```
=λ ny 2 e −λ yn 0 < y 2 < y 3 <···< yn
```
```
Continuing, we obtain
```
```
fY 3 ,..., Yn ( y 3 ,..., yn )=
```
```
∫ y 3
```
```
0
```
```
λ ny 2 e −λ yndy 2
```
```
=λ n
```
```
y^23
2
```
```
e −λ yn 0 < y 3 < y 4 <···< yn
```
```
The next integration yields
```
```
fY 4 ,..., Yn ( y 4 ,..., yn )=λ n
```
```
y^34
3!
```
```
e −λ yn 0 < y 4 <···< yn
```
```
Continuing in this fashion gives
```
```
fYn ( yn )=λ n
```
```
ynn −^1
( n − 1 )!
```
```
e −λ yn 0 < yn
```
```
which, in agreement with the result obtained in Example 3b, shows that X 1 +
··· + Xn is a gamma random variable with parameters n andλ..
```
##### ∗ 6.8 EXCHANGEABLE RANDOM VARIABLES

```
The random variables X 1 , X 2 ,..., Xn are said to be exchangeable if, for every permu-
tation i 1 ,..., in of the integers 1,..., n ,
```
```
P { Xi 1 ... x 1 , Xi 2 ... x 2 ,..., Xin ... xn }= P { X 1 ... x 1 , X 2 ... x 2 ,..., Xn ... xn }
```
```
for all x 1 ,..., xn. That is, the n random variables are exchangeable if their joint distri-
bution is the same no matter in which order the variables are observed.
Discrete random variables will be exchangeable if
```
```
P { Xi 1 = x 1 , Xi 2 = x 2 ,..., Xin = xn }= P { X 1 = x 1 , X 2 = x 2 ,..., Xn = xn }
```
```
for all permutations i 1 ,..., in , and all values x 1 ,..., xn. This is equivalent to stating
that p ( x 1 , x 2 ,..., xn )= P { X 1 = x 1 ,..., Xn = xn }is a symmetric function of the vector
( x 1 ,..., xn ), which means that its value does not change when the values of the vector
are permuted.
```
```
EXAMPLE 8a
Suppose that balls are withdrawn one at a time and without replacement from an
urn that initially contains n balls, of which k are considered special, in such a manner
that each withdrawal is equally likely to be any of the balls that remain in the urn
at the time. Let Xi =1ifthe i th ball withdrawn is special and let Xi =0 otherwise.
We will show that the random variables X 1 ,..., Xn are exchangeable. To do so, let
( x 1 ,..., xn )be a vector consisting of k ones and n − k zeros. However, before consid-
ering the joint mass function evaluated at( x 1 ,..., xn ), let us try to gain some insight by
```

```
Section 6.8 Exchangeable Random Variables 283
```
considering a fixed such vector—for instance, consider the vector(1, 1, 0, 1, 0,...,0,1),
which is assumed to have _k_ ones and _n_ − _k_ zeros. Then

```
p (1, 1, 0, 1, 0,...,0,1)=
```
```
k
n
```
```
k − 1
n − 1
```
```
n − k
n − 2
```
```
k − 2
n − 3
```
```
n − k − 1
n − 4
```
##### ···

##### 1

##### 2

##### 1

##### 1

which follows because the probability that the first ball is special is _k_ / _n_ , the condi-
tional probability that the next one is special is( _k_ − 1 )/( _n_ − 1 ), the conditional
probability that the next one is not special is( _n_ − _k_ )/( _n_ − 2 ), and so on. By the same
argument, it follows that _p_ ( _x_ 1 ,..., _xn_ )can be expressed as the product of _n_ fractions.
The successive denominator terms of these fractions will go from _n_ down to 1. The
numerator term at the location where the vector( _x_ 1 ,..., _xn_ )is 1 for the _i_ th time is
_k_ −( _i_ − 1 ), and where it is 0 for the _i_ th time it is _n_ − _k_ −( _i_ − 1 ). Hence, since the
vector( _x_ 1 ,..., _xn_ )consists of _k_ ones and _n_ − _k_ zeros, we obtain

```
p ( x 1 ,..., xn )=
```
```
k !( n − k )!
n!
```
```
xi =0, 1,
```
```
∑ n
```
```
i = 1
```
```
xi = k
```
Since this is a symmetric function of( _x_ 1 ,..., _xn_ ), it follows that the random variables
are exchangeable..

**Remark.** Another way to obtain the preceding formula for the joint probability
mass function is to regard all the _n_ balls as distinguishable from each other. Then,
since the outcome of the experiment is an ordering of these balls, it follows that
there are _n_! equally likely outcomes. Finally, because the number of outcomes hav-
ing special and nonspecial balls in specified places is equal to the number of ways of
permuting the special and the nonspecial balls among themselves, namely _k_ !( _n_ − _k_ )!,
we obtain the preceding density function..

It is easily seen that if _X_ 1 , _X_ 2 ,..., _Xn_ are exchangeable, then each _Xi_ has the same
probability distribution. For instance, if _X_ and _Y_ are exchangeable discrete random
variables, then

```
P { X = x }=
```
##### ∑

```
y
```
```
P { X = x , Y = y }=
```
##### ∑

```
y
```
```
P { X = y , Y = x }= P { Y = x }
```
For example, it follows from Example 8a that the _i_ th ball withdrawn will be special
with probability _k_ / _n_ , which is intuitively clear, since each of the _n_ balls is equally
likely to be the _i_ th one selected.

**_EXAMPLE 8b_**

In Example 8a, let _Yi_ denote the selection number of the first special ball withdrawn,
let _Y_ 2 denote the additional number of balls that are then withdrawn until the second
special ball appears, and, in general, let _Yi_ denote the additional number of balls
withdrawn after the( _i_ − 1 )st special ball is selected until the _i_ th is selected, _i_ =
1,..., _k_. For instance, if _n_ =4, _k_ =2and _X_ 1 =1, _X_ 2 =0, _X_ 3 =0, _X_ 4 =1, then
_Y_ 1 = 1, _Y_ 2 =3. Now, _Y_ 1 = _i_ 1 , _Y_ 2 = _i_ 2 ,..., _Yk_ = _ik_ 3 _Xi_ 1 = _Xi_ 1 + _i_ 2 = ··· =
_Xi_ 1 +···+ _ik_ = 1, _Xj_ =0, otherwise; thus, from the joint mass function of the _Xi_ ,we
obtain

```
P { Y 1 = i 1 , Y 2 = i 2 ,..., Yk = ik }=
```
```
k !( n − k )!
n!
```
```
i 1 + ··· + ik ... n
```
Hence, the random variables _Y_ 1 ,..., _Yk_ are exchangeable. Note that it follows from
this result that the number of cards one must select from a well-shuffled deck until


**284** Chapter 6 Jointly Distributed Random Variables

```
an ace appears has the same distribution as the number of additional cards one must
select after the first ace appears until the next one does, and so on..
```
```
EXAMPLE 8c
The following is known as Polya’s urn model: Suppose that an urn initially contains n
red and m blue balls. At each stage, a ball is randomly chosen, its color is noted, and
it is then replaced along with another ball of the same color. Let Xi =1ifthe i th ball
selected is red and let it equal 0 if the i th ball is blue, i Ú1. To obtain a feeling for the
joint probabilities of these Xi , note the following special cases:
```
```
P { X 1 =1, X 2 =1, X 3 =0, X 4 =1, X 5 = 0 }
```
```
=
```
```
n
n + m
```
```
n + 1
n + m + 1
```
```
m
n + m + 2
```
```
n + 2
n + m + 3
```
```
m + 1
n + m + 4
```
```
=
```
```
n ( n + 1 )( n + 2 ) m ( m + 1 )
( n + m )( n + m + 1 )( n + m + 2 )( n + m + 3 )( n + m + 4 )
```
```
and
```
```
P { X 1 =0, X 2 =1, X 3 =0, X 4 =1, X 5 = 1 }
```
```
=
```
```
m
n + m
```
```
n
n + m + 1
```
```
m + 1
n + m + 2
```
```
n + 1
n + m + 3
```
```
n + 2
n + m + 4
```
```
=
```
```
n ( n + 1 )( n + 2 ) m ( m + 1 )
( n + m )( n + m + 1 )( n + m + 2 )( n + m + 3 )( n + m + 4 )
```
```
By the same reasoning, for any sequence x 1 ,..., xk that contains r ones and k − r
zeros, we have
```
```
P { X 1 = x 1 ,..., Xk = xk }
```
```
=
```
```
n ( n + 1 )···( n + r − 1 ) m ( m + 1 )···( m + k − r − 1 )
( n + m )···( n + m + k − 1 )
```
```
Therefore, for any value of k , the random variables X 1 ,..., Xk are exchangeable.
An interesting corollary of the exchangeability in this model is that the probability
that the i th ball selected is red is the same as the probability that the first ball selected
is red, namely, n + nm. (For an intuitive argument for this initially nonintuitive result,
imagine that all the n + m balls initially in the urn are of different types. That is, one
is a red ball of type 1, one is a red ball of type 2,..., one is a red ball type of n , one is
a blue ball of type 1, and so on, down to the blue ball of type m. Suppose that when
a ball is selected it is replaced along with another of its type. Then, by symmetry, the
i th ball selected is equally likely to be of any of the n + m distinct types. Because n
of these n + m types are red, the probability is n + nm .).
```
```
Our final example deals with continuous random variables that are exchangeable.
```
```
EXAMPLE 8d
Let X 1 , X 2 ,..., Xn be independent uniform (0, 1) random variables, and denote their
order statistics by X ( 1 ),..., X ( n ). That is, X ( j )is the j th smallest of X 1 , X 2 ,..., Xn.
```

```
Summary 285
```
Also, let

```
Y 1 = X ( 1 ),
Yi = X ( i )− X ( i − 1 ), i =2,... n
```
Show that _Y_ 1 ,..., _Yn_ are exchangeable.

**_Solution._** The transformations

```
y 1 = x 1 ,..., yi = xi − xi − 1 i =2,..., n
```
yield
_xi_ = _y_ 1 + ··· + _yi i_ =1,..., _n_

As it is easy to see that the Jacobian of the preceding transformations is equal to 1,
so, from Equation (7.3), we obtain

```
fY 1 ,..., Yn ( y 1 , y 2 ,..., yn )= f ( y 1 , y 1 + y 2 ,..., y 1 + ··· + yn )
```
where _f_ is the joint density function of the order statistics. Hence, from Equation (6.1),
we obtain that

```
fY 1 ,..., Yn ( y 1 , y 2 ,..., yn )= n !0< y 1 < y 1 + y 2 <···< y 1 + ··· + yn < 1
```
or, equivalently,

```
fY 1 ,..., Yn ( y 1 , y 2 ,..., yn )= n !0< yi <1, i =1,..., n , y 1 + ··· + yn < 1
```
Because the preceding joint density is a symmetric function of _y_ 1 ,..., _yn_ , we see that
the random variables _Y_ 1 ,..., _Yn_ are exchangeable..

#### Summary

The _joint cumulative probability distribution function_ of the pair of random variables
_X_ and _Y_ is defined by

```
F ( x , y )= P { X ... x , Y ... y }−q< x , y <q
```
All probabilities regarding the pair can be obtained from _F_. To find the individual
probability distribution functions of _X_ and _Y_ ,use

```
FX ( x )= lim
y →q
```
```
F ( x , y ) FY ( y )= lim
x →q
```
```
F ( x , y )
```
If _X_ and _Y_ are both discrete random variables, then their _joint probability mass
function_ is defined by
_p_ ( _i_ , _j_ )= _P_ { _X_ = _i_ , _Y_ = _j_ }

The individual mass functions are

```
P { X = i }=
```
##### ∑

```
j
```
```
p ( i , j ) P { Y = j }=
```
##### ∑

```
i
```
```
p ( i , j )
```
The random variables _X_ and _Y_ are said to be _jointly continuous_ if there is a func-
tion _f_ ( _x_ , _y_ ), called the _joint probability density function_ , such that for any two-dimensional
set _C_ ,

```
P {( X , Y )∈ C }=
```
##### ∫∫

```
C
```
```
f ( x , y ) dx dy
```

**286** Chapter 6 Jointly Distributed Random Variables

```
It follows from the preceding formula that
```
```
P { x < X < x + dx , y < Y < y + dy }L f ( x , y ) dx dy
```
```
If X and Y are jointly continuous, then they are individually continuous with density
functions
fX ( x )=
```
```
∫q
```
```
−q
```
```
f ( x , y ) dy fY ( y )=
```
```
∫q
```
```
−q
```
```
f ( x , y ) dx
```
```
The random variables X and Y are independent if, for all sets A and B ,
```
```
P { X ∈ A , Y ∈ B }= P { X ∈ A } P { Y ∈ B }
```
```
If the joint distribution function (or the joint probability mass function in the discrete
case, or the joint density function in the continuous case) factors into a part depending
only on x and a part depending only on y ,then X and Y are independent.
In general, the random variables X 1 ,..., Xn are independent if, for all sets of real
numbers A 1 ,..., An ,
```
```
P { X 1 ∈ A 1 ,..., Xn ∈ An }= P { X 1 ∈ A 1 }··· P { Xn ∈ An }
```
```
If X and Y are independent continuous random variables, then the distribution func-
tion of their sum can be obtained from the identity
```
```
FX + Y ( a )=
```
```
∫q
```
```
−q
```
```
FX ( a − y ) fY ( y ) dy
```
```
If Xi , i =1,..., n , are independent normal random variables with respective param-
etersμ i andσ i^2 , i =1,..., n ,then
```
```
∑ n
i = 1
```
```
Xi is normal with parameters
```
```
∑ n
i = 1
```
```
μ i and
```
```
∑ n
i = 1
```
```
σ i^2.
```
```
If Xi , i =1,..., n , are independent Poisson random variables with respective param-
etersλ i , i =1,..., n ,then
```
```
∑ n
i = 1
```
```
Xi is Poisson with parameter
```
```
∑ n
i = 1
```
```
λ i.
```
```
If X and Y are discrete random variables, then the conditional probability mass
function of X given that Y = y is defined by
```
```
P { X = x | Y = y }=
```
```
p ( x , y )
pY ( y )
```
```
where p is their joint probability mass function. Also, if X and Y are jointly continu-
ous with joint density function f , then the conditional probability density function of
X given that Y = y is given by
```
```
fX | Y ( x | y )=
```
```
f ( x , y )
fY ( y )
```
```
The ordered values X ( 1 )... X ( 2 )...···... X ( n )of a set of independent and identically
distributed random variables are called the order statistics of that set. If the random
variables are continuous and have density function f , then the joint density function
of the order statistics is
```
```
f ( x 1 ,..., xn )= n! f ( x 1 )··· f ( xn ) x 1 ... x 2 ...···... xn
```
```
The random variables X 1 ,..., Xn are called exchangeable if the joint distribution of
Xi 1 ,..., Xin is the same for every permutation i 1 ,..., in of 1,..., n.
```

```
Problems 287
```
#### Problems...................................

**6.1.** Two fair dice are rolled. Find the joint probability
mass function of _X_ and _Y_ when
**(a)** _X_ is the largest value obtained on any die and
_Y_ is the sum of the values;
**(b)** _X_ is the value on the first die and _Y_ is the
larger of the two values;
**(c)** _X_ is the smallest and _Y_ is the largest value
obtained on the dice.
**6.2.** Suppose that 3 balls are chosen without replace-
ment from an urn consisting of 5 white and 8 red
balls. Let _Xi_ equal 1 if the _i_ th ball selected is white,
and let it equal 0 otherwise. Give the joint proba-
bility mass function of
**(a)** _X_ 1 , _X_ 2 ;
**(b)** _X_ 1 , _X_ 2 , _X_ 3.
**6.3.** In Problem 2, suppose that the white balls are
numbered, and let _Yi_ equal 1 if the _i_ th white ball is
selected and 0 otherwise. Find the joint probability
mass function of
**(a)** _Y_ 1 , _Y_ 2 ;
**(b)** _Y_ 1 , _Y_ 2 , _Y_ 3.
**6.4.** Repeat Problem 2 when the ball selected is
replaced in the urn before the next selection.
**6.5.** Repeat Problem 3a when the ball selected is
replaced in the urn before the next selection.
**6.6.** A bin of 5 transistors is known to contain 2 that
are defective. The transistors are to be tested, one
at a time, until the defective ones are identified.
Denote by _N_ 1 the number of tests made until the
first defective is identified and by _N_ 2 the number of
additional tests until the second defective is identi-
fied. Find the joint probability mass function of _N_ 1
and _N_ 2.
**6.7.** Consider a sequence of independent Bernoulli tri-
als, each of which is a success with probability _p_.
Let _X_ 1 be the number of failures preceding the
first success, and let _X_ 2 be the number of failures
between the first two successes. Find the joint mass
function of _X_ 1 and _X_ 2.
**6.8.** The joint probability density function of _X_ and _Y_
is given by

```
f ( x , y )= c ( y^2 − x^2 ) e − y − y ... x ... y ,0< y <q
```
**(a)** Find _c_.
**(b)** Find the marginal densities of _X_ and _Y_.
**(c)** Find _E_ [ _X_ ].
**6.9.** The joint probability density function of _X_ and _Y_
is given by

```
f ( x , y )=
```
```
6
7
```
```
(
x^2 +
```
```
xy
2
```
```
)
0 < x <1, 0< y < 2
```
```
(a) Verify that this is indeed a joint density func-
tion.
(b) Compute the density function of X.
(c) Find P { X > Y }.
(d) Find P { Y >^12 | X <^12 }.
(e) Find E [ X ].
(f) Find E [ Y ].
6.10. The joint probability density function of X and Y
is given by
```
```
f ( x , y )= e −( x + y ) 0 ... x <q,0... y <q
```
```
Find (a) P { X < Y }and (b) P { X < a }.
6.11. A television store owner figures that 45 percent of
the customers entering his store will purchase an
ordinary television set, 15 percent will purchase
a plasma television set, and 40 percent will just
be browsing. If 5 customers enter his store on
a given day, what is the probability that he will
sell exactly 2 ordinary sets and 1 plasma set on
that day?
6.12. The number of people that enter a drugstore in
a given hour is a Poisson random variable with
parameterλ=10. Compute the conditional prob-
ability that at most 3 men entered the drugstore,
given that 10 women entered in that hour. What
assumptions have you made?
6.13. A man and a woman agree to meet at a certain
location about 12:30P.M. If the man arrives at
a time uniformly distributed between 12:15 and
12:45, and if the woman independently arrives at
a time uniformly distributed between 12:00 and 1
P.M., find the probability that the first to arrive
waits no longer than 5 minutes. What is the proba-
bility that the man arrives first?
6.14. An ambulance travels back and forth at a con-
stant speed along a road of length L .Atacertain
moment of time, an accident occurs at a point uni-
formly distributed on the road. [That is, the dis-
tance of the point from one of the fixed ends of the
road is uniformly distributed over (0, L ).] Assum-
ing that the ambulance’s location at the moment
of the accident is also uniformly distributed, and
assuming independence of the variables, compute
the distribution of the distance of the ambulance
from the accident.
6.15. The random vector ( X , Y )issaidtobeuniformly
distributed over a region R in the plane if, for some
constant c , its joint density is
```
```
f ( x , y )=
```
```
{
c if( x , y )∈ R
0 otherwise
```

**288** Chapter 6 Jointly Distributed Random Variables

```
(a) Show that 1/ c =area of region R.
Suppose that ( X , Y ) is uniformly distributed over
the square centered at (0, 0) and with sides of
length 2.
(b) Show that X and Y are independent, with
each being distributed uniformly over(−1, 1).
(c) What is the probability that ( X , Y ) lies in the
circle of radius 1 centered at the origin? That
is, find P { X^2 + Y^2 ... 1 }.
6.16. Suppose that n points are independently chosen at
random on the circumference of a circle, and we
want the probability that they all lie in some semi-
circle. That is, we want the probability that there is
a line passing through the center of the circle such
that all the points are on one side of that line, as
shown in the following diagram:
```
```
Let P 1 ,..., Pn denote the n points. Let A denote
the event that all the points are contained in some
semicircle, and let Ai be the event that all the
points lie in the semicircle beginning at the point
Pi and going clockwise for 180◦, i =1,..., n.
(a) Express A in terms of the Ai.
(b) Are the Ai mutually exclusive?
(c) Find P ( A ).
6.17. Three points X 1 , X 2 , X 3 are selected at random
on a line L. What is the probability that X 2 lies
between X 1 and X 3?
6.18. Two points are selected randomly on a line of
length L so as to be on opposite sides of the mid-
point of the line. [In other words, the two points
X and Y are independent random variables such
that X is uniformly distributed over (0, L /2) and
Y is uniformly distributed over ( L /2, L ).] Find
the probability that the distance between the two
points is greater than L /3.
6.19. Show that f ( x , y )= 1 / x ,0< y < x <1, is a joint
density function. Assuming that f is the joint den-
sity function of X , Y , find
(a) the marginal density of Y ;
(b) the marginal density of X ;
(c) E [ X ];
(c) E [ Y ].
```
```
6.20. The joint density of X and Y is given by
```
```
f ( x , y )=
```
```
{
xe −( x + y ) x >0, y > 0
0 otherwise
```
```
Are X and Y independent? If, instead, f ( x , y )were
given by
```
```
f ( x , y )=
```
```
{
20 < x < y ,0< y < 1
0 otherwise
```
```
would X and Y be independent?
6.21. Let
```
```
f ( x , y )= 24 xy 0 ... x ...1, 0... y ...1, 0... x + y ... 1
```
```
and let it equal 0 otherwise.
(a) Show that f ( x , y ) is a joint probability density
function.
(b) Find E [ X ].
(c) Find E [ Y ].
6.22. The joint density function of X and Y is
```
```
f ( x , y )=
```
```
{
x + y 0 < x <1, 0< y < 1
0 otherwise
```
```
(a) Are X and Y independent?
(b) Find the density function of X.
(c) Find P { X + Y < 1 }.
6.23. The random variables X and Y have joint density
function
```
```
f ( x , y )= 12 xy ( 1 − x ) 0 < x <1, 0< y < 1
```
```
and equal to 0 otherwise.
(a) Are X and Y independent?
(b) Find E [ X ].
(c) Find E [ Y ].
(d) Find Var( X ).
(e) Find Var( Y ).
6.24. Consider independent trials, each of which results
in outcome i , i = 0, 1,..., k , with probability
pi ,
```
```
∑ k
i = 0
```
```
pi = 1. Let N denote the number of trials
needed to obtain an outcome that is not equal to 0,
and let X be that outcome.
(a) Find P { N = n }, n Ú1.
(b) Find P { X = j }, j =1,..., k.
(c) Show that P { N = n , X = j }= P { N =
n } P { X = j }.
(d) Is it intuitive to you that N is independent
of X?
(e) Is it intuitive to you that X is independent
of N?
6.25. Suppose that 10^6 people arrive at a service station
at times that are independent random variables,
```

```
Problems 289
```
```
each of which is uniformly distributed over(0, 10^6 ).
Let N denote the number that arrive in the first
hour. Find an approximation for P { N = i }.
```
**6.26.** Suppose that _A_ , _B_ , _C_ , are independent random
variables, each being uniformly distributed over
(0, 1).
**(a)** What is the joint cumulative distribution func-
tion of _A_ , _B_ , _C_?
**(b)** What is the probability that all of the roots of
the equation _Ax_^2 + _Bx_ + _C_ =0 are real?

**6.27.** If _X_ 1 and _X_ 2 are independent exponential ran-
dom variables with respective parametersλ 1 and
λ 2 , find the distribution of _Z_ = _X_ 1 / _X_ 2. Also com-
pute _P_ { _X_ 1 < _X_ 2 }.

**6.28.** The time that it takes to service a car is an expo-
nential random variable with rate 1.
**(a)** If A. J. brings his car in at time 0 and M. J.
brings her car in at time _t_ , what is the probabil-
ity that M. J.’s car is ready before A. J.’s car?
(Assume that service times are independent
and service begins upon arrival of the car.)
**(b)** If both cars are brought in at time 0, with
work starting on M. J.’s car only when A. J.’s
car has been completely serviced, what is the
probability that M. J.’s car is ready before
time 2?

**6.29.** The gross weekly sales at a certain restaurant is
a normal random variable with mean $2200 and
standard deviation $230. What is the probabil-
ity that
**(a)** the total gross sales over the next 2 weeks
exceeds $5000;
**(b)** weekly sales exceed $2000 in at least 2 of the
next 3 weeks?
What independence assumptions have you made?

**6.30.** Jill’s bowling scores are approximately normally
distributed with mean 170 and standard deviation
20, while Jack’s scores are approximately normally
distributed with mean 160 and standard deviation

15. If Jack and Jill each bowl one game, then
assuming that their scores are independent ran-
dom variables, approximate the probability that
**(a)** Jack’s score is higher;
**(b)** the total of their scores is above 350.

**6.31.** According to the U.S. National Center for Health
Statistics, 25.2 percent of males and 23.6 percent of
females never eat breakfast. Suppose that random
samples of 200 men and 200 women are chosen.
Approximate the probability that
**(a)** at least 110 of these 400 people never eat
breakfast;
**(b)** the number of the women who never eat
breakfast is at least as large as the number of
the men who never eat breakfast.

```
6.32. The expected number of typographical errors on a
page of a certain magazine is .2. What is the prob-
ability that an article of 10 pages contains (a) 0 and
(b) 2 or more typographical errors? Explain your
reasoning!
6.33. The monthly worldwide average number of air-
plane crashes of commercial airlines is 2.2. What
is the probability that there will be
(a) more than 2 such accidents in the next month?
(b) more than 4 such accidents in the next 2
months?
(c) more than 5 such accidents in the next 3
months?
Explain your reasoning!
6.34. Jay has two jobs to do, one after the other. Each
attempt at job i takes one hour and is successful
with probability pi .If p 1 =.3and p 2 =.4, what
is the probability that it will take Jay more than 12
hours to be successful on both jobs?
6.35. In Problem 4, calculate the conditional probability
mass function of X 1 given that
(a) X 2 =1;
(b) X 2 =0.
6.36. In Problem 3, calculate the conditional probability
mass function of Y 1 given that
(a) Y 2 =1;
(b) Y 2 =0.
6.37. In Problem 5, calculate the conditional probability
mass function of Y 1 given that
(a) Y 2 =1;
(b) Y 2 =0.
6.38. Choose a number X at random from the set of
numbers{1, 2, 3, 4, 5}. Now choose a number at
random from the subset no larger than X ,thatis,
from{1,..., X }. Call this second number Y.
(a) Find the joint mass function of X and Y.
(b) Find the conditional mass function of X given
that Y = i .Doitfor i =1, 2, 3, 4, 5.
(c) Are X and Y independent? Why?
6.39. Two dice are rolled. Let X and Y denote, respec-
tively, the largest and smallest values obtained.
Compute the conditional mass function of Y given
X = i ,for i =1, 2,...,6. Are X and Y indepen-
dent? Why?
6.40. The joint probability mass function of X and Y is
given by
```
```
p (1, 1)=
```
```
1
8
```
```
p (1, 2)=
```
```
1
4
p (2, 1)=
```
```
1
8
p (2, 2)=
```
```
1
2
(a) Compute the conditional mass function of X
given Y = i , i =1, 2.
(b) Are X and Y independent?
```

**290** Chapter 6 Jointly Distributed Random Variables

```
(c) Compute P { XY ... 3 }, P { X + Y > 2 },
P { X / Y > 1 }.
6.41. The joint density function of X and Y is given by
```
```
f ( x , y )= xe − x ( y +^1 ) x >0, y > 0
```
```
(a) Find the conditional density of X , given Y = y ,
and that of Y , given X = x.
(b) Find the density function of Z = XY.
6.42. The joint density of X and Y is
```
```
f ( x , y )= c ( x^2 − y^2 ) e − x 0 ... x <q,− x ... y ... x
```
```
Find the conditional distribution of Y , given
X = x.
6.43. An insurance company supposes that each per-
son has an accident parameter and that the yearly
number of accidents of someone whose accident
parameter isλis Poisson distributed with meanλ.
They also suppose that the parameter value of a
newly insured person can be assumed to be the
value of a gamma random variable with param-
eters s andα. If a newly insured person has n
accidents in her first year, find the conditional den-
sity of her accident parameter. Also, determine the
expected number of accidents that she will have in
the following year.
6.44. If X 1 , X 2 , X 3 are independent random variables
that are uniformly distributed over (0, 1), com-
pute the probability that the largest of the three
is greater than the sum of the other two.
6.45. A complex machine is able to operate effectively
as long as at least 3 of its 5 motors are functioning.
If each motor independently functions for a ran-
dom amount of time with density function f ( x )=
xe − x , x > 0, compute the density function of the
length of time that the machine functions.
6.46. If 3 trucks break down at points randomly dis-
tributed on a road of length L , find the probability
that no 2 of the trucks are within a distance d of
each other when d ... L /2.
6.47. Consider a sample of size 5 from a uniform distri-
bution over (0, 1). Compute the probability that
the median is in the interval
```
```
(
1
4 ,
```
```
3
4
```
```
)
.
6.48. If X 1 , X 2 , X 3 , X 4 , X 5 are independent and iden-
tically distributed exponential random variables
with the parameterλ, compute
(a) P {min( X 1 ,..., X 5 )... a };
(b) P {max( X 1 ,..., X 5 )... a }.
6.49. Let X ( 1 ), X ( 2 ),..., X ( n ) be the order statistics
of a set of n independent uniform(0, 1)random
variables. Find the conditional distribution of X ( n )
given that X ( 1 ) = s 1 , X ( 2 ) = s 2 ,..., X ( n − 1 ) =
sn − 1.
```
```
6.50. Let Z 1 and Z 2 be independent standard normal
random variables. Show that X , Y has a bivariate
normal distribution when X = Z 1 , Y = Z 1 + Z 2.
6.51. Derive the distribution of the range of a sample of
size 2 from a distribution having density function
f ( x )= 2 x ,0< x <1.
6.52. Let X and Y denote the coordinates of a point uni-
formly chosen in the circle of radius 1 centered at
the origin. That is, their joint density is
```
```
f ( x , y )=
1
π
```
```
x^2 + y^2 ... 1
```
```
Find the joint density function of the polar coordi-
nates R =( X^2 + Y^2 )^1 /^2 and=tan−^1 Y / X.
6.53. If X and Y are independent random variables
both uniformly distributed over (0, 1), find the
joint density function of R =
```
```
√
X^2 + Y^2 ,Θ =
tan−^1 Y / X.
6.54. If U is uniform on(0, 2π)and Z , independent of
U , is exponential with rate 1, show directly (with-
out using the results of Example 7b) that X and Y
defined by
```
```
X =
```
```
√
2 Z cos U
Y =
```
```
√
2 Z sin U
```
```
are independent standard normal random vari-
ables.
6.55. X and Y have joint density function
```
```
f ( x , y )=
```
```
1
x^2 y^2
```
```
x Ú1, y Ú 1
```
```
(a) Compute the joint density function of U =
XY , V = X / Y.
(b) What are the marginal densities?
6.56. If X and Y are independent and identically dis-
tributed uniform random variables on (0, 1),
compute the joint density of
(a) U = X + Y , V = X / Y ;
(b) U = X , V = X / Y ;
(c) U = X + Y , V = X /( X + Y ).
6.57. Repeat Problem 6.56 when X and Y are inde-
pendent exponential random variables, each with
parameterλ=1.
6.58. If X 1 and X 2 are independent exponential random
variables, each having parameterλ, find the joint
density function of Y 1 = X 1 + X 2 and Y 2 = eX^1.
6.59. If X , Y ,and Z are independent random variables
having identical density functions f ( x )= e − x ,0<
x <q, derive the joint distribution of U = X +
Y , V = X + Z , W = Y + Z.
```

```
Theoretical Exercises 291
```
**6.60.** In Example 8b, let _Yk_ + 1 = _n_ + 1 −

```
∑ k
i = 1
```
```
Yi. Show
that Y 1 ,..., Yk , Yk + 1 are exchangeable. Note that
Yk + 1 is the number of balls one must observe to
obtain a special ball if one considers the balls in
their reverse order of withdrawal.
```
```
6.61. Consider an urn containing n balls numbered
1,..., n , and suppose that k of them are randomly
withdrawn. Let Xi equal 1 if ball number i is
removed and let Xi be 0 otherwise. Show that
X 1 ,..., Xn are exchangeable.
```
#### Theoretical Exercises

```
6.1. Verify Equation (1.2).
6.2. Suppose that the number of events occurring in
a given time period is a Poisson random vari-
able with parameterλ. If each event is classi-
fied as a type i event with probability pi , i =
1,..., n ,
```
```
∑
pi =1, independently of other events,
show that the numbers of type i events that occur,
i =1,..., n , are independent Poisson random vari-
ables with respective parametersλ pi , i =1,..., n.
6.3. Suggest a procedure for using Buffon’s needle
problem to estimateπ. Surprisingly enough, this
was once a common method of evaluatingπ.
6.4. Solve Buffon’s needle problem when L > D.
ANSWER:
```
```
2 L
π D
```
```
( 1 −sinθ)+ 2 θ/π,wherecosθ=
D / L.
6.5. If X and Y are independent continuous positive
random variables, express the density function of
(a) Z = X / Y and (b) Z = XY in terms of the
density functions of X and Y. Evaluate the density
functions in the special case where X and Y are
both exponential random variables.
6.6. If X and Y are jointly continuous with joint density
function fX , Y ( x , y ), show that X + Y is continuous
with density function
```
```
fX + Y ( t )=
```
```
∫q
```
```
−q
```
```
fX , Y ( x , t − x ) dx
```
```
6.7. (a) If X has a gamma distribution with parame-
ters( t ,λ), what is the distribution of cX , c >0?
(b) Show that
1
2 λ
χ 22 n
```
```
has a gamma distribution with parameters n ,λ
when n is a positive integer and χ 22 n is a
chi-squared random variable with 2 n degrees
of freedom.
6.8. Let X and Y be independent continuous ran-
dom variables with respective hazard rate func-
tionsλ X ( t )andλ Y ( t ),andset W =min( X , Y ).
(a) Determine the distribution function of W in
terms of those of X and Y.
```
```
(b) Show thatλ W ( t ), the hazard rate function of
W , is given by
```
```
λ W ( t )=λ X ( t )+λ Y ( t )
```
```
6.9. Let X 1 ,..., Xn be independent exponential ran-
dom variables having a common parameter λ.
Determine the distribution of min( X 1 ,..., Xn ).
6.10. The lifetimes of batteries are independent expo-
nential random variables, each having parame-
terλ. A flashlight needs 2 batteries to work. If one
has a flashlight and a stockpile of n batteries, what
is the distribution of time that the flashlight can
operate?
6.11. Let X 1 , X 2 , X 3 , X 4 , X 5 be independent continu-
ous random variables having a common distribu-
tion function F and density function f ,andset
```
```
I = P { X 1 < X 2 < X 3 < X 4 < X 5 }
```
```
(a) Show that I does not depend on F.
Hint :Write I as a five-dimensional integral and
make the change of variables ui = F ( xi ), i =
1,...,5.
(b) Evaluate I.
(c) Give an intuitive explanation for your answer
to (b).
6.12. Show that the jointly continuous (discrete) ran-
dom variables X 1 ,..., Xn are independent if and
only if their joint probability density (mass) func-
tion f ( x 1 ,..., xn )can be written as
```
```
f ( x 1 ,..., xn )=
```
```
∏ n
```
```
i = 1
```
```
gi ( xi )
```
```
for nonnegative functions gi ( x ), i =1,..., n.
6.13. In Example 5c we computed the conditional den-
sity of a success probability for a sequence of tri-
als when the first n + m trials resulted in n suc-
cesses. Would the conditional density change if
we specified which n of these trials resulted in
successes?
```

**292** Chapter 6 Jointly Distributed Random Variables

```
6.14. Suppose that X and Y are independent geometric
random variables with the same parameter p.
(a) Without any computations, what do you think
is the value of
```
```
P { X = i | X + Y = n }?
```
```
Hint : Imagine that you continually flip a coin hav-
ing probability p of coming up heads. If the second
head occurs on the n th flip, what is the probability
mass function of the time of the first head?
(b) Verify your conjecture in part (a).
6.15. Consider a sequence of independent trials, with
each trial being a success with probability p. Given
that the k th success occurs on trial n , show that
all possible outcomes of the first n −1trialsthat
consist of k −1 successes and n − k failures are
equally likely.
6.16. If X and Y are independent binomial random
variables with identical parameters n and p , show
analytically that the conditional distribution of X
given that X + Y = m is the hypergeometric dis-
tribution. Also, give a second argument that yields
the same result without any computations.
Hint : Suppose that 2 n coins are flipped. Let X
denote the number of heads in the first n flips and
Y the number in the second n flips. Argue that
given a total of m heads, the number of heads in
the first n flips has the same distribution as the
number of white balls selected when a sample of
size m is chosen from n white and n black balls.
6.17. Suppose that Xi , i =1, 2, 3 are independent Pois-
son random variables with respective meansλ i , i =
1, 2, 3. Let X = X 1 + X 2 and Y = X 2 + X 3.
The random vector X , Y is said to have a bivari-
ate Poisson distribution. Find its joint probability
mass function. That is, find P { X = n , Y = m }.
6.18. Suppose X and Y are both integer-valued random
variables. Let
```
```
p ( i | j )= P ( X = i | Y = j )
```
```
and
q ( j | i )= P ( Y = j | X = i )
```
```
Show that
```
```
P ( X = i , Y = j )=
p ( i | j )
∑
i
```
```
p ( i | j )
q ( j | i )
```
```
6.19. Let X 1 , X 2 , X 3 be independent and identically dis-
tributed continuous random variables. Compute
(a) P { X 1 > X 2 | X 1 > X 3 };
(b) P { X 1 > X 2 | X 1 < X 3 };
(c) P { X 1 > X 2 | X 2 > X 3 };
(d) P { X 1 > X 2 | X 2 < X 3 }.
```
```
6.20. Let U denote a random variable uniformly dis-
tributed over (0, 1). Compute the conditional dis-
tribution of U given that
(a) U > a ;
(b) U < a ;
where 0< a <1.
6.21. Suppose that W , the amount of moisture in the
air on a given day, is a gamma random vari-
able with parameters( t ,β). That is, its density is
f ( w )=β e −β w (β w ) t −^1 /( t ), w >0. Suppose also
that given that W = w , the number of accidents
during that day—call it N —has a Poisson distribu-
tion with mean w. Show that the conditional dis-
tribution of W given that N = n is the gamma
distribution with parameters( t + n ,β+ 1 ).
6.22. Let W be a gamma random variable with param-
eters ( t ,β), and suppose that conditional on
W = w , X 1 , X 2 ,..., Xn are independent exponen-
tial random variables with rate w. Show that the
conditional distribution of W given that X 1 =
x 1 , X 2 = x 2 ,..., Xn = xn is gamma with parame-
```
```
ters
```
```
(
t + n ,β +
```
```
∑ n
i = 1
```
```
xi
```
```
)
.
```
```
6.23. A rectangular array of mn numbers arranged in n
rows, each consisting of m columns, is said to con-
tain a saddlepoint if there is a number that is both
the minimum of its row and the maximum of its
column. For instance, in the array
```
```
132
0 − 26
```
. 5123

```
the number 1 in the first row, first column is a
saddlepoint. The existence of a saddlepoint is of
significance in the theory of games. Consider a
rectangular array of numbers as described previ-
ously and suppose that there are two individuals—
A and B —that are playing the following game: A
is to choose one of the numbers 1, 2,..., n and B
one of the numbers 1, 2,..., m. These choices are
announced simultaneously, and if A chose i and
B chose j ,then A wins from B the amount spec-
ified by the number in the i th row, j th column of
the array. Now suppose that the array contains
a saddlepoint—say the number in the row r and
column k —call this number xrk. Now if player A
chooses row r , then that player can guarantee her-
self a win of at least xrk (since xrk is the minimum
number in the row r ). On the other hand, if player
B chooses column k , then he can guarantee that he
will lose no more than xrk (since xrk is the maxi-
mum number in the column k ). Hence, as A has a
way of playing that guarantees her a win of xrk and
as B has a way of playing that guarantees he will
lose no more than xrk , it seems reasonable to take
```

```
Self-Test Problems and Exercises 293
```
these two strategies as being optimal and declare
that the value of the game to player _A_ is _xrk_.
If the _nm_ numbers in the rectangular array
described are independently chosen from an
arbitrary continuous distribution, what is the
probability that the resulting array will contain a
saddle-point?
**6.24.** If _X_ is exponential with rateλ, find _P_ {[ _X_ ]= _n_ , _X_ −
[ _X_ ]... _x_ },where[ _x_ ] is defined as the largest integer
less than or equal to _x_. Can you conclude that [ _X_ ]
and _X_ −[ _X_ ] are independent?
**6.25.** Suppose that _F_ ( _x_ )is a cumulative distribution
function. Show that (a) _Fn_ ( _x_ )and (b) 1− [1−
_F_ ( _x_ )] _n_ are also cumulative distribution functions
when _n_ is a positive integer.
_Hint_ :Let _X_ 1 ,..., _Xn_ be independent random vari-
ables having the common distribution function _F_.
Define random variables _Y_ and _Z_ in terms of the
_Xi_ so that _P_ { _Y_ ... _x_ }= _Fn_ ( _x_ )and _P_ { _Z_ ... _x_ }=
1 −[1− _F_ ( _x_ )] _n_.
**6.26.** Show that if _n_ people are distributed at random
along a road _L_ miles long, then the probability that
no 2 people are less than a distance _D_ miles apart
is when _D_ ... _L_ /( _n_ − 1 ),[1−( _n_ − 1 ) _D_ / _L_ ] _n_. What
if _D_ > _L_ /( _n_ − 1 )?
**6.27.** Establish Equation (6.2) by differentiating Equa-
tion (6.4).
**6.28.** Show that the median of a sample of size 2 _n_ + 1
from a uniform distribution on (0, 1) has a beta
distribution with parameters( _n_ +1, _n_ + 1 ).
**6.29.** Verify Equation (6.6), which gives the joint density
of _X_ ( _i_ )and _X_ ( _j_ ).
**6.30.** Compute the density of the range of a sample of
size _n_ from a continuous distribution having den-
sity function _f_.
**6.31.** Let _X_ ( 1 )... _X_ ( 2 )...···... _X_ ( _n_ )be the ordered values
of _n_ independent uniform (0, 1) random variables.

```
Prove that for 1... k ... n +1,
```
```
P { X ( k )− X ( k − 1 )> t }=( 1 − t ) n
```
```
where X ( 0 )K0, X ( n + 1 )K t.
6.32. Let X 1 ,..., Xn be a set of independent and identi-
cally distributed continuous random variables hav-
ing distribution function F ,andlet X ( i ), i =1,..., n
denote their ordered values. If X , independent of
the Xi , i =1,..., n , also has distribution F , deter-
mine
(a) P { X > X ( n )};
(b) P { X > X ( 1 )};
(c) P { X ( i )< X < X ( j )},1... i < j ... n.
6.33. Let X 1 ,..., Xn be independent and identically
distributed random variables having distribution
function F and density f. The quantity M K[ X ( 1 )+
X ( n )]/2, defined to be the average of the small-
est and largest values in X 1 ,..., Xn , is called the
midrange of the sequence. Show that its distribu-
tion function is
```
```
FM ( m )= n
```
```
∫ m
```
```
−q
```
```
[ F ( 2 m − x )− F ( x )] n −^1 f ( x ) dx
```
```
6.34. Let X 1 ,..., Xn be independent uniform (0, 1) ran-
dom variables. Let R = X ( n )− X ( 1 )denote the
range and M =[ X ( n )+ X ( 1 )]/2 the midrange of
X 1 ,..., Xn. Compute the joint density function of
R and M.
6.35. If X and Y are independent standard normal ran-
dom variables, determine the joint density func-
tion of
U = XV =
```
```
X
Y
Then use your result to show that X / Y has a
Cauchy distribution.
```
#### Self-Test Problems and Exercises

```
6.1. Each throw of an unfair die lands on each of the
odd numbers 1, 3, 5 with probability C and on each
of the even numbers with probability 2 C.
(a) Find C.
(b) Suppose that the die is tossed. Let X equal
1 if the result is an even number, and let it
be 0 otherwise. Also, let Y equal 1 if the
result is a number greater than three and
let it be 0 otherwise. Find the joint prob-
ability mass function of X and Y. Suppose
now that 12 independent tosses of the die are
made.
(c) Find the probability that each of the six out-
comes occurs exactly twice.
```
```
(d) Find the probability that 4 of the outcomes
are either one or two, 4 are either three or
four, and 4 are either five or six.
(e) Find the probability that at least 8 of the
tosses land on even numbers.
6.2. The joint probability mass function of the random
variables X , Y , Z is
```
```
p (1, 2, 3)= p (2, 1, 1)= p (2, 2, 1)= p (2, 3, 2)=
```
```
1
4
Find (a) E [ XYZ ], and (b) E [ XY + XZ + YZ ].
6.3. The joint density of X and Y is given by
```
```
f ( x , y )= C ( y − x ) e − y − y < x < y ,0< y <q
```

**294** Chapter 6 Jointly Distributed Random Variables

```
(a) Find C.
(b) Find the density function of X.
(c) Find the density function of Y.
(d) Find E [ X ].
(e) Find E [ Y ].
6.4. Let r = r 1 + ...+ rk ,whereall ri are positive
integers. Argue that if X 1 ,..., Xr has a multino-
mial distribution, then so does Y 1 ,..., Yk where,
with r 0 =0,
```
```
Yi =
```
```
ri −∑ 1 + ri
```
```
j = ri − 1 + 1
```
```
Xj , i ... k
```
```
That is, Y 1 is the sum of the first r 1 of the X ′ s , Y 2
is the sum of the next r 2 , and so on.
6.5. Suppose that X , Y ,and Z are independent random
variables that are each equally likely to be either
1 or 2. Find the probability mass function of (a)
XYZ ,(b) XY + XZ + YZ ,and(c) X^2 + YZ.
6.6. Let X and Y be continuous random variables with
joint density function
```
```
f ( x , y )=
```
```
⎧
⎨
⎩
```
```
x
5
```
```
+ cy 0 < x <1, 1< y < 5
0 otherwise
```
```
where c is a constant.
(a) What is the value of c?
(b) Are X and Y independent?
(c) Find P { X + Y > 3 }.
6.7. The joint density function of X and Y is
```
```
f ( x , y )=
```
```
{
xy 0 < x <1, 0< y < 2
0 otherwise
```
```
(a) Are X and Y independent?
(b) Find the density function of X.
(c) Find the density function of Y.
(d) Find the joint distribution function.
(e) Find E [ Y ].
(f) Find P { X + Y < 1 }.
6.8. Consider two components and three types of
shocks. A type 1 shock causes component 1 to fail,
a type 2 shock causes component 2 to fail, and a
type 3 shock causes both components 1 and 2 to
fail. The times until shocks 1, 2, and 3 occur are
independent exponential random variables with
respective ratesλ 1 ,λ 2 ,andλ 3 .Let Xi denote the
time at which component i fails, i = 1, 2. The
random variables X 1 , X 2 are said to have a joint
bivariate exponential distribution. Find P { X 1 >
s , X 2 > t }.
6.9. Consider a directory of classified advertisements
that consists of m pages, where m is very large.
Suppose that the number of advertisements per
```
```
page varies and that your only method of finding
out how many advertisements there are on a spec-
ified page is to count them. In addition, suppose
that there are too many pages for it to be feasi-
ble to make a complete count of the total num-
ber of advertisements and that your objective is
to choose a directory advertisement in such a way
that each of them has an equal chance of being
selected.
(a) If you randomly choose a page and then
randomly choose an advertisement from that
page, would that satisfy your objective? Why
or why not?
Let n ( i )denote the number of advertise-
ments on page i , i = 1,..., m , and suppose
that whereas these quantities are unknown,
we can assume that they are all less than
or equal to some specified value n. Con-
sider the following algorithm for choosing an
advertisement.
Step 1. Choose a page at random. Suppose it is
page X. Determine n ( X )by counting the
number of advertisements on page X.
Step 2. “Accept” page X with probability n ( X )/ n.
If page X is accepted, go to step 3. Other-
wise, return to step 1.
Step 3. Randomly choose one of the advertise-
ments on page X.
Call each pass of the algorithm through step
1 an iteration. For instance, if the first ran-
domly chosen page is rejected and the second
accepted, than we would have needed 2 itera-
tions of the algorithm to obtain an advertise-
ment.
(b) What is the probability that a single iteration
of the algorithm results in the acceptance of
an advertisement on page i?
(c) What is the probability that a single iteration
of the algorithm results in the acceptance of
an advertisement?
(d) What is the probability that the algorithm
goes through k iterations, accepting the j th
advertisement on page i on the final iteration?
(e) What is the probability that the j th advertise-
ment on page i is the advertisement obtained
from the algorithm?
(f) What is the expected number of iterations
taken by the algorithm?
6.10. The “random” parts of the algorithm in Self-Test
Problem 8 can be written in terms of the generated
values of a sequence of independent uniform (0,
1) random variables, known as random numbers.
With [ x ] defined as the largest integer less than or
equal to x , the first step can be written as follows:
```

```
Self-Test Problems and Exercises 295
```
Step 1. Generate a uniform (0, 1) random variable _U_.
Let _X_ =[ _mU_ ]+1, and determine the value of
_n_ ( _X_ ).
**(a)** Explain why the above is equivalent to step 1
of Problem 8.
_Hint_ : What is the probability mass function of _X_?
**(b)** Write the remaining steps of the algorithm in
a similar style.
**6.11.** Let _X_ 1 , _X_ 2 ,...be a sequence of independent uni-
form (0, 1) random variables. For a fixed con-
stant _c_ , define the random variable _N_ by

```
N =min{ n : Xn > c }
```
Is _N_ independent of _XN_? That is, does know-
ing the value of the first random variable that is
greater than _c_ affect the probability distribution of
when this random variable occurs? Give an intu-
itive explanation for your answer.
**6.12.** The accompanying dartboard is a square whose
sides are of length 6:

```
10
20
30
```
The three circles are all centered at the center of
the board and are of radii 1, 2, and 3, respectively.
Darts landing within the circle of radius 1 score 30
points, those landing outside this circle, but within
the circle of radius 2, are worth 20 points, and
those landing outside the circle of radius 2, but
within the circle of radius 3, are worth 10 points.
Darts that do not land within the circle of radius
3 do not score any points. Assuming that each
dart that you throw will, independently of what
occurred on your previous throws, land on a point
uniformly distributed in the square, find the prob-
abilities of the accompanying events:
**(a)** You score 20 on a throw of the dart.
**(b)** You score at least 20 on a throw of the
dart.
**(c)** You score 0 on a throw of the dart.
**(d)** The expected value of your score on a throw
of the dart.
**(e)** Both of your first two throws score at least 10.
**(f)** Your total score after two throws is 30.
**6.13.** A model proposed for NBA basketball supposes
that when two teams with roughly the same record
play each other, the number of points scored in
a quarter by the home team minus the number

```
scored by the visiting team is approximately a nor-
mal random variable with mean 1.5 and variance
```
6. In addition, the model supposes that the point
differentials for the four quarters are independent.
Assume that this model is correct.
**(a)** What is the probability that the home team
    wins?
**(b)** What is the conditional probability that the
    home team wins, given that it is behind by 5
    points at halftime?
**(c)** What is the conditional probability that the
    home team wins, given that it is ahead by 5
    points at the end of the first quarter?
**6.14.** Let _N_ be a geometric random variable with param-
eter _p_. Suppose that the conditional distribution
of _X_ given that _N_ = _n_ is the gamma distribu-
tion with parameters _n_ andλ. Find the condi-
tional probability mass function of _N_ given that
_X_ = _x_.
**6.15.** Let _X_ and _Y_ be independent uniform (0, 1) ran-
dom variables.
**(a)** Find the joint density of _U_ = _X_ , _V_ = _X_ + _Y_.
**(b)** Use the result obtained in part (a) to compute
the density function of _V_.
**6.16.** You and three other people are to place bids for an
object, with the high bid winning. If you win, you
plan to sell the object immediately for 10 thousand
dollars. How much should you bid to maximize
your expected profit if you believe that the bids
of the others can be regarded as being indepen-
dent and uniformly distributed between 7 and 11
thousand dollars?
**6.17.** Find the probability that _X_ 1 , _X_ 2 ,..., _Xn_ is a per-
mutation of 1, 2,..., _n_ ,when _X_ 1 , _X_ 2 ,..., _Xn_ are
independent and
**(a)** each is equally likely to be any of the values
1,..., _n_ ;
**(b)** each has the probability mass function _P_ { _Xi_ =
_j_ }= _pj_ , _j_ =1,..., _n_.
**6.18.** Let _X_ 1 ,..., _Xn_ and _Y_ 1 ,..., _Yn_ be independent ran-
dom vectors, with each vector being a random
ordering of _k_ ones and _n_ − _k_ zeroes. That is, their
joint probability mass functions are

```
P { X 1 = i 1 ,..., Xn = in }= P { Y 1 = i 1 ,..., Yn = in }
```
```
=
```
```
1
(
n
k
```
```
), ij =0, 1,
```
```
∑ n
```
```
j = 1
```
```
ij = k
```
```
Let
```
```
N =
```
```
∑ n
```
```
i = 1
```
```
| Xi − Yi |
```

**296** Chapter 6 Jointly Distributed Random Variables

denote the number of coordinates at which the two
vectors have different values. Also, let _M_ denote
the number of values of _i_ for which _Xi_ =1, _Yi_ =0.
**(a)** Relate _N_ to _M_.
**(b)** What is the distribution of _M_?
**(c)** Find _E_ [ _N_ ].
**(d)** Find Var( _N_ ).
∗ **6.19.** Let _Z_ 1 , _Z_ 2 ,..., _Zn_ be independent standard nor-

```
mal random variables, and let
```
```
Sj =
```
```
∑ j
```
```
i = 1
```
```
Zi
```
```
(a) What is the conditional distribution of Sn
given that Sk = y ,for k =1,..., n?
(b) Show that, for 1 ... k ... n , the conditional
distribution of Sk given that Sn = x is
normal with mean xk / n and variance k ( n −
k )/ n.
```
```
6.20. Let X 1 , X 2 ,...be a sequence of independent and
identically distributed continuous random vari-
ables. Find
(a) P { X 6 > X 1 | X 1 =max( X 1 ,..., X 5 )}
(b) P { X 6 > X 2 | X 1 =max( X 1 ,..., X 5 )}
```

## CHAPTER 7

# Properties of Expectation

### 7.1 Introduction

**7.2 EXPECTATION OF SUMS OF RANDOM VARIABLES
7.3 MOMENTS OF THE NUMBER OF EVENTS THAT OCCUR
7.4 COVARIANCE, VARIANCE OF SUMS, AND CORRELATIONS
7.5 CONDITIONAL EXPECTATION
7.6 CONDITIONAL EXPECTATION AND PREDICTION
7.7 MOMENT GENERATING FUNCTIONS
7.8 ADDITIONAL PROPERTIES OF NORMAL RANDOM VARIABLES
7.9 GENERAL DEFINITION OF EXPECTATION**

##### 7.1 INTRODUCTION

```
In this chapter, we develop and exploit additional properties of expected values. To
begin, recall that the expected value of the random variable X is defined by
```
```
E [ X ]=
```
##### ∑

```
x
```
```
xp ( x )
```
```
where X is a discrete random variable with probability mass function p(x) , and by
```
##### E [ X ]=

```
∫q
```
```
−q
```
```
xf ( x ) dx
```
```
when X is a continuous random variable with probability density function f(x).
Since E[X] is a weighted average of the possible values of X , it follows that if X
must lie between a and b , then so must its expected value. That is, if
```
```
P { a ... X ... b }= 1
```
```
then
a ... E [ X ]... b
```
```
To verify the preceding statement, suppose that X is a discrete random variable for
which P { a ... X ... b }=1. Since this implies that p ( x )=0 for all x outside of the
interval [ a , b ], it follows that
```
```
E [ X ]=
```
##### ∑

```
x : p ( x )> 0
```
```
xp ( x )
```
##### Ú

##### ∑

```
x : p ( x )> 0
```
```
ap ( x )
```
```
297
```

**298** Chapter 7 Properties of Expectation

```
= a
```
##### ∑

```
x : p ( x )> 0
```
```
p ( x )
```
```
= a
```
```
In the same manner, it can be shown that E [ X ]... b , so the result follows for discrete
random variables. As the proof in the continuous case is similar, the result follows.
```
### 7.2 Expectation of Sums of Random Variables

```
For a two-dimensional analog of Propositions 4.1 of Chapter 4 and 2.1 of Chapter 5,
which give the computational formulas for the expected value of a function of a ran-
dom variable, suppose that X and Y are random variables and g is a function of two
variables. Then we have the following result.
```
```
Proposition 2.1. If X and Y have a joint probability mass function p(x,y) ,then
```
```
E [ g ( X , Y )]=
```
##### ∑

```
y
```
##### ∑

```
x
```
```
g ( x , y ) p ( x , y )
```
```
If X and Y have a joint probability density function f(x,y) ,then
```
```
E [ g ( X , Y )]=
```
```
∫q
```
```
−q
```
```
∫q
```
```
−q
```
```
g ( x , y ) f ( x , y ) dx dy
```
```
Let us give a proof of Proposition 2.1 when the random variables X and Y are
jointly continuous with joint density function f ( x , y )and when g ( X , Y )is a nonneg-
ative random variable. Because g ( X , Y )Ú0, we have, by Lemma 2.1 of Chapter 5,
that
E [ g ( X , Y )]=
```
```
∫q
```
```
0
```
```
P { g ( X , Y )> t } dt
```
```
Writing
P { g ( X , Y )> t }=
```
##### ∫∫

```
( x , y ): g ( x , y )> t
```
```
f ( x , y ) dy dx
```
```
shows that
E [ g ( X , Y )]=
```
```
∫q
```
```
0
```
##### ∫∫

```
( x , y ): g ( x , y )> t
```
```
f ( x , y ) dy dx dt
```
```
Interchanging the order of integration gives
```
```
E [ g ( X , Y )=
```
##### ∫

```
x
```
##### ∫

```
y
```
```
∫ g ( x , y )
```
```
t = 0
```
```
f ( x , y ) dt dy dx
```
##### =

##### ∫

```
x
```
##### ∫

```
y
```
```
g ( x , y ) f ( x , y ) dy dx
```
```
Thus, the result is proven when g ( X , Y )is a nonnegative random variable. The gen-
eral case then follows as in the one-dimensional case. (See Theoretical Exercises 2
and 3 of Chapter 5.)
```
```
EXAMPLE 2a
An accident occurs at a point X that is uniformly distributed on a road of length L.
At the time of the accident, an ambulance is at a location Y that is also uniformly
```

```
Section 7.2 Expectation of Sums of Random Variables 299
```
distributed on the road. Assuming that _X_ and _Y_ are independent, find the expected
distance between the ambulance and the point of the accident.

**_Solution._** We need to compute _E_ [| _X_ − _Y_ |]. Since the joint density function of _X_ and
_Y_ is

```
f ( x , y )=
```
##### 1

##### L^2

```
,0< x < L ,0< y < L
```
it follows from Proposition 2.1 that

##### E [| X − Y |]=

##### 1

##### L^2

##### ∫ L

```
0
```
##### ∫ L

```
0
```
```
| x − y | dy dx
```
Now,
∫ _L_

```
0
```
```
| x − y | dy =
```
```
∫ x
```
```
0
```
```
( x − y ) dy +
```
##### ∫ L

```
x
```
```
( y − x ) dy
```
##### =

```
x^2
2
```
##### +

##### L^2

##### 2

##### −

```
x^2
2
```
```
− x ( L − x )
```
##### =

##### L^2

##### 2

```
+ x^2 − xL
```
Therefore,

##### E [| X − Y |]=

##### 1

##### L^2

##### ∫ L

```
0
```
##### (

##### L^2

##### 2

```
+ x^2 − xL
```
##### )

```
dx
```
##### =

##### L

##### 3

##### .

For an important application of Proposition 2.1, suppose that _E_ [ _X_ ]and _E_ [ _Y_ ] are
both finite and let _g_ ( _X_ , _Y_ )= _X_ + _Y_. Then, in the continuous case,

```
E [ X + Y ]=
```
```
∫q
```
```
−q
```
```
∫q
```
```
−q
```
```
( x + y ) f ( x , y ) dx dy
```
##### =

```
∫q
```
```
−q
```
```
∫q
```
```
−q
```
```
xf ( x , y ) dy dx +
```
```
∫q
```
```
−q
```
```
∫q
```
```
−q
```
```
yf ( x , y ) dx dy
```
##### =

```
∫q
```
```
−q
```
```
xfX ( x ) dx +
```
```
∫q
```
```
−q
```
```
yfY ( y ) dy
```
```
= E [ X ]+ E [ Y ]
```
The same result holds in general; thus, whenever _E_ [ _X_ ]and _E_ [ _Y_ ] are finite,

```
E [ X + Y ]= E [ X ] + E [ Y ] (2.1)
```
**_EXAMPLE 2b_**

Suppose that, for random variables _X_ and _Y_ ,

```
X Ú Y
```
That is, for any outcome of the probability experiment, the value of the random vari-
able _X_ is greater than or equal to the value of the random variable _Y_. Since _x_ Ú _y_ is
equivalent to the inequality _X_ − _Y_ Ú0, it follows that _E_ [ _X_ − _Y_ ]Ú0, or, equivalently,

```
E [ X ]Ú E [ Y ].
```

**300** Chapter 7 Properties of Expectation

```
Using Equation (2.1), we may show by a simple induction proof that if E [ Xi ]is
finite for all i =1,..., n ,then
```
```
E [ X 1 + ··· + Xn ]= E [ X 1 ]+ ··· + E [ Xn ] (2.2)
```
```
Equation (2.2) is an extremely useful formula whose utility will now be illustrated by
a series of examples.
```
```
EXAMPLE 2c The sample mean
Let X 1 ,..., Xn be independent and identically distributed random variables having
distribution function F and expected valueμ. Such a sequence of random variables is
said to constitute a sample from the distribution F. The quantity
```
##### X =

```
∑ n
```
```
i = 1
```
```
Xi
n
```
```
is called the sample mean. Compute E [ X ].
```
```
Solution.
```
##### E [ X ]= E

##### ⎡

##### ⎣

```
∑ n
```
```
i = 1
```
```
Xi
n
```
##### ⎤

##### ⎦

##### =

##### 1

```
n
```
##### E

##### ⎡

##### ⎣

```
∑ n
```
```
i = 1
```
```
Xi
```
##### ⎤

##### ⎦

##### =

##### 1

```
n
```
```
∑ n
```
```
i = 1
```
```
E [ Xi ]
```
```
=μ since E [ Xi ]Kμ
```
```
That is, the expected value of the sample mean isμ, the mean of the distribution.
When the distribution meanμis unknown, the sample mean is often used in statistics
to estimate it..
```
```
EXAMPLE 2d Boole’s inequality
Let A 1 ,..., An denote events, and define the indicator variables Xi , i =1,..., n ,by
```
```
Xi =
```
##### {

```
1if Ai occurs
0 otherwise
```
```
Let
```
##### X =

```
∑ n
```
```
i = 1
```
```
Xi
```
```
so X denotes the number of the events Ai that occur. Finally, let
```
##### Y =

##### {

```
1if X Ú 1
0 otherwise
```

```
Section 7.2 Expectation of Sums of Random Variables 301
```
so _Y_ is equal to 1 if at least one of the _Ai_ occurs and is 0 otherwise. Now, it is imme-
diate that
_X_ Ú _Y_

so
_E_ [ _X_ ]Ú _E_ [ _Y_ ]

But since

```
E [ X ]=
```
```
∑ n
```
```
i = 1
```
```
E [ Xi ]=
```
```
∑ n
```
```
i = 1
```
```
P ( Ai )
```
and

```
E [ Y ]= P {at least one of the Ai occur}= P
```
##### ⎛

##### ⎝

```
⋃ n
```
```
i = 1
```
```
Ai
```
##### ⎞

##### ⎠

we obtain Boole’s inequality, namely,

##### P

##### ⎛

##### ⎝

```
⋃ n
```
```
i = 1
```
```
Ai
```
##### ⎞

##### ⎠...

```
∑ n
```
```
i = 1
```
```
P ( Ai ).
```
The next three examples show how Equation (2.2) can be used to calculate the
expected value of binomial, negative binomial, and hypergeometric random vari-
ables. These derivations should be compared with those presented in Chapter 4.

**_EXAMPLE 2e Expectation of a binomial random variable_**

Let _X_ be a binomial random variable with parameters _n_ and _p_. Recalling that such
a random variable represents the number of successes in _n_ independent trials when
each trial has probability _p_ of being a success, we have that

```
X = X 1 + X 2 + ··· + Xn
```
where

```
Xi =
```
##### {

```
1ifthe i th trial is a success
0ifthe i th trial is a failure
```
Hence, _Xi_ is a Bernoulli random variable having expectation _E_ [ _Xi_ ]= 1 ( _p_ )+ 0 ( 1 −
_p_ ). Thus,
_E_ [ _X_ ]= _E_ [ _X_ 1 ]+ _E_ [ _X_ 2 ]+ ··· + _E_ [ _Xn_ ]= _np_.

**_EXAMPLE 2f Mean of a negative binomial random variable_**

If independent trials having a constant probability _p_ of being successes are performed,
determine the expected number of trials required to amass a total of _r_ successes.

**_Solution._** If _X_ denotes the number of trials needed to amass a total of _r_ successes,
then _X_ is a negative binomial random variable that can be represented by

```
X = X 1 + X 2 + ··· + Xr
```
where _X_ 1 is the number of trials required to obtain the first success, _X_ 2 the number
of additional trials until the second success is obtained, _X_ 3 the number of additional


**302** Chapter 7 Properties of Expectation

```
trials until the third success is obtained, and so on. That is, Xi represents the num-
ber of additional trials required after the ( i −1)st success until a total of i successes
is amassed. A little thought reveals that each of the random variables Xi is a geo-
metric random variable with parameter p. Hence, from the results of Example 8b of
Chapter 4, E [ Xi ]= 1 / p , i =1, 2,..., r ; thus,
```
```
E [ X ]= E [ X 1 ]+ ··· + E [ Xr ]=
```
```
r
p
```
##### .

```
EXAMPLE 2g Mean of a hypergeometric random variable
If n balls are randomly selected from an urn containing N balls of which m are white,
find the expected number of white balls selected.
```
```
Solution. Let X denote the number of white balls selected, and represent X as
```
```
X = X 1 + ··· + Xm
```
```
where
Xi =
```
##### {

```
1ifthe i th white ball is selected
0 otherwise
```
```
Now
```
```
E [ Xi ]= P { Xi = 1 }
= P { i th white ball is selected}
```
##### =

##### (

##### 1

##### 1

##### )(

##### N − 1

```
n − 1
```
##### )

##### (

##### N

```
n
```
##### )

##### =

```
n
N
Hence,
E [ X ]= E [ X 1 ]+ ··· + E [ Xm ]=
```
```
mn
N
We could also have obtained the preceding result by using the alternative represen-
tation
X = Y 1 + ··· + Yn
```
```
where
Yi =
```
##### {

```
1ifthe i th ball selected is white
0 otherwise
```
```
Since the i th ball selected is equally likely to be any of the N balls, it follows that
```
```
E [ Yi ]=
```
```
m
N
so
E [ X ]= E [ Y 1 ]+ ··· + E [ Yn ]=
```
```
nm
N
```
##### .


```
Section 7.2 Expectation of Sums of Random Variables 303
```
**_EXAMPLE 2h Expected number of matches_**

Suppose that _N_ people throw their hats into the center of a room. The hats are mixed
up, and each person randomly selects one. Find the expected number of people that
select their own hat.

**_Solution._** Letting _X_ denote the number of matches, we can compute _E_ [ _X_ ] most eas-
ily by writing
_X_ = _X_ 1 + _X_ 2 + ··· + _XN_

where

```
Xi =
```
##### {

```
1ifthe i th person selects his own hat
0 otherwise
```
Since, for each _i_ ,the _i_ th person is equally likely to select any of the _N_ hats,

```
E [ Xi ]= P { Xi = 1 }=
```
##### 1

##### N

Thus,

```
E [ X ]= E [ X 1 ]+ ··· + E [ XN ]=
```
##### (

##### 1

##### N

##### )

##### N = 1

Hence, on the average, exactly one person selects his own hat..

**_EXAMPLE 2i Coupon-collecting problems_**

Suppose that there are _N_ different types of coupons, and each time one obtains a
coupon, it is equally likely to be any one of the _N_ types. Find the expected number of
coupons one need amass before obtaining a complete set of at least one of each type.

**_Solution._** Let _X_ denote the number of coupons collected before a complete set is
attained. We compute _E_ [ _X_ ] by using the same technique we used in computing the
mean of a negative binomial random variable (Example 2f). That is, we define _Xi_ , _i_ =
0, 1,..., _N_ −1 to be the number of additional coupons that need be obtained after
_i_ distinct types have been collected in order to obtain another distinct type, and we
note that
_X_ = _X_ 0 + _X_ 1 + ··· + _XN_ − 1

When _i_ distinct types of coupons have already been collected, a new coupon obtained
will be of a distinct type with probability( _N_ − _i_ )/ _N_. Therefore,

```
P { Xi = k }=
```
```
N − i
N
```
##### (

```
i
N
```
```
) k − 1
k Ú 1
```
or, in other words, _Xi_ is a geometric random variable with parameter( _N_ − _i_ )/ _N_.
Hence,
_E_ [ _Xi_ ]=

##### N

```
N − i
```
implying that

##### E [ X ]= 1 +

##### N

##### N − 1

##### +

##### N

##### N − 2

##### + ··· +

##### N

##### 1

##### = N

##### [

##### 1 + ··· +

##### 1

##### N − 1

##### +

##### 1

##### N

##### ]

##### .


**304** Chapter 7 Properties of Expectation

```
EXAMPLE 2j
Ten hunters are waiting for ducks to fly by. When a flock of ducks flies overhead, the
hunters fire at the same time, but each chooses his target at random, independently
of the others. If each hunter independently hits his target with probability p , com-
pute the expected number of ducks that escape unhurt when a flock of size 10 flies
overhead.
```
```
Solution. Let Xi equal 1 if the i th duck escapes unhurt and 0 otherwise, for i =1,
2,..., 10. The expected number of ducks to escape can be expressed as
```
```
E [ X 1 + ··· + X 10 ]= E [ X 1 ]+ ··· + E [ X 10 ]
```
```
To compute E [ Xi ]= P { Xi = 1 }, we note that each of the hunters will, independently,
hit the i th duck with probability p /10, so
```
```
P { Xi = 1 }=
```
##### (

##### 1 −

```
p
10
```
##### ) 10

```
Hence,
```
##### E [ X ]= 10

##### (

##### 1 −

```
p
10
```
##### ) 10

##### .

```
EXAMPLE 2k Expected number of runs
Suppose that a sequence of n 1’s and m 0’s is randomly permuted so that each of the
( n + m )!/( n! m !)possible arrangements is equally likely. Any consecutive string of 1’s
is said to constitute a run of 1’s—for instance, if n =6, m =4, and the ordering is 1,
1, 1, 0, 1, 1, 0, 0, 1, 0, then there are 3 runs of 1’s—and we are interested in computing
the mean number of such runs. To compute this quantity, let
```
```
Ii =
```
##### {

```
1 if a run of 1’s starts at the i th position
0 otherwise
```
```
Therefore, R (1), the number of runs of 1, can be expressed as
```
##### R ( 1 )=

```
n ∑+ m
```
```
i = 1
```
```
Ii
```
```
and it follows that
```
##### E [ R ( 1 )]=

```
n ∑+ m
```
```
i = 1
```
```
E [ Ii ]
```
```
Now,
```
```
E [ I 1 ]= P {“1” in position 1}
```
```
=
```
```
n
n + m
```

```
Section 7.2 Expectation of Sums of Random Variables 305
```
```
and for 1< i ... n + m ,
```
```
E [ Ii ]= P {“0” in position i −1, “1” in position i }
```
```
=
```
```
m
n + m
```
```
n
n + m − 1
```
Hence,

```
E [ R ( 1 )]=
```
```
n
n + m
```
```
+( n + m − 1 )
```
```
nm
( n + m )( n + m − 1 )
```
Similarly, _E_ [ _R_ (0)], the expected number of runs of 0’s, is

```
E [ R ( 0 )]=
```
```
m
n + m
```
##### +

```
nm
n + m
```
and the expected number of runs of either type is

##### E [ R ( 1 )+ R ( 0 )]= 1 +

```
2 nm
n + m
```
##### .

**_EXAMPLE 2l A random walk in the plane_**

Consider a particle initially located at a given point in the plane, and suppose that it
undergoes a sequence of steps of fixed length, but in a completely random direction.
Specifically, suppose that the new position after each step is one unit of distance from
the previous position and at an angle of orientation from the previous position that is
uniformly distributed over (0, 2π). (See Figure 7.1.) Compute the expected square of
the distance from the origin after _n_ steps.

```
1
```
```

```
```
2
```
```
0 1
```
```
1
```
```
 2
```
```
1
```
```
0 = initial position
1 = position after first step
2 = position after second step
```
```
FIGURE 7.1
```
**_Solution._** Letting ( _Xi_ , _Yi_ ) denote the change in position at the _i_ th step, _i_ =1,..., _n_ ,
in rectangular coordinates, we have

```
Xi =cosθ i
Yi =sinθ i
```

**306** Chapter 7 Properties of Expectation

```
whereθ i , i =1,..., n , are, by assumption, independent uniform (0, 2π) random vari-
```
```
ables. Because the position after n steps has rectangular coordinates
```
##### (

```
∑ n
i = 1
```
```
Xi ,
```
```
∑ n
i = 1
```
```
Yi
```
##### )

##### ,

```
it follows that D^2 , the square of the distance from the origin, is given by
```
##### D^2 =

##### ⎛

##### ⎝

```
∑ n
```
```
i = 1
```
```
Xi
```
##### ⎞

##### ⎠

```
2
```
```
+
```
##### ⎛

##### ⎝

```
∑ n
```
```
i = 1
```
```
Yi
```
##### ⎞

##### ⎠

```
2
```
##### =

```
∑ n
```
```
i = 1
```
```
( Xi^2 + Yi^2 )+
```
##### ∑∑

```
i Z j
```
```
( XiXj + YiYj )
```
```
= n +
```
##### ∑∑

```
i Z j
```
```
(cosθ i cosθ j +sinθ i sinθ j )
```
```
where cos^2 θ i +sin^2 θ i =1. Taking expectations and using the independence ofθ i and
θ j when i Z j and the fact that
```
```
2 π E [cosθ i ]=
```
```
∫ 2 π
```
```
0
```
```
cos udu =sin 2π −sin 0= 0
```
```
2 π E [sinθ i ]=
```
```
∫ 2 π
```
```
0
```
```
sin udu =cos 0−cos 2π= 0
```
```
we arrive at
E [ D^2 ]= n.
```
```
EXAMPLE 2m Analyzing the quick-sort algorithm
Suppose that we are presented with a set of n distinct values x 1 , x 2 ,..., xn and that
we desire to put them in increasing order, or as it is commonly stated, to sort them.
An efficient procedure for accomplishing this task is the quick-sort algorithm, which
is defined as follows. When n =2, the algorithm compares the two values and then
puts them in the appropriate order. When n > 2, one of the elements is randomly
chosen—say it is xi —and then all of the other values are compared with xi. Those
smaller than xi are put in a bracket to the left of xi and those larger than xi are put
in a bracket to the right of xi. The algorithm then repeats itself on these brackets and
continues until all values have been sorted. For instance, suppose that we desire to
sort the following 10 distinct values:
```
```
5, 9, 3, 10, 11, 14, 8, 4, 17, 6
```
```
We start by choosing one of them at random (that is, each value has probability 101 of
being chosen). Suppose, for instance, that the value 10 is chosen. We then compare
each of the others to this value, putting in a bracket to the left of 10 all those values
smaller than 10 and to the right all those larger. This gives
```
```
{5, 9, 3, 8, 4, 6}, 10,{11, 14, 17}
```
```
We now focus on a bracketed set that contains more than a single value—say the one
on the left of the preceding—and randomly choose one of its values—say that 6 is
chosen. Comparing each of the values in the bracket with 6 and putting the smaller
```

```
Section 7.2 Expectation of Sums of Random Variables 307
```
ones in a new bracket to the left of 6 and the larger ones in a bracket to the right
of 6 gives
{5, 3, 4},6,{9, 8}, 10,{11, 14, 17}

If we now consider the leftmost bracket, and randomly choose the value 4 for com-
parison then the next iteration yields

```
{ 3 },4,{ 5 },6,{9, 8}, 10,{11, 14, 17}
```
This continues until there is no bracketed set that contains more than a single value.
If we let _X_ denote the number of comparisons that it takes the quick-sort algorithm
to sort _n_ distinct numbers, then _E_ [ _X_ ] is a measure of the effectiveness of this algo-
rithm. To compute _E_ [ _X_ ], we will first express _X_ as a sum of other random variables
as follows. To begin, give the following names to the values that are to be sorted:
Let 1 stand for the smallest, let 2 stand for the next smallest, and so on. Then, for
1 ... _i_ < _j_ ... _n_ , let _I_ ( _i_ , _j_ )equal 1 if _i_ and _j_ are ever directly compared, and let it equal
0 otherwise. With this definition, it follows that

##### X =

```
n ∑− 1
```
```
i = 1
```
```
∑ n
```
```
j = i + 1
```
```
I ( i , j )
```
implying that

##### E [ X ]= E

##### ⎡

##### ⎢

##### ⎣

```
n ∑− 1
```
```
i = 1
```
```
∑ n
```
```
j = i + 1
```
```
I ( i , j )
```
##### ⎤

##### ⎥

##### ⎦

##### =

```
n ∑− 1
```
```
i = 1
```
```
∑ n
```
```
j = i + 1
```
```
E [ I ( i , j )]
```
##### =

```
n ∑− 1
```
```
i = 1
```
```
∑ n
```
```
j = i + 1
```
```
P { i and j are ever compared}
```
To determine the probability that _i_ and _j_ are ever compared, note that the values
_i_ , _i_ +1,..., _j_ −1, _j_ will initially be in the same bracket (since all values are initially
in the same bracket) and will remain in the same bracket if the number chosen for
the first comparison is not between _i_ and _j_. For instance, if the comparison number is
larger than _j_ , then all the values _i_ , _i_ +1,..., _j_ −1, _j_ will go in a bracket to the left of
the comparison number, and if it is smaller than _i_ , then they will all go in a bracket
to the right. Thus all the values _i_ , _i_ +1,..., _j_ −1, _j_ will remain in the same bracket
until the first time that one of them is chosen as a comparison value. At that point all
the other values between _i_ and _j_ will be compared with this comparison value. Now,
if this comparison value is neither _i_ nor _j_ , then upon comparison with it, _i_ will go into
a left bracket and _j_ into a right bracket, and thus _i_ and _j_ will be in different brackets
and so will never be compared. On the other hand, if the comparison value of the set
_i_ , _i_ +1,..., _j_ − 1, _j_ is either _i_ or _j_ , then there will be a direct comparison between
_i_ and _j_. Now, given that the comparison value is one of the values between _i_ and _j_ ,
it follows that it is equally likely to be any of these _j_ − _i_ + 1 values, and thus the
probability that it is either _i_ or _j_ is 2/( _j_ − _i_ +1). Therefore, we can conclude that

```
P { i and j are ever compared}=
```
##### 2

```
j − i + 1
```

**308** Chapter 7 Properties of Expectation

```
and
```
##### E [ X ]=

```
n ∑− 1
```
```
i = 1
```
```
∑ n
```
```
j = i + 1
```
##### 2

```
j − i + 1
```
```
To obtain a rough approximation of the magnitude of E [ X ] when n is large, we can
approximate the sums by integrals. Now
```
```
∑ n
```
```
j = i + 1
```
##### 2

```
j − i + 1
```
##### L

```
∫ n
```
```
i + 1
```
##### 2

```
x − i + 1
```
```
dx
```
```
=2log( x − i + 1 )
```
##### ∣

```
∣ n
i + 1
=2log( n − i + 1 )−2log( 2 )
L2log( n − i + 1 )
```
```
Thus
```
##### E [ X ]L

```
n ∑− 1
```
```
i = 1
```
```
2log( n − i + 1 )
```
##### L 2

```
∫ n − 1
```
```
1
```
```
log( n − x + 1 ) dx
```
##### = 2

```
∫ n
```
```
2
```
```
log( y ) dy
```
```
= 2 ( y log( y )− y )| n 2
L 2 n log( n )
```
```
Thus we see that when n is large, the quick-sort algorithm requires, on average,
approximately 2 n log( n )comparisons to sort n distinct values..
```
```
EXAMPLE 2n The probability of a union of events
Let A 1 ,... An denote events, and define the indicator variables Xi , i =1,..., n ,by
```
```
Xi =
```
##### {

```
1if Ai occurs
0 otherwise
```
```
Now, note that
```
##### 1 −

```
∏ n
```
```
i = 1
```
```
( 1 − Xi )=
```
##### {

```
1if∪ Ai occurs
0 otherwise
```
```
Hence,
```
##### E

##### ⎡

##### ⎣ 1 −

```
∏ n
```
```
i = 1
```
```
( 1 − Xi )
```
##### ⎤

##### ⎦= P

##### ⎛

##### ⎝

```
⋃ n
```
```
i = 1
```
```
Ai
```
##### ⎞

##### ⎠


```
Section 7.2 Expectation of Sums of Random Variables 309
```
```
Expanding the left side of the preceding formula yields
```
##### P

##### ⎛

##### ⎝

```
⋃ n
```
```
i = 1
```
```
Ai
```
##### ⎞

##### ⎠= E

##### ⎡

##### ⎢

##### ⎣

```
∑ n
```
```
i = 1
```
```
Xi −
```
##### ∑∑

```
i < j
```
```
XiXj +
```
##### ∑∑∑

```
i < j < k
```
```
XiXjXk
```
```
−··· +(− 1 ) n +^1 X 1 ··· Xn
```
##### ⎤

##### ⎦ (2.3)

However,

```
Xi 1 Xi 2 ··· Xik =
```
##### {

```
1if Ai 1 Ai 2 ··· Aik occurs
0 otherwise
```
so
_E_ [ _Xi_ 1 ··· _Xik_ ]= _P_ ( _Ai_ 1 ··· _Aik_ )

Thus, Equation (2.3) is just a statement of the well-known formula for the union of
events:

```
P (∪ Ai )=
```
##### ∑

```
i
```
```
P ( Ai )−
```
##### ∑∑

```
i < j
```
```
P ( AiAj )+
```
##### ∑∑∑

```
i < j < k
```
```
P ( AiAjAk )
```
```
− ··· +(− 1 ) n +^1 P ( A 1 ··· An ).
```
When one is dealing with an infinite collection of random variables _Xi_ , _i_ Ú1, each
having a finite expectation, it is not necessarily true that

##### E

##### ⎡

##### ⎣

```
∑q
```
```
i = 1
```
```
Xi
```
##### ⎤

##### ⎦=

```
∑q
```
```
i = 1
```
```
E [ Xi ] (2.4)
```
To determine when (2.4) is valid, we note that

```
∑q
i = 1
```
```
Xi = lim
n →q
```
```
∑ n
i = 1
```
```
Xi. Thus,
```
##### E

##### ⎡

##### ⎣

```
∑q
```
```
i = 1
```
```
Xi
```
##### ⎤

##### ⎦= E

##### ⎡

```
⎣lim
n →q
```
```
∑ n
```
```
i = 1
```
```
Xi
```
##### ⎤

##### ⎦

```
?
= lim
n →q
```
##### E

##### ⎡

##### ⎣

```
∑ n
```
```
i = 1
```
```
Xi
```
##### ⎤

##### ⎦

```
= lim
n →q
```
```
∑ n
```
```
i = 1
```
```
E [ Xi ]
```
##### =

```
∑q
```
```
i = 1
```
```
E [ Xi ] (2.5)
```
Hence, Equation (2.4) is valid whenever we are justified in interchanging the expec-
tation and limit operations in Equation (2.5). Although, in general, this interchange
is _not_ justified, it can be shown to be valid in two important special cases:

1. The _Xi_ are all nonnegative random variables. (That is, _P_ { _Xi_ Ú 0 }=1 for all _i_ .)

```
2.
```
```
∑q
i = 1
```
```
E [| Xi |] <q.
```

**310** Chapter 7 Properties of Expectation

```
EXAMPLE 2o
Consider any nonnegative, integer-valued random variable X. If, for each i Ú1, we
define
Xi =
```
##### {

```
1if X Ú i
0if X < i
```
```
then
```
```
∑q
```
```
i = 1
```
```
Xi =
```
##### ∑ X

```
i = 1
```
```
Xi +
```
```
∑q
```
```
i = X + 1
```
```
Xi
```
##### =

##### ∑ X

```
i = 1
```
##### 1 +

```
∑q
```
```
i = X + 1
```
##### 0

##### = X

```
Hence, since the Xi are all nonnegative, we obtain
```
##### E [ X ]=

```
∑q
```
```
i = 1
```
```
E ( Xi )
```
##### =

```
∑q
```
```
i = 1
```
```
P { X Ú i } (2.6)
```
```
a useful identity..
```
```
EXAMPLE 2p
Suppose that n elements—call them 1, 2,..., n —must be stored in a computer in the
form of an ordered list. Each unit of time, a request will be made for one of these
elements—∑ i being requested, independently of the past, with probability P ( i ), i Ú1,
```
```
i
```
```
P ( i )=1. Assuming that these probabilities are known, what ordering minimizes
```
```
the average position in the line of the element requested?
```
```
Solution. Suppose that the elements are numbered so that P ( 1 )Ú P ( 2 )Ú···Ú P ( n ).
To show that 1, 2,..., n is the optimal ordering, let X denote the position of the
requested element. Now, under any ordering—say, O = i 1 , i 2 ,..., in ,
```
```
PO { X Ú k }=
```
```
∑ n
```
```
j = k
```
```
P ( ij )
```
##### Ú

```
∑ n
```
```
j = k
```
```
P ( j )
```
```
= P 1,2,..., n { X Ú k }
```
```
Summing over k and using Equation (2.6) yields
```
```
Eo [ X ]Ú E 1,2,..., n [ X ]
```
```
thus showing that ordering the elements in decreasing order of the probability that
they are requested minimizes the expected position of the element requested..
```

```
Section 7.2 Expectation of Sums of Random Variables 311
```
∗ **7.2.1 Obtaining Bounds from Expectations via the Probabilistic Method**

The probabilistic method is a technique for analyzing the properties of the elements
of a set by introducing probabilities on the set and then studying an element chosen
according to those probabilities. The technique was previously seen in Example 4l of
Chapter 3, where it was used to show that a set contained an element that satisfied a
certain property. In this subsection, we show how it can sometimes be used to bound
complicated functions.
Let _f_ be a function on the elements of a finite setS, and suppose that we are
interested in
_m_ =max
_s_ ∈S

```
f ( s )
```
A useful lower bound for _m_ can often be obtained by letting _S_ be a random element
ofSfor which the expected value of _f_ ( _S_ )is computable and then noting that _m_ Ú _f_ ( _S_ )
implies that

```
m Ú E [ f ( S )]
```
with strict inequality if _f_ ( _S_ )is not a constant random variable. That is, _E_ [ _f_ ( _S_ )]isa
lower bound on the maximum value.

**_EXAMPLE 2q The maximum number of Hamiltonian paths in a tournament_**

A round-robin tournament of( _n_ >2 contestants is a tournament in which each of the
_n_
2

##### )

```
pair of contestants play each other exactly once. Suppose that the players are
```
numbered 1, 2, 3,..., _n_. The permutation _i_ 1 , _i_ 2 ,... _in_ is said to be a _Hamiltonian path_ if
_i_ 1 beats _i_ 2 , _i_ 2 beats _i_ 3 ,...,and _in_ − 1 beats _in_. A problem of some interest is to determine
the largest possible number of Hamiltonian paths.
As an illustration, suppose that there are 3 players. On the one hand, one of them
wins twice, then there is a single Hamiltonian path. (For instance, if 1 wins twice and
2 beats 3, then the only Hamiltonian path is 1, 2, 3.) On the other hand, if each of
the players wins once, than there are 3 Hamiltonian paths. (For instance, if 1 beats 2,
2 beats 3, and 3 beats 1, then 1, 2, 3; 2, 3, 1; and 3, 1, 2, are all Hamiltonians). Hence,
when _n_ =3, there is a maximum of 3 Hamiltonian paths.
We now show that there is an outcome of the tournament that results in more than
_n_ !/ 2 _n_ −^1 Hamiltonian paths. To begin, let the outcome of the tournament specify the

result of each of the

##### (

```
n
2
```
##### )

```
games played, and letSdenote the set of all 2
```
```
(
n
2
```
```
)
```
```
possible
```
tournament outcomes. Then, with _f_ ( _s_ )defined as the number of Hamiltonian paths
that result when the outcome is _s_ ∈S, we are asked to show that

```
max
s
```
```
f ( s )Ú
```
```
n!
2 n −^1
```
To show this, consider the randomly chosen outcome _S_ that is obtained when the

results of the

##### (

```
n
2
```
##### )

```
games are independent, with each contestant being equally likely
```
to win each encounter. To determine _E_ [ _f_ ( _S_ )], the expected number of Hamiltonian
paths that result from the outcome _S_ , number the _n_! permutations, and, for _i_ =
1,..., _n_ !, let

```
Xi =
```
##### {

```
1, if permutation i is a Hamiltonian
0, otherwise
```

**312** Chapter 7 Properties of Expectation

```
Since
f ( S )=
```
##### ∑

```
i
```
```
Xi
```
```
it follows that
E [ f ( S )]=
```
##### ∑

```
i
```
```
E [ Xi ]
```
```
Because, by the assumed independence of the outcomes of the games, the probability
that any specified permutation is a Hamiltonian is( 1 / 2 ) n −^1 , it follows that
```
```
E [ Xi ]= P { Xi = 1 }=( 1 / 2 ) n −^1
```
```
Therefore,
E [ f ( S )]= n !( 1 / 2 ) n −^1
```
```
Since f ( S )is not a constant random variable, the preceding equation implies that
there is an outcome of the tournament having more than n !/ 2 n −^1 Hamiltonian
paths..
```
```
EXAMPLE 2r
A grove of 52 trees is arranged in a circular fashion. If 15 chipmunks live in these
trees, show that there is a group of 7 consecutive trees that together house at least 3
chipmunks.
```
```
Solution. Let the neighborhood of a tree consist of that tree along with the next six
trees visited by moving in the clockwise direction. We want to show that, for any
choice of living accommodations of the 15 chipmunks, there is a tree that has at least
3 chipmunks living in its neighborhood. To show this, choose a tree at random and
let X denote the number of chipmunks that live in its neighborhood. To determine
E [ X ], arbitrarily number the 15 chipmunks and for i =1,..., 15, let
```
```
Xi =
```
##### {

```
1, if chipmunk i lives in the neighborhood of the randomly chosen tree
0, otherwise
```
```
Because
```
```
X =
```
##### ∑^15

```
i = 1
```
```
Xi
```
```
we obtain that
E [ X ]=
```
##### ∑^15

```
i = 1
```
```
E [ Xi ]
```
```
However, because Xi will equal 1 if the randomly chosen tree is any of the 7 trees
consisting of the tree in which chipmunk i lives along with its 6 neighboring trees
when moving in the counterclockwise direction,
```
```
E [ Xi ]= P { Xi = 1 }=
```
##### 7

##### 52

```
Consequently,
E [ X ]=
```
##### 105

##### 52

##### > 2

```
showing that there exists a tree with more than 2 chipmunks living in its neigh-
borhood..
```

```
Section 7.2 Expectation of Sums of Random Variables 313
```
∗ **7.2.2 The Maximum–Minimums Identity**

We start with an identity relating the maximum of a set of numbers to the minimums
of the subsets of these numbers.

**Proposition 2.2.** For arbitrary numbers _xi_ , _i_ =1,..., _n_ ,

```
max
i
```
```
xi =
```
##### ∑

```
i
```
```
xi −
```
##### ∑

```
i < j
```
```
min( xi , xj )+
```
##### ∑

```
i < j < k
```
```
min( xi , xj , xk )
```
```
+...+(− 1 ) n +^1 min( x 1 ,..., xn )
```
```
Proof. We will give a probabilistic proof of the proposition. To begin, assume that
all the xi are in the interval [0, 1]. Let U be a uniform (0, 1) random variable, and
define the events Ai , i =1,..., n ,by Ai ={ U < xi }. That is, Ai is the event that
the uniform random variable is less than xi. Because at least one of these events Ai
will occur if U is less than at least one of the values xi , we have that
```
```
∪ iAi =
```
##### {

```
U <max
i
```
```
xi
```
##### }

```
Therefore,
P (∪ iAi )= P
```
##### {

```
U <max
i
```
```
xi
```
##### }

```
=max
i
```
```
xi
```
```
Also,
P ( Ai )= P
```
##### {

```
U < xi
```
##### }

```
= xi
```
```
In addition, because all of the events Ai 1 ,..., Air will occur if U is less than all the
values xi 1 ,..., xir , we see that the intersection of these events is
```
```
Ai 1 ... Air =
```
##### {

```
U < min
j =1,... r
```
```
xij
```
##### }

```
implying that
```
```
P ( Ai 1 ... Air )= P
```
##### {

```
U < min
j =1,... r
```
```
xij
```
##### }

```
= min
j =1,... r
```
```
xij
```
```
Thus, the proposition follows from the inclusion–exclusion formula for the proba-
bility of the union of events:
```
```
P (∪ iAi )=
```
##### ∑

```
i
```
```
P ( Ai )−
```
##### ∑

```
i < j
```
```
P ( AiAj )+
```
##### ∑

```
i < j < k
```
```
P ( AiAjAk )
```
```
+...+(− 1 ) n +^1 P ( A 1 ... An )
```
```
When the xi are nonnegative, but not restricted to the unit interval, let c be such
that all the xi are less than c. Then the identity holds for the values yi = xi / c ,and
the desired result follows by multiplying through by c. When the xi can be negative,
let b be such that xi + b >0 for all i. Therefore, by the preceding,
```
```
max
i
```
```
( xi + b )=
```
##### ∑

```
i
```
```
( xi + b )−
```
##### ∑

```
i < j
```
```
min( xi + b , xj + b )
```
```
+ ··· +(− 1 ) n +^1 min( x 1 + b ,..., xn + b )
```

**314** Chapter 7 Properties of Expectation

```
Letting
```
```
M =
```
##### ∑

```
i
```
```
xi −
```
##### ∑

```
i < j
```
```
min( xi , xj )+ ··· +(− 1 ) n +^1 min( x 1 ,..., xn )
```
```
we can rewrite the foregoing identity as
```
```
max
i
```
```
xi + b = M + b
```
##### (

```
n −
```
##### (

```
n
2
```
##### )

```
+ ··· +(− 1 ) n +^1
```
##### (

```
n
n
```
##### ))

```
But
0 =( 1 − 1 ) n = 1 − n +
```
##### (

```
n
2
```
##### )

```
+ ··· +(− 1 ) n
```
##### (

```
n
n
```
##### )

```
The preceding two equations show that
```
```
max
i
```
```
xi = M
```
```
and the proposition is proven.
```
```
It follows from Proposition 2.2 that, for any random variables X 1 ,..., Xn ,
```
```
max
i
```
```
Xi =
```
##### ∑

```
i
```
```
Xi −
```
##### ∑

```
i < j
```
```
min( Xi , Xj )+ ··· +(− 1 ) n +^1 min( X 1 ,..., Xn )
```
```
Taking expectations of both sides of this equality yields the following relationship
between the expected value of the maximum and those of the partial minimums:
```
##### E

##### [

```
max
i
```
```
Xi
```
##### ]

##### =

##### ∑

```
i
```
```
E [ Xi ]−
```
##### ∑

```
i < j
```
```
E [min( Xi , Xj )]
```
```
+ ··· +(− 1 ) n +^1 E [min( X 1 ,..., Xn )] (2.7)
```
```
EXAMPLE 2s Coupon collecting with unequal probabilities
Suppose there are n different types of coupons and that each time one collects a
coupon, it is, independently of previous coupons collected, a type i coupon with prob-
ability pi ,
```
```
∑ n
i = 1
```
```
pi =1. Find the expected number of coupons one needs to collect to
```
```
obtain a complete set of at least one of each type.
```
```
Solution. If we let Xi denote the number of coupons one needs collect to obtain a
type i , then we can express X as
```
```
X = max
i =1,..., n
```
```
Xi
```
```
Because each new coupon obtained is a type i with probability pi , Xi is a geometric
random variable with parameter pi. Also, because the minimum of Xi and Xj is the
number of coupons needed to obtain either a type i or a type j , it follows that, for
i Z j ,min( Xi , Xj ) is a geometric random variable with parameter pi + pj. Similarly,
min ( Xi , Xj , Xk ), the number needed to obtain any of types i , j ,and k , is a geometric
```

```
Section 7.3 Moments of the Number of Events that Occur 315
```
```
random variable with parameter pi + pj + pk , and so on. Therefore, the identity (2.7)
yields
```
##### E [ X ]=

##### ∑

```
i
```
##### 1

```
pi
```
##### −

##### ∑

```
i < j
```
##### 1

```
pi + pj
```
##### +

##### ∑

```
i < j < k
```
##### 1

```
pi + pj + pk
```
```
+ ··· +(− 1 ) n +^1
```
##### 1

```
p 1 + ··· + pn
```
```
Noting that
∫q
```
```
0
```
```
e − pxdx =
```
##### 1

```
p
```
```
and using the identity
```
##### 1 −

```
∏ n
```
```
i = 1
```
```
( 1 − e − pix )=
```
##### ∑

```
i
```
```
e − pix −
```
##### ∑

```
i < j
```
```
e −( pi + pj ) x + ··· +(− 1 ) n +^1 e −( p^1 +···+ pn ) x
```
```
shows, upon integrating the identity, that
```
##### E [ X ]=

```
∫q
```
```
0
```
##### ⎛

##### ⎝ 1 −

```
∏ n
```
```
i = 1
```
```
( 1 − e − pix )
```
##### ⎞

```
⎠ dx
```
```
is a more useful computational form..
```
### 7.3 Moments of the Number of Events that Occur

```
Many of the examples solved in the previous section were of the following form: For
given events A 1 ,..., An , find E [ X ], where X is the number of these events that occur.
The solution then involved defining an indicator variable Ii for event Ai such that
```
```
Ii =
```
##### {

```
1, if Ai occurs
0, otherwise
```
```
Because
```
```
X =
```
```
∑ n
```
```
i = 1
```
```
Ii
```
```
we obtained the result
```
##### E [ X ]= E

##### ⎡

##### ⎣

```
∑ n
```
```
i = 1
```
```
Ii
```
##### ⎤

##### ⎦=

```
∑ n
```
```
i = 1
```
```
E [ Ii ]=
```
```
∑ n
```
```
i = 1
```
```
P ( Ai ) (3.1)
```
```
Now suppose we are interested in the number of pairs of events that occur.
Because IiIj will equal 1 if both Ai and Aj occur, and will equal 0 otherwise, it fol-
lows that the number of pairs is equal to
```
##### ∑

```
i < jIiIj .But because X is the number of
events that occur, it also follows that the number of pairs of events that occur is
```
##### ( X

```
2
```
##### )

##### .

```
Consequently, (
X
2
```
##### )

##### =

##### ∑

```
i < j
```
```
IiIj
```

**316** Chapter 7 Properties of Expectation

```
where there are
```
```
( n
2
```
##### )

```
terms in the summation. Taking expectations yields
```
##### E

##### [(

##### X

##### 2

##### )]

##### =

##### ∑

```
i < j
```
```
E [ IiIj ]=
```
##### ∑

```
i < j
```
```
P ( AiAj ) (3.2)
```
```
or
E
```
##### [

##### X ( X − 1 )

##### 2

##### ]

##### =

##### ∑

```
i < j
```
```
P ( AiAj )
```
```
giving that
E [ X^2 ]− E [ X ]= 2
```
##### ∑

```
i < j
```
```
P ( AiAj ) (3.3)
```
```
which yields E [ X^2 ], and thus Var( X )= E [ X^2 ]−( E [ X ])^2.
Moreover, by considering the number of distinct subsets of k events that all occur,
we see that (
X
k
```
##### )

##### =

##### ∑

```
i 1 < i 2 <...< ik
```
```
Ii 1 Ii 2 ··· Iik
```
```
Taking expectations gives the identity
```
##### E

##### [(

##### X

```
k
```
##### )]

##### =

##### ∑

```
i 1 < i 2 <...< ik
```
```
E [ Ii 1 Ii 2 ··· Iik ]=
```
##### ∑

```
i 1 < i 2 <...< ik
```
```
P ( Ai 1 Ai 2 ··· Aik ) (3.4)
```
```
EXAMPLE 3a Moments of binomial random variables
Consider n independent trials, with each trial being a success with probability p .Let
Ai be the event that trial i is a success. When i Z j , P ( AiAj )= p^2. Consequently,
Equation (3.2) yields
```
```
E
```
##### [(

##### X

##### 2

##### )]

##### =

##### ∑

```
i < j
```
```
p^2 =
```
##### (

```
n
2
```
##### )

```
p^2
```
```
or
E [ X ( X − 1 )]= n ( n − 1 ) p^2
```
```
or
E [ X^2 ]− E [ X ]= n ( n − 1 ) p^2
```
```
Now, E [ X ]=
```
```
∑ n
i = 1 P ( Ai )= np , so, from the preceding equation
```
```
Var( X )= E [ X^2 ]−( E [ X ])^2 = n ( n − 1 ) p^2 + np −( np )^2 = np ( 1 − p )
```
```
which is in agreement with the result obtained in Section 4.6.1.
In general, because P ( Ai 1 Ai 2 ··· Aik )= pk , we obtain from Equation( 3. 4 )that
```
##### E

##### [(

##### X

```
k
```
##### )]

##### =

##### ∑

```
i 1 < i 2 <...< ik
```
```
pk =
```
##### (

```
n
k
```
##### )

```
pk
```
```
or, equivalently,
```
```
E [ X ( X − 1 )···( X − k + 1 )]= n ( n − 1 )···( n − k + 1 ) pk
```

```
Section 7.3 Moments of the Number of Events that Occur 317
```
The successive values _E_ [ _Xk_ ], _k_ Ú3, can be recursively obtained from this identity.
For instance, with _k_ =3, it yields

```
E [ X ( X − 1 )( X − 2 )]= n ( n − 1 )( n − 2 ) p^3
```
or

```
E [ X^3 − 3 X^2 + 2 X ]= n ( n − 1 )( n − 2 ) p^3
```
or

```
E [ X^3 ]= 3 E [ X^2 ]− 2 E [ X ]+ n ( n − 1 )( n − 2 ) p^3
= 3 n ( n − 1 ) p^2 + np + n ( n − 1 )( n − 2 ) p^3.
```
**_EXAMPLE 3b Moments of hypergeometric random variables_**

Suppose _n_ balls are randomly selected from an urn containing _N_ balls, of which _m_
are white. Let _Ai_ be the event that the _i_ th ball selected is white. Then _X_ , the number
of white balls selected, is equal to the number of the events _A_ 1 ,..., _An_ that occur.
Because the _i_ th ball selected is equally likely to be any of the _N_ balls, of which _m_ are
white, _P_ ( _Ai_ )= _m_ / _N_ .Consequently, Equation( 3. 1 )gives that _E_ [ _X_ ]=

∑ _n
i_ = 1 _P_ ( _Ai_ )=
_nm_ / _N_. Also, since

```
P ( AiAj )= P ( Ai ) P ( Aj | Ai )=
```
```
m
N
```
```
m − 1
N − 1
```
we obtain, from Equation( 3. 2 ),that

##### E

##### [(

##### X

##### 2

##### )]

##### =

##### ∑

```
i < j
```
```
m ( m − 1 )
N ( N − 1 )
```
##### =

##### (

```
n
2
```
##### )

```
m ( m − 1 )
N ( N − 1 )
```
or

```
E [ X ( X − 1 )]= n ( n − 1 )
```
```
m ( m − 1 )
N ( N − 1 )
```
showing that

```
E [ X^2 ]= n ( n − 1 )
```
```
m ( m − 1 )
N ( N − 1 )
```
##### + E [ X ]

This formula yields the variance of the hypergeometric, namely,

```
Var( X )= E [ X^2 ]−( E [ X ])^2
```
```
= n ( n − 1 )
```
```
m ( m − 1 )
N ( N − 1 )
```
##### +

```
nm
N
```
##### −

```
n^2 m^2
N^2
```
```
=
```
```
mn
N
```
##### [

```
( n − 1 )( m − 1 )
N − 1
```
##### + 1 −

```
mn
N
```
##### ]

which agrees with the result obtained in Example 8j of Chapter 4.
Higher moments of _X_ are obtained by using Equation (3.4). Because

```
P ( Ai 1 Ai 2 ··· Aik )=
```
```
m ( m − 1 )···( m − k + 1 )
N ( N − 1 )···( N − k + 1 )
```

**318** Chapter 7 Properties of Expectation

```
Equation (3.4) yields
```
##### E

##### [(

##### X

```
k
```
##### )]

##### =

##### (

```
n
k
```
##### )

```
m ( m − 1 )···( m − k + 1 )
N ( N − 1 )···( N − k + 1 )
```
```
or
```
```
E [ X ( X − 1 )···( X − k + 1 )]
```
```
= n ( n − 1 )···( n − k + 1 )
```
```
m ( m − 1 )···( m − k + 1 )
N ( N − 1 )···( N − k + 1 )
```
##### .

```
EXAMPLE 3c Moments in the match problem
For i =1,..., N , let Ai be the event that person i selects his or her own hat in the
match problem. Then
```
```
P ( AiAj )= P ( Ai ) P ( Aj | Ai )=
```
##### 1

##### N

##### 1

##### N − 1

```
which follows because, conditional on person i selecting her own hat, the hat selected
by person j is equally likely to be any of the other N −1 hats, of which one is his
own. Consequently, with X equal to the number of people who select their own hat,
it follows from Equation (3.2) that
```
##### E

##### [(

##### X

##### 2

##### )]

##### =

##### ∑

```
i < j
```
##### 1

##### N ( N − 1

##### =

##### (

##### N

##### 2

##### )

##### 1

##### N ( N − 1 )

```
thus showing that
E [ X ( X − 1 )]= 1
```
```
Therefore, E [ X^2 ]= 1 + E [ X ]. Because E [ X ]=
```
##### ∑ N

```
i = 1 P ( Ai )=1, we obtain that
```
```
Var( X )= E [ X^2 ]−( E [ X ])^2 = 1.
```
```
Hence, both the mean and variance of the number of matches is 1. For higher moments,
we use Equation (3.4), along with the fact that P ( Ai 1 Ai 2 ··· Aik )= N ( N − 1 )···^1 ( N − k + 1 ),
to obtain
```
```
E
```
##### [(

##### X

```
k
```
##### )]

##### =

##### (

##### N

```
k
```
##### )

##### 1

```
N ( N − 1 )···( N − k + 1 )
```
```
or
E [ X ( X − 1 )···( X − k + 1 )]= 1.
```
```
EXAMPLE 3d Another coupon-collecting problem
Suppose that there are N distinct types of coupons and that, independently of past
types collected, each new one obtained is type j with probability pj ,
```
##### ∑ N

```
j = 1 pj =1. Find
the expected value and variance of the number of different types of coupons that
appear among the first n collected.
```
```
Solution. We will find it more convenient to work with the number of uncollected
types. So, let Y equal the number of different types of coupons collected, and let
X = N − Y denote the number of uncollected types. With Ai defined as the event
that there are no type i coupons in the collection, X is equal to the number of the
```

```
Section 7.3 Moments of the Number of Events that Occur 319
```
events _A_ 1 ,..., _AN_ that occur. Because the types of the successive coupons collected
are independent, and, with probability 1− _pi_ each new coupon is not type _i_ , we have

```
P ( Ai )=( 1 − pi ) n
```
Hence, _E_ [ _X_ ]=

##### ∑ N

```
i = 1 (^1 − pi )
n , from which it follows that
```
##### E [ Y ]= N − E [ X ]= N −

##### ∑ N

```
i = 1
```
```
( 1 − pi ) n
```
Similarly, because each of the _n_ coupons collected is neither a type _i_ nor a type _j_
coupon, with probability 1− _pi_ − _pj_ , we have

```
P ( AiAj )=( 1 − pi − pj ) n , i Z j
```
Thus,
_E_ [ _X_ ( _X_ − 1 )]= 2

##### ∑

```
i < j
```
```
P ( AiAj )= 2
```
##### ∑

```
i < j
```
```
( 1 − pi − pj ) n
```
or
_E_ [ _X_^2 ]= 2

##### ∑

```
i < j
```
```
( 1 − pi − pj ) n + E [ X ]
```
Hence, we obtain

```
Var( Y )=Var( X )
= E [ X^2 ]−( E [ X ])^2
```
##### = 2

##### ∑

```
i < j
```
```
( 1 − pi − pj ) n +
```
##### ∑ N

```
i = 1
```
```
( 1 − pi ) n −
```
##### ⎛

##### ⎝

##### ∑ N

```
i = 1
```
```
( 1 − pi ) n
```
##### ⎞

##### ⎠

```
2
```
In the special case where _pi_ = 1 / _N_ , _i_ =1,..., _N_ , the preceding formula gives

##### E [ Y ]= N

##### [

##### 1 −

##### (

##### 1 −

##### 1

##### N

```
) n ]
```
and

```
Var( Y )= N ( N − 1 )
```
##### (

##### 1 −

##### 2

##### N

```
) n
+ N
```
##### (

##### 1 −

##### 1

##### N

```
) n
− N^2
```
##### (

##### 1 −

##### 1

##### N

```
) 2 n
.
```
**_EXAMPLE 3e The negative hypergeometric random variables_**

Suppose an urn contains _n_ + _m_ balls, of which _n_ are special and _m_ are ordinary. These
items are removed one at a time, with each new removal being equally likely to be
any of the balls that remain in the urn. The random variable _Y_ , equal to the number
of balls that need be withdrawn until a total of _r_ special balls have been removed,
is said to have a _negative hypergeometric distribution_. The negative hypergeometric
distribution bears the same relationship to the hypergeometric distribution as the
negative binomial does to the binomial. That is, in both cases, rather than considering
a random variable equal to the number of successes in a fixed number of trials (as are
the binomial and hypergeometric variables), they refer to the number of trials needed
to obtain a fixed number of successes.


**320** Chapter 7 Properties of Expectation

```
To obtain the probability mass function of a negative hypergeometric random vari-
able X , note that X will equal k if both
(a) the first k −1 withdrawals consist of r −1 special and k − r ordinary balls and
(b) the k th ball withdrawn is special.
Consequently,
```
```
P { X = k }=
```
```
( n
r − 1
```
```
)( m
k − r
```
##### )

```
( n + m
k − 1
```
##### )

```
n − r + 1
n + m − k + 1
```
```
We will not, however, utilize the preceding probability mass function to obtain the
mean and variance of Y. Rather, let us number the m ordinary balls as o 1 ,..., om ,
and then, for each i =1,..., n , let Ai be the event that oi is withdrawn before r
special balls have been removed. Then, if X is the number of the events A 1 ,..., Am
that occur, it follows that X is the number of ordinary balls that are withdrawn before
a total of r special balls have been removed. Consequently,
```
```
Y = r + X
```
```
showing that
```
```
E [ Y ]= r + E [ X ]= r +
```
```
∑ m
```
```
i = 1
```
```
P ( Ai )
```
```
To determine P ( Ai ), consider the n +1 balls consisting of oi along with the n special
balls. Of these n +1 balls, oi is equally likely to be the first one withdrawn, or the
second one withdrawn,..., or the final one withdrawn. Hence, the probability that
it is among the first r of these to be selected (and so is removed before a total or r
special balls have been withdrawn) is n + r 1. Consequently,
```
```
P ( Ai )=
```
```
r
n + 1
and
E [ Y ]= r + m
```
```
r
n + 1
```
##### =

```
r ( n + m + 1 )
n + 1
Thus, for instance, the expected number of cards of a well-shuffled deck that would
need to be turned over until a spade appears is 1+^3914 = 3 .786, and the expected
number of cards that would need to be turned over until an ace appears is
1 +^485 = 10 .6.
To determine Var(Y)=Var(X), we use the identity
```
```
E [ X ( X − 1 )]= 2
```
##### ∑

```
i < j
```
```
P ( AiAj )
```
```
Now, P ( AiAj )is the probability that both oi and oj are removed before there have
been a total of r special balls removed. So consider the n +2 balls consisting of oi , oj ,
and the n special balls. Because all withdrawal orderings of these balls are equally
likely, the probability that oi and oj are both among the first r +1ofthemtobe
removed (and so are both removed before r special balls have been withdrawn) is
```
```
P ( AiAj )=
```
##### ( 2

```
2
```
```
)( n
r − 1
```
##### )

```
( n + 2
r + 1
```
##### ) =

```
r ( r + 1 )
( n + 1 )( n + 2 )
```

```
Section 7.3 Moments of the Number of Events that Occur 321
```
Consequently,

```
E [ X ( X − 1 )]= 2
```
##### (

```
m
2
```
##### )

```
r ( r + 1 )
( n + 1 )( n + 2 )
```
so

```
E [ X^2 ]= m ( m − 1 )
```
```
r ( r + 1 )
( n + 1 )( n + 2 )
```
##### + E [ X ]

Because _E_ [ _X_ ]= _mn_ + _r_ 1 , this yields

```
Var(Y)=Var(X)= m ( m − 1 )
```
```
r ( r + 1 )
( n + 1 )( n + 2 )
```
```
m
```
```
r
n + 1
```
##### −

##### (

```
m
```
```
r
n + 1
```
##### ) 2

A little algebra now shows that

```
Var(Y)=
```
```
mr ( n + 1 − r )( n + m + 1 )
( n + 1 )^2 ( n + 2 )
```
##### .

**_EXAMPLE 3f Singletons in the coupon collector’s problem_**

Suppose that there are _n_ distinct types of coupons and that, independently of past
types collected, each new one obtained is equally likely to be any of the _n_ types.
Suppose also that one continues to collect coupons until a complete set of at least
one of each type has been obtained. Find the expected value and variance of the
number of types for which exactly one coupon of that type is collected.

**_Solution._** Let _X_ equal the number of types for which exactly one of that type is col-
lected. Also, let _Ti_ denote the _i_ th type of coupon to be collected, and let _Ai_ be the
event that there is only a single type _Ti_ coupon in the complete set. Because _X_ is
equal to the number of the events _A_ 1 ,..., _An_ that occur, we have

##### E [ X ]=

```
∑ n
```
```
i = 1
```
```
P ( Ai )
```
Now, at the moment when the first type _Ti_ coupon is collected, there remain _n_ − _i_
types that need to be collected to have a complete set. Because, starting at this moment,
each of these _n_ − _i_ + 1 types (the _n_ − _i_ not yet collected and type _Ti_ ) is equally
likely to be the last of these types to be collected, it follows that the type _Ti_ will be the
last of these types (and so will be a singleton) with probability _n_ −^1 _i_ + 1 .Consequently,

_P_ ( _Ai_ )= _n_ −^1 _i_ + 1 , yielding

##### E [ X ]=

```
∑ n
```
```
i = 1
```
##### 1

```
n − i + 1
```
##### =

```
∑ n
```
```
i = 1
```
##### 1

```
i
```
To determine the variance of the number of singletons, let _Si_ , _j_ ,for _i_ < _j_ , be the event
that the first type _Ti_ coupon to be collected is still the only one of its type to have
been collected at the moment that the first type _Tj_ coupon has been collected. Then

```
P ( AiAj )= P ( AiAj | Si , j ) P ( Si , j )
```
Now, _P_ ( _Si_ , _j_ )is the probability that when a type _Ti_ has just been collected, of the
_n_ − _i_ +1 types consisting of type _Ti_ and the _n_ − _i_ as yet uncollected types, a type _Ti_
is not among the first _j_ − _i_ of these types to be collected. Because type _Ti_ is equally
likely to be the first, or second, or..., _n_ − _i_ +1 of these types to be collected, we have

```
P ( Si , j )= 1 −
```
```
j − i
n − i + 1
```
##### =

```
n + 1 − j
n + 1 − i
```

**322** Chapter 7 Properties of Expectation

```
Now, conditional on the event Si , j , both Ai and Aj will occur if, at the time the first
type Tj coupon is collected, of the n − j +2 types consisting of types Ti , Tj , and the
n − j as yet uncollected types, Ti and Tj are both collected after the other n − j. But
this implies that
```
```
P ( AiAj | Si , j )= 2
```
##### 1

```
n − j + 2
```
##### 1

```
n − j + 1
```
```
Therefore,
```
```
P ( AiAj )=
```
##### 2

```
( n + 1 − i )( n + 2 − j )
```
```
, i < j
```
```
yielding
```
```
E [ X ( X − 1 )]= 4
```
##### ∑

```
i < j
```
##### 1

```
( n + 1 − i )( n + 2 − j )
```
```
Consequently, using the previous result for E [ X ], we obtain
```
```
Var( X )= 4
```
##### ∑

```
i < j
```
##### 1

```
( n + 1 − i )( n + 2 − j )
```
##### +

```
∑ n
```
```
i = 1
```
##### 1

```
i
```
##### −

##### ⎛

##### ⎝

```
∑ n
```
```
i = 1
```
##### 1

```
i
```
##### ⎞

##### ⎠

```
2
```
### 7.4 Covariance, Variance of Sums, and Correlations

```
The following proposition shows that the expectation of a product of independent
random variables is equal to the product of their expectations.
```
```
Proposition 4.1. If X and Y are independent, then, for any functions h and g ,
```
```
E [ g ( X ) h ( Y )]= E [ g ( X )] E [ h ( Y )]
```
```
Proof. Suppose that X and Y are jointly continuous with joint density f ( x , y ). Then
```
```
E [ g ( X ) h ( Y )]=
```
```
∫q
```
```
−q
```
```
∫q
```
```
−q
```
```
g ( x ) h ( y ) f ( x , y ) dx dy
```
##### =

```
∫q
```
```
−q
```
```
∫q
```
```
−q
```
```
g ( x ) h ( y ) fX ( x ) fY ( y ) dx dy
```
##### =

```
∫q
```
```
−q
```
```
h ( y ) fY ( y ) dy
```
```
∫q
```
```
−q
```
```
g ( x ) fX ( x ) dx
```
```
= E [ h ( Y )] E [ g ( X )]
```
```
The proof in the discrete case is similar.
```
```
Just as the expected value and the variance of a single random variable give us
information about that random variable, so does the covariance between two random
variables give us information about the relationship between the random variables.
```
```
Definition
```
```
The covariance between X and Y , denoted by Cov ( X , Y ), is defined by
```
```
Cov( X , Y )= E [( X − E [ X ])( Y − E [ Y ])]
```

```
Section 7.4 Covariance, Variance of Sums, and Correlations 323
```
```
Upon expanding the right side of the preceding definition, we see that
```
```
Cov( X , Y )= E [ XY − E [ X ] Y − XE [ Y ]+ E [ Y ] E [ X ]]
= E [ XY ]− E [ X ] E [ Y ]− E [ X ] E [ Y ]+ E [ X ] E [ Y ]
= E [ XY ]− E [ X ] E [ Y ]
```
```
Note that if X and Y are independent, then, by Proposition 4.1, Cov( X , Y )=0.
However, the converse is not true. A simple example of two dependent random vari-
ables X and Y having zero covariance is obtained by letting X be a random variable
such that
P { X = 0 }= P { X = 1 }= P { X =− 1 }=
```
##### 1

##### 3

and defining

```
Y =
```
##### {

```
0if X Z 0
1if X = 0
```
Now, _XY_ =0, so _E_ [ _XY_ ]=0. Also, _E_ [ _X_ ]=0. Thus,

```
Cov( X , Y )= E [ XY ]− E [ X ] E [ Y ]= 0
```
However, _X_ and _Y_ are clearly not independent.
The following proposition lists some of the properties of covariance.

**Proposition 4.2.**

```
(i) Cov( X , Y )=Cov( Y , X )
(ii) Cov( X , X )=Var(X)
(iii) Cov( aX , Y )= a Cov( X , Y )
```
```
(iv) Cov
```
##### ⎛

##### ⎜

##### ⎝

```
∑ n
```
```
i = 1
```
```
Xi ,
```
```
∑ m
```
```
j = 1
```
```
Yj
```
##### ⎞

##### ⎟

##### ⎠=

```
∑ n
```
```
i = 1
```
```
∑ m
```
```
j = 1
```
```
Cov( Xi , Yj )
```
**Proof of Proposition 4.2:** Parts (i) and (ii) follow immediately from the definition
of covariance, and part (iii) is left as an exercise for the reader. To prove part (iv),
which states that the covariance operation is additive (as is the operation of taking
expectations), letμ _i_ = _E_ [ _Xi_ ]and _vj_ = _E_ [ _Yj_ ]. Then

##### E

##### ⎡

##### ⎣

```
∑ n
```
```
i = 1
```
```
Xi
```
##### ⎤

##### ⎦=

```
∑ n
```
```
i = 1
```
```
μ i , E
```
##### ⎡

##### ⎢

##### ⎣

```
∑ m
```
```
j = 1
```
```
Yj
```
##### ⎤

##### ⎥

##### ⎦=

```
∑ m
```
```
j = 1
```
```
vj
```
```
and
```
```
Cov
```
##### ⎛

##### ⎜

##### ⎝

```
∑ n
```
```
i = 1
```
```
Xi ,
```
```
∑ m
```
```
j = 1
```
```
Yj
```
##### ⎞

##### ⎟

##### ⎠= E

##### ⎡

##### ⎢

##### ⎢

##### ⎣

##### ⎛

##### ⎝

```
∑ n
```
```
i = 1
```
```
Xi −
```
```
∑ n
```
```
i = 1
```
```
μ i
```
##### ⎞

##### ⎠

##### ⎛

##### ⎜

##### ⎝

```
∑ m
```
```
j = 1
```
```
Yj −
```
```
∑ m
```
```
j = 1
```
```
vj
```
##### ⎞

##### ⎟

##### ⎠

##### ⎤

##### ⎥

##### ⎥

##### ⎦

##### = E

##### ⎡

##### ⎢

##### ⎣

```
∑ n
```
```
i = 1
```
```
( Xi −μ i )
```
```
∑ m
```
```
j = 1
```
```
( Yj − vj )
```
##### ⎤

##### ⎥

##### ⎦


**324** Chapter 7 Properties of Expectation

##### = E

##### ⎡

##### ⎢

##### ⎣

```
∑ n
```
```
i = 1
```
```
∑ m
```
```
j = 1
```
```
( Xi −μ i )( Yj − vj )
```
##### ⎤

##### ⎥

##### ⎦

##### =

```
∑ n
```
```
i = 1
```
```
∑ m
```
```
j = 1
```
```
E [( Xi −μ i )( Yj − vj )]
```
```
where the last equality follows because the expected value of a sum of random vari-
ables is equal to the sum of the expected values.
It follows from parts (ii) and (iv) of Proposition 4.2, upon taking Yj = Xj , j =
1,..., n ,that
```
```
Var
```
##### ⎛

##### ⎝

```
∑ n
```
```
i = 1
```
```
Xi
```
##### ⎞

```
⎠=Cov
```
##### ⎛

##### ⎜

##### ⎝

```
∑ n
```
```
i = 1
```
```
Xi ,
```
```
∑ n
```
```
j = 1
```
```
Xj
```
##### ⎞

##### ⎟

##### ⎠

##### =

```
∑ n
```
```
i = 1
```
```
∑ n
```
```
j = 1
```
```
Cov( Xi , Xj )
```
##### =

```
∑ n
```
```
i = 1
```
```
Var( Xi )+
```
##### ∑∑

```
i Z j
```
```
Cov( Xi , Xj )
```
```
Since each pair of indices i , j , i Z j , appears twice in the double summation, the pre-
ceding formula is equivalent to
```
```
Var
```
##### ⎛

##### ⎝

```
∑ n
```
```
i = 1
```
```
Xi
```
##### ⎞

##### ⎠=

```
∑ n
```
```
i = 1
```
```
Var( Xi )+ 2
```
##### ∑∑

```
i < j
```
```
Cov( Xi , Xj ) (4.1)
```
```
If X 1 ,..., Xn are pairwise independent, in that Xi and Xj are independent for i Z j ,
then Equation (4.1) reduces to
```
```
Var
```
##### ⎛

##### ⎝

```
∑ n
```
```
i = 1
```
```
Xi
```
##### ⎞

##### ⎠=

```
∑ n
```
```
i = 1
```
```
Var( Xi )
```
```
The following examples illustrate the use of Equation (4.1).
```
```
EXAMPLE 4a
Let X 1 ,..., Xn be independent and identically distributed random variables having
expected valueμand varianceσ^2 , and as in Example 2c, let X =
```
```
∑ n
i = 1
```
```
Xi / n be the sam-
```
```
ple mean. The quantities Xi − X , i =1,..., n , are called deviations , as they equal the
differences between the individual data and the sample mean. The random variable
```
##### S^2 =

```
∑ n
```
```
i = 1
```
```
( Xi − X )^2
n − 1
```
```
is called the sample variance. Find (a) Var( X )and(b) E [ S^2 ].
```

```
Section 7.4 Covariance, Variance of Sums, and Correlations 325
```
**_Solution._**

```
(a) Var( X )=
```
##### (

##### 1

```
n
```
##### ) 2

```
Var
```
##### ⎛

##### ⎝

```
∑ n
```
```
i = 1
```
```
Xi
```
##### ⎞

##### ⎠

##### =

##### (

##### 1

```
n
```
) (^2) ∑ _n
i_ = 1
Var( _Xi_ ) by independence

##### =

```
σ^2
n
(b) We start with the following algebraic identity:
```
```
( n − 1 ) S^2 =
```
```
∑ n
```
```
i = 1
```
```
( Xi −μ+μ− X )^2
```
##### =

```
∑ n
```
```
i = 1
```
```
( Xi −μ)^2 +
```
```
∑ n
```
```
i = 1
```
```
( X −μ)^2 − 2 ( X −μ)
```
```
∑ n
```
```
i = 1
```
```
( Xi −μ)
```
##### =

```
∑ n
```
```
i = 1
```
```
( Xi −μ)^2 + n ( X −μ)^2 − 2 ( X −μ) n ( X −μ)
```
##### =

```
∑ n
```
```
i = 1
```
```
( Xi −μ)^2 − n ( X −μ)^2
```
Taking expectations of the preceding yields

```
( n − 1 ) E [ S^2 ]=
```
```
∑ n
```
```
i = 1
```
```
E [( Xi −μ)^2 ] − nE [( X −μ)^2 ]
```
```
= n σ^2 − n Var( X )
=( n − 1 )σ^2
```
where the final equality made use of part (a) of this example and the one preceding
it made use of the result of Example 2c, namely, that _E_ [ _X_ ]=μ. Dividing through
by _n_ − 1 shows that the expected value of the sample variance is the distribution
varianceσ^2..

Our next example presents another method for obtaining the variance of a bino-
mial random variable.

**_EXAMPLE 4b Variance of a binomial random variable_**

Compute the variance of a binomial random variable _X_ with parameters _n_ and _p_.

**_Solution._** Since such a random variable represents the number of successes in _n_ inde-
pendent trials when each trial has the common probability _p_ of being a success, we
may write
_X_ = _X_ 1 + ··· + _Xn_

where the _Xi_ are independent Bernoulli random variables such that

```
Xi =
```
##### {

```
1ifthe i th trial is a success
0 otherwise
```

**326** Chapter 7 Properties of Expectation

```
Hence, from Equation (4.1), we obtain
```
```
Var( X )=Var( X 1 )+ ··· +Var( Xn )
```
```
But
```
```
Var( Xi )= E [ Xi^2 ]−( E [ Xi ])^2
= E [ Xi ] −( E [ Xi ])^2 since Xi^2 = Xi
= p − p^2
```
```
Thus,
Var( X )= np ( 1 − p ).
```
```
EXAMPLE 4c Sampling from a finite population
Consider a set of N people, each of whom has an opinion about a certain subject that
is measured by a real number v that represents the person’s “strength of
feeling” about the subject. Let vi represent the strength of feeling of person i ,
i =1,... N.
Suppose that the quantities vi , i =1,..., N , are unknown and, to gather informa-
tion, a group of( n of the N people is “randomly chosen” in the sense that all of the
N
n
```
##### )

```
subsets of size n are equally likely to be chosen. These n people are then ques-
tioned and their feelings determined. If S denotes the sum of the n sampled values,
determine its mean and variance.
An important application of the preceding problem is to a forthcoming election
in which each person in the population is either for or against a certain candidate or
proposition. If we take vi to equal 1 if person i is in favor and 0 if he or she is against,
```
```
then v =
```
##### ∑ N

```
i = 1
```
```
vi / N represents the proportion of the population that is in favor. To
```
```
estimate v , a random sample of n people is chosen, and these people are polled. The
proportion of those polled who are in favor—that is, S/n —is often used as an estimate
of v.
```
```
Solution. For each person i , i =1,..., N , define an indicator variable Ii to indicate
whether or not that person is included in the sample. That is,
```
```
Ii =
```
##### {

```
1 if person i is in the random sample
0 otherwise
```
```
Now, S can be expressed by
```
```
S =
```
##### ∑ N

```
i = 1
```
```
viIi
```
```
so
```
##### E [ S ]=

##### ∑ N

```
i = 1
```
```
viE [ Ii ]
```

```
Section 7.4 Covariance, Variance of Sums, and Correlations 327
```
```
Var( S )=
```
##### ∑ N

```
i = 1
```
```
Var( viIi )+ 2
```
##### ∑∑

```
i < j
```
```
Cov( viIi , vjIj )
```
##### =

##### ∑ N

```
i = 1
```
```
v^2 i Var( Ii )+ 2
```
##### ∑∑

```
i < j
```
```
vivj Cov( Ii , Ij )
```
Because

```
E [ Ii ]=
```
```
n
N
E [ IiIj ]=
```
```
n
N
```
```
n − 1
N − 1
```
it follows that

```
Var( Ii )=
```
```
n
N
```
##### (

##### 1 −

```
n
N
```
##### )

```
Cov( Ii , Ij )=
```
```
n ( n − 1 )
N ( N − 1 )
```
##### −

##### (

```
n
N
```
##### ) 2

##### =

```
− n ( N − n )
N^2 ( N − 1 )
```
Hence,

```
E [ S ]= n
```
##### ∑ N

```
i = 1
```
```
vi
N
```
```
= nv
```
```
Var( S )=
```
```
n
N
```
##### (

```
N − n
N
```
##### )∑ N

```
i = 1
```
```
v^2 i −
```
```
2 n ( N − n )
N^2 ( N − 1 )
```
##### ∑∑

```
i < j
```
```
vivj
```
The expression for Var( _S_ ) can be simplified somewhat by using the identity

( _v_ 1 + ··· + _vN_ )^2 =

##### ∑ N

```
i = 1
```
```
v^2 i + 2
```
##### ∑∑

```
i < j
```
```
vivj. After some simplification, we obtain
```
```
Var( S )=
```
```
n ( N − n )
N − 1
```
##### ⎛

##### ⎜

##### ⎜

##### ⎝

##### ∑ N

```
i = 1
```
```
v^2 i
```
##### N

```
− v^2
```
##### ⎞

##### ⎟

##### ⎟

##### ⎠

Consider now the special case in which _Np_ of the _v_ ’s are equal to 1 and the remain-
der equal to 0. Then, in this case, _S_ is a hypergeometric random variable and has
mean and variance given, respectively, by

```
E [ S ]= nv = np since v =
```
```
Np
N
```
```
= p
```
and

```
Var( S )=
```
```
n ( N − n )
N − 1
```
##### (

```
Np
N
```
```
− p^2
```
##### )

##### =

```
n ( N − n )
N − 1
```
```
p ( 1 − p )
```

**328** Chapter 7 Properties of Expectation

```
The quantity S/n , equal to the proportion of those sampled which have values equal
to 1, is such that
```
##### E

##### [

##### S

```
n
```
##### ]

```
= p
```
```
Var
```
##### (

##### S

```
n
```
##### )

##### =

```
N − n
n ( N − 1 )
```
```
p ( 1 − p ).
```
```
The correlation of two random variables X and Y , denoted byρ( X , Y ), is defined,
as long as Var( X )Var( Y )is positive, by
```
```
ρ( X , Y )=
```
```
Cov( X , Y )
√
Var( X )Var( Y )
```
```
It can be shown that
− 1 ...ρ( X , Y )... 1 (4.2)
```
```
To prove Equation (4.2), suppose that X and Y have variances given byσ x^2 andσ y^2 ,
respectively. Then, on the one hand,
```
```
0 ...Var
```
##### (

##### X

```
σ x
```
##### +

##### Y

```
σ y
```
##### )

##### =

```
Var( X )
σ x^2
```
##### +

```
Var( Y )
σ y^2
```
##### +

```
2Cov( X , Y )
σ x σ y
=2[1+ρ( X , Y )]
```
```
implying that
− 1 ...ρ( X , Y )
```
```
On the other hand,
```
```
0 ...Var
```
##### (

##### X

```
σ x
```
##### −

##### Y

```
σ y
```
##### )

##### =

```
Var( X )
σ x^2
```
##### +

```
Var Y
(−σ y )^2
```
##### −

```
2Cov( X , Y )
σ x σ y
=2[1−ρ( X , Y )]
```
```
implying that
ρ( X , Y )... 1
```
```
which completes the proof of Equation (4.2).
In fact, since Var( Z )=0 implies that Z is constant with probability 1 (this intu-
itive relationship will be rigorously proven in Chapter 8), it follows from the proof of
Equation (4.2) thatρ( X , Y )=1 implies that Y = a + bX , where b =σ y /σ x >0and
ρ( X , Y )=−1 implies that Y = a + bX , where b =−σ y /σ x <0. We leave it as an
exercise for the reader to show that the reverse is also true: that if Y = a + bX ,then
ρ( X , Y )is either+1or−1, depending on the sign of b.
The correlation coefficient is a measure of the degree of linearity between X and Y.
A value ofρ( X , Y )near+1or−1 indicates a high degree of linearity between
X and Y , whereas a value near 0 indicates that such linearity is absent. A positive
```

```
Section 7.4 Covariance, Variance of Sums, and Correlations 329
```
value ofρ( _X_ , _Y_ )indicates that _Y_ tends to increase when _X_ does, whereas a negative
value indicates that _Y_ tends to decrease when _X_ increases. Ifρ( _X_ , _Y_ )=0, then _X_
and _Y_ are said to be _uncorrelated_.

**_EXAMPLE 4d_**

Let _IA_ and _IB_ be indicator variables for the events _A_ and _B_. That is,

##### IA =

##### {

```
1if A occurs
0 otherwise
```
```
IB =
```
##### {

```
1if B occurs
0 otherwise
```
Then

##### E [ IA ]= P ( A )

##### E [ IB ]= P ( B )

##### E [ IAIB ]= P ( AB )

so

```
Cov( IA , IB )= P ( AB )− P ( A ) P ( B )
= P ( B )[ P ( A | B )− P ( A )]
```
Thus, we obtain the quite intuitive result that the indicator variables for _A_ and _B_
are either positively correlated, uncorrelated, or negatively correlated, depending on
whether _P_ ( _A_ | _B_ )is, respectively, greater than, equal to, or less than _P_ ( _A_ )..

Our next example shows that the sample mean and a deviation from the sample
mean are uncorrelated.

**_EXAMPLE 4e_**

Let _X_ 1 ,..., _Xn_ be independent and identically distributed random variables having
varianceσ^2. Show that

```
Cov( Xi − X , X )= 0
```
**_Solution._** We have

```
Cov( Xi − X , X )=Cov( Xi , X )−Cov( X , X )
```
```
=Cov
```
##### ⎛

##### ⎜

```
⎝ Xi ,
```
##### 1

```
n
```
```
∑ n
```
```
j = 1
```
```
Xj
```
##### ⎞

##### ⎟

```
⎠−Var( X )
```
##### =

##### 1

```
n
```
```
∑ n
```
```
j = 1
```
```
Cov( Xi , Xj )−
```
```
σ^2
n
```
##### =

```
σ^2
n
```
##### −

```
σ^2
n
```
##### = 0


**330** Chapter 7 Properties of Expectation

```
where the next-to-last equality uses the result of Example 4a and the final equality
follows because
```
```
Cov( Xi , Xj )=
```
##### {

```
0if j Z i by independence
σ^2 if j = i since Var( Xi )=σ^2
```
```
Although X and the deviation Xi − X are uncorrelated, they are not, in gen-
eral, independent. However, in the special case where the Xi are normal random
variables, it turns out that not only is X independent of a single deviation, but it is
independent of the entire sequence of deviations Xj − X , j =1,..., n. This result
will be established in Section 7.8, where we will also show that, in this case, the sam-
ple mean X and the sample variance S^2 are independent, with( n − 1 ) S^2 /σ^2 having
a chi-squared distribution with n −1 degrees of freedom. (See Example 4a for the
definition of S^2 .).
```
```
EXAMPLE 4f
Consider m independent trials, each of which results in any of r possible outcomes
with probabilities P 1 , P 2 ,..., Pr ,
```
```
∑ r
1
```
```
Pi =1. If we let Ni , i =1,..., r , denote the num-
```
```
berofthe m trials that result in outcome i ,then N 1 , N 2 ,..., Nr have the multinomial
distribution
```
```
P { N 1 = n 1 , N 2 = n 2 ,..., Nr = nr }=
```
```
m!
n 1! n 2 !... nr!
```
##### P

```
n 1
1 P
```
```
n 2
2 ··· P
```
```
nr
r
```
```
∑ r
```
```
i = 1
```
```
ni = m
```
```
For i Z j , it seems likely that when Ni is large, Nj would tend to be small; hence, it is
intuitive that they should be negatively correlated. Let us compute their covariance
by using Proposition 4.2(iv) and the representation
```
```
Ni =
```
```
∑ m
```
```
k = 1
```
```
Ii ( k ) and Nj =
```
```
∑ m
```
```
k = 1
```
```
Ij ( k )
```
```
where
```
```
Ii ( k )=
```
##### {

```
1 if trial k results in outcome i
0 otherwise
```
```
Ij ( k )=
```
##### {

```
1 if trial k results in outcome j
0 otherwise
```
```
From Proposition 4.2(iv), we have
```
```
Cov( Ni , Nj )=
```
```
∑ m
```
```
= 1
```
```
∑ m
```
```
k = 1
```
```
Cov( Ii ( k ), Ij ())
```
```
Now, on the one hand, when k Z,
```
```
Cov( Ii ( k ), Ij ())= 0
```

```
Section 7.5 Conditional Expectation 331
```
```
since the outcome of trial k is independent of the outcome of trial. On the other hand,
```
```
Cov( Ii (), Ij ())= E [ Ii () Ij ()]− E [ Ii ()] E [ Ij ()]
= 0 − PiPj =− PiPj
```
```
where the equation uses the fact that Ii () Ij ()=0, since trialcannot result in both
outcome i and outcome j. Hence, we obtain
```
```
Cov( Ni , Nj )=− mPiPj
```
```
which is in accord with our intuition that Ni and Nj are negatively correlated..
```
### 7.5 Conditional Expectation

#### 7.5.1 Definitions..............................

```
Recall that if X and Y are jointly discrete random variables, then the conditional
probability mass function of X , given that Y = y , is defined, for all y such that
P { Y = y }>0, by
```
```
pX | Y ( x | y )= P { X = x | Y = y }=
```
```
p ( x , y )
pY ( y )
```
```
It is therefore natural to define, in this case, the conditional expectation of X given
that Y = y , for all values of y such that pY ( y )>0, by
```
```
E [ X | Y = y ]=
```
##### ∑

```
x
```
```
xP { X = x | Y = y }
```
##### =

##### ∑

```
x
```
```
xpX | Y ( x | y )
```
```
EXAMPLE 5a
If X and Y are independent binomial random variables with identical parameters n
and p , calculate the conditional expected value of X given that X + Y = m.
```
```
Solution. Let us first calculate the conditional probability mass function of X given
that X + Y = m .For k ...min( n , m ),
```
```
P { X = k | X + Y = m }=
```
```
P { X = k , X + Y = m }
P { X + Y = m }
```
```
=
```
```
P { X = k , Y = m − k }
P { X + Y = m }
```
```
=
```
```
P { X = k } P { Y = m − k }
P { X + Y = m }
```
##### =

##### (

```
n
k
```
##### )

```
pk ( 1 − p ) n − k
```
##### (

```
n
m − k
```
##### )

```
pm − k ( 1 − p ) n − m + k
(
2 n
m
```
##### )

```
pm ( 1 − p )^2 n − m
```
##### =

##### (

```
n
k
```
##### )(

```
n
m − k
```
##### )

##### (

```
2 n
m
```
##### )


**332** Chapter 7 Properties of Expectation

```
where we have used the fact (see Example 3f of Chapter 6) that X + Y is a binomial
random variable with parameters 2 n and p. Hence, the conditional distribution of X ,
given that X + Y = m , is the hypergeometric distribution, and from Example 2g, we
obtain
```
```
E [ X | X + Y = m ]=
```
```
m
2
```
##### .

```
Similarly, let us recall that if X and Y are jointly continuous with a joint probabil-
ity density function f ( x , y ), then the conditional probability density of X , given that
Y = y , is defined, for all values of y such that fY ( y )>0, by
```
```
fX | Y ( x | y )=
```
```
f ( x , y )
fY ( y )
```
```
It is natural, in this case, to define the conditional expectation of X , given that Y =
y ,by
```
```
E [ X | Y = y ]=
```
```
∫q
```
```
−q
```
```
xfX | Y ( x | y ) dx
```
```
provided that fY ( y )>0.
```
```
EXAMPLE 5b
Suppose that the joint density of X and Y is given by
```
```
f ( x , y )=
```
```
e − x / ye − y
y
```
```
0 < x <q,0< y <q
```
```
Compute E [ X | Y = y ].
```
```
Solution. We start by computing the conditional density
```
```
fX | Y ( x | y )=
```
```
f ( x , y )
fY ( y )
```
```
=
```
```
f ( x , y )
∫q
```
```
−q
```
```
f ( x , y ) dx
```
##### =

```
( 1 / y ) e − x / ye − y
∫q
```
```
0
```
```
( 1 / y ) e − x / ye − ydx
```
##### =

```
( 1 / y ) e − x / y
∫q
```
```
0
```
```
( 1 / y ) e − x / ydx
```
##### =

##### 1

```
y
```
```
e − x / y
```

```
Section 7.5 Conditional Expectation 333
```
Hence, the conditional distribution of _X_ , given that _Y_ = _y_ , is just the exponential
distribution with mean _y_. Thus,

```
E [ X | Y = y ]=
```
```
∫q
```
```
0
```
```
x
y
```
```
e − x / ydx = y.
```
**Remark.** Just as conditional probabilities satisfy all of the properties of ordinary
probabilities, so do conditional expectations satisfy the properties of ordinary expec-
tations. For instance, such formulas as

```
E [ g ( X )| Y = y ]=
```
##### ⎧

##### ⎪⎪

##### ⎪⎨

##### ⎪⎪

##### ⎪⎩

##### ∑

```
x
```
```
g ( x ) pX | Y ( x | y ) in the discrete case
```
```
∫q
```
```
−q
```
```
g ( x ) fX | Y ( x | y ) dx in the continuous case
```
and

##### E

##### ⎡

##### ⎣

```
∑ n
```
```
i = 1
```
```
Xi | Y = y
```
##### ⎤

##### ⎦=

```
∑ n
```
```
i = 1
```
```
E [ Xi | Y = y ]
```
remain valid. As a matter of fact, conditional expectation given that _Y_ = _y_ can be
thought of as being an ordinary expectation on a reduced sample space consisting
only of outcomes for which _Y_ = _y_..

#### 7.5.2 Computing Expectations by Conditioning

Let us denote by _E_ [ _X_ | _Y_ ] that function of the random variable _Y_ whose value at _Y_ = _y_
is _E_ [ _X_ | _Y_ = _y_ ]. Note that _E_ [ _X_ | _Y_ ] is itself a random variable. An extremely important
property of conditional expectations is given by the following proposition.

**Proposition 5.1.**

```
E [ X ]= E [ E [ X | Y ]] (5.1)
```
```
If Y is a discrete random variable, then Equation (5.1) states that
```
##### E [ X ]=

##### ∑

```
y
```
```
E [ X | Y = y ] P { Y = y } (5.1a)
```
whereas if _Y_ is continuous with density _fY_ ( _y_ ), then Equation (5.1) states

##### E [ X ]=

```
∫q
```
```
−q
```
```
E [ X | Y = y ] fY ( y ) dy (5.1b)
```
We now give a proof of Equation (5.1) in the case where _X_ and _Y_ are both discrete
random variables.

**Proof of Equation (5.1) when** **_X_** **and** **_Y_** **Are Discrete:** We must show that

##### E [ X ]=

##### ∑

```
y
```
```
E [ X | Y = y ] P { Y = y } (5.2)
```

**334** Chapter 7 Properties of Expectation

```
Now, the right-hand side of Equation (5.2) can be written as
∑
```
```
y
```
```
E [ X | Y = y ] P { Y = y }=
```
##### ∑

```
y
```
##### ∑

```
x
```
```
xP { X = x | Y = y } P { Y = y }
```
##### =

##### ∑

```
y
```
##### ∑

```
x
```
```
x
```
```
P { X = x , Y = y }
P { Y = y }
```
```
P { Y = y }
```
##### =

##### ∑

```
y
```
##### ∑

```
x
```
```
xP { X = x , Y = y }
```
##### =

##### ∑

```
x
```
```
x
```
##### ∑

```
y
```
```
P { X = x , Y = y }
```
##### =

##### ∑

```
x
```
```
xP { X = x }
```
##### = E [ X ]

```
and the result is proved.
One way to understand Equation (5.2) is to interpret it as follows: To calculate
E [ X ], we may take a weighted average of the conditional expected value of X given
that Y = y , each of the terms E [ X | Y = y ] being weighted by the probability of
the event on which it is conditioned. (Of what does this remind you?) This is an
extremely useful result that often enables us to compute expectations easily by first
conditioning on some appropriate random variable. The following examples illustrate
its use.
```
```
EXAMPLE 5c
A miner is trapped in a mine containing 3 doors. The first door leads to a tunnel that
will take him to safety after 3 hours of travel. The second door leads to a tunnel that
will return him to the mine after 5 hours of travel. The third door leads to a tunnel
that will return him to the mine after 7 hours. If we assume that the miner is at all
times equally likely to choose any one of the doors, what is the expected length of
time until he reaches safety?
```
```
Solution. Let X denote the amount of time (in hours) until the miner reaches safety,
and let Y denote the door he initially chooses. Now,
```
```
E [ X ]= E [ X | Y =1] P { Y = 1 }+ E [ X | Y =2] P { Y = 2 }
+ E [ X | Y =3] P { Y = 3 }
```
```
=
```
##### 1

##### 3

##### ( E [ X | Y =1]+ E [ X | Y =2]+ E [ X | Y =3])

```
However,
```
```
E [ X | Y =1]= 3
E [ X | Y =2]= 5 + E [ X ] (5.3)
E [ X | Y =3]= 7 + E [ X ]
```
```
To understand why Equation (5.3) is correct, consider, for instance, E [ X | Y = 2]
and reason as follows: If the miner chooses the second door, he spends 5 hours in
the tunnel and then returns to his cell. But once he returns to his cell, the prob-
lem is as before; thus his expected additional time until safety is just E [ X ]. Hence,
```

```
Section 7.5 Conditional Expectation 335
```
_E_ [ _X_ | _Y_ =2]= 5 + _E_ [ _X_ ]. The argument behind the other equalities in Equation (5.3)
is similar. Hence,

##### E [ X ]=

##### 1

##### 3

##### ( 3 + 5 + E [ X ] + 7 + E [ X ])

or
_E_ [ _X_ ]= 15.

**_EXAMPLE 5d Expectation of a sum of a random number of random variables_**

Suppose that the number of people entering a department store on a given day is
a random variable with mean 50. Suppose further that the amounts of money spent
by these customers are independent random variables having a common mean of $8.
Finally, suppose also that the amount of money spent by a customer is also inde-
pendent of the total number of customers who enter the store. What is the expected
amount of money spent in the store on a given day?

**_Solution._** If we let _N_ denote the number of customers that enter the store and _Xi_ the
amount spent by the _i_ th such customer, then the total amount of money spent can be

expressed as

##### ∑ N

```
i = 1
```
```
Xi. Now,
```
##### E

##### ⎡

##### ⎣

##### ∑ N

```
1
```
```
Xi
```
##### ⎤

##### ⎦= E

##### ⎡

##### ⎢

##### ⎣ E

##### ⎡

##### ⎣

##### ∑ N

```
1
```
```
Xi | N
```
##### ⎤

##### ⎦

##### ⎤

##### ⎥

##### ⎦

But

##### E

##### ⎡

##### ⎣

##### ∑ N

```
1
```
```
Xi | N = n
```
##### ⎤

##### ⎦= E

##### ⎡

##### ⎣

```
∑ n
```
```
1
```
```
Xi | N = n
```
##### ⎤

##### ⎦

##### = E

##### ⎡

##### ⎣

```
∑ n
```
```
1
```
```
Xi
```
##### ⎤

```
⎦ by the independence of the Xi and N
```
```
= nE [ X ] where E [ X ]= E [ Xi ]
```
which implies that

```
E
```
##### ⎡

##### ⎣

##### ∑ N

```
1
```
```
Xi | N
```
##### ⎤

##### ⎦= NE [ X ]

Thus,

```
E
```
##### ⎡

##### ⎣

##### ∑ N

```
i = 1
```
```
Xi
```
##### ⎤

##### ⎦= E [ NE [ X ]]= E [ N ] E [ X ]

Hence, in our example, the expected amount of money spent in the store is 50*$8,
or $400..

**_EXAMPLE 5e_**

The game of craps is begun by rolling an ordinary pair of dice. If the sum of the dice is
2, 3, or 12, the player loses. If it is 7 or 11, the player wins. If it is any other number _i_ ,


**336** Chapter 7 Properties of Expectation

```
the player continues to roll the dice until the sum is either 7 or i. If it is 7, the player
loses; if it is i , the player wins. Let R denote the number of rolls of the dice in a game
of craps. Find
(a) E [ R ];
(b) E [ R |player wins];
(c) E [ R |player loses].
```
```
Solution. If we let Pi denote the probability that the sum of the dice is i ,then
```
```
Pi = P 14 − i =
```
```
i − 1
36
```
```
, i =2,...,7
```
```
To compute E [ R ], we condition on S , the initial sum, giving
```
##### E [ R ]=

##### ∑^12

```
i = 2
```
```
E [ R | S = i ] Pi
```
```
However,
```
```
E [ R | S = i ]=
```
##### ⎧

##### ⎨

##### ⎩

```
1, if i =2, 3, 7, 11, 12
1 +
```
##### 1

```
Pi + P 7
```
```
, otherwise
```
```
The preceding equation follows because if the sum is a value i that does not end
the game, then the dice will continue to be rolled until the sum is either i or 7, and
the number of rolls until this occurs is a geometric random variable with parameter
Pi + P 7. Therefore,
```
##### E [ R ]= 1 +

##### ∑^6

```
i = 4
```
```
Pi
Pi + P 7
```
##### +

##### ∑^10

```
i = 8
```
```
Pi
Pi + P 7
```
```
= 1 + 2 ( 3 / 9 + 4 / 10 + 5 / 11 )= 3. 376
```
```
To determine E [ R |win], let us start by determining p , the probability that the player
wins. Conditioning on S yields
```
```
p =
```
##### ∑^12

```
i = 2
```
```
P {win| S = i } Pi
```
##### = P 7 + P 11 +

##### ∑^6

```
i = 4
```
```
Pi
Pi + P 7
```
```
Pi +
```
##### ∑^10

```
i = 8
```
```
Pi
Pi + P 7
```
```
Pi
```
##### = 0. 493

```
where the preceding uses the fact that the probability of obtaining a sum of i before
one of 7 is Pi /( Pi + P 7 ). Now, let us determine the conditional probability mass
function of S , given that the player wins. Letting Qi = P { S = i |win}, we have
```
```
Q 2 = Q 3 = Q 12 =0, Q 7 = P 7 / p , Q 11 = P 11 / p
```

```
Section 7.5 Conditional Expectation 337
```
and, for _i_ =4, 5, 6, 8, 9, 10,

```
Qi =
```
```
P { S = i ,win}
P {win}
```
```
=
```
```
PiP {win| S = i }
p
```
##### =

```
P^2 i
p ( Pi + P 7 )
```
Now, conditioning on the initial sum gives

```
E [ R |win]=
```
##### ∑

```
i
```
```
E [ R |win, S = i ] Qi
```
However, as was noted in Example 2j of Chapter 6, given that the initial sum is _i_ ,
the number of additional rolls needed and the outcome (whether a win or a loss) are
independent. (This is easily seen by first noting that, conditional on an initial sum
of _i_ , the outcome is independent of the number of additional dice rolls needed and
then using the symmetry property of independence, which states that if event _A_ is
independent of event _B_ , then event _B_ is independent of event _A_ .) Therefore,

```
E [ R |win]=
```
##### ∑

```
i
```
```
E [ R | S = i ] Qi
```
##### = 1 +

##### ∑^6

```
i = 4
```
```
Qi
Pi + P 7
```
##### +

##### ∑^10

```
i = 8
```
```
Qi
Pi + P 7
```
```
= 2. 938
```
Although we could determine _E_ [ _R_ |player loses] exactly as we did _E_ [ _R_ |player wins],
it is easier to use

```
E [ R ]= E [ R |win] p + E [ R |lose]( 1 − p )
```
implying that

```
E [ R |lose]=
```
```
E [ R ]− E [ R |win] p
1 − p
```
##### = 3. 801.

**_EXAMPLE 5f_**

As defined in Example 5c of Chapter 6, the bivariate normal joint density function of
the random variables _X_ and _Y_ is

```
f ( x , y )=
```
##### 1

```
2 πσ x σ y
```
##### √

```
1 −ρ^2
```
```
exp
```
##### ⎧

##### ⎪⎨

##### ⎪⎩

##### −

##### 1

```
2 ( 1 −ρ^2 )
```
##### ⎡

##### ⎣

##### (

```
x −μ x
σ x
```
##### ) 2

##### +

##### (

```
y −μ y
σ y
```
##### ) 2

```
− 2 ρ
```
```
( x −μ x )( y −μ y )
σ x σ y
```
##### ⎤

##### ⎦

##### ⎫

##### ⎪⎬

##### ⎪⎭


**338** Chapter 7 Properties of Expectation

```
We will now show thatρis the correlation between X and Y. As shown in Exam-
ple 5c,μ x = E [ X ],σ x^2 =Var( X ),andμ y = E [ Y ],σ y^2 =Var( Y ). Consequently,
```
```
Corr( X , Y )=
```
```
Cov( X , Y )
σ x σ y
```
```
=
```
```
E [ XY ]−μ x μ y
σ x σ y
```
```
To determine E [ XY ], we condition on Y. That is, we use the identity
```
```
E [ XY ]= E
```
##### [

##### E [ XY | Y ]

##### ]

```
Recalling from Example 5c that the conditional distribution of X given that Y = y is
normal with meanμ x +ρσσ xy ( y −μ y ), we see that
```
```
E [ XY | Y = y ]= E [ Xy | Y = y ]
= yE [ X | Y = y ]
```
```
= y
```
##### [

```
μ x +ρ
```
```
σ x
σ y
```
```
( y −μ y )
```
##### ]

```
= y μ x +ρ
```
```
σ x
σ y
```
```
( y^2 −μ yy )
```
```
Consequently,
E [ XY | Y ]= Y μ x +ρ
```
```
σ x
σ y
```
```
( Y^2 −μ yY )
```
```
implying that
```
##### E [ XY ]= E

##### [

```
Y μ x +ρ
```
```
σ x
σ y
```
```
( Y^2 −μ yY )
```
##### ]

```
=μ xE [ Y ]+ρ
```
```
σ x
σ y
```
```
E [ Y^2 −μ yY ]
```
```
=μ x μ y +ρ
```
```
σ x
σ y
```
##### (

```
E [ Y^2 ]−μ^2 y
```
##### )

```
=μ x μ y +ρ
```
```
σ x
σ y
```
```
Var( Y )
```
```
=μ x μ y +ρσ x σ y
```
```
Therefore,
Corr( X , Y )=
```
```
ρσ x σ y
σ x σ y
```
```
=ρ.
```
```
Sometimes E [ X ] is easy to compute, and we use the conditioning identity to com-
pute a conditional expected value. This approach is illustrated by our next example.
```
```
EXAMPLE 5g
Consider n independent trials, each of which results in one of the outcomes 1,..., k ,
with respective probabilities p 1 ,..., pk ,
```
```
∑ k
i = 1 pi =1. Let Ni denote the number of
trials that result in outcome i , i =1,..., k .For i Z j , find
```
```
(a) E [ Nj | Ni >0] and (b) E [ Nj | Ni >1]
```

```
Section 7.5 Conditional Expectation 339
```
**_Solution._** To solve (a), let

```
I =
```
##### {

```
0, if Ni = 0
1, if Ni > 0
```
Then
_E_ [ _Nj_ ]= _E_ [ _Nj_ | _I_ =0] _P_ { _I_ = 0 }+ _E_ [ _Nj_ | _I_ =1] _P_ { _I_ = 1 }

or, equivalently,

```
E [ Nj ]= E [ Nj | Ni =0] P { Ni = 0 }+ E [ Nj | Ni >0] P { Ni > 0 }
```
Now, the unconditional distribution of _Nj_ is binomial with parameters _n_ , _pj_. Also,
given that _Ni_ = _r_ , each of the _n_ − _r_ trials that do not result in outcome _i_ will,
independently, result in outcome _j_ with probability _P_ ( _j_ |not _i_ )=
_pj_
1 − _pi_. Consequently,
the conditional distribution of _Nj_ , given that _Ni_ = _r_ , is binomial with parameters
_n_ − _r_ ,
_pj_
1 − _pi_. (For a more detailed argument for this conclusion, see Example 4c of
Chapter 6.) Because _P_ { _Ni_ = 0 }=( 1 − _pi_ ) _n_ , the preceding equation yields

```
npj = n
```
```
pj
1 − pi
```
```
( 1 − pi ) n + E [ Nj | Ni >0]( 1 −( 1 − pi ) n
```
giving the result

```
E [ Nj | Ni >0]= npj
```
```
1 −( 1 − pi ) n −^1
1 −( 1 − pi ) n
```
```
We can solve part (b) in a similar manner. Let
```
##### J =

##### ⎧

##### ⎨

##### ⎩

```
0, if Ni = 0
1, if Ni = 1
2, if Ni > 1
```
Then

```
E [ Nj ]= E [ Nj | J =0] P { J = 0 }+ E [ Nj | J =1] P { J = 1 }
+ E [ Nj | J =2] P { J = 2 }
```
or, equivalently,

```
E [ Nj ]= E [ Nj | Ni =0] P { Ni = 0 }+ E [ Nj | Ni =1] P { Ni = 1 }
+ E [ Nj | Ni >1] P { Ni > 1 }
```
This equation yields

```
npj = n
```
```
pj
1 − pi
```
```
( 1 − pi ) n +( n − 1 )
```
```
pj
1 − pi
```
```
npi ( 1 − pi ) n −^1
```
```
+ E [ Nj | Ni >1]( 1 −( 1 − pi ) n − npi ( 1 − pi ) n −^1 )
```
giving the result

```
E [ Nj | Ni >1]=
```
```
npj [1−( 1 − pi ) n −^1 −( n − 1 ) pi ( 1 − pi ) n −^2 ]
1 −( 1 − pi ) n − npi ( 1 − pi ) n −^1
```
##### .

It is also possible to obtain the variance of a random variable by conditioning. We
illustrate this approach by the following example.


**340** Chapter 7 Properties of Expectation

```
EXAMPLE 5h Variance of the geometric distribution
Independent trials, each resulting in a success with probability p , are successively
performed. Let N be the time of the first success. Find Var( N ).
```
```
Solution. Let Y =1 if the first trial results in a success and Y =0 otherwise. Now,
```
```
Var( N )= E [ N^2 ]−( E [ N ])^2
```
```
To calculate E [ N^2 ], we condition on Y as follows:
```
```
E [ N^2 ]= E [ E [ N^2 | Y ]]
```
```
However,
```
```
E [ N^2 | Y =1]= 1
E [ N^2 | Y =0]= E [( 1 + N )^2 ]
```
```
These two equations follow because, on the one hand, if the first trial results in a
success, then, clearly, N =1; thus, N^2 =1. On the other hand, if the first trial results
in a failure, then the total number of trials necessary for the first success will have the
same distribution as 1 (the first trial that results in failure) plus the necessary number
of additional trials. Since the latter quantity has the same distribution as N , we obtain
E [ N^2 | Y =0]= E [( 1 + N )^2 ]. Hence,
```
```
E [ N^2 ]= E [ N^2 | Y =1] P { Y = 1 }+ E [ N^2 | Y =0] P { Y = 0 }
= p +( 1 − p ) E [( 1 + N )^2 ]
= 1 +( 1 − p ) E [2 N + N^2 ]
```
```
However, as was shown in Example 8b of Chapter 4, E [ N ]= 1 / p ; therefore,
```
##### E [ N^2 ]= 1 +

```
2 ( 1 − p )
p
```
```
+( 1 − p ) E [ N^2 ]
```
```
or
E [ N^2 ]=
```
```
2 − p
p^2
```
```
Consequently,
```
```
Var( N )= E [ N^2 ]−( E [ N ])^2
```
##### =

```
2 − p
p^2
```
##### −

##### (

##### 1

```
p
```
##### ) 2

##### =

```
1 − p
p^2
```
##### .

```
EXAMPLE 5i
Consider a gambling situation in which there are r players, with player i initially hav-
ing ni units, ni > 0, i =1,..., r .At each stage, two of the players are chosen to play
a game, with the winner of the game receiving 1 unit from the loser. Any player
whose fortune drops to 0 is eliminated, and this continues until a single player has all
n K
```
```
∑ r
i = 1 ni units, with that player designated as the victor. Assuming that the results
of successive games are independent and that each game is equally likely to be won
```

```
Section 7.5 Conditional Expectation 341
```
by either of its two players, find the average number of stages until one of the players
has all _n_ units.

**_Solution._** To find the expected number of stages played, suppose first that there are
only 2 players, with players 1 and 2 initially having _j_ and _n_ − _j_ units, respectively.
Let _Xj_ denote the number of stages that will be played, and let _mj_ = _E_ [ _Xj_ ].Then, for
_j_ =1,..., _n_ −1,
_Xj_ = 1 + _Aj_

where _Aj_ is the additional number of stages needed beyond the first stage. Taking
expectations gives
_mj_ = 1 + _E_ [ _Aj_ ]

Conditioning on the result of the first stage then yields

```
mj = 1 + E [ Aj |1 wins first stage]1/ 2 + E [ Aj |2 wins first stage]1/ 2
```
Now, if player 1 wins at the first stage, then the situation from that point on is exactly
the same as in a problem which supposes that player _1_ starts with _j_ +1 and player _2_
with _n_ −( _j_ + 1 )units. Consequently,

```
E [ Aj |1 wins first stage]= mj + 1
```
and, analogously,
_E_ [ _Aj_ |2 wins first stage]= _mj_ − 1

Thus,

```
mj = 1 +
```
##### 1

##### 2

```
mj + 1 +
```
##### 1

##### 2

```
mj − 1
```
or, equivalently,

```
mj + 1 = 2 mj − mj − 1 −2, j =1,..., n − 1 (5.4)
```
Using that _m_ 0 =0, the preceding equation yields

```
m 2 = 2 m 1 − 2
m 3 = 2 m 2 − m 1 − 2 = 3 m 1 − 6 = 3 ( m 1 − 2 )
m 4 = 2 m 3 − m 2 − 2 = 4 m 1 − 12 = 4 ( m 1 − 3 )
```
suggesting that
_mi_ = _i_ ( _m_ 1 − _i_ + 1 ), _i_ =1,..., _n_ (5.5)

To prove the preceding equality, we use mathematical induction. Since we’ve already
shown the equation to be true for _i_ =1, 2, we take as the induction hypothesis that
it is true whenever _i_ ... _j_ < _n_. Now we must prove that it is true for _j_ + 1. Using
Equation( 5. 4 )yields

```
mj + 1 = 2 mj − mj − 1 − 2
= 2 j ( m 1 − j + 1 )−( j − 1 )( m 1 − j + 2 )− 2 (by the induction hypothesis)
=( j + 1 ) m 1 − 2 j^2 + 2 j + j^2 − 3 j + 2 − 2
=( j + 1 ) m 1 − j^2 − j
=( j + 1 )( m 1 − j )
```

**342** Chapter 7 Properties of Expectation

```
which completes the induction proof of( 5. 5 ). Letting i = n in( 5. 5 ), and using that
mn =0, now yields that
m 1 = n − 1
```
```
which, again using( 5. 5 ), gives the result
```
```
mi = i ( n − i )
```
```
Thus, the mean number of games played when there are only 2 players with initial
amounts i and n − i is the product of their initial amounts. Because both players play
all stages, this is also the mean number of stages involving player 1.
Now let us return to the problem involving r players with initial amounts ni , i =
1,..., r ,
```
```
∑ r
i = 1 ni = n .Let X denote the number of stages needed to obtain a victor,
and let Xi denote the number of stages involving player i. Now, from the point of
view of player i , starting with ni , he will continue to play stages, independently being
equally likely to win or lose each one, until his fortune is either n or 0. Thus, the
number of stages he plays is exactly the same as when he has a single opponent with
an initial fortune of n − ni. Consequently, by the preceding result it follows that
```
```
E [ Xi ]= ni ( n − ni )
```
```
so
```
```
E
```
##### ⎡

##### ⎣

```
∑ r
```
```
i = 1
```
```
Xi
```
##### ⎤

##### ⎦=

```
∑ r
```
```
i = 1
```
```
ni ( n − ni )= n^2 −
```
```
∑ r
```
```
i = 1
```
```
n^2 i
```
```
But because each stage involves two players,
```
##### X =

##### 1

##### 2

```
∑ r
```
```
i = 1
```
```
Xi
```
```
Taking expectations now yields
```
##### E [ X ]=

##### 1

##### 2

##### ⎛

```
⎝ n^2 −
```
```
∑ r
```
```
i = 1
```
```
n^2 i
```
##### ⎞

##### ⎠

```
It is interesting to note that while our argument shows that the mean number of stages
does not depend on the manner in which the teams are selected at each stage, the
same is not true for the distribution of the number of stages. To see this, suppose
r =3, n 1 = n 2 =1, and n 3 = 2 .If players 1 and 2 are chosen in the first stage, then it
will take at least three stages to determine a winner, whereas if player 3 is in the first
stage, then it is possible for there to be only two stages..
In our next example, we use conditioning to verify a result previously noted in
Section 6. 3 .1: that the expected number of uniform(0, 1)random variables that need
to be added for their sum to exceed 1 is equal to e.
```
```
EXAMPLE 5j
Let U 1 , U 2 ,...be a sequence of independent uniform (0, 1) random variables. Find
E [ N ] when
```
```
N =min
```
##### ⎧

##### ⎨

##### ⎩

```
n :
```
```
∑ n
```
```
i = 1
```
```
Ui > 1
```
##### ⎫

##### ⎬

##### ⎭


```
Section 7.5 Conditional Expectation 343
```
**_Solution._** We will find E[N] by obtaining a more general result. For _x_ ∈[0, 1], let

```
N ( x )=min
```
##### ⎧

##### ⎨

##### ⎩

```
n :
```
```
∑ n
```
```
i = 1
```
```
Ui > x
```
##### ⎫

##### ⎬

##### ⎭

and set

```
m ( x )= E [ N ( x )]
```
That is, _N_ ( _x_ )is the number of uniform (0, 1) random variables we must add until
their sum exceeds _x_ ,and _m_ ( _x_ )is its expected value. We will now derive an equation
for _m_ ( _x_ )by conditioning on _U_ 1. This gives, from Equation (5.1b),

```
m ( x )=
```
##### ∫ 1

```
0
```
```
E [ N ( x )| U 1 = y ] dy (5.6)
```
Now,

```
E [ N ( x )| U 1 = y ]=
```
##### {

```
1if y > x
1 + m ( x − y ) if y ... x (5.7)
```
The preceding formula is obviously true when _y_ > _x_. It is also true when _y_ ... _x_ , since,
if the first uniform value is _y_ , then, at that point, the remaining number of uniform
random variables needed is the same as if we were just starting and were going to add
uniform random variables until their sum exceeded _x_ − _y_. Substituting Equation (5.7)
into Equation (5.6) gives

```
m ( x )= 1 +
```
```
∫ x
```
```
0
```
```
m ( x − y ) dy
```
##### = 1 +

```
∫ x
```
```
0
```
```
m ( u ) du
by letting
u = x − y
```
Differentiating the preceding equation yields

```
m ′( x )= m ( x )
```
or, equivalently,

```
m ′( x )
m ( x )
```
##### = 1

Integrating this equation gives

```
log[ m ( x )]= x + c
```
or

```
m ( x )= kex
```
Since _m_ ( 0 )=1, it follows that _k_ =1, so we obtain

```
m ( x )= ex
```
Therefore, _m_ (1), the expected number of uniform (0, 1) random variables that need
to be added until their sum exceeds 1, is equal to _e_..


**344** Chapter 7 Properties of Expectation

#### 7.5.3 Computing Probabilities by Conditioning

```
Not only can we obtain expectations by first conditioning on an appropriate random
variable, but we may also use this approach to compute probabilities. To see this, let
E denote an arbitrary event, and define the indicator random variable X by
```
##### X =

##### {

```
1if E occurs
0if E does not occur
```
```
It follows from the definition of X that
```
```
E [ X ]= P ( E )
E [ X | Y = y ]= P ( E | Y = y ) for any random variable Y
```
```
Therefore, from Equations (5.1a) and (5.1b), we obtain
```
```
P ( E )=
```
##### ∑

```
y
```
```
P ( E | Y = y ) P ( Y = y ) if Y is discrete
```
##### =

```
∫q
```
```
−q
```
```
P ( E | Y = y ) fY ( y ) dy if Y is continuous
```
##### (5.8)

```
Note that if Y is a discrete random variable taking on one of the values y 1 ,..., yn ,
then, by defining the events Fi , i =1,..., n ,by Fi ={ Y = yi }, Equation (5.8) reduces
to the familiar equation
```
##### P ( E )=

```
∑ n
```
```
i = 1
```
```
P ( E | Fi ) P ( Fi )
```
```
where F 1 ,..., Fn are mutually exclusive events whose union is the sample space.
```
```
EXAMPLE 5k The best-prize problem
Suppose that we are to be presented with n distinct prizes, in sequence. After being
presented with a prize, we must immediately decide whether to accept it or to reject
it and consider the next prize. The only information we are given when deciding
whether to accept a prize is the relative rank of that prize compared to ones already
seen. That is, for instance, when the fifth prize is presented, we learn how it compares
with the four prizes we’ve already seen. Suppose that once a prize is rejected, it is
lost, and that our objective is to maximize the probability of obtaining the best prize.
Assuming that all n! orderings of the prizes are equally likely, how well can we do?
```
```
Solution. Rather surprisingly, we can do quite well. To see this, fix a value k ,0...
k < n , and consider the strategy that rejects the first k prizes and then accepts the
first one that is better than all of those first k .Let Pk (best)denote the probability that
the best prize is selected when this strategy is employed. To compute this probability,
condition on X , the position of the best prize. This gives
```
```
Pk (best)=
```
```
∑ n
```
```
i = 1
```
```
Pk (best| X = i ) P ( X = i )
```
##### =

##### 1

```
n
```
```
∑ n
```
```
i = 1
```
```
Pk (best| X = i )
```

```
Section 7.5 Conditional Expectation 345
```
Now, on the one hand, if the overall best prize is among the first _k_ , then no prize is
ever selected under the strategy considered. That is,

```
Pk (best| X = i )=0if i ... k
```
On the other hand, if the best prize is in position _i_ , where _i_ > _k_ , then the best prize
will be selected if the best of the first _i_ −1 prizes is among the first _k_ (for then none
of the prizes in positions _k_ +1, _k_ +2,..., _i_ −1 would be selected). But, conditional
on the best prize being in position _i_ , it is easy to verify that all possible orderings of
the other prizes remain equally likely, which implies that each of the first _i_ −1 prizes
is equally likely to be the best of that batch. Hence, we have

```
Pk (best| X = i )= P {best of first i −1 is among the first k | X = i }
```
```
=
```
```
k
i − 1
```
```
if i > k
```
From the preceding, we obtain

```
Pk (best)=
```
```
k
n
```
```
∑ n
```
```
i = k + 1
```
##### 1

```
i − 1
```
##### L

```
k
n
```
```
∫ n
```
```
k + 1
```
##### 1

```
x − 1
```
```
dx
```
##### =

```
k
n
```
```
log
```
##### (

```
n − 1
k
```
##### )

##### L

```
k
n
```
```
log
```
##### (

```
n
k
```
##### )

Now, if we consider the function

```
g ( x )=
```
```
x
n
```
```
log
```
##### (

```
n
x
```
##### )

then

```
g ′( x )=
```
##### 1

```
n
```
```
log
```
##### (

```
n
x
```
##### )

##### −

##### 1

```
n
```
so

```
g ′( x )= 0 *log
```
##### (

```
n
x
```
##### )

```
= 1 * x =
```
```
n
e
```
Thus, since _Pk_ (best)L _g_ ( _k_ ), we see that the best strategy of the type considered is to
let the first _n/e_ prizes go by and then accept the first one to appear that is better than
all of those. In addition, since _g_ ( _n_ / _e_ )= 1 / _e_ , the probability that this strategy selects
the best prize is approximately 1/ _e_ L.36788.

**Remark.** Most people are quite surprised by the size of the probability of obtain-
ing the best prize, thinking that this probability would be close to 0 when _n_ is large.
However, even without going through the calculations, a little thought reveals that
the probability of obtaining the best prize can be made reasonably large. Consider
the strategy of letting half of the prizes go by and then selecting the first one to appear
that is better than all of those. The probability that a prize is actually selected is the
probability that the overall best is among the second half, and this is^12. In addition,
given that a prize is selected, at the time of selection that prize would have been


**346** Chapter 7 Properties of Expectation

```
the best of more than n /2 prizes to have appeared and would thus have probability of
at least^12 of being the overall best. Hence, the strategy of letting the first half of all
prizes go by and then accepting the first one that is better than all of those prizes has
a probability greater than^14 of obtaining the best prize..
```
```
EXAMPLE 5l
Let U be a uniform random variable on (0, 1), and suppose that the conditional dis-
tribution of X , given that U = p , is binomial with parameters n and p. Find the
probability mass function of X.
```
```
Solution. Conditioning on the value of U gives
```
```
P { X = i }=
```
##### ∫ 1

```
0
```
```
P { X = i | U = p } fU ( p ) dp
```
##### =

##### ∫ 1

```
0
```
```
P { X = i | U = p } dp
```
##### =

```
n!
i !( n − i )!
```
##### ∫ 1

```
0
```
```
pi ( 1 − p ) n − idp
```
```
Now, it can be shown (a probabilistic proof is given in Section 6.6) that
∫ 1
```
```
0
```
```
pi ( 1 − p ) n − idp =
```
```
i !( n − i )!
( n + 1 )!
```
```
Hence, we obtain
P { X = i }=
```
##### 1

```
n + 1
```
```
i =0,..., n
```
```
That is, we obtain the surprising result that if a coin whose probability of coming up
heads is uniformly distributed over (0, 1) is flipped n times, then the number of heads
occurring is equally likely to be any of the values 0,..., n.
Because the preceding conditional distribution has such a nice form, it is worth try-
ing to find another argument to enhance our intuition as to why such a result is true.
To do so, let U , U 1 ,..., Un be n + 1 independent uniform (0, 1) random variables,
and let X denote the number of the random variables U 1 ,..., Un that are smaller than
U. Since all the random variables U , U 1 ,..., Un have the same distribution, it follows
that U is equally likely to be the smallest, or second smallest, or largest of them; so
X is equally likely to be any of the values 0, 1,..., n. However, given that U = p ,the
number of the Ui that are less than U is a binomial random variable with parameters
n and p , thus establishing our previous result..
```
```
EXAMPLE 5m
Suppose that X and Y are independent continuous random variables having densities
fX and fY , respectively. Compute P { X < Y }.
```
```
Solution. Conditioning on the value of Y yields
```
##### P { X < Y }=

```
∫q
```
```
−q
```
```
P { X < Y | Y = y } fY ( y ) dy
```
##### =

```
∫q
```
```
−q
```
```
P { X < y | Y = y } fY ( y ) dy
```

```
Section 7.5 Conditional Expectation 347
```
##### =

```
∫q
```
```
−q
```
```
P { X < y } fY ( y } dy by independence
```
##### =

```
∫q
```
```
−q
```
```
FX ( y ) fY ( y ) dy
```
where

```
FX ( y )=
```
```
∫ y
```
```
−q
```
```
fX ( x ) dx.
```
**_EXAMPLE 5n_**

Suppose that _X_ and _Y_ are independent continuous random variables. Find the distri-
bution of _X_ + _Y_.

**_Solution._** By conditioning on the value of _Y_ , we obtain

```
P { X + Y < a }=
```
```
∫q
```
```
−q
```
```
P { X + Y < a | Y = y } fY ( y ) dy
```
##### =

```
∫q
```
```
−q
```
```
P { X + y < a | Y = y } fY ( y ) dy
```
##### =

```
∫q
```
```
−q
```
```
P { X < a − y } fY ( y ) dy
```
##### =

```
∫q
```
```
−q
```
```
FX ( a − y ) fY ( y ) dy.
```
#### 7.5.4 Conditional Variance

Just as we have defined the conditional expectation of _X_ given the value of _Y_ , we can
also define the conditional variance of _X_ given that _Y_ = _y_ :

```
Var( X | Y )K E [( X − E [ X | Y ])^2 | Y ]
```
That is, Var( _X_ | _Y_ )is equal to the (conditional) expected square of the difference
between _X_ and its (conditional) mean when the value of _Y_ is given. In other words,
Var( _X_ | _Y_ )is exactly analogous to the usual definition of variance, but now all expec-
tations are conditional on the fact that _Y_ is known.
There is a very useful relationship between Var( _X_ ), the unconditional variance of
_X_ , and Var( _X_ | _Y_ ), the conditional variance of _X_ given _Y_ , that can often be applied to
compute Var( _X_ ). To obtain this relationship, note first that, by the same reasoning
that yields Var( _X_ )= _E_ [ _X_^2 ] −( _E_ [ _X_ ])^2 , we have

```
Var( X | Y )= E [ X^2 | Y ]−( E [ X | Y ])^2
```
so

```
E [Var( X | Y )]= E [ E [ X^2 | Y ]]− E [( E [ X | Y ])^2 ]
= E [ X^2 ]− E [( E [ X | Y ])^2 ] (5.9)
```

**348** Chapter 7 Properties of Expectation

```
Also, since E [ E [ X | Y ]]= E [ X ], we have
```
```
Var( E [ X | Y ])= E [( E [ X | Y ])^2 ] −( E [ X ])^2 (5.10)
```
```
Hence, by adding Equations (5.9) and (5.10), we arrive at the following proposition.
```
```
Proposition 5.2. The conditional variance formula
```
```
Var( X )= E [Var( X | Y )]+Var( E [ X | Y ])
```
```
EXAMPLE 5o
Suppose that by any time t the number of people that have arrived at a train depot is
a Poisson random variable with meanλ t. If the initial train arrives at the depot at a
time (independent of when the passengers arrive) that is uniformly distributed over
(0, T ), what are the mean and variance of the number of passengers who enter the
train?
```
```
Solution. For each t Ú0, let N ( t )denote the number of arrivals by t , and let Y denote
the time at which the train arrives. The random variable of interest is then N ( Y ).
Conditioning on Y gives
```
```
E [ N ( Y )| Y = t ]= E [ N ( t )| Y = t ]
= E [ N ( t )] by the independence of Y and N ( t )
=λ t since N ( t )is Poisson with meanλ t
```
```
Hence,
E [ N ( Y )| Y ]=λ Y
```
```
so taking expectations gives
```
```
E [ N ( Y )]=λ E [ Y ]=
```
```
λ T
2
```
```
To obtain Var( N ( Y )), we use the conditional variance formula:
```
```
Var( N ( Y )| Y = t )=Var( N ( t )| Y = t )
=Var( N ( t )) by independence
=λ t
```
```
Thus,
```
```
Var( N ( Y )| Y )=λ Y
E [ N ( Y )| Y ]=λ Y
```
```
Hence, from the conditional variance formula,
```
```
Var( N ( Y ))= E [λ Y ]+Var(λ Y )
```
```
=λ
```
##### T

##### 2

```
+λ^2
```
##### T^2

##### 12

```
where we have used the fact that Var( Y )= T^2 /12..
```

```
Section 7.6 Conditional Expectation and Prediction 349
```
```
EXAMPLE 5p Variance of a sum of a random number of random variables
Let X 1 , X 2 ,...be a sequence of independent and identically distributed random vari-
ables, and let N be a nonnegative integer-valued random variable that is independent
```
```
of the sequence Xi , i Ú1. To compute Var
```
##### (

##### ∑ N

```
i = 1
```
```
Xi
```
##### )

```
, we condition on N :
```
##### E

##### ⎡

##### ⎣

##### ∑ N

```
i = 1
```
```
Xi | N
```
##### ⎤

##### ⎦= NE [ X ]

```
Var
```
##### ⎛

##### ⎝

##### ∑ N

```
i = 1
```
```
Xi | N
```
##### ⎞

```
⎠= N Var( X )
```
```
The preceding result follows because, given N ,
```
##### ∑ N

```
i = 1 Xi is just the sum of a fixed num-
ber of independent random variables, so its expectation and variance are just the
sums of the individual means and variances, respectively. Hence, from the conditional
variance formula,
```
```
Var
```
##### ⎛

##### ⎝

##### ∑ N

```
i = 1
```
```
Xi
```
##### ⎞

```
⎠= E [ N ]Var( X )+( E [ X ])^2 Var( N ).
```
### 7.6 Conditional Expectation and Prediction

```
Sometimes a situation arises in which the value of a random variable X is observed
and then, on the basis of the observed value, an attempt is made to predict the value
of a second random variable Y .Let g ( X )denote the predictor; that is, if X is observed
to equal x ,then g ( x )is our prediction for the value of Y. Clearly, we would like to
choose g so that g ( X )tends to be close to Y. One possible criterion for closeness is to
choose g so as to minimize E [( Y − g ( X ))^2 ]. We now show that, under this criterion,
the best possible predictor of Y is g ( X )= E [ Y | X ].
```
```
Proposition 6.1.
E [( Y − g ( X ))^2 ]Ú E [( Y − E [ Y | X ])^2 ]
```
```
Proof.
```
```
E [( Y − g ( X ))^2 | X ]= E [( Y − E [ Y | X ]+ E [ Y | X ] − g ( X ))^2 | X ]
= E [( Y − E [ Y | X ])^2 | X ]
+ E [( E [ Y | X ]− g ( X ))^2 | X ]
+ 2 E [( Y − E [ Y | X ])( E [ Y | X ]− g ( X ))| X ] (6.1)
```
```
However, given X , E [ Y | X ] − g ( X ), being a function of X , can be treated as a
constant. Thus,
```
```
E [( Y − E [ Y | X ])( E [ Y | X ]− g ( X ))| X ]
=( E [ Y | X ]− g ( X )) E [ Y − E [ Y | X ]| X ]
=( E [ Y | X ]− g ( X ))( E [ Y | X ]− E [ Y | X ])
= 0 (6.2)
```

**350** Chapter 7 Properties of Expectation

```
Hence, from Equations (6.1) and (6.2), we obtain
```
```
E [( Y − g ( X ))^2 | X ]Ú E [( Y − E [ Y | X ])^2 | X ]
```
```
and the desired result follows by taking expectations of both sides of the preceding
expression.
```
```
Remark. A second, more intuitive, although less rigorous, argument verifying
Proposition 6.1 is as follows. It is straightforward to verify that E [( Y − c )^2 ]ismini-
mized at c = E [ Y ]. (See Theoretical Exercise 1.) Thus, if we want to predict the value
of Y when there are no data available to use, the best possible prediction, in the
sense of minimizing the mean square error, is to predict that Y will equal its mean.
However, if the value of the random variable X is observed to be x , then the predic-
tion problem remains exactly as in the previous (no-data) case, with the exception
that all probabilities and expectations are now conditional on the event that X = x.
Hence, the best prediction in this situation is to predict that Y will equal its condi-
tional expected value given that X = x , thus establishing Proposition 6.1..
```
```
EXAMPLE 6a
Suppose that the son of a man of height x (in inches) attains a height that is normally
distributed with mean x +1 and variance 4. What is the best prediction of the height
at full growth of the son of a man who is 6 feet tall?
```
```
Solution. Formally, this model can be written as
```
```
Y = X + 1 + e
```
```
where e is a normal random variable, independent of X , having mean 0 and variance
```
4. The _X_ and _Y_ , of course, represent the heights of the man and his son, respectively.
The best prediction _E_ [ _Y_ | _X_ =72] is thus equal to

```
E [ Y | X =72]= E [ X + 1 + e | X =72]
= 73 + E [ e | X =72]
= 73 + E ( e ) by independence
= 73.
```
```
EXAMPLE 6b
Suppose that if a signal value s is sent from location A , then the signal value received
at location B is normally distributed with parameters ( s , 1). If S , the value of the signal
sent at A , is normally distributed with parameters (μ,σ^2 ), what is the best estimate of
the signal sent if R , the value received at B , is equal to r?
```
```
Solution. Let us start by computing the conditional density of S given R. We have
```
```
fS | R ( s | r )=
```
```
fS , R ( s , r )
fR ( r )
```
```
=
```
```
fS ( s ) fR | S ( r | s )
fR ( r )
= Ke −( s −μ)
```
(^2) / 2 σ 2
_e_ −( _r_ − _s_ )
(^2) / 2


```
Section 7.6 Conditional Expectation and Prediction 351
```
where _K_ does not depend on _s_. Now,

```
( s −μ)^2
2 σ^2
```
##### +

```
( r − s )^2
2
```
```
= s^2
```
##### (

##### 1

```
2 σ^2
```
##### +

##### 1

##### 2

##### )

##### −

##### (

```
μ
σ^2
```
```
+ r
```
##### )

```
s + C 1
```
##### =

```
1 +σ^2
2 σ^2
```
##### ⎡

```
⎣ s^2 − 2
```
##### (

```
μ+ r σ^2
1 +σ^2
```
##### )

```
s
```
##### ⎤

##### ⎦+ C 1

##### =

```
1 +σ^2
2 σ^2
```
##### (

```
s −
```
```
(μ+ r σ^2 )
1 +σ^2
```
##### ) 2

##### + C 2

where _C_ 1 and _C_ 2 do not depend on _s_. Hence,

```
fS | R ( s | r )= C exp
```
##### ⎧

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎨

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎩

##### −

##### [

```
s −
```
```
(μ+ r σ^2 )
1 +σ^2
```
##### ] 2

##### 2

##### (

```
σ^2
1 +σ^2
```
##### )

##### ⎫

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎬

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎭

where _C_ does not depend on _s_. Thus, we may conclude that the conditional distribu-
tion of _S_ , the signal sent, given that _r_ is received, is normal with mean and variance
now given by

```
E [ S | R = r ]=
```
```
μ+ r σ^2
1 +σ^2
```
```
Var( S | R = r )=
```
```
σ^2
1 +σ^2
```
Consequently, from Proposition 6.1, given that the value received is _r_ , the best esti-
mate, in the sense of minimizing the mean square error, for the signal sent is

```
E [ S | R = r ]=
```
##### 1

```
1 +σ^2
```
```
μ+
```
```
σ^2
1 +σ^2
```
```
r
```
Writing the conditional mean as we did previously is informative, for it shows that it
equals a weighted average ofμ, the a priori expected value of the signal, and _r_ ,the
value received. The relative weights given toμand _r_ are in the same proportion to
each other as 1 (the conditional variance of the received signal when _s_ is sent) is toσ^2
(the variance of the signal to be sent)..

**_EXAMPLE 6c_**

In digital signal processing, raw continuous analog data _X_ must be quantized, or dis-
cretized, in order to obtain a digital representation. In order to quantize the raw
data _X_ , an increasing set of numbers _ai_ , _i_ =0,;1,;2,..., such that lim
_i_ →+q

_ai_ =qand
lim
_i_ →−q

```
ai =−qis fixed, and the raw data are then quantized according to the interval
```
( _ai_ , _ai_ + 1 ] in which _X_ lies. Let us denote by _yi_ the discretized value when _X_ ∈( _ai_ , _ai_ + 1 ],
and let _Y_ denote the observed discretized value—that is,

```
Y = yi if ai < X ... ai + 1
```

**352** Chapter 7 Properties of Expectation

```
The distribution of Y is given by
```
```
P { Y = yi }= FX ( ai + 1 )− FX ( ai )
```
```
Suppose now that we want to choose the values yi , i =0,;1,;2,...so as to mini-
mize E [( X − Y )^2 ], the expected mean square difference between the raw data and
their quantized version.
(a) Find the optimal values yi , i =0,;1,....
For the optimal quantizer Y , show that
(b) E [ Y ]= E [ X ], so the mean square error quantizer preserves the input mean;
(c) Var( Y )=Var( X )− E [( X − Y )^2 ].
```
```
Solution. (a) For any quantizer Y , upon conditioning on the value of Y , we obtain
```
```
E [( X − Y )^2 ]=
```
##### ∑

```
i
```
```
E [( X − yi )^2 | ai < X ... ai + 1 ] P { ai < X ... ai + 1 }
```
```
Now, if we let
I = i if ai < X ... ai + 1
```
```
then
E [( X − yi )^2 | ai < X ... ai + 1 ]= E [( X − yi )^2 | I = i ]
```
```
and by Proposition 6.1, this quantity is minimized when
```
```
yi = E [ X | I = i ]
= E [ X | ai < X ... ai + 1 ]
```
```
=
```
```
∫ ai + 1
```
```
ai
```
```
xfX ( x ) dx
FX ( ai + 1 )− FX ( ai )
```
```
Now, since the optimal quantizer is given by Y = E [ X | I ], it follows that
(b) E [ Y ]= E [ X ]
(c)
Var( X )= E [Var( X | I )] +Var( E [ X | I ])
= E [ E [( X − Y )^2 | I ]]+Var( Y )
= E [( X − Y )^2 ]+Var( Y ).
```
```
It sometimes happens that the joint probability distribution of X and Y is not
completely known; or if it is known, it is such that the calculation of E [ Y | X = x ]
is mathematically intractable. If, however, the means and variances of X and Y and
the correlation of X and Y are known, then we can at least determine the best linear
predictor of Y with respect to X.
To obtain the best linear predictor of Y with respect to X , we need to choose a and
b so as to minimize E [( Y −( a + bX ))^2 ]. Now,
```
```
E [( Y −( a + bX ))^2 ]= E [ Y^2 − 2 aY − 2 bXY + a^2 + 2 abX + b^2 X^2 ]
= E [ Y^2 ]− 2 aE [ Y ] − 2 bE [ XY ]+ a^2
+ 2 abE [ X ]+ b^2 E [ X^2 ]
```

```
Section 7.6 Conditional Expectation and Prediction 353
```
Taking partial derivatives, we obtain

##### ∂

```
∂ a
```
```
E [( Y − a − bX )^2 ]=− 2 E [ Y ]+ 2 a + 2 bE [ X ]
```
```
∂
∂ b
```
```
E [( Y − a − bX )^2 ]=− 2 E [ XY ]+ 2 aE [ X ] + 2 bE [ X^2 ]
```
##### (6.3)

Setting Equations (6.3) to 0 and solving for _a_ and _b_ yields the solutions

```
b =
```
##### E [ XY ]− E [ X ] E [ Y ]

##### E [ X^2 ]−( E [ X ])^2

##### =

```
Cov( X , Y )
σ x^2
```
```
=ρ
```
```
σ y
σ x
```
```
a = E [ Y ]− bE [ X ]= E [ Y ] −
```
```
ρσ yE [ X ]
σ x
```
##### (6.4)

whereρ =Correlation( _X_ , _Y_ ),σ _y_^2 =Var( _Y_ ),andσ _x_^2 =Var( _X_ ). It is easy to ver-

ify that the values of _a_ and _b_ from Equation (6.4) minimize _E_ [( _Y_ − _a_ − _bX_ )^2 ];
thus, the best (in the sense of mean square error) linear predictor _Y_ with respect
to _X_ is

```
μ y +
```
```
ρσ y
σ x
```
```
( X −μ x )
```
whereμ _y_ = _E_ [ _Y_ ]andμ _x_ = _E_ [ _X_ ].
The mean square error of this predictor is given by

##### E

##### [(

```
Y −μ y −ρ
```
```
σ y
σ x
```
```
( X −μ x )
```
##### ) 2 ]

##### = E

##### [

```
( Y −μ y )^2
```
##### ]

```
+ρ^2
```
```
σ y^2
σ x^2
```
##### E

##### [

```
( X −μ x )^2
```
##### ]

```
− 2 ρ
```
```
σ y
σ x
```
##### E

##### [

```
( Y −μ y )( X −μ x )
```
##### ]

```
=σ y^2 +ρ^2 σ y^2 − 2 ρ^2 σ y^2
=σ y^2 ( 1 −ρ^2 ) (6.5)
```
We note from Equation (6.5) that ifρis near+1or−1, then the mean square error
of the best linear predictor is near zero..

**_EXAMPLE 6d_**

An example in which the conditional expectation of _Y_ given _X_ is linear in _X_ ,and
hence in which the best linear predictor of _Y_ with respect to _X_ is the best overall
predictor, is when _X_ and _Y_ have a bivariate normal distribution. For, as shown in
Example 5c of Chapter 6, in that case,

```
E [ Y | X = x ]=μ y +ρ
```
```
σ y
σ x
```
```
( x −μ x ).
```

**354** Chapter 7 Properties of Expectation

### 7.7 Moment Generating Functions.......................

```
The moment generating function M ( t )of the random variable X is defined for all real
values of t by
```
```
M ( t )= E [ etX ]
```
##### =

##### ⎧

##### ⎪⎪

##### ⎪⎨

##### ⎪⎪

##### ⎪⎩

##### ∑

```
x
```
```
etxp ( x ) if X is discrete with mass function p ( x )
```
```
∫q
```
```
−q
```
```
etxf ( x ) dx if X is continuous with density f ( x )
```
```
We call M ( t )the moment generating function because all of the moments of X can be
obtained by successively differentiating M ( t )and then evaluating the result at t =0.
For example,
```
```
M ′( t )=
```
```
d
dt
```
```
E [ etX ]
```
##### = E

##### [

```
d
dt
```
```
( etX )
```
##### ]

##### (7.1)

```
= E [ XetX ]
```
```
where we have assumed that the interchange of the differentiation and expectation
operators is legitimate. That is, we have assumed that
```
```
d
dt
```
##### ⎡

##### ⎣

##### ∑

```
x
```
```
etxp ( x )
```
##### ⎤

##### ⎦=

##### ∑

```
x
```
```
d
dt
```
```
[ etxp ( x )]
```
```
in the discrete case and
```
```
d
dt
```
##### [∫

```
etxf ( x ) dx
```
##### ]

##### =

##### ∫

```
d
dt
```
```
[ etxf ( x )] dx
```
```
in the continuous case. This assumption can almost always be justified and, indeed, is
valid for all of the distributions considered in this book. Hence, from Equation (7.1),
evaluated at t =0, we obtain
M ′( 0 )= E [ X ]
```
```
Similarly,
```
```
M ′′( t )=
```
```
d
dt
```
```
M ′( t )
```
##### =

```
d
dt
```
```
E [ XetX ]
```
##### = E

##### [

```
d
dt
```
```
( XetX )
```
##### ]

```
= E [ X^2 etX ]
```
```
Thus,
M ′′( 0 )= E [ X^2 ]
```

```
Section 7.7 Moment Generating Functions 355
```
In general, the _n_ th derivative of _M_ ( _t_ )is given by

```
Mn ( t )= E [ XnetX ] n Ú 1
```
implying that
_Mn_ ( 0 )= _E_ [ _Xn_ ] _n_ Ú 1

```
We now compute M ( t )for some common distributions.
```
**_EXAMPLE 7a Binomial distribution with parameters n and p_**

If _X_ is a binomial random variable with parameters _n_ and _p_ ,then

```
M ( t )= E [ etX ]
```
##### =

```
∑ n
```
```
k = 0
```
```
etk
```
##### (

```
n
k
```
##### )

```
pk ( 1 − p ) n − k
```
##### =

```
∑ n
```
```
k = 0
```
##### (

```
n
k
```
##### )

```
( pet ) k ( 1 − p ) n − k
```
```
=( pet + 1 − p ) n
```
where the last equality follows from the binomial theorem. Differentiation yields

```
M ′( t )= n ( pet + 1 − p ) n −^1 pet
```
Thus,
_E_ [ _X_ ]= _M_ ′( 0 )= _np_

Differentiating a second time yields

```
M ′′( t )= n ( n − 1 )( pet + 1 − p ) n −^2 ( pet )^2 + n ( pet + 1 − p ) n −^1 pet
```
so
_E_ [ _X_^2 ]= _M_ ′′( 0 )= _n_ ( _n_ − 1 ) _p_^2 + _np_

The variance of _X_ is given by

```
Var( X )= E [ X^2 ]−( E [ X ])^2
= n ( n − 1 ) p^2 + np − n^2 p^2
= np ( 1 − p )
```
verifying the result obtained previously..

**_EXAMPLE 7b Poisson distribution with mean_** λ

If _X_ is a Poisson random variable with parameterλ,then

```
M ( t )= E [ etX ]
```
##### =

```
∑q
```
```
n = 0
```
```
etne −λλ n
n!
```
```
= e −λ
```
```
∑q
```
```
n = 0
```
```
(λ et ) n
n!
```

**356** Chapter 7 Properties of Expectation

```
= e −λ e λ e
```
```
t
```
```
=exp{λ( et − 1 )}
```
```
Differentiation yields
```
```
M ′( t )=λ et exp{λ( et − 1 )}
M ′′( t )=(λ et )^2 exp{λ( et − 1 )}+λ et exp{λ( et − 1 )}
```
```
Thus,
```
```
E [ X ]= M ′( 0 )=λ
E [ X^2 ]= M ′′( 0 )=λ^2 +λ
Var( X )= E [ X^2 ]−( E [ X ])^2
=λ
```
```
Hence, both the mean and the variance of the Poisson random variable equalλ..
```
```
EXAMPLE 7c Exponential distribution with parameter λ
```
```
M ( t )= E [ etX ]
```
```
=
```
```
∫q
```
```
0
```
```
etx λ e −λ xdx
```
```
=λ
```
```
∫q
```
```
0
```
```
e −(λ− t ) xdx
```
##### =

```
λ
λ− t
```
```
for t <λ
```
```
We note from this derivation that, for the exponential distribution, M ( t )is defined
only for values of t less thanλ. Differentiation of M ( t )yields
```
```
M ′( t )=
```
```
λ
(λ− t )^2
```
```
M ′′( t )=
```
```
2 λ
(λ− t )^3
```
```
Hence,
```
```
E [ X ]= M ′( 0 )=
```
##### 1

```
λ
```
##### E [ X^2 ]= M ′′( 0 )=

##### 2

```
λ^2
The variance of X is given by
```
```
Var( X )= E [ X^2 ]−( E [ X ])^2
```
```
=
```
##### 1

```
λ^2
```
##### .

```
EXAMPLE 7d Normal distribution
We first compute the moment generating function of a unit normal random variable
with parameters 0 and 1. Letting Z be such a random variable, we have
```
```
MZ ( t )= E [ etZ ]
```
```
=
```
##### 1

##### √

```
2 π
```
```
∫q
```
```
−q
```
```
etxe − x
```
(^2) / 2
_dx_


```
Section 7.7 Moment Generating Functions 357
```
##### =

##### 1

##### √

```
2 π
```
```
∫q
```
```
−q
```
```
exp
```
##### {

##### −

```
( x^2 − 2 tx )
2
```
##### }

```
dx
```
##### =

##### 1

##### √

```
2 π
```
```
∫q
```
```
−q
```
```
exp
```
##### {

##### −

```
( x − t )^2
2
```
##### +

```
t^2
2
```
##### }

```
dx
```
```
= et
```
(^2) / 2 1
√
2 π
∫q
−q
_e_ −( _x_ − _t_ )
(^2) / 2
_dx_
= _et_
(^2) / 2
Hence, the moment generating function of the unit normal random variable _Z_ is given
by _MZ_ ( _t_ )= _et_
(^2) / 2

. To obtain the moment generating function of an arbitrary normal
random variable, we recall (see Section 5.4) that _X_ =μ +σ _Z_ will have a normal
distribution with parametersμandσ^2 whenever _Z_ is a unit normal random variable.
Hence, the moment generating function of such a random variable is given by

```
MX ( t )= E [ etX ]
= E [ et (μ+σ Z )]
= E [ et μ et σ Z ]
= et μ E [ et σ Z ]
= et μ MZ ( t σ)
= et μ e ( t σ)
```
(^2) / 2
=exp

##### {

```
σ^2 t^2
2
```
```
+μ t
```
##### }

By differentiating, we obtain

```
M ′ X ( t )=(μ+ t σ^2 )exp
```
##### {

```
σ^2 t^2
2
```
```
+μ t
```
##### }

```
M ′′ X ( t )=(μ+ t σ^2 )^2 exp
```
##### {

```
σ^2 t^2
2
```
```
+μ t
```
##### }

```
+σ^2 exp
```
##### {

```
σ^2 t^2
2
```
```
+μ t
```
##### }

Thus,

```
E [ X ]= M ′( 0 )=μ
E [ X^2 ]= M ′′( 0 )=μ^2 +σ^2
```
implying that

```
Var( X )= E [ X^2 ]− E ([ X ])^2
=σ^2.
```
Tables 7.1 and 7.2 give the moment generating functions for some common dis-
crete and continuous distributions.
An important property of moment generating functions is that the moment gen-
erating function of the sum of independent random variables equals the product of
the individual moment generating functions. To prove this, suppose that _X_ and _Y_ are


**358** Chapter 7 Properties of Expectation

```
TABLE 7.1: DISCRETE PROBABILITY DISTRIBUTION
```
```
Moment
Probability mass generating
function, p ( x ) function, M ( t ) Mean Variance
```
```
Binomial with
parameters n , p ;
0 ... p ... 1
```
```
(
n
x
```
```
)
px ( 1 − p ) n − x ( pet + 1 − p ) n np np ( 1 − p )
```
```
x =0, 1,..., n
```
```
Poisson with
parameterλ> 0
```
```
e −λ
```
```
λ x
x!
exp{λ( et − 1 )} λλ
```
```
x =0, 1, 2,...
Geometric with
parameter
0 ... p ... 1
```
```
p ( 1 − p ) x −^1
```
```
pet
1 −( 1 − p ) et
```
```
1
p
```
```
1 − p
p^2
x =1, 2,...
```
```
Negative
binomial with
parameters r , p ;
0 ... p ... 1
```
```
(
n − 1
r − 1
```
```
)
pr ( 1 − p ) n − r
```
```
[
pet
1 −( 1 − p ) et
```
```
] r
r
p
```
```
r ( 1 − p )
p^2
```
```
n = r , r +1,...
```
```
independent and have moment generating functions MX ( t )and MY ( t ), respectively.
Then MX + Y ( t ), the moment generating function of X + Y , is given by
```
```
MX + Y ( t )= E [ et ( X + Y )]
= E [ etXetY ]
= E [ etX ] E [ etY ]
= MX ( t ) MY ( t )
```
```
where the next-to-last equality follows from Proposition 4.1, since X and Y are inde-
pendent.
Another important result is that the moment generating function uniquely deter-
mines the distribution. That is, if MX ( t )exists and is finite in some region about t =0,
then the distribution of X is uniquely determined. For instance, if
```
```
MX ( t )=
```
##### (

##### 1

##### 2

##### ) 10

```
( et + 1 )^10 ,
```
```
then it follows from Table 7.1 that X is a binomial random variable with parameters
10 and^12.
```
```
EXAMPLE 7e
Suppose that the moment generating function of a random variable X is given by
M ( t )= e^3 ( e
```
```
t − 1 )
.Whatis P { X = 0 }?
```

```
Section 7.7 Moment Generating Functions 359
```
**TABLE 7.2:**

CONTINUOUS PROBABILITY DISTRIBUTION

```
Momentgenerating
```
```
Probability mass function,
```
```
f (
```
```
x )
```
```
function,
```
```
M
```
```
( t
)
```
```
Mean
```
```
Variance
```
```
Uniform over (
```
```
a ,
```
```
b )
```
```
f (
```
```
x )
```
```
=
```
```
⎧⎪⎨ ⎪⎩
```
```
1
b
```
```
−
```
```
a
```
```
a
```
```
<
```
```
x
```
```
<
```
```
b
```
```
0
```
```
otherwise
```
```
tbe
```
```
−
```
```
tae
```
```
t (
```
```
b
```
```
−
```
```
a )
```
```
a
```
```
+
```
```
b
2
```
```
( b
```
```
−
```
```
a )
```
```
2
```
```
12
```
```
Exponential withparameter
```
```
λ>
```
```
0
```
```
f (
```
```
x )
```
```
=
```
```
{
λ
```
```
− e
λ x
```
```
x
```
```
Ú
```
```
0
```
```
0
```
```
x
```
```
<
```
```
0
```
```
λ
λ
```
```
−
```
```
t
```
```
1 λ
```
(^12) λ
Gamma with parameters( _s_
,λ)
,λ>
0
_f_ (
_x_ )
=
⎧⎪⎪⎨ ⎪⎪⎩
λ _e_
−
λ _x_
(λ
_x_ )
_s_ −
1
(
_s_ )
_x_
Ú
0
0
_x_
<
0
(
λ
λ
−
) _t
s
s_ λ
_s_^2 λ
Normal with parameters(μ
,σ
2 )
_f_ (
_x_ )
=
1
√
2 πσ
− _e_
( _x_
−
μ)
2 /
2 σ
2
−
q
<
_x_
<
q
exp
{
μ
_t_
+
σ
2 _t_
2
2
}
μσ
2


**360** Chapter 7 Properties of Expectation

```
Solution. We see from Table 7.1 that M ( t )= e^3 ( e
```
```
t − 1 )
is the moment generating func-
tion of a Poisson random variable with mean 3. Hence, by the one-to-one correspon-
dence between moment generating functions and distribution functions, it follows
that X must be a Poisson random variable with mean 3. Thus, P { X = 0 }= e −^3..
```
```
EXAMPLE 7f Sums of independent binomial random variables
If X and Y are independent binomial random variables with parameters ( n , p )and
( m , p ), respectively, what is the distribution of X + Y?
```
```
Solution. The moment generating function of X + Y is given by
```
```
MX + Y ( t )= MX ( t ) MY ( t )=( pet + 1 − p ) n ( pet + 1 − p ) m
=( pet + 1 − p ) m + n
```
```
However,( pet + 1 − p ) m + n is the moment generating function of a binomial ran-
dom variable having parameters m + n and p. Thus, this must be the distribution
of X + Y..
```
```
EXAMPLE 7g Sums of independent Poisson random variables
Calculate the distribution of X + Y when X and Y are independent Poisson random
variables with means respectiveλ 1 andλ 2.
```
```
Solution.
```
```
MX + Y ( t )= MX ( t ) MY ( t )
=exp{λ 1 ( et − 1 )}exp{λ 2 ( et − 1 )}
=exp{(λ 1 +λ 2 )( et − 1 )}
```
```
Hence, X + Y is Poisson distributed with meanλ 1 +λ 2 , verifying the result given
in Example 3e of Chapter 6..
```
```
EXAMPLE 7h Sums of independent normal random variables
Show that if X and Y are independent normal random variables with respective
parameters(μ 1 ,σ 12 )and(μ 2 ,σ 22 ),then X + Y is normal with meanμ 1 + μ 2 and
varianceσ 12 +σ 22.
```
```
Solution.
```
```
MX + Y ( t )= MX ( t ) MY ( t )
```
```
=exp
```
##### {

```
σ 12 t^2
2
```
```
+μ 1 t
```
##### }

```
exp
```
##### {

```
σ 22 t^2
2
```
```
+μ 2 t
```
##### }

```
=exp
```
##### {

```
(σ 12 +σ 22 ) t^2
2
```
```
+(μ 1 +μ 2 ) t
```
##### }

```
which is the moment generating function of a normal random variable with mean
μ 1 +μ 2 and varianceσ 12 +σ 22. The desired result then follows because the moment
generating function uniquely determines the distribution..
```

```
Section 7.7 Moment Generating Functions 361
```
**_EXAMPLE 7i_**

Compute the moment generating function of a chi-squared random variable with _n_
degrees of freedom.

**_Solution._** We can represent such a random variable as

```
Z 12 + ··· + Z^2 n
```
where _Z_ 1 ,..., _Zn_ are independent standard normal random variables. Let _M_ ( _t_ )be its
moment generating function. Then, by the preceding,

```
M ( t )=( E [ etZ
```
```
2
]) n
```
where _Z_ is a standard normal random variable. Now,

```
E [ etZ
```
```
2
]=
```
##### 1

##### √

```
2 π
```
```
∫q
```
```
−q
```
```
etx
```
```
2
e − x
```
(^2) / 2
_dx_

##### =

##### 1

##### √

```
2 π
```
```
∫q
```
```
−q
```
```
e − x
```
(^2) / 2 σ 2
_dx_ whereσ^2 =( 1 − 2 _t_ )−^1
=σ
=( 1 − 2 _t_ )−^1 /^2
where the next-to-last equality uses the fact that the normal density with mean 0 and
varianceσ^2 integrates to 1. Therefore,
_M_ ( _t_ )=( 1 − 2 _t_ )− _n_ /^2.
**_EXAMPLE 7j Moment generating function of the sum of a random number of
random variables_**
Let _X_ 1 , _X_ 2 ,...be a sequence of independent and identically distributed random vari-
ables, and let _N_ be a nonnegative, integer-valued random variable that is independent
of the sequence _X_ , _i_ Ú1. We want to compute the moment generating function of

##### Y =

##### ∑ N

```
i = 1
```
```
Xi
```
(In Example 5d, _Y_ was interpreted as the amount of money spent in a store on a
given day when both the amount spent by a customer and the number of customers
are random variables.)
To compute the moment generating function of _Y_ , we first condition on _N_ as
follows:

##### E

##### ⎡

##### ⎢

##### ⎢

```
⎣exp
```
##### ⎧

##### ⎨

##### ⎩

```
t
```
##### ∑ N

```
1
```
```
Xi
```
##### ⎫

##### ⎬

##### ⎭

##### ∣ ∣ ∣ ∣ ∣ ∣ ∣

```
N = n
```
##### ⎤

##### ⎥

##### ⎥

##### ⎦= E

##### ⎡

##### ⎢

##### ⎢

```
⎣exp
```
##### ⎧

##### ⎨

##### ⎩

```
t
```
```
∑ n
```
```
1
```
```
Xi
```
##### ⎫

##### ⎬

##### ⎭

##### ∣ ∣ ∣ ∣ ∣ ∣ ∣

```
N = n
```
##### ⎤

##### ⎥

##### ⎥

##### ⎦

##### = E

##### ⎡

##### ⎢

```
⎣exp
```
##### ⎧

##### ⎨

##### ⎩

```
t
```
```
∑ n
```
```
1
```
```
Xi
```
##### ⎫

##### ⎬

##### ⎭

##### ⎤

##### ⎥

##### ⎦

```
=[ MX ( t )] n
```

**362** Chapter 7 Properties of Expectation

```
where
MX ( t )= E [ etXi ]
```
```
Hence,
E [ etY | N ]=( MX ( t )) N
```
```
Thus,
MY ( t )= E [( MX ( t )) N ]
```
```
The moments of Y can now be obtained upon differentiation, as follows:
```
```
M ′ Y ( t )= E [ N ( MX ( t )) N −^1 M ′ X ( t )]
```
```
So
```
```
E [ Y ]= M ′ Y ( 0 )
= E [ N ( MX ( 0 )) N −^1 M ′ X ( 0 )]
= E [ NEX ] (7.2)
= E [ N ] E [ X ]
```
```
verifying the result of Example 5d. (In this last set of equalities, we have used the fact
that MX ( 0 )= E [ e^0 X ]=1.)
Also,
```
```
MY ′′( t )= E [ N ( N − 1 )( MX ( t )) N −^2 ( M ′ X ( t ))^2 + N ( MX ( t )) N −^1 MX ′′( t )]
```
```
so
```
```
E [ Y^2 ]= M ′′ Y ( 0 )
= E [ N ( N − 1 )( E [ X ])^2 + NE [ X^2 ]]
=( E [ X ])^2 ( E [ N^2 ]− E [ N ])+ E [ N ] E [ X^2 ] (7.3)
= E [ N ]( E [ X^2 ] −( E [ X ])^2 )+( E [ X ])^2 E [ N^2 ]
= E [ N ]Var( X )+( E [ X ])^2 E [ N^2 ]
```
```
Hence, from Equations (7.2) and (7.3), we have
```
```
Var( Y )= E [ N ]Var( X )+( E [ X ])^2 ( E [ N^2 ]−( E [ N ])^2 )
= E [ N ]Var( X )+( E [ X ])^2 Var( N ).
```
```
EXAMPLE 7k
Let Y denote a uniform random variable on (0, 1), and suppose that, conditional on
Y = p , the random variable X has a binomial distribution with parameters n and p.
In Example 5k, we showed that X is equally likely to take on any of the values
0, 1,..., n. Establish this result by using moment generating functions.
```
```
Solution. To compute the moment generating function of X , start by conditioning
on the value of Y. Using the formula for the binomial moment generating function
gives
E [ etX | Y = p ]=( pet + 1 − p ) n
```

```
Section 7.7 Moment Generating Functions 363
```
Now, _Y_ is uniform on (0, 1), so, upon taking expectations, we obtain

```
E [ etX ]=
```
##### ∫ 1

```
0
```
```
( pet + 1 − p ) ndp
```
##### =

##### 1

```
et − 1
```
```
∫ et
```
```
1
```
```
yndy (by the substitution y = pet + 1 − p )
```
##### =

##### 1

```
n + 1
```
```
et ( n +^1 )− 1
et − 1
```
```
=
```
##### 1

```
n + 1
```
```
( 1 + et + e^2 t + ··· + ent )
```
Because the preceding is the moment generating function of a random variable that
is equally likely to be any of the values 0, 1,..., _n_ , the desired result follows from the
fact that the moment generating function of a random variable uniquely determines
its distribution..

#### 7.7.1 Joint Moment Generating Functions

It is also possible to define the joint moment generating function of two or more
random variables. This is done as follows: For any _n_ random variables _X_ 1 ,..., _Xn_ ,
the joint moment generating function, _M_ ( _t_ 1 ,..., _tn_ ), is defined, for all real values of
_t_ 1 ,..., _tn_ ,by

```
M ( t 1 ,..., tn )= E [ et^1 X^1 +···+ tnXn ]
```
The individual moment generating functions can be obtained from _M_ ( _t_ 1 ,..., _tn_ )by
letting all but one of the _tj_ ’s be 0. That is,

```
MXi ( t )= E [ etXi ]= M (0,...,0, t ,0,...,0)
```
where the _t_ is in the _i_ th place.
It can be proven (although the proof is too advanced for this text) that the joint
moment generating function _M_ ( _t_ 1 ,..., _tn_ )uniquely determines the joint distribution
of _X_ 1 ,..., _Xn_. This result can then be used to prove that the _n_ random variables
_X_ 1 ,..., _Xn_ are independent if and only if

```
M ( t 1 ,..., tn )= MX 1 ( t 1 )··· MXn ( tn ) (7.4)
```
For the proof in one direction, if the _n_ random variables are independent, then

```
M ( t 1 ,..., tn )= E [ e ( t^1 X^1 +···+ tnXn )]
= E [ et^1 X^1 ··· etnXn ]
= E [ et^1 X^1 ]··· E [ etnXn ] by independence
= MX 1 ( t 1 )··· MXn ( tn )
```
For the proof in the other direction, if Equation (7.4) is satisfied, then the joint
moment generating function _M_ ( _t_ 1 ,..., _tn_ )is the same as the joint moment generating
function of _n_ independent random variables, the _i_ th of which has the same distri-
bution as _Xi_. As the joint moment generating function uniquely determines the joint
distribution, this must be the joint distribution; hence, the random variables are
independent.


**364** Chapter 7 Properties of Expectation

```
EXAMPLE 7l
Let X and Y be independent normal random variables, each with meanμand vari-
anceσ^2. In Example 7a of Chapter 6, we showed that X + Y and X − Y are inde-
pendent. Let us now establish this result by computing their joint moment generating
function:
```
```
E [ et ( X + Y )+ s ( X − Y )]= E [ e ( t + s ) X +( t − s ) Y ]
= E [ e ( t + s ) X ] E [ e ( t − s ) Y ]
```
```
= e μ( t + s )+σ
```
(^2) ( _t_ + _s_ ) (^2) / 2
_e_ μ( _t_ − _s_ )+σ
(^2) ( _t_ − _s_ ) (^2) / 2
= _e_^2 μ _t_ +σ
(^2) _t_ 2
_e_ σ
(^2) _s_ 2
But we recognize the preceding as the joint moment generating function of the sum
of a normal random variable with mean 2μand variance 2σ^2 and an independent
normal random variable with mean 0 and variance 2σ^2. Because the joint moment
generating function uniquely determines the joint distribution, it follows that _X_ + _Y_
and _X_ − _Y_ are independent normal random variables..
In the next example, we use the joint moment generating function to verify a result
that was established in Example 2b of Chapter 6.
**_EXAMPLE 7m_**
Suppose that the number of events that occur is a Poisson random variable with
meanλand that each event is independently counted with probability _p_. Show that
the number of counted events and the number of uncounted events are independent
Poisson random variables with respective meansλ _p_ andλ( 1 − _p_ ).
**_Solution._** Let _X_ denote the total number of events, and let _Xc_ denote the number
of them that are counted. To compute the joint moment generating function of _Xc_ ,
the number of events that are counted, and _X_ − _Xc_ , the number that are uncounted,
start by conditioning on _X_ to obtain
_E_ [ _esXc_ + _t_ ( _X_ − _Xc_ )| _X_ = _n_ ]= _etnE_ [ _e_ ( _s_ − _t_ ) _Xc_ | _X_ = _n_ ]
= _etn_ ( _pes_ − _t_ + 1 − _p_ ) _n_
=( _pes_ +( 1 − _p_ ) _et_ ) _n_
which follows because, conditional on _X_ = _n_ , _Xc_ is a binomial random variable with
parameters _n_ and _p_. Hence,
_E_ [ _esXc_ + _t_ ( _X_ − _Xc_ )| _X_ ]=( _pes_ +( 1 − _p_ ) _et_ ) _X_
Taking expectations of both sides of this equation yields
_E_ [ _esXc_ + _t_ ( _X_ − _Xc_ )]= _E_ [( _pes_ +( 1 − _p_ ) _et_ ) _X_ ]
Now, since _X_ is Poisson with meanλ, it follows that _E_ [ _etX_ ]= _e_ λ( _e
t_ − 1 )

. Therefore, for
any positive value _a_ we see (by letting _a_ = _et_ )that _E_ [ _aX_ ]= _e_ λ( _a_ −^1 ). Thus

```
E [ esXc + t ( X − Xc )]= e λ( pe
```
```
s +( 1 − p ) et − 1 )
```
```
= e λ p ( e
```
_s_ − (^1) )
_e_ λ(^1 − _p_ )( _e
t_ − 1 )


```
Section 7.8 Additional Properties of Normal Random Variables 365
```
```
As the preceding is the joint moment generating function of independent Poisson
random variables with respective meansλ p andλ( 1 − p ), the result is proven..
```
### 7.8 Additional Properties of Normal Random Variables

#### 7.8.1 The Multivariate Normal Distribution

```
Let Z 1 ,..., Zn be a set of n independent unit normal random variables. If, for some
constants aij ,1... i ... m ,1... j ... n ,andμ i ,1... i ... m ,
```
```
X 1 = a 11 Z 1 + ··· + a 1 nZn +μ 1
X 2 = a 21 Z 1 + ··· + a 2 nZn +μ 2
.
.
.
Xi = ai 1 Z 1 + ··· + ainZn +μ i
.
.
.
Xm = am 1 Z 1 + ··· + amnZn +μ m
```
```
then the random variables X 1 ,..., Xm are said to have a multivariate normal distri-
bution.
From the fact that the sum of independent normal random variables is itself a
normal random variable, it follows that each Xi is a normal random variable with
mean and variance given, respectively, by
```
```
E [ Xi ]=μ i
```
```
Var( Xi )=
```
```
∑ n
```
```
j = 1
```
```
a^2 ij
```
```
Let us now consider
```
```
M ( t 1 ,..., tm )= E [exp{ t 1 X 1 + ··· + tmXm }]
```
```
the joint moment generating function of X 1 ,..., Xm. The first thing to note is that
since
```
```
∑ m
i = 1
```
```
tiXi is itself a linear combination of the independent normal random vari-
```
```
ables Z 1 ,..., Zn , it is also normally distributed. Its mean and variance are
```
##### E

##### ⎡

##### ⎣

```
∑ m
```
```
i = 1
```
```
tiXi
```
##### ⎤

##### ⎦=

```
∑ m
```
```
i = 1
```
```
ti μ i
```
```
and
```
```
Var
```
##### ⎛

##### ⎝

```
∑ m
```
```
i = 1
```
```
tiXi
```
##### ⎞

```
⎠=Cov
```
##### ⎛

##### ⎜

##### ⎝

```
∑ m
```
```
i = 1
```
```
tiXi ,
```
```
∑ m
```
```
j = 1
```
```
tjXj
```
##### ⎞

##### ⎟

##### ⎠

##### =

```
∑ m
```
```
i = 1
```
```
∑ m
```
```
j = 1
```
```
titj Cov( Xi , Xj )
```

**366** Chapter 7 Properties of Expectation

```
Now, if Y is a normal random variable with meanμand varianceσ^2 ,then
```
```
E [ eY ]= MY ( t )| t = 1 = e μ+σ
```
(^2) / 2
Thus,
_M_ ( _t_ 1 ,..., _tm_ )=exp

##### ⎧

##### ⎪⎨

##### ⎪⎩

```
∑ m
```
```
i = 1
```
```
ti μ i +
```
##### 1

##### 2

```
∑ m
```
```
i = 1
```
```
∑ m
```
```
j = 1
```
```
titj Cov( Xi , Xj )
```
##### ⎫

##### ⎪⎬

##### ⎪⎭

```
which shows that the joint distribution of X 1 ,..., Xm is completely determined from
a knowledge of the values of E [ Xi ] and Cov( Xi , Xj ), i , j =1,..., m.
It can be shown that when m =2, the multivariate normal distribution reduces to
the bivariate normal.
```
```
EXAMPLE 8a
Find P ( X < Y )for bivariate normal random variables X and Y having parameters
```
```
μ x = E [ X ],μ y = E [ Y ],σ x^2 =Var( X ),σ y^2 =Var( Y ),ρ=Corr( X , Y )
```
```
Solution. Because X − Y is normal with mean
```
```
E [ X − Y ]=μ x −μ y
```
```
and variance
```
```
Var( X − Y )=Var( X )+Var(− Y )+2Cov( X ,− Y )
=σ x^2 +σ y^2 − 2 ρσ x σ y
```
```
we obtain
```
```
P { X < Y }= P { X − Y < 0 }
```
##### = P

##### ⎧

##### ⎪⎨

##### ⎪⎩

```
X − Y −(μ x −μ y )
√
σ x^2 +σ y^2 − 2 ρσ x σ y
```
##### <

```
−(μ x −μ y )
√
σ x^2 +σ y^2 − 2 ρσ x σ y
```
##### ⎫

##### ⎪⎬

##### ⎪⎭

##### =

```
( μ y −μ x
√
σ x^2 +σ y^2 − 2 ρσ x σ y
```
##### )

##### .

```
EXAMPLE 8b
Suppose that the conditional distribution of X , given that = θ, is normal with
meanθand variance 1. Moreover, suppose thatitself is a normal random variable
with meanμand varianceσ^2. Find the conditional distribution ofgiven that X = x.
```
```
Solution. Rather than using and then simplifying Bayes’s formula, we will solve this
problem by first showing that X ,has a bivariate normal distribution. To do so, note
that the joint density function of X ,can be written as
```
```
fX ,( x ,θ)= fX |( x |θ) f (θ)
```
```
where fX |( x |θ)is a normal density with meanθand variance 1.However, if we let Z
be a standard normal random variable that is independent of, then the conditional
distribution of Z +, given that=θ, is also normal with meanθand variance 1.
```

```
Section 7.8 Additional Properties of Normal Random Variables 367
```
Consequently, the joint density of _Z_ +,is the same as that of _X_ ,.Because the
former joint density is clearly bivariate normal (since _Z_ +andare both linear
combinations of the independent normal random variables _Z_ and), it follows that
_X_ ,has a bivariate normal distribution. Now,

```
E [ X ]= E [ Z +]=μ
Var( X )=Var( Z +)= 1 +σ^2
```
and

```
ρ=Corr( X ,)
=Corr( Z +,)
```
```
=
```
```
Cov( Z +,)
√
Var( Z +)Var()
=
```
```
σ
√
1 +σ^2
```
Because _X_ ,has a bivariate normal distribution, the conditional distribution of,
given that _X_ = _x_ , is normal with mean

```
E [| X = x ]= E [] +ρ
```
##### √

```
Var()
Var( X )
```
```
( x − E [ X ])
```
```
=μ+
```
```
σ^2
1 +σ^2
```
```
( x −μ)
```
and variance

```
Var(| X = x )=Var()( 1 −ρ^2 )
```
```
=
```
```
σ^2
1 +σ^2
```
##### .

**7.8.2 The Joint Distribution of the Sample Mean and Sample Variance**

Let _X_ 1 ,..., _Xn_ be independent normal random variables, each with meanμand vari-

anceσ^2 .Let _X_ =

```
∑ n
i = 1
```
```
Xi / n denote their sample mean. Since the sum of independent
```
normal random variables is also a normal random variable, it follows that _X_ is a nor-
mal random variable with (from Examples 2c and 4a) expected valueμand variance
σ^2 / _n_.
Now, recall from Example 4e that

```
Cov( X , Xi − X )=0, i =1,..., n (8.1)
```
Also, note that since _X_ , _X_ 1 − _X_ , _X_ 2 − _X_ ,..., _Xn_ − _X_ are all linear combinations
of the independent standard normals( _Xi_ −μ)/σ, _i_ =1,..., _n_ , it follows that _X_ , _Xi_ −
_X_ , _i_ = 1,..., _n_ has a joint distribution that is multivariate normal. If we let _Y_ be
a normal random variable, with meanμand varianceσ^2 / _n_ , that is independent of
the _Xi_ , _i_ =1,..., _n_ ,then _Y_ , _Xi_ − _X_ , _i_ =1,..., _n_ also has a multivariate normal dis-
tribution and, indeed, because of Equation (8.1), has the same expected values and
covariances as the random variables _X_ , _Xi_ − _X_ , _i_ =1,..., _n_. But since a multivariate
normal distribution is determined completely by its expected values and covariances,


**368** Chapter 7 Properties of Expectation

```
it follows that Y , Xi − X , i =1,..., n and X , Xi − X , i =1,..., n have the same
joint distribution, thus showing that X is independent of the sequence of deviations
Xi − X , i =1,..., n.
Since X is independent of the sequence of deviations Xi − X , i =1,..., n , it is also
independent of the sample variance S^2 K
```
```
∑ n
i = 1
```
```
( Xi − X )^2 /( n − 1 ).
```
```
Since we already know that X is normal with meanμand varianceσ^2 / n , it remains
only to determine the distribution of S^2. To accomplish this, recall, from Example 4a,
the algebraic identity
```
```
( n − 1 ) S^2 =
```
```
∑ n
```
```
i = 1
```
```
( Xi − X )^2
```
##### =

```
∑ n
```
```
i = 1
```
```
( Xi −μ)^2 − n ( X −μ)^2
```
```
Upon dividing the preceding equation byσ^2 , we obtain
```
```
( n − 1 ) S^2
σ^2
```
##### +

##### (

```
X −μ
σ/
```
##### √

```
n
```
##### ) 2

##### =

```
∑ n
```
```
i = 1
```
##### (

```
Xi −μ
σ
```
##### ) 2

##### (8.2)

```
Now,
∑ n
```
```
i = 1
```
##### (

```
Xi −μ
σ
```
##### ) 2

```
is the sum of the squares of n independent standard normal random variables and so
is a chi-squared random variable with n degrees of freedom. Hence, from Example 7i,
its moment generating function is( 1 − 2 t )− n /^2. Also, because
(
X −μ
σ/
```
##### √

```
n
```
##### ) 2

```
is the square of a standard normal variable, it is a chi-squared random variable with
1 degree of freedom, and so has moment generating function( 1 − 2 t )−^1 /^2. Now, we
have seen previously that the two random variables on the left side of Equation (8.2)
are independent. Hence, as the moment generating function of the sum of indepen-
dent random variables is equal to the product of their individual moment generating
functions, we have
```
```
E [ et ( n −^1 ) S
```
(^2) /σ 2
]( 1 − 2 _t_ )−^1 /^2 =( 1 − 2 _t_ )− _n_ /^2
or
_E_ [ _et_ ( _n_ −^1 ) _S_
(^2) /σ 2
]=( 1 − 2 _t_ )−( _n_ −^1 )/^2
But as( 1 − 2 _t_ )−( _n_ −^1 )/^2 is the moment generating function of a chi-squared random
variable with _n_ −1 degrees of freedom, we can conclude, since the moment gener-
ating function uniquely determines the distribution of the random variable, it follows
that that is the distribution of( _n_ − 1 ) _S_^2 /σ^2.
Summing up, we have shown the following.


```
Section 7.9 General Definition of Expectation 369
```
```
Proposition 8.1. If X 1 ,..., Xn are independent and identically distributed normal
random variables with meanμand varianceσ^2 , then the sample mean X and the
sample variance S^2 are independent. X is a normal random variable with meanμand
varianceσ^2 / n ;( n − 1 ) S^2 /σ^2 is a chi-squared random variable with n −1 degrees of
freedom.
```
### 7.9 General Definition of Expectation

```
Up to this point, we have defined expectations only for discrete and continuous ran-
dom variables. However, there also exist random variables that are neither discrete
nor continuous, and they, too, may possess an expectation. As an example of such a
random variable, let X be a Bernoulli random variable with parameter p =^12 , and let
Y be a uniformly distributed random variable over the interval [0, 1]. Furthermore,
suppose that X and Y are independent, and define the new random variable W by
```
##### W =

##### {

```
X if X = 1
Y if X Z 1
```
```
Clearly, W is neither a discrete (since its set of possible values, [0, 1], is uncountable)
nor a continuous (since P { W = 1 }=^12 ) random variable.
In order to define the expectation of an arbitrary random variable, we require the
notion of a Stieltjes integral. Before defining this integral, let us recall that, for any
function g ,
```
```
∫ b
ag ( x ) dx is defined by
∫ b
```
```
a
```
```
g ( x ) dx =lim
```
```
∑ n
```
```
i = 1
```
```
g ( xi )( xi − xi − 1 )
```
```
where the limit is taken over all a = x 0 < x 1 < x 2 ···< xn = b as n →qand where
max
i =1,..., n
```
```
( xi − xi − 1 )→0.
For any distribution function F , we define the Stieltjes integral of the nonnegative
function g over the interval [ a , b ]by
∫ b
```
```
a
```
```
g ( x ) dF ( x )=lim
```
```
∑ n
```
```
i = 1
```
```
g ( xi )[ F ( xi )− F ( xi − 1 )]
```
```
where, as before, the limit is taken over all a = x 0 < x 1 <···< xn = b as n →qand
where max
i =1,..., n
```
```
( xi − xi − 1 )→0. Further, we define the Stieltjes integral over the whole
```
```
real line by
∫q
```
```
−q
```
```
g ( x ) dF ( x )= lim
a →−q
b →+q
```
```
∫ b
```
```
a
```
```
g ( x ) dF ( x )
```
```
Finally, if g is not a nonnegative function, we define g +and g −by
```
```
g +( x )=
```
##### {

```
g ( x ) if g ( x )Ú 0
0if g ( x )< 0
```
```
g −( x )=
```
##### {

```
0if g ( x )Ú 0
− g ( x ) if g ( x )< 0
```

**370** Chapter 7 Properties of Expectation

```
Because g ( x )= g +( x )− g −( x )and g +and g −are both nonnegative functions, it is
natural to define
∫q
```
```
−q
```
```
g ( x ) dF ( x )=
```
```
∫q
```
```
−q
```
```
g +( x ) dF ( x )−
```
```
∫q
```
```
−q
```
```
g −( x ) dF ( x )
```
```
and we say that
```
```
∫q
−q g ( x ) dF ( x )exists as long as
```
```
∫q
−q g
```
```
+( x ) dF ( x )and∫q
−q g
```
```
−( x ) dF ( x )
are not both equal to+q.
If X is an arbitrary random variable having cumulative distribution F , we define
the expected value of X by
E [ X ]=
```
```
∫q
```
```
−q
```
```
xdF ( x ) (9.1)
```
```
It can be shown that if X is a discrete random variable with mass function p ( x ),then
∫q
```
```
−q
```
```
xdF ( x )=
```
##### ∑

```
x : p ( x )> 0
```
```
xp ( x )
```
```
whereas if X is a continuous random variable with density function f ( x ),then
∫q
```
```
−q
```
```
xdF ( x )=
```
```
∫q
```
```
−q
```
```
xf ( x ) dx
```
```
The reader should note that Equation (9.1) yields an intuitive definition of E [ X ];
consider the approximating sum
∑ n
```
```
i = 1
```
```
xi [ F ( xi )− F ( xi − 1 )]
```
```
of E [ X ]. Because F ( xi )− F ( xi − 1 )is just the probability that X will be in the interval
( xi − 1 , xi ], the approximating sum multiplies the approximate value of X whenitisin
the interval ( xi − 1 , xi ] by the probability that it will be in that interval and then sums
over all the intervals. Clearly, as these intervals get smaller and smaller in length, we
obtain the “expected value” of X.
Stieltjes integrals are mainly of theoretical interest because they yield a compact
way of defining and dealing with the properties of expectation. For instance, the use
of Stieltjes integrals avoids the necessity of having to give separate statements and
proofs of theorems for the continuous and the discrete cases. However, their prop-
erties are very much the same as those of ordinary integrals, and all of the proofs
presented in this chapter can easily be translated into proofs in the general case.
```
#### Summary

```
If X and Y have a joint probability mass function p ( x , y ), then
```
```
E [ g ( X , Y )]=
```
##### ∑

```
y
```
##### ∑

```
x
```
```
g ( x , y ) p ( x , y )
```
```
whereas if they have a joint density function f ( x , y ), then
```
```
E [ g ( X , Y )]=
```
```
∫q
```
```
−q
```
```
∫q
```
```
−q
```
```
g ( x , y ) f ( x , y ) dx dy
```
```
A consequence of the preceding equations is that
```
```
E [ X + Y ]= E [ X ] + E [ Y ]
```

```
Summary 371
```
which generalizes to

```
E
```
##### ⎡

##### ⎣

```
∑ n
```
```
i = 1
```
```
Xi
```
##### ⎤

##### ⎦=

```
∑ n
```
```
i = 1
```
```
E [ Xi ]
```
The _covariance_ between random variables _X_ and _Y_ is given by

```
Cov( X , Y )= E [( X − E [ X ])( Y − E [ Y ])]= E [ XY ]− E [ X ] E [ Y ]
```
A useful identity is

```
Cov
```
##### ⎛

##### ⎜

##### ⎝

```
∑ n
```
```
i = 1
```
```
Xi ,
```
```
∑ m
```
```
j = 1
```
```
Yj
```
##### ⎞

##### ⎟

##### ⎠=

```
∑ n
```
```
i = 1
```
```
∑ m
```
```
j = 1
```
```
Cov( Xi , Yj )
```
When _n_ = _m_ and _Yi_ = _Xi_ , _i_ =1,..., _n_ , the preceding formula gives

```
Var
```
##### ⎛

##### ⎝

```
∑ n
```
```
i = 1
```
```
Xi
```
##### ⎞

##### ⎠=

```
∑ n
```
```
i = 1
```
```
Var( Xi )+ 2
```
##### ∑∑

```
i < j
```
```
Cov( Xi , Yj )
```
The correlation between _X_ and _Y_ , denoted byρ( _X_ , _Y_ ), is defined by

```
ρ( X , Y )=
```
```
Cov( X , Y )
√
Var( X )Var( Y )
```
If _X_ and _Y_ are jointly discrete random variables, then the conditional expected value
of _X_ , given that _Y_ = _y_ , is defined by

```
E [ X | Y = y ]=
```
##### ∑

```
x
```
```
xP { X = x | Y = y ]
```
If _X_ and _Y_ are jointly continuous random variables, then

```
E [ X | Y = y ]=
```
```
∫q
```
```
−q
```
```
xfX | Y ( x | y )
```
where

```
fX | Y ( x | y )=
```
```
f ( x , y )
fY ( y )
```
is the conditional probability density of _X_ given that _Y_ = _y_. Conditional expecta-
tions, which are similar to ordinary expectations except that all probabilities are now
computed conditional on the event that _Y_ = _y_ , satisfy all the properties of ordinary
expectations.
Let _E_ [ _X_ | _Y_ ] denote that function of _Y_ whose value at _Y_ = _y_ is _E_ [ _X_ | _Y_ = _y_ ]. A very
useful identity is
_E_ [ _X_ ]= _E_ [ _E_ [ _X_ | _Y_ ]]

In the case of discrete random variables, this equation reduces to the identity

```
E [ X ]=
```
##### ∑

```
y
```
```
E [ X | Y = y ] P { Y = y }
```
and, in the continuous case, to

##### E [ X ]=

```
∫q
```
```
−q
```
```
E [ X | Y = y ] fY ( y )
```

**372** Chapter 7 Properties of Expectation

```
The preceding equations can often be applied to obtain E [ X ] by first “conditioning”
on the value of some other random variable Y. In addition, since, for any event A ,
P ( A )= E [ IA ], where IA is 1 if A occurs and is 0 otherwise, we can use the same
equations to compute probabilities.
The conditional variance of X , given that Y = y , is defined by
```
```
Var( X | Y = y )= E [( X − E [ X | Y = y ])^2 | Y = y ]
```
```
Let Var( X | Y )be that function of Y whose value at Y = y is Var( X | Y = y ). The
following is known as the conditional variance formula :
```
```
Var( X )= E [Var( X | Y )]+Var( E [ X | Y ])
```
```
Suppose that the random variable X is to be observed and, on the basis of its value,
one must then predict the value of the random variable Y. In such a situation, it turns
out that, among all predictors, E [ Y | X ] has the smallest expectation of the square of
the difference between it and Y.
The moment generating function of the random variable X is defined by
```
```
M ( t )= E [ etX ]
```
```
The moments of X can be obtained by successively differentiating M ( t )and then
evaluating the resulting quantity at t =0. Specifically, we have
```
```
E [ Xn ]=
```
```
dn
dtn
```
```
M ( t )
```
##### ∣

##### ∣

##### ∣

##### ∣

##### ∣

```
t = 0
```
```
n =1, 2,...
```
```
Two useful results concerning moment generating functions are, first, that the
moment generating function uniquely determines the distribution function of the
random variable and, second, that the moment generating function of the sum of
independent random variables is equal to the product of their moment generating
functions. These results lead to simple proofs that the sum of independent normal
(Poisson, gamma) random variables remains a normal (Poisson, gamma) random
variable.
If X 1 ,..., Xm are all linear combinations of a finite set of independent standard
normal random variables, then they are said to have a multivariate normal distri-
bution. Their joint distribution is specified by the values of E [ Xi ], Cov( Xi , Xj ), i , j =
1,..., m.
If X 1 ,..., Xn are independent and identically distributed normal random variables,
then their sample mean
```
```
X =
```
```
∑ n
```
```
i = 1
```
```
Xi
n
```
```
and their sample variance
```
```
S^2 =
```
```
∑ n
```
```
i = 1
```
```
( Xi − X )^2
n − 1
```
```
are independent. The sample mean X is a normal random variable with meanμand
varianceσ^2 / n ; the random variable( n − 1 ) S^2 /σ^2 is a chi-squared random variable
with n −1 degrees of freedom.
```

```
Problems 373
```
#### Problems...................................

**7.1.** A player throws a fair die and simultaneously
flips a fair coin. If the coin lands heads, then she
wins twice, and if tails, then one-half of the value
that appears on the die. Determine her expected
winnings.
**7.2.** The game of Clue involves 6 suspects, 6 weapons,
and 9 rooms. One of each is randomly chosen and
the object of the game is to guess the chosen three.
**(a)** How many solutions are possible?
In one version of the game, the selection is
made and then each of the players is randomly
given three of the remaining cards. Let _S_ , _W_ ,
and _R_ be, respectively, the numbers of sus-
pects, weapons, and rooms in the set of three
cards given to a specified player. Also, let _X_
denote the number of solutions that are possi-
ble after that player observes his or her three
cards.
**(b)** Express _X_ in terms of _S_ , _W_ ,and _R_.
**(c)** Find _E_ [ _X_ ].
**7.3.** Gambles are independent, and each one results in
the player being equally likely to win or lose 1 unit.
Let _W_ denote the net winnings of a gambler whose
strategy is to stop gambling immediately after his
first win. Find
**(a)** _P_ { _W_ > 0 }
**(b)** _P_ { _W_ < 0 }
**(c)** _E_ [ _W_ ]
**7.4.** If _X_ and _Y_ have joint density function

```
fX , Y ( x , y )=
```
```
{
1 / y ,if0< y <1, 0< x < y
0, otherwise
```
find
**(a)** _E_ [ _XY_ ]
**(b)** _E_ [ _X_ ]
**(c)** _E_ [ _Y_ ]
**7.5.** The county hospital is located at the center of a
square whose sides are 3 miles wide. If an accident
occurs within this square, then the hospital sends
out an ambulance. The road network is rectangu-
lar, so the travel distance from the hospital, whose
coordinates are (0, 0), to the point ( _x_ , _y_ )is| _x_ |+| _y_ |.
If an accident occurs at a point that is uniformly
distributed in the square, find the expected travel
distance of the ambulance.
**7.6.** A fair die is rolled 10 times. Calculate the expected
sum of the 10 rolls.
**7.7.** Suppose that _A_ and _B_ each randomly and indepen-
dently choose 3 of 10 objects. Find the expected
number of objects
**(a)** chosen by both _A_ and _B_ ;
**(b)** not chosen by either _A_ or _B_ ;
**(c)** chosen by exactly one of _A_ and _B_.

```
7.8. N people arrive separately to a professional din-
ner. Upon arrival, each person looks to see if he
or she has any friends among those present. That
person then sits either at the table of a friend or
at an unoccupied table if none of those present
is a friend. Assuming that each of the
```
```
(
N
2
```
```
)
```
```
pairs of people is, independently, a pair of friends
with probability p , find the expected number of
occupied tables.
Hint :Let Xi equal 1 or 0, depending on whether
the i th arrival sits at a previously unoccupied
table.
7.9. A total of n balls, numbered 1 through n , are put
into n urns, also numbered 1 through n in such a
way that ball i is equally likely to go into any of the
urns 1, 2,..., i .Find
(a) the expected number of urns that are empty;
(b) the probability that none of the urns is
empty.
7.10. Consider 3 trials, each having the same proba-
bility of success. Let X denote the total num-
ber of successes in these trials. If E [ X ] = 1 .8,
what is
(a) the largest possible value of P { X = 3 }?
(b) the smallest possible value of P { X = 3 }?
In both cases, construct a probability scenario that
results in P { X = 3 }having the stated value.
Hint : For part (b), you might start by letting U be a
uniform random variable on (0, 1) and then defin-
ing the trials in terms of the value of U.
7.11. Consider n independent flips of a coin having
probability p of landing on heads. Say that a
changeover occurs whenever an outcome differs
from the one preceding it. For instance, if n =
5 and the outcome is HHTHT , then there are
3 changeovers. Find the expected number of
changeovers.
Hint : Express the number of changeovers as the
sum of n −1 Bernoulli random variables.
7.12. A group of n men and n women is lined up at
random.
(a) Find the expected number of men who have a
woman next to them.
(b) Repeat part (a), but now assuming that the
group is randomly seated at a round table.
7.13. A set of 1000 cards numbered 1 through 1000
is randomly distributed among 1000 people with
each receiving one card. Compute the expected
number of cards that are given to people whose
age matches the number on the card.
7.14. An urn has m black balls. At each stage, a black
ball is removed and a new ball that is black with
```

**374** Chapter 7 Properties of Expectation

```
probability p and white with probability 1 − p
is put in its place. Find the expected number of
stages needed until there are no more black balls
in the urn.
NOTE: The preceding has possible applications
to understanding the AIDS disease. Part of the
body’s immune system consists of a certain class
of cells known as T-cells. There are 2 types of T-
cells, called CD4 and CD8. Now, while the total
number of T-cells in AIDS sufferers is (at least in
the early stages of the disease) the same as that
in healthy individuals, it has recently been dis-
covered that the mix of CD4 and CD8 T-cells is
different. Roughly 60 percent of the T-cells of a
healthy person are of the CD4 type, whereas the
percentage of the T-cells that are of CD4 type
appears to decrease continually in AIDS sufferers.
A recent model proposes that the HIV virus (the
virus that causes AIDS) attacks CD4 cells and that
the body’s mechanism for replacing killed T-cells
does not differentiate between whether the killed
T-cell was CD4 or CD8. Instead, it just produces
a new T-cell that is CD4 with probability .6 and
CD8 with probability .4. However, although this
would seem to be a very efficient way of replac-
ing killed T-cells when each one killed is equally
likely to be any of the body’s T-cells (and thus has
probability .6 of being CD4), it has dangerous con-
sequences when facing a virus that targets only the
CD4 T-cells.
7.15. In Example 2h, say that i and j , i Z j ,forma
matched pair if i chooses the hat belonging to j and
j chooses the hat belonging to i. Find the expected
number of matched pairs.
7.16. Let Z be a standard normal random variable, and,
for a fixed x ,set
```
```
X =
```
```
{
Z if Z > x
0 otherwise
```
```
Show that E [ X ]=
1
√
2 π
```
```
e − x
```
(^2) / 2
.
**7.17.** Adeckof _n_ cards numbered 1 through _n_ is thor-
oughly shuffled so that all possible _n_! orderings can
be assumed to be equally likely. Suppose you are
to make _n_ guesses sequentially, where the _i_ th one
is a guess of the card in position _i_ .Let _N_ denote
the number of correct guesses.
**(a)** If you are not given any information about
your earlier guesses show that, for any strat-
egy, _E_ [ _N_ ]=1.
**(b)** Suppose that after each guess you are shown
the card that was in the position in question.
What do you think is the best strategy? Show
that, under this strategy,
_E_ [ _N_ ]=
1
_n_
+
1
_n_ − 1
+ ··· + 1
L
∫ _n_
1
1
_x
dx_ =log _n_
**(c)** Suppose that you are told after each guess
whether you are right or wrong. In this case,
it can be shown that the strategy which maxi-
mizes _E_ [ _N_ ] is one that keeps on guessing the
same card until you are told you are correct
and then changes to a new card. For this strat-
egy, show that
_E_ [ _N_ ]= 1 +
1
2!
+
1
3!
+ ··· +
1
_n_!
L _e_ − 1
_Hint_ : For all parts, express _N_ as the sum of indica-
tor (that is, Bernoulli) random variables.
**7.18.** Cards from an ordinary deck of 52 playing cards
are turned face up one at a time. If the 1st card
is an ace, or the 2nd a deuce, or the 3rd a three,
or..., or the 13th a king, or the 14 an ace, and so
on, we say that a match occurs. Note that we do
not require that the (13 _n_ +1)th card be any par-
ticular ace for a match to occur but only that it be
an ace. Compute the expected number of matches
that occur.
**7.19.** A certain region is inhabited by _r_ distinct types of
a certain species of insect. Each insect caught will,
independently of the types of the previous catches,
be of type _i_ with probability
_Pi_ , _i_ =1,..., _r_
∑ _r_
1
_Pi_ = 1
**(a)** Compute the mean number of insects that are
caught before the first type 1 catch.
**(b)** Compute the mean number of types of insects
that are caught before the first type 1 catch.
**7.20.** In an urn containing _n_ balls, the _i_ th ball has weight
_W_ ( _i_ ), _i_ = 1,..., _n_. The balls are removed with-
out replacement, one at a time, according to the
following rule: At each selection, the probabil-
ity that a given ball in the urn is chosen is equal
to its weight divided by the sum of the weights
remaining in the urn. For instance, if at some
time _i_ 1 ,..., _ir_ is the set of balls remaining in the
urn, then the next selection will be _ij_ with prob-
ability _W_ ( _ij_ )
/∑ _r
k_ = 1
_W_ ( _ik_ ), _j_ = 1,..., _r_. Compute
the expected number of balls that are withdrawn
before ball number 1 is removed.
**7.21.** For a group of 100 people, compute
**(a)** the expected number of days of the year that
are birthdays of exactly 3 people:
**(b)** the expected number of distinct birthdays.


```
Problems 375
```
```
7.22. How many times would you expect to roll a fair die
before all 6 sides appeared at least once?
7.23. Urn 1 contains 5 white and 6 black balls, while urn
2 contains 8 white and 10 black balls. Two balls
are randomly selected from urn 1 and are put into
urn 2. If 3 balls are then randomly selected from
urn 2, compute the expected number of white balls
in the trio.
Hint :Let Xi =1ifthe i th white ball initially in urn
1 is one of the three selected, and let Xi =0other-
wise. Similarly, let Yi =1ifthe i th white ball from
urn 2 is one of the three selected, and let Yi = 0
otherwise. The number of white balls in the trio
can now be written as
```
```
∑^5
1
```
```
Xi +
```
```
∑^8
1
```
```
Yi.
7.24. A bottle initially contains m large pills and n small
pills. Each day, a patient randomly chooses one of
the pills. If a small pill is chosen, then that pill is
eaten. If a large pill is chosen, then the pill is bro-
ken in two; one part is returned to the bottle (and
is now considered a small pill) and the other part
is then eaten.
(a) Let X denote the number of small pills in the
bottle after the last large pill has been chosen
and its smaller half returned. Find E [ X ].
Hint : Define n + m indicator variables, one for
each of the small pills initially present and one
for each of the m small pills created when a large
one is split in two. Now use the argument of
Example 2m.
(b) Let Y denote the day on which the last large
pill is chosen. Find E [ Y ].
Hint : What is the relationship between X and Y?
7.25. Let X 1 , X 2 ,...be a sequence of independent and
identically distributed continuous random vari-
ables. Let N Ú2 be such that
```
```
X 1 Ú X 2 Ú···Ú XN − 1 < XN
```
That is, _N_ is the point at which the sequence stops
decreasing. Show that _E_ [ _N_ ]= _e_.
_Hint_ : First find _P_ { _N_ Ú _n_ }.
**7.26.** If _X_ 1 , _X_ 2 ,..., _Xn_ are independent and identically
distributed random variables having uniform dis-
tributions over (0, 1), find
**(a)** _E_ [max( _X_ 1 ,..., _Xn_ )];
**(b)** _E_ [min( _X_ 1 ,..., _Xn_ )].
∗ **7.27.** If 101 items are distributed among 10 boxes, then

at least one of the boxes must contain more than 10
items. Use the probabilistic method to prove this
result.
∗ **7.28.** The _k_ -of- _r_ -out-of- _n_ circular reliability system, _k_ ...

```
r ... n , consists of n components that are arranged in
a circular fashion. Each component is either func-
tional or failed, and the system functions if there
is no block of r consecutive components of which
```
```
at least k are failed. Show that there is no way
to arrange 47 components, 8 of which are failed,
to make a functional 3-of-12-out-of-47 circular
system.
∗ 7.29. There are 4 different types of coupons, the first
2 of which compose one group and the second 2
another group. Each new coupon obtained is type i
with probability pi ,where p 1 = p 2 = 1 /8, p 3 =
p 4 = 3 /8. Find the expected number of coupons
that one must obtain to have at least one of
(a) all 4 types;
(b) all the types of the first group;
(c) all the types of the second group;
(d) all the types of either group.
7.30. If X and Y are independent and identically dis-
tributed with meanμand varianceσ^2 , find
```
```
E [( X − Y )^2 ]
```
```
7.31. In Problem 6, calculate the variance of the sum of
the rolls.
7.32. In Problem 9, compute the variance of the number
of empty urns.
7.33. If E [ X ]=1andVar( X )=5, find
(a) E [( 2 + X )^2 ];
(b) Var( 4 + 3 X ).
7.34. If 10 married couples are randomly seated at a
round table, compute (a) the expected number and
(b) the variance of the number of wives who are
seated next to their husbands.
7.35. Cards from an ordinary deck are turned face up
one at a time. Compute the expected number of
cards that need to be turned face up in order to
obtain
(a) 2aces;
(b) 5 spades;
(c) all 13 hearts.
7.36. Let X be the number of 1’s and Y the number
of 2’s that occur in n rolls of a fair die. Compute
Cov( X , Y ).
7.37. A die is rolled twice. Let X equal the sum of the
outcomes, and let Y equal the first outcome minus
the second. Compute Cov( X , Y ).
7.38. The random variables X and Y have a joint density
function given by
```
```
f ( x , y )=
```
```
{
2 e −^2 x / x 0 ... x <q,0... y ... x
0 otherwise
```
```
Compute Cov( X , Y ).
7.39. Let X 1 ,...be independent with common meanμ
and common varianceσ^2 ,andset Yn = Xn +
Xn + 1 + Xn + 2 .For j Ú0, find Cov( Yn , Yn + j ).
```

**376** Chapter 7 Properties of Expectation

```
7.40. The joint density function of X and Y is given by
```
```
f ( x , y )=
1
y
```
```
e −( y + x / y ), x >0, y > 0
```
```
Find E [ X ], E [ Y ], and show that Cov( X , Y )=1.
7.41. A pond contains 100 fish, of which 30 are carp. If 20
fish are caught, what are the mean and variance of
the number of carp among the 20? What assump-
tions are you making?
7.42. A group of 20 people consisting of 10 men and
10 women is randomly arranged into 10 pairs of
2 each. Compute the expectation and variance of
the number of pairs that consist of a man and a
woman. Now suppose the 20 people consist of 10
married couples. Compute the mean and variance
of the number of married couples that are paired
together.
7.43. Let X 1 , X 2 ,..., Xn be independent random vari-
ables having an unknown continuous distribution
function F ,andlet Y 1 , Y 2 ,..., Ym be independent
random variables having an unknown continuous
distribution function G. Now order those n + m
variables, and let
```
```
Ii =
```
```
⎧
⎨
⎩
```
```
1ifthe i th smallest of the n + m
variables is from the X sample
0 otherwise
```
```
The random variable R =
```
```
n ∑+ m
i = 1
```
```
iIi is the sum of the
ranks of the X sample and is the basis of a standard
statistical procedure (called the Wilcoxon sum-of-
ranks test) for testing whether F and G are iden-
tical distributions. This test accepts the hypothesis
that F = G when R is neither too large nor too
small. Assuming that the hypothesis of equality is
in fact correct, compute the mean and variance
of R.
Hint : Use the results of Example 3e.
7.44. Between two distinct methods for manufacturing
certain goods, the quality of goods produced by
method i is a continuous random variable having
distribution Fi , i =1, 2. Suppose that n goods are
produced by method 1 and m by method 2. Rank
the n + m goods according to quality, and let
```
```
Xj =
```
```
⎧
⎨
⎩
```
```
1ifthe j th best was produced from
method 1
2 otherwise
```
```
For the vector X 1 , X 2 ,..., Xn + m , which consists of
n 1’s and m 2’s, let R denote the number of runs
of 1. For instance, if n = 5, m = 2, and X =
1, 2, 1, 1, 1, 1, 2, then R =2. If F 1 = F 2 (that is,
if the two methods produce identically distributed
goods), what are the mean and variance of R?
```
```
7.45. If X 1 , X 2 , X 3 ,and X 4 are (pairwise) uncorrelated
random variables, each having mean 0 and vari-
ance 1, compute the correlations of
(a) X 1 + X 2 and X 2 + X 3 ;
(b) X 1 + X 2 and X 3 + X 4.
7.46. Consider the following dice game, as played at a
certain gambling casino: Players 1 and 2 roll a pair
of dice in turn. The bank then rolls the dice to
determine the outcome according to the follow-
ing rule: Player i , i =1, 2, wins if his roll is strictly
greater than the bank’s. For i =1, 2, let
```
```
Ii =
```
```
{
1if i wins
0 otherwise
```
```
and show that I 1 and I 2 are positively correlated.
Explain why this result was to be expected.
7.47. Consider a graph having n vertices labeled
1, 2,( ..., n , and suppose that, between each of the
n
2
```
```
)
pairs of distinct vertices, an edge is indepen-
dently present with probability p. The degree of
vertex i ,designatedas Di , is the number of edges
that have vertex i as one of their vertices.
(a) What is the distribution of Di?
(b) Findρ( Di , Dj ), the correlation between Di
and Dj.
7.48. A fair die is successively rolled. Let X and Y
denote, respectively, the number of rolls necessary
to obtain a 6 and a 5. Find
(a) E [ X ];
(b) E [ X | Y =1];
(c) E [ X | Y =5].
7.49. There are two misshapen coins in a box; their
probabilities for landing on heads when they are
flipped are, respectively,.4and.7. One of the coins
is to be randomly chosen and flipped 10 times.
Given that two of the first three flips landed on
heads, what is the conditional expected number of
heads in the 10 flips?
7.50. The joint density of X and Y is given by
```
```
f ( x , y )=
e − x / ye − y
y
```
```
,0< x <q,0< y <q
```
```
Compute E [ X^2 | Y = y ].
7.51. The joint density of X and Y is given by
```
```
f ( x , y )=
```
```
e − y
y
,0< x < y ,0< y <q
```
```
Compute E [ X^3 | Y = y ].
7.52. A population is made up of r disjoint subgroups.
Let pi denote the proportion of the population that
is in subgroup i , i =1,..., r. If the average weight
of the members of subgroup i is wi , i =1,..., r ,
what is the average weight of the members of the
population?
```

```
Problems 377
```
**7.53.** A prisoner is trapped in a cell containing 3 doors.
The first door leads to a tunnel that returns him
to his cell after 2 days’ travel. The second leads
to a tunnel that returns him to his cell after 4
days’ travel. The third door leads to freedom after
1 day of travel. If it is assumed that the pris-
oner will always select doors 1, 2, and 3 with
respective probabilities .5, .3, and .2, what is the
expected number of days until the prisoner reaches
freedom?
**7.54.** Consider the following dice game: A pair of dice
is rolled. If the sum is 7, then the game ends and
you win 0. If the sum is not 7, then you have the
option of either stopping the game and receiv-
ing an amount equal to that sum or starting over
again. For each value of _i_ , _i_ =2,..., 12, find your
expected return if you employ the strategy of stop-
ping the first time that a value at least as large
as _i_ appears. What value of _i_ leads to the largest
expected return?
_Hint_ :Let _Xi_ denote the return when you use the
critical value _i_. To compute _E_ [ _Xi_ ], condition on the
initial sum.
**7.55.** Ten hunters are waiting for ducks to fly by. When
a flock of ducks flies overhead, the hunters fire at
the same time, but each chooses his target at ran-
dom, independently of the others. If each hunter
independently hits his target with probability .6,
compute the expected number of ducks that are
hit. Assume that the number of ducks in a flock is
a Poisson random variable with mean 6.
**7.56.** The number of people who enter an elevator on
the ground floor is a Poisson random variable with
mean 10. If there are _N_ floors above the ground
floor, and if each person is equally likely to get off
at any one of the _N_ floors, independently of where
the others get off, compute the expected number
of stops that the elevator will make before dis-
charging all of its passengers.
**7.57.** Suppose that the expected number of accidents per
week at an industrial plant is 5. Suppose also that
the numbers of workers injured in each accident
are independent random variables with a common
mean of 2.5. If the number of workers injured in
each accident is independent of the number of
accidents that occur, compute the expected num-
ber of workers injured in a week.
**7.58.** A coin having probability _p_ of coming up heads is
continually flipped until both heads and tails have
appeared. Find
**(a)** the expected number of flips;
**(b)** the probability that the last flip lands on
heads.
**7.59.** There are _n_ + 1 participants in a game. Each
person independently is a winner with probabil-
ity _p_. The winners share a total prize of 1 unit.

```
(For instance, if 4 people win, then each of them
receives^14 , whereas if there are no winners, then
none of the participants receive anything.) Let A
denote a specified one of the players, and let X
denote the amount that is received by A.
(a) Compute the expected total prize shared by
the players.
```
```
(b) Argue that E [ X ]=
```
```
1 −( 1 − p ) n +^1
n + 1
```
```
.
(c) Compute E [ X ] by conditioning on whether A
is a winner, and conclude that
```
```
E [( 1 + B )−^1 ]=
1 −( 1 − p ) n +^1
( n + 1 ) p
```
```
when B is a binomial random variable with param-
eters n and p.
7.60. Each of m + 2 players pays 1 unit to a kitty in
order to play the following game: A fair coin is to
be flipped successively n times, where n is an odd
number, and the successive outcomes are noted.
Before the n flips, each player writes down a pre-
diction of the outcomes. For instance, if n = 3,
then a player might write down( H , H , T ),which
means that he or she predicts that the first flip
will land on heads, the second on heads, and the
third on tails. After the coins are flipped, the play-
ers count their total number of correct predictions.
Thus, if the actual outcomes are all heads, then the
player who wrote ( H , H , T ) would have 2 correct
predictions. The total kitty of m +2 is then evenly
split up among those players having the largest
number of correct predictions.
Since each of the coin flips is equally likely to
land on either heads or tails, m of the players have
decided to make their predictions in a totally ran-
dom fashion. Specifically, they will each flip one
of their own fair coins n times and then use the
result as their prediction. However, the final 2 of
the players have formed a syndicate and will use
the following strategy: One of them will make pre-
dictions in the same random fashion as the other
m players, but the other one will then predict
exactly the opposite of the first. That is, when the
randomizing member of the syndicate predicts an
H , the other member predicts a T .Forinstance,
if the randomizing member of the syndicate
predicts ( H , H , T ), then the other one predicts ( T ,
T , H ).
(a) Argue that exactly one of the syndicate mem-
bers will have more than n /2 correct predic-
tions. (Remember, n is odd.)
(b) Let X denote the number of the m nonsyndi-
cate players that have more than n /2 correct
predictions. What is the distribution of X?
```

**378** Chapter 7 Properties of Expectation

```
(c) With X as defined in part (b), argue that
```
```
E [payoff to the syndicate]=( m + 2 )
```
```
* E
```
```
[
1
X + 1
```
```
]
```
```
(d) Use part (c) of Problem 59 to conclude that
```
```
E [payoff to the syndicate]=
```
```
2 ( m + 2 )
m + 1
```
```
*
```
```
[
1 −
```
```
(
1
2
```
```
) m + 1 ]
```
```
and explicitly compute this number when m =
1, 2, and 3. Because it can be shown that
```
```
2 ( m + 2 )
m + 1
```
```
[
1 −
```
```
(
1
2
```
```
) m + 1 ]
> 2
```
```
it follows that the syndicate’s strategy always
gives it a positive expected profit.
7.61. Let X 1 ,...be independent random variables with
the common distribution function F , and sup-
pose they are independent of N , a geometric
random variable with parameter p .Let M =
max( X 1 ,..., XN ).
(a) Find P { M ... x }by conditioning on N.
(b) Find P { M ... x | N = 1 }.
(c) Find P { M ... x | N > 1 }.
(d) Use (b) and (c) to rederive the probability you
found in (a).
7.62. Let U 1 , U 2 ,...be a sequence of independent uni-
form (0, 1) random variables. In Example 5i we
showed that, for 0... x ...1, E [ N ( x )]= ex ,where
```
```
N ( x )=min
```
```
⎧
⎨
⎩
n :
```
```
∑ n
```
```
i = 1
```
```
Ui > x
```
```
⎫
⎬
⎭
```
```
This problem gives another approach to establish-
ing that result.
(a) Show by induction on n that, for 0< x ... 1
and all n Ú0,
```
```
P { N ( x )Ú n + 1 }=
xn
n!
Hint : First condition on U 1 andthenusethe
induction hypothesis.
Use part (a) to conclude that
```
```
E [ N ( x )]= ex
```
```
7.63. An urn contains 30 balls, of which 10 are red and
8 are blue. From this urn, 12 balls are randomly
withdrawn. Let X denote the number of red and Y
```
```
the number of blue balls that are withdrawn. Find
Cov( X , Y )
(a) by defining appropriate indicator (that is,
Bernoulli) random variables
```
```
Xi , Yj such that X =
```
```
∑^10
```
```
i = 1
```
```
Xi , Y =
```
```
∑^8
```
```
j = 1
```
```
Yj
```
```
(b) by conditioning (on either X or Y ) to deter-
mine E [ XY ].
7.64. Type i light bulbs function for a random amount
of time having meanμ i and standard deviation
σ i , i =1, 2. A light bulb randomly chosen from a
bin of bulbs is a type 1 bulb with probability p and
a type 2 bulb with probability 1− p .Let X denote
the lifetime of this bulb. Find
(a) E [ X ];
(b) Var( X ).
7.65. The number of winter storms in a good year is a
Poisson random variable with mean 3, whereas the
number in a bad year is a Poisson random variable
with mean 5. If next year will be a good year with
probability .4 or a bad year with probability .6, find
the expected value and variance of the number of
storms that will occur.
7.66. In Example 5c, compute the variance of the length
of time until the miner reaches safety.
7.67. Consider a gambler who, at each gamble, either
wins or loses her bet with respective probabilities p
and 1 − p. A popular gambling system known
as the Kelley strategy is to always bet the frac-
tion 2 p −1 of your current fortune when p >^12.
Compute the expected fortune after n gambles of
a gambler who starts with x units and employs the
Kelley strategy.
7.68. The number of accidents that a person has in
a given year is a Poisson random variable with
meanλ. However, suppose that the value of λ
changes from person to person, being equal to 2
for 60 percent of the population and 3 for the other
40 percent. If a person is chosen at random, what
is the probability that he will have (a) 0 accidents
and (b) exactly 3 accidents in a certain year? What
is the conditional probability that he will have 3
accidents in a given year, given that he had no acci-
dents the preceding year?
7.69. Repeat Problem 68 when the proportion of the
population having a value ofλless than x is equal
to 1− e − x.
7.70. Consider an urn containing a large number of
coins, and suppose that each of the coins has some
probability p of turning up heads when it is flipped.
However, this value of p varies from coin to coin.
Suppose that the composition of the urn is such
that if a coin is selected at random from it, then
```

```
Problems 379
```
the _p_ -value of the coin can be regarded as being
the value of a random variable that is uniformly
distributed over [0, 1]. If a coin is selected at ran-
dom from the urn and flipped twice, compute the
probability that
**(a)** the first flip results in a head;
**(b)** both flips result in heads.
**7.71.** In Problem 70, suppose that the coin is tossed _n_
times. Let _X_ denote the number of heads that
occur. Show that

```
P { X = i }=
1
n + 1
```
```
i =0, 1,..., n
```
```
Hint : Make use of the fact that
∫ 1
```
```
0
```
```
xa −^1 ( 1 − x ) b −^1 dx =
```
( _a_ − 1 )!( _b_ − 1 )!
( _a_ + _b_ − 1 )!
when _a_ and _b_ are positive integers.
**7.72.** Suppose that in Problem 70 we continue to flip the
coin until a head appears. Let _N_ denote the num-
ber of flips needed. Find
**(a)** _P_ { _N_ Ú _i_ }, _i_ Ú0;
**(b)** _P_ { _N_ = _i_ };
**(c)** _E_ [ _N_ ].
**7.73.** In Example 6b, let _S_ denote the signal sent and _R_
the signal received.
**(a)** Compute _E_ [ _R_ ].
**(b)** Compute Var( _R_ ).
**(c)** Is _R_ normally distributed?
**(d)** Compute Cov( _R_ , _S_ ).
**7.74.** In Example 6c, suppose that _X_ is uniformly dis-
tributed over (0, 1). If the discretized regions are
determined by _a_ 0 = 0, _a_ 1 =^12 ,and _a_ 2 = 1,
calculate the optimal quantizer _Y_ and compute
_E_ [( _X_ − _Y_ )^2 ].
**7.75.** The moment generating function of _X_ is given by
_MX_ ( _t_ )=exp{ 2 _et_ − 2 }and that of _Y_ by _MY_ ( _t_ )=
(^34 _et_ +^14 )^10 .If _X_ and _Y_ are independent, what are
**(a)** _P_ { _X_ + _Y_ = 2 }?
**(b)** _P_ { _XY_ = 0 }?
**(c)** _E_ [ _XY_ ]?
**7.76.** Let _X_ be the value of the first die and _Y_ the sum of
the values when two dice are rolled. Compute the
joint moment generating function of _X_ and _Y_.
**7.77.** The joint density of _X_ and _Y_ is given by

```
f ( x , y )=
1
√
2 π
```
```
e − ye −( x − y )
```
(^2) / 2
0 < _y_ <q,
−q< _x_ <q
**(a)** Compute the joint moment generating func-
tion of _X_ and _Y_.
**(b)** Compute the individual moment generating
functions.
**7.78.** Two envelopes, each containing a check, are
placed in front of you. You are to choose one of
the envelopes, open it, and see the amount of the
check. At this point, either you can accept that
amount or you can exchange it for the check in
the unopened envelope. What should you do? Is it
possible to devise a strategy that does better than
just accepting the first envelope?
Let _A_ and _B_ , _A_ < _B_ , denote the (unknown)
amounts of the checks, and note that the strat-
egy that randomly selects an envelope and always
accepts its check has an expected return of
( _A_ + _B_ )/2. Consider the following strategy: Let
_F_ (·)be any strictly increasing (that is, continu-
ous) distribution function. Choose an envelope
randomly and open it. If the discovered check has
the value _x_ , then accept it with probability _F_ ( _x_ )and
exchange it with probability 1− _F_ ( _x_ ).
**(a)** Show that if you employ the latter strategy,
then your expected return is greater than
( _A_ + _B_ )/2.
_Hint_ : Condition on whether the first envelope
has the value _A_ or _B_.
Now consider the strategy that fixes a value _x_
and then accepts the first check if its value is
greater than _x_ and exchanges it otherwise.
**(b)** Show that, for any _x_ , the expected return
under the _x_ -strategy is always at least
( _A_ + _B_ )/2 and that it is strictly larger than
( _A_ + _B_ )/2if _x_ lies between _A_ and _B_.
**(c)** Let _X_ be a continuous random variable on the
whole line, and consider the following strat-
egy: Generate the value of _X_ ,andif _X_ = _x_ ,
then employ the _x_ -strategy of part (b). Show
that the expected return under this strategy is
greater than( _A_ + _B_ )/2.
**7.79.** Successive weekly sales, in units of one thousand
dollars, have a bivariate normal distribution with
common mean 40, common standard deviation 6,
and correlation.6.
**(a)** Find the probability that the total of the next
2 weeks’ sales exceeds 90.
**(b)** If the correlation were.2 rather than.6, do
you think that this would increase or decrease
the answer to (a)? Explain your reasoning.
**(c)** Repeat (a) when the correlation is.2.


**380** Chapter 7 Properties of Expectation

#### Theoretical Exercises

```
7.1. Show that E [( X − a )^2 ] is minimized at a = E [ X ].
7.2. Suppose that X is a continuous random variable
with density function f. Show that E [| X − a |]is
minimized when a is equal to the median of F.
Hint :Write
```
```
E [| X − a |]=
```
```
∫
| x − a | f ( x ) dx
```
```
Now break up the integral into the regions where
x < a and where x > a , and differentiate.
7.3. Prove Proposition 2.1 when
(a) X and Y have a joint probability mass func-
tion;
(b) X and Y have a joint probability density func-
tion and g ( x , y )Ú0forall x , y.
7.4. Let X be a random variable having finite expec-
tationμand varianceσ^2 ,andlet g (·)be a twice
differentiable function. Show that
```
```
E [ g ( X )]L g (μ)+
g ”(μ)
2
```
```
σ^2
```
```
Hint : Expand g (·)in a Taylor series aboutμ.Use
the first three terms and ignore the remainder.
7.5. Let A 1 , A 2 ,..., An be arbitrary events, and define
Ck ={at least k of the Ai occur}. Show that
```
```
∑ n
```
```
k = 1
```
```
P ( Ck )=
```
```
∑ n
```
```
k = 1
```
```
P ( Ak )
```
```
Hint :Let X denote the number of the Ai that
occur. Show that both sides of the preceding equa-
tion are equal to E [ X ].
7.6. In the text, we noted that
```
```
E
```
```
⎡
⎣
```
```
∑q
```
```
i = 1
```
```
Xi
```
```
⎤
⎦=
```
```
∑q
```
```
i = 1
```
```
E [ Xi ]
```
```
when the Xi are all nonnegative random variables.
Since an integral is a limit of sums, one might
expect that
```
```
E
```
```
[∫q
```
```
0
```
```
X ( t ) dt
```
```
]
=
```
```
∫q
```
```
0
```
```
E [ X ( t )] dt
```
```
whenever X ( t ),0... t <q, are all nonnegative ran-
dom variables; and this result is indeed true. Use it
to give another proof of the result that, for a non-
negative random variable X ,
```
```
E [ X )=
```
```
∫q
```
```
0
```
```
P { X > t } dt
```
```
Hint : Define, for each nonnegative t , the random
variable X ( t )by
```
```
X ( t )=
```
```
{
1if t < X
0if t Ú X
```
```
Now relate
```
```
∫q
0 X ( t ) dt to X.
7.7. We say that X is stochastically larger than Y ,writ-
ten X Úst Y , if, for all t.
```
```
P { X > t }Ú P { Y > t }
```
```
Show that if X Úst Y ,then E [ X ]Ú E [ Y ]when
(a) X and Y are nonnegative random variables;
(b) X and Y are arbitrary random variables.
Hint :Write X as
```
```
X = X +− X −
```
```
where
```
```
X +=
```
```
{
X if X Ú 0
0if X < 0
, X −=
```
```
{
0if X Ú 0
− X if X < 0
```
```
Similarly, represent Y as Y +− Y −.Thenmake
useofpart(a).
7.8. Show that X is stochastically larger than Y if and
only if
E [ f ( X )]Ú E [ f ( Y )]
```
```
for all increasing functions f.
Hint : Show that X Úst Y ,then E [ f ( X )]Ú E [ f ( Y )]
by showing that f ( X )Úst f ( Y )andthenusingThe-
oretical Exercise 7.7. To show that if E [ f ( X )] Ú
E [ f ( Y )] for all increasing functions f ,then P { X >
t }Ú P { Y > t }, define an appropriate increasing
function f.
7.9. A coin having probability p of landing on heads
is flipped n times. Compute the expected number
of runs of heads of size 1, of size 2, and of size
k ,1... k ... n.
7.10. Let X 1 , X 2 ,..., Xn be independent and identically
distributed positive random variables. For k ... n ,
find
```
```
E
```
```
⎡
⎢⎢
⎢
⎢⎢
⎢
⎣
```
```
∑ k
```
```
i = 1
```
```
Xi
```
```
∑ n
```
```
i = 1
```
```
Xi
```
```
⎤
⎥⎥
⎥
⎥⎥
⎥
⎦
```
```
7.11. Consider n independent trials, each resulting in
any one of r possible outcomes with probabilities
P 1 , P 2 ,..., Pr .Let X denote the number of out-
comes that never occur in any of the trials. Find
```

```
Theoretical Exercises 381
```
```
E [ X ] and show that, among all probability vectors
P 1 ,..., Pr , E [ X ] is minimized when Pi = 1 / r , i =
1,..., r.
7.12. Let X 1 , X 2 ,... be a sequence of independent
random variables having the probability mass
function
```
```
P { Xn = 0 }= P { Xn = 2 }= 1 /2, n Ú 1
```
```
The random variable X =
```
```
∑q
n = 1 Xn /^3
n is said
to have the Cantor distribution .Find E [ X ]and
Var( X ).
7.13. Let X 1 ,..., Xn be independent and identically dis-
tributed continuous random variables. We say that
a record value occurs at time j , j ... n ,if Xj Ú Xi for
all 1... i ... j. Show that
```
```
(a) E [number of record values]=
```
```
∑ n
```
```
j = 1
```
```
1 / j ;
```
```
(b) Var(number of record values)=
```
```
∑ n
```
```
j = 1
```
```
( j − 1 )/ j^2.
```
```
7.14. For Example 2i, show that the variance of the
number of coupons needed to amass a full set is
equal to
N ∑− 1
```
```
i = 1
```
```
iN
( N − i )^2
```
When _N_ is large, this can be shown to be
approximately equal (in the sense that their ratio
approaches 1 as _N_ →q)to _N_^2 π^2 /6.
**7.15.** Consider _n_ independent trials, the _i_ th of which
results in a success with probability _Pi_.
**(a)** Compute the expected number of successes in
the _n_ trials—call itμ.
**(b)** For a fixed value of μ, what choice of
_P_ 1 ,..., _Pn_ maximizes the variance of the num-
ber of successes?
**(c)** What choice minimizes the variance?
∗ **7.16.** Suppose that each of the elements of _S_ =

```
{1, 2,..., n }is to be colored either red or blue.
Show that if A 1 ,..., Ar are subsets of S ,there
is a way of doing the coloring so that at most
∑ r
i = 1
```
```
( 1 / 2 )| Ai |−^1 of these subsets have all their ele-
ments the same color (where| A |denotes the num-
ber of elements in the set A ).
7.17. Suppose that X 1 and X 2 are independent random
variables having a common meanμ. Suppose also
that Var( X 1 )=σ 12 and Var( X 2 )=σ 22. The value
ofμis unknown, and it is proposed thatμbe esti-
mated by a weighted average of X 1 and X 2 .That
is,λ X 1 +( 1 − λ) X 2 will be used as an estimate
ofμfor some appropriate value ofλ. Which value
ofλyields the estimate having the lowest possible
```
```
variance? Explain why it is desirable to use this
value ofλ.
7.18. In Example 4f, we showed that the covariance of
the multinomial random variables Ni and Nj is
equal to− mPiPj by expressing Ni and Nj as the
sum of indicator variables. We could also have
obtained that result by using the formula
```
```
Var( Ni + Nj )=Var( Ni )+Var( Nj )+2Cov( Ni , Nj )
```
```
(a) What is the distribution of Ni + Nj?
(b) Use the preceding identity to show that
Cov( Ni , Nj )=− mPiPj.
7.19. Show that X and Y are identically distributed and
not necessarily independent, then
```
```
Cov( X + Y , X − Y )= 0
7.20. The Conditional Covariance Formula. The con-
ditional covariance of X and Y , given Z ,is
defined by
```
```
Cov( X , Y | Z )K E [( X − E [ X | Z ])( Y − E [ Y | Z ])| Z ]
```
```
(a) Show that
```
```
Cov( X , Y | Z )= E [ XY | Z ]− E [ X | Z ] E [ Y | Z ]
```
```
(b) Prove the conditional covariance formula
```
```
Cov( X , Y )= E [Cov( X , Y | Z )]
+Cov( E [ X | Z ], E [ Y | Z ])
```
```
(c) Set X = Y in part (b) and obtain the condi-
tional variance formula.
7.21. Let X ( i ), i = 1,..., n , denote the order statis-
tics from a set of n uniform (0, 1) random vari-
ables, and note that the density function of X ( i )is
given by
```
```
f ( x )=
```
```
n!
( i − 1 )!( n − i )!
xi −^1 ( 1 − x ) n − i 0 < x < 1
```
```
(a) Compute Var( X ( i )), i =1,..., n.
(b) Which value of i minimizes, and which value
maximizes, Var( X ( i ))?
7.22. Show that Y = a + bX ,then
```
```
ρ( X , Y )=
```
```
{
+1if b > 0
−1if b < 0
```
```
7.23. Show that Z is a standard normal random variable
and if Y is defined by Y = a + bZ + cZ^2 ,then
```
```
ρ( Y , Z )=
```
```
b
√
b^2 + 2 c^2
```

**382** Chapter 7 Properties of Expectation

```
7.24. Prove the Cauchy–Schwarz inequality, namely,
```
```
( E [ XY ])^2 ... E [ X^2 ] E [ Y^2 ]
```
```
Hint :Unless Y =− tX for some constant, in which
case the inequality holds with equality, if follows
that, for all t ,
```
```
0 < E [( tX + Y )^2 ]= E [ X^2 ] t^2 + 2 E [ XY ] t + E [ Y^2 ]
```
```
Hence, the roots of the quadratic equation
```
```
E [ X^2 ] t^2 + 2 E [ XY ] t + E [ Y^2 ]= 0
```
```
must be imaginary, which implies that the discrim-
inant of this quadratic equation must be negative.
7.25. Show that if X and Y are independent, then
```
```
E [ X | Y = y ]= E [ X ]forall y
```
```
(a) in the discrete case;
(b) in the continuous case.
7.26. Prove that E [ g ( X ) Y | X ]= g ( X ) E [ Y | X ].
7.27. Prove that if E [ Y | X = x ]= E [ Y ]forall x ,then X
and Y are uncorrelated; give a counterexample to
show that the converse is not true.
Hint : Prove and use the fact that E [ XY ] =
E [ XE [ Y | X ]].
7.28. Show that Cov( X , E [ Y | X ])=Cov( X , Y ).
7.29. Let X 1 ,..., Xn be independent and identically dis-
tributed random variables. Find
```
```
E [ X 1 | X 1 + ··· + Xn = x ]
```
```
7.30. Consider Example 4f, which is concerned with the
multinomial distribution. Use conditional expec-
tation to compute E [ NiNj ], and then use this to
verify the formula for Cov( Ni , Nj )given in Exam-
ple 4f.
7.31. An urn initially contains b black and w white balls.
At each stage, we add r black balls and then with-
draw, at random, r balls from the b + w + r balls
in the urn. Show that
```
```
E [number of white balls after stage t ]
```
```
=
```
```
(
b + w
b + w + r
```
```
) t
w
```
```
7.32. For an event A ,let IA equal 1 if A occurs and
let it equal 0 if A does not occur. For a random
variable X , show that
```
```
E [ X | A ]=
```
```
E [ XIA ]
P ( A )
7.33. A coin that lands on heads with probability p is
continually flipped. Compute the expected num-
ber of flips that are made until a string of r heads
in a row is obtained.
```
```
Hint : Condition on the time of the first occurrence
of tails to obtain the equation
```
```
E [ X ]=( 1 − p )
```
```
∑ r
```
```
i = 1
```
```
pi −^1 ( i + E [ X ])
```
```
+( 1 − p )
```
```
∑q
```
```
i = r + 1
```
```
pi −^1 r
```
```
Simplify and solve for E [ X ].
7.34. For another approach to Theoretical Exercise 33,
let Tr denote the number of flips required to obtain
a run of r consecutive heads.
(a) Determine E [ Tr | Tr − 1 ].
(b) Determine E [ Tr ]intermsof E [ Tr − 1 ].
(c) What is E [ T 1 ]?
(d) What is E [ Tr ]?
7.35. The probability generating function of the dis-
crete nonnegative integer valued random variable
X having probability mass function pj , j Ú 0, is
defined by
```
```
φ( s )= E [ sX ]=
```
```
∑q
```
```
j = 0
```
```
pjsj
```
```
Let Y be a geometric random variable with param-
eter p = 1 − s ,where0< s <1. Suppose that Y
is independent of X , and show that
```
```
φ( s )= P { X < Y }
```
```
7.36. One ball at a time is randomly selected from an
urn containing a white and b black balls until all of
the remaining balls are of the same color. Let Ma , b
denote the expected number of balls left in the urn
when the experiment ends. Compute a recursive
formula for Ma , b and solve when a =3and b =5.
7.37. An urn contains a white and b black balls. After a
ball is drawn, it is returned to the urn if it is white;
but if it is black, it is replaced by a white ball from
another urn. Let Mn denote the expected number
of white balls in the urn after the foregoing opera-
tion has been repeated n times.
(a) Derive the recursive equation
```
```
Mn + 1 =
```
```
(
1 −
1
a + b
```
```
)
Mn + 1
```
```
(b) Use part (a) to prove that
```
```
Mn = a + b − b
```
```
(
1 −
1
a + b
```
```
) n
```
```
(c) What is the probability that the( n + 1 )st ball
drawn is white?
```

```
Theoretical Exercises 383
```
**7.38.** The best linear predictor of _Y_ with respect to _X_ 1
and _X_ 2 is equal to _a_ + _bX_ 1 + _cX_ 2 ,where _a_ , _b_ ,and
_c_ are chosen to minimize

```
E [( Y −( a + bX 1 + cX 2 ))^2 ]
```
Determine _a_ , _b_ ,and _c_.
**7.39.** The best quadratic predictor of _Y_ with respect to
_X_ is _a_ + _bX_ + _cX_^2 ,where _a_ , _b_ ,and _c_ are chosen to
minimize _E_ [( _Y_ −( _a_ + _bX_ + _cX_^2 ))^2 ]. Determine
_a_ , _b_ ,and _c_.
**7.40.** Use the conditional variance formula to determine
the variance of a geometric random variable _X_
having parameter _p_.
**7.41.** Let _X_ be a normal random variable with parame-
tersμ=0andσ^2 =1, and let _I_ , independent of _X_ ,
be such that _P_ { _I_ = 1 }=^12 = _P_ { _I_ = 0 }. Now define
_Y_ by

```
Y =
```
```
{
X if I = 1
− X if I = 0
```
In words, _Y_ is equally likely to equal either _X_
or− _X_.
**(a)** Are _X_ and _Y_ independent?
**(b)** Are _I_ and _Y_ independent?
**(c)** Show that _Y_ is normal with mean 0 and vari-
ance 1.
**(d)** Show that Cov( _X_ , _Y_ )=0.
**7.42.** It follows from Proposition 6.1 and the fact that
the best linear predictor of _Y_ with respect to _X_ is
μ _y_ +ρ
σ _y_
σ _x_ ( _X_ −μ _x_ )that if
_E_ [ _Y_ | _X_ ]= _a_ + _bX_

```
then
a =μ y −ρ
```
```
σ y
σ x
μ x b =ρ
```
```
σ y
σ x
```
(Why?) Verify this directly.
**7.43.** Show that, for random variables _X_ and _Z_ ,

```
E [( X − Y )^2 ]= E [ X^2 ]− E [ Y^2 ]
```
```
where
Y = E [ X | Z ]
```
**7.44.** Consider a population consisting of individuals
able to produce offspring of the same kind. Sup-
pose that, by the end of its lifetime, each individual
will have produced _j_ new offspring with probability
_Pj_ , _j_ Ú0, independently of the number produced
by any other individual. The number of individu-
als initially present, denoted by _X_ 0 , is called the
size of the zeroth generation. All offspring of the
zeroth generation constitute the first generation,

```
and their number is denoted by X 1. In general,
let Xn denote the size of the n th generation. Let
μ=
```
```
∑q
j = 0
```
```
jPj andσ^2 =
```
```
∑q
j = 0
```
```
( j −μ)^2 Pj denote, respec-
```
```
tively, the mean and the variance of the number
of offspring produced by a single individual. Sup-
pose that X 0 =1—that is, initially there is a single
individual in the population.
(a) Show that
```
```
E [ Xn ]=μ E [ Xn − 1 ]
```
```
(b) Use part (a) to conclude that
```
```
E [ Xn ]=μ n
```
```
(c) Show that
```
```
Var( Xn )=σ^2 μ n −^1 +μ^2 Var( Xn − 1 )
```
```
(d) Use part (c) to conclude that
```
```
Var( Xn )=
```
```
⎧
⎪⎪
⎨
⎪⎪
⎩
```
```
σ^2 μ n −^1
```
```
(
μ n − 1
μ− 1
```
```
)
ifμZ 1
```
```
n σ^2 ifμ= 1
```
```
The model just described is known as a
branching process , and an important ques-
tion for a population that evolves along such
lines is the probability that the population will
eventually die out. Letπdenote this proba-
bility when the population starts with a single
individual. That is,
```
```
π= P {population eventually dies out| X 0 = 1 )
```
```
(e) Argue thatπsatisfies
```
```
π=
```
```
∑q
```
```
j = 0
```
```
Pj π j
```
```
Hint : Condition on the number of offspring of
the initial member of the population.
7.45. Verify the formula for the moment generating
function of a uniform random variable that is given
in Table 7.7. Also, differentiate to verify the for-
mulas for the mean and variance.
7.46. For a standard normal random variable Z ,letμ n =
E [ Zn ]. Show that
```
```
μ n =
```
```
⎧
⎪⎨
```
```
⎪⎩
```
```
0when n is odd
( 2 j )!
2 jj!
```
```
when n = 2 j
```

**384** Chapter 7 Properties of Expectation

```
Hint : Start by expanding the moment generating
function of Z into a Taylor series about 0 to obtain
E [ etZ ]= et
```
(^2) / 2
=
∑q
_j_ = 0
( _t_^2 / 2 ) _j
j_!
**7.47.** Let _X_ be a normal random variable with mean
μand varianceσ^2. Use the results of Theoretical
Exercise 46 to show that
_E_ [ _Xn_ ]=
[∑ _n_ /2]
_j_ = 0
(
_n_
2 _j_
)
μ _n_ −^2 _j_ σ^2 _j_ ( 2 _j_ )!
2 _jj_!
In the preceding equation, [ _n_ /2] is the largest inte-
ger less than or equal to _n_ /2. Check your answer by
letting _n_ =1and _n_ =2.
**7.48.** If _Y_ = _aX_ + _b_ ,where _a_ and _b_ are constants,
express the moment generating function of _Y_ in
terms of the moment generating function of _X_.
**7.49.** The positive random variable _X_ is said to be a _log-
normal_ random variable with parametersμandσ^2
if log( _X_ )is a normal random variable with mean
μand varianceσ^2. Use the normal moment gener-
ating function to find the mean and variance of a
lognormal random variable.
**7.50.** Let _X_ have moment generating function _M_ ( _t_ ),and
define( _t_ )=log _M_ ( _t_ ). Show that
′′( _t_ )| _t_ = 0 =Var( _X_ )
**7.51.** Use Table 7.2 to determine the distribution of _n_
∑
_i_ = 1
_Xi_ when _X_ 1 ,..., _Xn_ are independent and
identically distributed exponential random vari-
ables, each having mean 1/λ.
**7.52.** Show how to compute Cov( _X_ , _Y_ ) from the joint
moment generating function of _X_ and _Y_.
**7.53.** Suppose that _X_ 1 ,..., _Xn_ have a multivariate nor-
mal distribution. Show that _X_ 1 ,..., _Xn_ are inde-
pendent random variables if and only if
Cov( _Xi_ , _Xj_ )=0when _i_ Z _j_
**7.54.** If _Z_ is a standard normal random variable, what is
Cov( _Z_ , _Z_^2 )?
**7.55.** Suppose that _Y_ is a normal random variable with
meanμand varianceσ^2 , and suppose also that the
conditional distribution of _X_ , given that _Y_ = _y_ ,is
normal with mean _y_ and variance 1.
**(a)** Argue that the joint distribution of _X_ , _Y_ is the
same as that of _Y_ + _Z_ , _Y_ when _Z_ is a standard
normal random variable that is independent
of _Y_.
**(b)** Use the result of part (a) to argue that _X_ , _Y_
has a bivariate normal distribution.
**(c)** Find _E_ [ _X_ ], Var( _X_ ),andCorr( _X_ , _Y_ ).
**(d)** Find _E_ [ _Y_ | _X_ = _x_ ].
**(e)** What is the conditional distribution of _Y_ given
that _X_ = _x_?

#### Self-Test Problems and Exercises

```
7.1. Consider a list of m names, where the same name
may appear more than once on the list. Let n ( i ),
i =1,..., m , denote the number of times that the
name in position i appears on the list, and let d
denote the number of distinct names on the list.
(a) Express d in terms of the variables m , n ( i ), i =
1,..., m .Let U be a uniform (0, 1) random
variable, and let X =[ mU ]+1.
(b) What is the probability mass function of X?
(c) Argue that E [ m / n ( X )]= d.
7.2. An urn has n white and m black balls that are
removed one at a time in a randomly chosen order.
Find the expected number of instances in which a
white ball is immediately followed by a black one.
7.3. Twenty individuals consisting of 10 married cou-
ples are to be seated at 5 different tables, with 4
people at each table.
(a) If the seating is done “at random,” what is the
expected number of married couples that are
seated at the same table?
(b) If 2 men and 2 women are randomly chosen to
be seated at each table, what is the expected
```
```
number of married couples that are seated at
the same table?
7.4. If a die is to be rolled until all sides have appeared
at least once, find the expected number of times
that outcome 1 appears.
7.5. Adeckof2 n cards consists of n red and n black
cards. The cards are shuffled and then turned over
one at a time. Suppose that each time a red card is
turned over, we win 1 unit if more red cards than
black cards have been turned over by that time.
(For instance, if n =2 and the result is r b r b, then
we would win a total of 2 units.) Find the expected
amount that we win.
7.6. Let A 1 , A 2 ,..., An be events, and let N denote the
number of them that occur. Also, let I =1ifallof
these events occur, and let it be 0 otherwise. Prove
Bonferroni’s inequality, namely,
```
```
P ( A 1 ··· An )Ú
```
```
∑ n
```
```
i = 1
```
```
P ( Ai )−( n − 1 )
```
```
Hint : Argue first that N ... n − 1 + I.
```

```
Self-Test Problems and Exercises 385
```
```
7.7. Let X be the smallest value obtained when k num-
bers are randomly chosen from the set 1,..., n.
Find E [ X ] by interpreting X as a negative hyper-
geometric random variable.
7.8. An arriving plane carries r families. A total of
nj of these families have checked in a total of j
pieces of luggage,
```
```
∑
j
```
```
nj = r. Suppose that when
```
```
the plane lands, the N =
```
```
∑
j
```
```
jnj pieces of luggage
```
come out of the plane in a random order. As soon
as a family collects all of its luggage, it immediately
departs the airport. If the Sanchez family checked
in _j_ pieces of luggage, find the expected number of
families that depart after they do.
∗ **7.9.** Nineteen items on the rim of a circle of radius 1 are

to be chosen. Show that, for any choice of these
points, there will be an arc of (arc) length 1 that
contains at least 4 of them.
**7.10.** Let _X_ be a Poisson random variable with meanλ.
Show that ifλis not too small, then

```
Var(
```
```
√
X )L. 25
```
```
Hint : Use the result of Theoretical Exercise 4 to
approximate E [
```
√
_X_ ].
**7.11.** Suppose in Self-Test Problem 3 that the 20 peo-
ple are to be seated at seven tables, three of which
have 4 seats and four of which have 2 seats. If
the people are randomly seated, find the expected
value of the number of married couples that are
seated at the same table.
**7.12.** Individuals 1 through _n_ , _n_ >1, are to be recruited
into a firm in the following manner: Individual 1
starts the firm and recruits individual 2. Individ-
uals 1 and 2 will then compete to recruit indi-
vidual 3. Once individual 3 is recruited, individu-
als 1, 2, and 3 will compete to recruit individual 4,
and so on. Suppose that when individuals 1, 2,..., _i_
compete to recruit individual _i_ +1, each of them
is equally likely to be the successful recruiter.
**(a)** Find the expected number of the individuals
1,..., _n_ who did not recruit anyone else.
**(b)** Derive an expression for the variance of the
number of individuals who did not recruit
anyone else, and evaluate it for _n_ =5.
**7.13.** The nine players on a basketball team consist of 2
centers, 3 forwards, and 4 backcourt players. If the
players are paired up at random into three groups
of size 3 each, find (a) the expected value and (b)
the variance of the number of triplets consisting of
one of each type of player.
**7.14.** A deck of 52 cards is shuffled and a bridge hand
of 13 cards is dealt out. Let _X_ and _Y_ denote,
respectively, the number of aces and the number
of spades in the hand.

```
(a) Show that X and Y are uncorrelated.
(b) Are they independent?
7.15. Each coin in a bin has a value attached to it. Each
time that a coin with value p is flipped, it lands
on heads with probability p. When a coin is ran-
domly chosen from the bin, its value is uniformly
distributed on (0, 1). Suppose that after the coin is
chosen, but before it is flipped, you must predict
whether it will land on heads or on tails. You will
win 1 if you are correct and will lose 1 otherwise.
(a) What is your expected gain if you are not told
the value of the coin?
(b) Suppose now that you are allowed to inspect
the coin before it is flipped, with the result of
your inspection being that you learn the value
of the coin. As a function of p , the value of the
coin, what prediction should you make?
(c) Under the conditions of part (b), what is your
expected gain?
7.16. In Self-Test Problem 1, we showed how to use
the value of a uniform (0, 1) random variable
(commonly called a random number ) to obtain the
value of a random variable whose mean is equal
to the expected number of distinct names on a list.
However, its use required that one choose a ran-
dom position and then determine the number of
times that the name in that position appears on
the list. Another approach, which can be more effi-
cient when there is a large amount of replication of
names, is as follows: As before, start by choosing
the random variable X as in Problem 1. Now iden-
tify the name in position X , and then go through
the list, starting at the beginning, until that name
appears. Let I equal 0 if you encounter that name
before getting to position X ,andlet I equal 1 if
your first encounter with the name is at position X.
Show that E [ mI ]= d.
Hint : Compute E [ I ] by using conditional expecta-
tion.
7.17. A total of m items are to be sequentially dis-
tributed among n cells, with each item indepen-
dently being put in cell j with probability pj , j =
1,..., n. Find the expected number of collisions
that occur, where a collision occurs whenever an
item is put into a nonempty cell.
7.18. Let X be the length of the initial run in a random
ordering of n ones and m zeroes. That is, if the first
k values are the same (either all ones or all zeroes),
then X Ú k .Find E [ X ].
7.19. There are n items in a box labeled H and m in a
box labeled T. A coin that comes up heads with
probability p and tails with probability 1− p is
flipped. Each time it comes up heads, an item is
removed from the H box, and each time it comes
up tails, an item is removed from the T box. (If a
box is empty and its outcome occurs, then no items
```

**386** Chapter 7 Properties of Expectation

```
are removed.) Find the expected number of coin
flips needed for both boxes to become empty.
Hint : Condition on the number of heads in the first
n + m flips.
7.20. Let X be a nonnegative random variable having
distribution function F. Show that if F ( x )= 1 −
F ( x ),then
```
```
E [ Xn ]=
```
```
∫q
```
```
0
```
```
xn −^1 F ( x ) dx
```
```
Hint : Start with the identity
```
```
Xn = n
```
```
∫ x
```
```
0
```
```
xn −^1 dx
```
```
= n
```
```
∫q
```
```
0
```
```
xn −^1 IX ( x ) dx
```
```
where
Ix ( x )=
```
```
{
1, if x < X
0, otherwise
```
∗ **7.21.** Let _a_ 1 ,..., _an_ , not all equal to 0, be such that
∑ _n
i_ = 1 _ai_ = 0. Show that there is a permutation
_i_ 1 ,..., _in_ such that

```
∑ n
j = 1 aijaij + 1 <0.
Hint : Use the probabilistic method. (It is interest-
ing that there need not be a permutation whose
sum of products of successive pairs is positive. For
instance, if n =3, a 1 = a 2 =−1, and a 3 =2, there
is no such permutation.)
7.22. Suppose that Xi , i =1, 2, 3, are independent Pois-
son random variables with respective meansλ i ,
i =1, 2, 3. Let X = X 1 + X 2 and Y = X 2 + X 3.
The random vector X , Y is said to have a bivariate
Poisson distribution.
(a) Find E [ X ]and E [ Y ].
(b) Find Cov( X , Y ).
(c) Find the joint probability mass function
P { X = i , Y = j }.
7.23. Let( Xi , Yi ), i =1,..., be a sequence of indepen-
dent and identically distributed random vectors.
That is, X 1 , Y 1 is independent of, and has the same
distribution as X 2 , Y 2 , and so on. Although Xi and
Yi can be dependent, Xi and Yj are independent
when i Z j .Let
```
```
μ x = E [ Xi ], μ y = E [ Yi ], σ x^2 =Var( Xi ),
σ y^2 =Var( Yi ), ρ=Corr( Xi , Yi )
```
```
Find Corr(
```
```
∑ n
i = 1 Xi ,
```
```
∑ n
j = 1 Yj ).
7.24. Three cards are randomly chosen without replace-
ment from an ordinary deck of 52 cards. Let X
denote the number of aces chosen.
(a) Find E [ X |the ace of spades is chosen].
(b) Find E [ X |at least one ace is chosen].
```
```
7.25. Let be the standard normal distribution func-
tion, and let X be a normal random variable with
meanμand variance 1. We want to find E [
( X )].
To do so, let Z be a standard normal random vari-
able that is independent of X ,andlet
```
```
I =
```
```
{
1, if Z < X
0, if Z Ú X
```
```
(a) Show that E [ I | X = x ]=
( x ).
(b) Show that E [
( X )]= P { Z < X }.
(c) Show that E [
( X )]=
(√μ 2 ).
Hint : What is the distribution of X − Z?
The preceding comes up in statistics. Suppose
you are about to observe the value of a random
variable X that is normally distributed with an
unknown meanμand variance 1, and suppose that
you want to test the hypothesis that the meanμ
is greater than or equal to 0. Clearly you would
want to reject this hypothesis if X is sufficiently
small. If it results that X = x , then the p-value
of the hypothesis that the mean is greater than
or equal to 0 is defined to be the probability that
X would be as small as x ifμwere equal to 0
(its smallest possible value if the hypothesis were
true). (A small p -value is taken as an indication
that the hypothesis is probably false.) Because X
has a standard normal distribution whenμ =0,
the p -value that results when X = x is
( x ).
Therefore, the preceding shows that the expected
p -value that results when the true mean is μ
is
(√μ 2 ).
7.26. A coin that comes up heads with probability p
is flipped until either a total of n heads or of
m tails is amassed. Find the expected number of
flips.
Hint : Imagine that one continues to flip even after
the goal is attained. Let X denote the number of
flips needed to obtain n heads, and let Y denote
the number of flips needed to obtain m tails. Note
that max( X , Y )+min( X , Y )= X + Y. Com-
pute E [max( X , Y )] by conditioning on the number
of heads in the first n + m −1flips.
7.27. Adeckof n cards numbered 1 through n , initially
in any arbitrary order, is shuffled in the following
manner: At each stage, we randomly choose one
of the cards and move it to the front of the deck,
leaving the relative positions of the other cards
unchanged. This procedure is continued until all
but one of the cards has been chosen. At this point
it follows by symmetry that all n! possible order-
ings are equally likely. Find the expected number
of stages that are required.
7.28. Suppose that a sequence of independent trials in
which each trial is a success with probability p is
```

```
Self-Test Problems and Exercises 387
```
performed until either a success occurs or a total of
_n_ trials has been reached. Find the mean number
of trials that are performed.
_Hint_ : The computations are simplified if you use
the identity that, for a nonnegative integer valued
random variable _X_ ,

```
E [ X ]=
```
```
∑q
```
```
i = 1
```
```
P { X Ú i }
```
```
7.29. Suppose that X and Y are both Bernoulli random
variables. Show that X and Y are independent if
and only if Cov( X , Y )= 0.
7.30. In the generalized match problem, there are n
individuals of whom ni wear hat size i ,
```
```
∑ r
i = 1 ni =
n .There are also n hats, of which hi are of
size i ,
```
```
∑ r
i = 1 hi = n .If each individual randomly
chooses a hat (without replacement), find the
expected number who choose a hat that is their
size.
```

## CHAPTER 8

# Limit Theorems

### 8.1 Introduction

**8.2 CHEBYSHEV’S INEQUALITY AND THE WEAK LAW OF LARGE NUMBERS
8.3 THE CENTRAL LIMIT THEOREM
8.4 THE STRONG LAW OF LARGE NUMBERS
8.5 OTHER INEQUALITIES
8.6 BOUNDING THE ERROR PROBABILITY WHEN APPROXIMATING A SUM OF INDEPENDENT BERNOULLI
RANDOM VARIABLES BY A POISSON RANDOM VARIABLE**

##### 8.1 INTRODUCTION

```
The most important theoretical results in probability theory are limit theorems. Of
these, the most important are those classified either under the heading laws of large
numbers or under the heading central limit theorems. Usually, theorems are consid-
ered to be laws of large numbers if they are concerned with stating conditions under
which the average of a sequence of random variables converges (in some sense) to
the expected average. By contrast, central limit theorems are concerned with deter-
mining conditions under which the sum of a large number of random variables has a
probability distribution that is approximately normal.
```
**8.2 CHEBYSHEV’S INEQUALITY AND THE WEAK LAW OF LARGE NUMBERS**

```
We start this section by proving a result known as Markov’s inequality.
Proposition 2.1. Markov’s inequality
If X is a random variable that takes only nonnegative values, then, for any value
a >0,
P { X Ú a }...
```
##### E [ X ]

```
a
Proof. For a >0, let
I =
```
##### {

```
1if X Ú a
0 otherwise
and note that, since X Ú0,
I ...
```
##### X

```
a
Taking expectations of the preceding inequality yields
```
##### E [ I ]...

##### E [ X ]

```
a
which, because E [ I ]= P { X Ú a }, proves the result.
```
```
As a corollary, we obtain Proposition 2.2.
```
**388**


```
Section 8.2 Chebyshev’s Inequality and the Weak Law of Large Numbers 389
```
**Proposition 2.2. Chebyshev’s inequality**
If _X_ is a random variable with finite meanμand varianceσ^2 , then, for any value
_k_ >0,

```
P {| X −μ|Ú k }...
```
```
σ^2
k^2
```
```
Proof. Since( X −μ)^2 is a nonnegative random variable, we can apply Markov’s
inequality (with a = k^2 ) to obtain
```
```
P {( X −μ)^2 Ú k^2 }...
```
```
E [( X −μ)^2 ]
k^2
```
##### (2.1)

```
But since( X −μ)^2 Ú k^2 if and only if| X −μ|Ú k , Equation (2.1) is equivalent to
```
```
P {| X −μ|Ú k }...
```
```
E [( X −μ)^2 ]
k^2
```
##### =

```
σ^2
k^2
and the proof is complete.
```
The importance of Markov’s and Chebyshev’s inequalities is that they enable us to
derive bounds on probabilities when only the mean, or both the mean and the vari-
ance, of the probability distribution are known. Of course, if the actual distribution
were known, then the desired probabilities could be computed exactly and we would
not need to resort to bounds.

**_EXAMPLE 2a_**

Suppose that it is known that the number of items produced in a factory during a
week is a random variable with mean 50.

```
(a) What can be said about the probability that this week’s production will
exceed 75?
(b) If the variance of a week’s production is known to equal 25, then what can
be said about the probability that this week’s production will be between 40
and 60?
```
**_Solution._** Let _X_ be the number of items that will be produced in a week.

```
(a) By Markov’s inequality,
```
##### P { X > 75 }...

##### E [ X ]

##### 75

##### =

##### 50

##### 75

##### =

##### 2

##### 3

```
(b) By Chebyshev’s inequality,
```
##### P {| X − 50 |Ú 10 }...

```
σ^2
102
```
##### =

##### 1

##### 4

```
Hence,
```
```
P {| X − 50 |< 10 }Ú 1 −
```
##### 1

##### 4

##### =

##### 3

##### 4

```
so the probability that this week’s production will be between 40 and 60 is at
least .75..
```

**390** Chapter 8 Limit Theorems

```
As Chebyshev’s inequality is valid for all distributions of the random variable X ,
we cannot expect the bound on the probability to be very close to the actual proba-
bility in most cases. For instance, consider Example 2b.
```
```
EXAMPLE 2b
If X is uniformly distributed over the interval (0, 10), then, since E [ X ] = 5and
Var( X )=^253 , it follows from Chebyshev’s inequality that
```
##### P {| X − 5 |> 4 }...

##### 25

##### 3 ( 16 )

##### L. 52

```
whereas the exact result is
P {| X − 5 |> 4 }=. 20
```
```
Thus, although Chebyshev’s inequality is correct, the upper bound that it provides is
not particularly close to the actual probability.
Similarly, if X is a normal random variable with mean μand variance σ^2 ,
Chebyshev’s inequality states that
```
```
P {| X −μ|> 2 σ}...
```
##### 1

##### 4

```
whereas the actual probability is given by
```
```
P {| X −μ|> 2 σ}= P
```
##### {∣

##### ∣

##### ∣

##### ∣

```
X −μ
σ
```
##### ∣

##### ∣

##### ∣

##### ∣>^2

##### }

##### =2[1−
( 2 )]L. 0456.

```
Chebyshev’s inequality is often used as a theoretical tool in proving results. This
use is illustrated first by Proposition 2.3 and then, most importantly, by the weak law
of large numbers.
```
```
Proposition 2.3. If Var( X )=0, then
```
```
P { X = E [ X ]}= 1
```
```
In other words, the only random variables having variances equal to 0 are those which
are constant with probability 1.
```
```
Proof. By Chebyshev’s inequality, we have, for any n Ú1,
```
##### P

##### {

```
| X −μ|>
```
##### 1

```
n
```
##### }

##### = 0

```
Letting n →qand using the continuity property of probability yields
```
```
0 = lim
n →q
```
##### P

##### {

```
| X −μ|>
```
##### 1

```
n
```
##### }

##### = P

##### {

```
lim
n →q
```
##### {

```
| X −μ|>
```
##### 1

```
n
```
##### }}

```
= P { X Zμ}
```
```
and the result is established.
```

```
Section 8.3 The Central Limit Theorem 391
```
```
Theorem 2.1 The weak law of large numbers
Let X 1 , X 2 ,... be a sequence of independent and identically distributed random vari-
ables, each having finite mean E [ Xi ]=μ. Then, for any ε> 0 ,
```
##### P

##### {∣

##### ∣

##### ∣

##### ∣

```
X 1 + ··· + Xn
n
```
```
−μ
```
##### ∣

##### ∣

##### ∣

```
∣Úε
```
##### }

```
→ 0 as n →q
```
```
Proof. We shall prove the theorem only under the additional assumption that the
random variables have a finite varianceσ^2. Now, since
```
##### E

##### [

```
X 1 + ··· + Xn
n
```
##### ]

```
=μ and Var
```
##### (

```
X 1 + ··· + Xn
n
```
##### )

##### =

```
σ^2
n
```
```
it follows from Chebyshev’s inequality that
```
##### P

##### {∣

##### ∣

##### ∣

##### ∣

```
X 1 + ··· + Xn
n
```
```
−μ
```
##### ∣

##### ∣

##### ∣

```
∣Úε
```
##### }

```
σ^2
n ε^2
```
```
and the result is proven.
```
The weak law of large numbers was originally proven by James Bernoulli for the
special case where the _Xi_ are 0, 1 (that is, Bernoulli) random variables. His statement
and proof of this theorem were presented in his book _Ars Conjectandi_ , which was
published in 1713, eight years after his death, by his nephew Nicholas Bernoulli. Note
that, because Chebyshev’s inequality was not known in Bernoulli’s time, Bernoulli
had to resort to a quite ingenious proof to establish the result. The general form of
the weak law of large numbers presented in Theorem 2.1 was proved by the Russian
mathematician Khintchine.

### 8.3 TheCentralLimitTheorem

The central limit theorem is one of the most remarkable results in probability theory.
Loosely put, it states that the sum of a large number of independent random variables
has a distribution that is approximately normal. Hence, it not only provides a simple
method for computing approximate probabilities for sums of independent random
variables, but also helps explain the remarkable fact that the empirical frequencies of
so many natural populations exhibit bell-shaped (that is, normal) curves.
In its simplest form the central limit theorem is as follows.
**Theorem 3.1 The central limit theorem**
_Let X_ 1 , _X_ 2 ,... _be a sequence of independent and identically distributed random vari-
ables, each having mean_ μ _and variance_ σ^2_. Then the distribution of_

```
X 1 + ··· + Xn − n μ
σ
```
##### √

```
n
```
```
tends to the standard normal as n →q. That is, for −q< a <q ,
```
##### P

##### {

```
X 1 + ··· + Xn − n μ
σ
```
##### √

```
n
```
```
... a
```
##### }

##### →

##### 1

##### √

```
2 π
```
```
∫ a
```
```
−q
```
```
e − x
```
(^2) / 2
_dx as n_ →q
The key to the proof of the central limit theorem is the following lemma, which we
state without proof.


**392** Chapter 8 Limit Theorems

```
Lemma 3.1
Let Z 1 , Z 2 ,...be a sequence of random variables having distribution functions FZn
and moment generating functions MZn , n Ú1; and let Z be a random variable
having distribution function FZ and moment generating function MZ .If MZn ( t )→
MZ ( t )for all t ,then FZn ( t )→ FZ ( t )for all t at which FZ ( t )is continuous.
```
```
If we let Z be a standard normal random variable, then, since MZ ( t )= et
```
(^2) / 2
,it
follows from Lemma 3.1 that if _MZn_ ( _t_ )→ _et_
(^2) / 2
as _n_ →q,then _FZn_ ( _t_ )→
( _t_ )as _n_ →q.
We are now ready to prove the central limit theorem.
**Proof of the Central Limit Theorem:** Let us assume at first thatμ=0andσ^2 =1.
We shall prove the theorem under the assumption that the moment generating func-
tion of the _Xi_ , _M_ ( _t_ ), exists and is finite. Now, the moment generating function of
_Xi_ /

##### √

```
n is given by
```
```
E
```
##### ⎡

```
⎣exp
```
##### {

```
tXi
√
n
```
##### }⎤

##### ⎦= M

##### (

```
t
√
n
```
##### )

```
Thus, the moment generating function of
```
```
∑ n
i = 1
```
```
Xi /
```
##### √

```
n is given by
```
##### [

##### M

##### (

```
√ t
n
```
```
)] n
.Let
```
```
L ( t )=log M ( t )
and note that
L ( 0 )= 0
```
```
L ′( 0 )=
```
##### M ′( 0 )

##### M ( 0 )

```
=μ
= 0
```
```
L ′′( 0 )=
```
##### M ( 0 ) M ′′( 0 )−[ M ′( 0 )]^2

##### [ M ( 0 )]^2

##### = E [ X^2 ]

##### = 1

```
Now, to prove the theorem, we must show that [ M ( t /
```
##### √

```
n )] n → et
```
(^2) / 2
as _n_ →q,or,
equivalently, that _nL_ ( _t_ /

##### √

```
n )→ t^2 /2as n →q. To show this, note that
```
```
lim
n →q
```
```
L ( t /
```
##### √

```
n )
n −^1
```
```
= lim
n →q
```
```
− L ′( t /
```
##### √

```
n ) n −^3 /^2 t
− 2 n −^2
```
```
by L’Hopital’s ruleˆ
```
```
= lim
n →q
```
##### [

```
L ′( t /
```
##### √

```
n ) t
2 n −^1 /^2
```
##### ]

```
= lim
n →q
```
##### [

```
− L ′′( t /
```
##### √

```
n ) n −^3 /^2 t^2
− 2 n −^3 /^2
```
##### ]

```
again by L’Hopital’s ruleˆ
```
```
= lim
n →q
```
##### ⎡

##### ⎣ L ′′

##### (

```
t
√
n
```
##### )

```
t^2
2
```
##### ⎤

##### ⎦

##### =

```
t^2
2
```

```
Section 8.3 The Central Limit Theorem 393
```
Thus, the central limit theorem is proven whenμ = 0andσ^2 = 1. The result
now follows in the general case by considering the standardized random variables
_X_ ∗ _i_ =( _Xi_ −μ)/σand applying the preceding result, since _E_ [ _X_ ∗ _i_ ]=0, Var( _X_ ∗ _i_ )=1.

```
Remark. Although Theorem 3.1 states only that, for each a ,
```
##### P

##### {

```
X 1 + ··· + Xn − n μ
σ
```
##### √

```
n
```
```
... a
```
##### }

```
→
( a )
```
it can, in fact, be shown that the convergence is uniform in _a_. [We say that _fn_ ( _a_ )→ _f_ ( _a_ )
uniformly in _a_ if, for eachε>0, there exists an _N_ such that| _fn_ ( _a_ )− _f_ ( _a_ )|<εfor all
_a_ whenever _n_ Ú _N_ .].

The first version of the central limit theorem was proven by DeMoivre around
1733 for the special case where the _Xi_ are Bernoulli random variables with _p_ =^12.
The theorem was subsequently extended by Laplace to the case of arbitrary _p_. (Since
a binomial random variable may be regarded as the sum of _n_ independent and identi-
cally distributed Bernoulli random variables, this justifies the normal approximation
to the binomial that was presented in Section 5.4.1.) Laplace also discovered the more
general form of the central limit theorem given in Theorem 3.1. His proof, however,
was not completely rigorous and, in fact, cannot easily be made rigorous. A truly
rigorous proof of the central limit theorem was first presented by the Russian mathe-
matician Liapounoff in the period 1901–1902.
This important theorem is illustrated by the central limit theorem module on the
text website. This website yields plots of the density function of the sum of _n_ inde-
pendent and identically distributed random variables that each take on one of the
values 0, 1, 2, 3, 4. When using it, one enters the probability mass function and the
desired value of _n_. Figure 8.1 shows the resulting plots for a specified probability mass
function when (a) _n_ =5, (b) _n_ =10, (c) _n_ =25, and (d) _n_ =100.

**_EXAMPLE 3a_**

An astronomer is interested in measuring the distance, in light-years, from his obser-
vatory to a distant star. Although the astronomer has a measuring technique, he
knows that, because of changing atmospheric conditions and normal error, each time
a measurement is made it will not yield the exact distance, but merely an estimate.
As a result, the astronomer plans to make a series of measurements and then use the
average value of these measurements as his estimated value of the actual distance.
If the astronomer believes that the values of the measurements are independent and
identically distributed random variables having a common mean _d_ (the actual dis-
tance) and a common variance of 4 (light-years), how many measurements need he
make to be reasonably sure that his estimated distance is accurate to within;.5 light-
year?

**_Solution._** Suppose that the astronomer decides to make _n_ observations. If _X_ 1 ,
_X_ 2 ,..., _Xn_ are the _n_ measurements, then, from the central limit theorem, it
follows that

```
Zn =
```
```
∑ n
```
```
i = 1
```
```
Xi − nd
```
##### 2

##### √

```
n
```

**394** Chapter 8 Limit Theorems

```
Central Limit Theorem
```
```
Enter the probabilities and the number of random
variables to be summed. The output gives the mass
function of the sum along with its mean and
variance.
```
```
P0 .25
P1 .15
P2 .1
P3 .2
P4 .3
```
```
n = 5
```
```
Start
```
```
Quit
```
```
Mean = 10.75
Variance = 12.6375
```
```
0 5 10 15 20
i
```
```
0.00
```
```
0.05
```
```
0.10
```
```
0.15
```
```
p(i)
```
```
FIGURE 8.1(a)
```
```
has approximately a standard normal distribution. Hence,
```
##### P

##### ⎧

##### ⎪⎪

##### ⎨

##### ⎪⎪

##### ⎩−.^5 ...

```
∑ n
```
```
i = 1
```
```
Xi
```
```
n
```
```
− d .... 5
```
##### ⎫

##### ⎪⎪

##### ⎬

##### ⎪⎪

##### ⎭= P

##### {

##### −. 5

##### √

```
n
2
```
```
... Zn .... 5
```
##### √

```
n
2
```
##### }

##### L

##### (√

```
n
4
```
##### )

```
−φ
```
##### (

##### −

##### √

```
n
4
```
##### )

##### = 2

##### (√

```
n
4
```
##### )

##### − 1

```
Therefore, if the astronomer wants, for instance, to be 95 percent certain that his
estimated value is accurate to within .5 light year, he should make n ∗measurements,
where n ∗is such that
```
##### 2

##### (√

```
n ∗
4
```
##### )

```
− 1 =. 95 or
```
##### (√

```
n ∗
4
```
##### )

##### =. 975

```
Thus, from Table 5.1 of Chapter 5,
√
n ∗
4
```
```
= 1. 96 or n ∗=( 7. 84 )^2 L 61. 47
```
```
As n ∗is not integral valued, he should make 62 observations.
```

```
Section 8.3 The Central Limit Theorem 395
```
```
Central Limit Theorem
```
```
Enter the probabilities and the number of random
variables to be summed. The output gives the mass
function of the sum along with its mean and
variance.
```
```
P0 .25
P1 .15
P2 .1
P3 .2
P4 .3
```
```
n = 10
```
```
Start
```
```
Quit
```
```
Mean = 21.5
Variance = 25.275
```
```
0 10 20 30 40
i
```
```
0.00
```
```
0.08
```
```
p(i)
```
```
0.06
0.04
0.02
```
```
FIGURE 8.1(b)
```
Note, however, that the preceding analysis has been done under the assumption
that the normal approximation will be a good approximation when _n_ =62. Although
this will usually be the case, in general the question of how large _n_ need be before
the approximation is “good” depends on the distribution of the _Xi_. If the astronomer
is concerned about this point and wants to take no chances, he can still solve his
problem by using Chebyshev’s inequality. Since

##### E

##### ⎡

##### ⎣

```
∑ n
```
```
i = 1
```
```
Xi
n
```
##### ⎤

```
⎦= d Var
```
##### ⎛

##### ⎝

```
∑ n
```
```
i = 1
```
```
Xi
n
```
##### ⎞

##### ⎠=

##### 4

```
n
```
Chebyshev’s inequality yields

##### P

##### ⎧

##### ⎪⎨

##### ⎪⎩

##### ∣ ∣ ∣ ∣ ∣ ∣

```
∑ n
```
```
i = 1
```
```
Xi
n
```
```
− d
```
##### ∣ ∣ ∣ ∣ ∣ ∣

##### >. 5

##### ⎫

##### ⎪⎬

##### ⎪⎭

##### ...

##### 4

```
n (. 5 )^2
```
##### =

##### 16

```
n
```
Hence, if he makes _n_ = 16 /. 05 =320 observations, he can be 95 percent certain that
his estimate will be accurate to within .5 light-year..


**396** Chapter 8 Limit Theorems

```
Central Limit Theorem
```
```
Enter the probabilities and the number of random
variables to be summed. The output gives the mass
function of the sum along with its mean and
variance.
```
```
P0 .25
P1 .15
P2 .1
P3 .2
P4 .3
```
```
n = 25
```
```
Start
```
```
Quit
```
```
Mean = 53.75
Variance = 63.1875
```
```
0 100
i
```
```
0.00
```
```
0.05
```
```
p(i)
```
```
0.04
0.03
0.02
0.01
```
```
20 40 60 80
```
```
FIGURE 8.1(c)
```
```
EXAMPLE 3b
The number of students who enroll in a psychology course is a Poisson random vari-
able with mean 100. The professor in charge of the course has decided that if the
number enrolling is 120 or more, he will teach the course in two separate sections,
whereas if fewer than 120 students enroll, he will teach all of the students together
in a single section. What is the probability that the professor will have to teach two
sections?
```
```
Solution. The exact solution
```
```
e −^100
```
```
∑q
```
```
i = 120
```
```
( 100 ) i
i!
```
```
does not readily yield a numerical answer. However, by recalling that a Poisson ran-
dom variable with mean 100 is the sum of 100 independent Poisson random variables,
each with mean 1, we can make use of the central limit theorem to obtain an approx-
imate solution. If X denotes the number of students that enroll in the course, we
have
```
```
P { X Ú 120 }= P { X Ú 119. 5 } (the continuity correction)
```

```
Section 8.3 The Central Limit Theorem 397
```
```
Central Limit Theorem
```
```
Enter the probabilities and the number of random
variables to be summed. The output gives the mass
function of the sum along with its mean and
variance.
```
```
P0 .25
P1 .15
P2 .1
P3 .2
P4 .3
```
```
n = 100
```
```
Start
```
```
Quit
```
```
Mean = 215.
Variance = 252.75
```
```
0 400
i
```
```
0.000
```
```
0.030
```
```
p(i)
```
```
100 200 300
```
```
0.025
0.020
0.015
0.010
0.005
```
```
FIGURE 8.1(d)
```
##### = P

##### {

##### X − 100

##### √

##### 100

##### Ú

##### 119. 5 − 100

##### √

##### 100

##### }

##### L 1 −
( 1. 95 )

##### L. 0256

where we have used the fact that the variance of a Poisson random variable is equal
to its mean..

**_EXAMPLE 3c_**

If 10 fair dice are rolled, find the approximate probability that the sum obtained is
between 30 and 40, inclusive.

**_Solution._** Let _Xi_ denote the value of the _i_ th die, _i_ =1, 2,..., 10. Since

```
E ( Xi )=
```
##### 7

##### 2

```
,Var( Xi )= E [ Xi^2 ]−( E [ Xi ])^2 =
```
##### 35

##### 12

##### ,


**398** Chapter 8 Limit Theorems

```
the central limit theorem yields
```
##### P { 29. 5 ... X ... 40. 5 }= P

##### ⎧

##### ⎪⎪

##### ⎪⎨

##### ⎪⎪

##### ⎪⎩

##### 29. 5 − 35

##### √

##### 350

##### 12

##### ...

##### X − 35

##### √

##### 350

##### 12

##### ...

##### 40. 5 − 35

##### √

##### 350

##### 12

##### ⎫

##### ⎪⎪

##### ⎪⎬

##### ⎪⎪

##### ⎪⎭

##### L 2 
( 1. 0184 )− 1

##### L. 692.

```
EXAMPLE 3d
Let Xi , i =1,..., 10, be independent random variables, each uniformly distributed
```
```
over (0, 1). Calculate an approximation to P
```
##### {

##### ∑^10

```
i = 1
```
```
Xi > 6
```
##### }

##### .

```
Solution. Since E [ Xi ]=^12 and Var( Xi )= 121 , we have, by the central limit theorem,
```
##### P

##### ⎧

##### ⎨

##### ⎩

##### ∑^10

```
1
```
```
Xi > 6
```
##### ⎫

##### ⎬

##### ⎭

##### = P

##### ⎧

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎨

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎩

##### ∑^10

```
1
```
```
Xi − 5
```
```
√
10 (
```
##### 1

##### 12

##### )

##### >

##### 6 − 5

##### √

##### 10 (

##### 1

##### 12

##### )

##### ⎫

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎬

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎭

##### L 1 −
(

##### √

##### 1. 2 )

##### L. 1367

```
Hence,
```
##### ∑^10

```
i = 1
```
```
Xi will be greater than 6 only 14 percent of the time..
```
```
EXAMPLE 3e
An instructor has 50 exams that will be graded in sequence. The times required to
grade the 50 exams are independent, with a common distribution that has mean
20 minutes and standard deviation 4 minutes. Approximate the probability that the
instructor will grade at least 25 of the exams in the first 450 minutes of work.
```
```
Solution. If we let Xi be the time that it takes to grade exam i ,then
```
##### X =

##### ∑^25

```
i = 1
```
```
Xi
```
```
is the time it takes to grade the first 25 exams. Because the instructor will grade at
least 25 exams in the first 450 minutes of work if the time it takes to grade the first 25
exams is less than or equal to 450, we see that the desired probability is P { X ... 450 }.
To approximate this probability, we use the central limit theorem. Now,
```
##### E [ X ]=

##### ∑^25

```
i = 1
```
```
E [ Xi ]= 25 ( 20 )= 500
```
```
and
```
```
Var( X )=
```
##### ∑^25

```
i = 1
```
```
Var( Xi )= 25 ( 16 )= 400
```

```
Section 8.3 The Central Limit Theorem 399
```
Consequently, with _Z_ being a standard normal random variable, we have

```
P { X ... 450 }= P {
```
##### X − 500

##### √

##### 400

##### ...

##### 450 − 500

##### √

##### 400

##### }

##### L P { Z ...− 2. 5 }

##### = P { Z Ú 2. 5 }

##### = 1 −
( 2. 5 )=. 006.

Central limit theorems also exist when the _Xi_ are independent, but not necessarily
identically distributed random variables. One version, by no means the most general,
is as follows.

```
Theorem 3.2 Central limit theorem for independent random variables
Let X 1 , X 2 ,... be a sequence of independent random variables having respective
means and variances μ i = E [ Xi ],σ i^2 = Var( Xi ). If (a) the Xiare uniformly
```
```
bounded—that is, if for some M , P {| Xi |< M }= 1 for all i, and (b)
```
```
∑q
i = 1
```
```
σ i^2 =q —then
```
##### P

##### ⎧

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎪⎨

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎪⎩

```
∑ n
```
```
i = 1
```
```
( Xi −μ i )
√
√
√
√
```
```
∑ n
```
```
i = 1
```
```
σ i^2
```
```
... a
```
##### ⎫

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎪⎬

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎪⎭

```
→
( a ) as n →q
```
```
Historical Note
```
```
Pierre-Simon, Marquis de Laplace
The central limit theorem was originally stated and proven by the French math-
ematician Pierre-Simon, Marquis de Laplace, who came to the theorem from his
observations that errors of measurement (which can usually be regarded as being
the sum of a large number of tiny forces) tend to be normally distributed. Laplace,
who was also a famous astronomer (and indeed was called “the Newton of France”),
was one of the great early contributors to both probability and statistics. Laplace
was also a popularizer of the uses of probability in everyday life. He strongly believed
in its importance, as is indicated by the following quotations of his taken from his
published book Analytical Theory of Probability : “We see that the theory of proba-
bility is at bottom only common sense reduced to calculation; it makes us appreciate
with exactitude what reasonable minds feel by a sort of instinct, often without being
able to account for it....It is remarkable that this science, which originated in the
consideration of games of chance, should become the most important object of
human knowledge....The most important questions of life are, for the most part,
really only problems of probability.”
The application of the central limit theorem to show that measurement errors
are approximately normally distributed is regarded as an important contribution to
science. Indeed, in the 17th and 18th centuries the central limit theorem was often
called the law of frequency of errors. Listen to the words of Francis Galton (taken
from his book Natural Inheritance , published in 1889): “I know of scarcely anything
so apt to impress the imagination as the wonderful form of cosmic order expressed
by the ‘Law of Frequency of Error.’ The Law would have been personified by the
Greeks and deified, if they had known of it. It reigns with serenity and in complete
self-effacement amidst the wildest confusion. The huger the mob and the greater the
apparent anarchy, the more perfect is its sway. It is the supreme law of unreason.”
```

**400** Chapter 8 Limit Theorems

### 8.4 The Strong Law of Large Numbers

```
The strong law of large numbers is probably the best-known result in probability the-
ory. It states that the average of a sequence of independent random variables having
a common distribution will, with probability 1, converge to the mean of that distribu-
tion.
Theorem 4.1 The strong law of large numbers
Let X 1 , X 2 ,... be a sequence of independent and identically distributed random vari-
ables, each having a finite mean μ= E [ Xi ]. Then, with probability 1,
```
```
X 1 + X 2 + ··· + Xn
n
```
```
→μ as n →q†
As an application of the strong law of large numbers, suppose that a sequence of
independent trials of some experiment is performed. Let E be a fixed event of the
experiment, and denote by P ( E )the probability that E occurs on any particular trial.
Letting
Xi =
```
##### {

```
1if E occurs on the i th trial
0if E does not occur on the i th trial
```
```
we have, by the strong law of large numbers, that with probability 1,
```
```
X 1 + ··· + Xn
n
```
##### → E [ X ]= P ( E ) (4.1)

```
Since X 1 + ··· + Xn represents the number of times that the event E occurs in the
first n trials, we may interpret Equation (4.1) as stating that, with probability 1, the
limiting proportion of time that the event E occurs is just P ( E ).
Although the theorem can be proven without this assumption, our proof of the
strong law of large numbers will assume that the random variables Xi have a finite
fourth moment. That is, we will suppose that E [ Xi^4 ]= K <q.
Proof of the Strong Law of Large Numbers: To begin, assume thatμ, the mean of
the Xi , is equal to 0. Let Sn =
```
```
∑ n
i = 1
```
```
Xi and consider
```
```
E [ S^4 n ]= E [( X 1 + ··· + Xn )( X 1 + ··· + Xn )
*( X 1 + ··· + Xn )( X 1 + ··· + Xn )]
```
```
Expanding the right side of the preceding equation results in terms of the form
```
```
Xi^4 , X^3 iXj , X^2 iXj^2 , Xi^2 XjXk ,and XiXjXkXl
```
```
where i , j , k ,and l are all different. Because all the Xi have mean 0, it follows by
independence that
```
```
E [ Xi^3 Xj ]= E [ Xi^3 ] E [ Xj ]= 0
E [ Xi^2 XjXk ]= E [ Xi^2 ] E [ Xj ] E [ Xk ]= 0
E [ XiXjXkXl ]= 0
```
```
†That is, the strong law of large numbers states that
```
```
P {lim
n →q
( X 1 + ··· + Xn )/ n =μ}= 1
```

```
Section 8.4 The Strong Law of Large Numbers 401
```
Now, for a given pair _i_ and _j_ , there will be

##### (

##### 4

##### 2

##### )

```
=6 terms in the expansion that will
```
equal _Xi_^2 _Xj_^2. Hence, upon expanding the preceding product and taking expectations
term by term, it follows that

```
E [ S^4 n ]= nE [ Xi^4 ]+ 6
```
##### (

```
n
2
```
##### )

```
E [ Xi^2 Xj^2 ]
```
```
= nK + 3 n ( n − 1 ) E [ Xi^2 ] E [ Xj^2 ]
```
where we have once again made use of the independence assumption. Now, since

```
0 ...Var( Xi^2 )= E [ Xi^4 ] −( E [ Xi^2 ])^2
```
we have
( _E_ [ _Xi_^2 ])^2 ... _E_ [ _Xi_^4 ]= _K_

Therefore, from the preceding, we obtain

```
E [ S^4 n ]... nK + 3 n ( n − 1 ) K
```
which implies that

```
E
```
##### [

```
S^4 n
n^4
```
##### ]

##### ...

##### K

```
n^3
```
##### +

##### 3 K

```
n^2
```
Therefore,

```
E
```
##### ⎡

##### ⎣

```
∑q
```
```
n = 1
```
```
S^4 n
n^4
```
##### ⎤

##### ⎦=

```
∑q
```
```
n = 1
```
##### E

##### [

```
S^4 n
n^4
```
##### ]

```
<q
```
But the preceding implies that, with probability 1,

```
∑q
n = 1
```
```
S^4 n / n^4 <q. (For if there is a
```
positive probability that the sum is infinite, then its expected value is infinite.) But the
convergence of a series implies that its _n_ th term goes to 0; so we can conclude that,
with probability 1,

```
lim
n →q
```
```
S^4 n
n^4
```
##### = 0

But if _S_^4 _n_ / _n_^4 =( _Sn_ / _n_ )^4 goes to 0, then so must _Sn_ / _n_ ; hence, we have proven that, with
probability 1,
_Sn
n_

```
→0as n →q
```
Whenμ, the mean of the _Xi_ , is not equal to 0, we can apply the preceding argument
to the random variables _Xi_ −μto obtain that with probability 1,

```
lim
n →q
```
```
∑ n
```
```
i = 1
```
```
( Xi −μ)
n
```
##### = 0

or, equivalently,

```
lim
n →q
```
```
∑ n
```
```
i = 1
```
```
Xi
n
```
```
=μ
```
which proves the result.


**402** Chapter 8 Limit Theorems

```
The strong law is illustrated by two modules on the text website that consider inde-
pendent and identically distributed random variables which take on one of the values
0, 1, 2, 3, and 4. The modules simulate the values of n such random variables; the
proportions of time that each outcome occurs, as well as the resulting sample mean
∑ n
i = 1
```
```
Xi / n , are then indicated and plotted. When using these modules, which differ only
```
```
in the type of graph presented, one enters the probabilities and the desired value of n.
Figure 8.2 gives the results of a simulation using a specified probability mass function
and (a) n =100, (b) n =1000, and (c) n =10,000.
Many students are initially confused about the difference between the weak and
the strong laws of large numbers. The weak law of large numbers states that, for any
specified large value n ∗,( X 1 + ··· + Xn ∗)/ n ∗is likely to be nearμ. However, it does
not say that( X 1 + ··· + Xn )/ n is bound to stay nearμfor all values of n larger than
n ∗. Thus, it leaves open the possibility that large values of|( X 1 + ··· + Xn )/ n −μ|
can occur infinitely often (though at infrequent intervals). The strong law shows that
this cannot occur. In particular, it implies that, with probability 1, for any positive
valueε, ∣
∣
∣
∣
∣
∣
```
```
∑ n
```
```
1
```
```
Xi
n
```
```
−μ
```
##### ∣ ∣ ∣ ∣ ∣ ∣

```
will be greater thanεonly a finite number of times.
```
```
Strong Law Of Large Numbers
```
```
Enter the probabilities and the number of trials
to be simulated. The output gives the total number
of times each outcome occurs, and the average
of all outcomes.
```
```
P0 .1
P1 .2
P2 .3
P3 .35
P4 .05
```
```
n = 100
```
```
Start
```
```
Quit
```
```
Theoretical Mean = 2.05
Sample Mean = 1.89
```
##### 0

```
15
```
##### 1

```
20
```
##### 2

```
30
```
##### 3

```
31
```
##### 4

```
4
```
```
FIGURE 8.2(a)
```

```
Section 8.5 Other Inequalities 403
```
```
Strong Law Of Large Numbers
```
```
Enter the probabilities and the number of trials
to be simulated. The output gives the total number
of times each outcome occurs, and the average
of all outcomes.
```
```
P0 .1
P1 .2
P2 .3
P3 .35
P4 .05
```
```
n = 1000
```
```
Start
```
```
Quit
```
```
Theoretical Mean = 2.05
Sample Mean = 2.078
```
##### 0

```
106
```
##### 1

```
189
```
##### 2

```
285
```
##### 3

```
361
```
##### 4

```
59
```
```
FIGURE 8.2(b)
```
```
The strong law of large numbers was originally proven, in the special case of
Bernoulli random variables, by the French mathematician Borel. The general form of
the strong law presented in Theorem 4.1 was proven by the Russian mathematician
A. N. Kolmogorov.
```
### 8.5 Other Inequalities

```
We are sometimes confronted with situations in which we are interested in obtaining
an upper bound for a probability of the form P { X −μÚ a }, where a is some positive
value and when only the meanμ= E [ X ] and varianceσ^2 =Var( X )of the distribu-
tion of X are known. Of course, since X −μÚ a >0 implies that| X −μ|Ú a ,it
follows from Chebyshev’s inequality that
```
```
P { X −μÚ a }... P {| X −μ|Ú a }...
```
```
σ^2
a^2
```
```
when a > 0
```
```
However, as the following proposition shows, it turns out that we can do better.
Proposition 5.1. One-sided Chebyshev inequality
If X is a random variable with mean 0 and finite varianceσ^2 , then, for any a >0,
```
```
P { X Ú a }...
```
```
σ^2
σ^2 + a^2
```

**404** Chapter 8 Limit Theorems

```
Strong Law Of Large Numbers
```
```
Enter the probabilities and the number of trials
to be simulated. The output gives the total number
of times each outcome occurs, and the average
of all outcomes.
```
```
P0 .1
P1 .2
P2 .3
P3 .35
P4 .05
```
```
n = 10000
```
```
Start
```
```
Quit
```
```
Theoretical Mean = 2.05
Sample Mean = 2.0416
```
##### 0

```
1041
```
##### 1

```
2027
```
##### 2

```
2917
```
##### 3

```
3505
```
##### 4

```
510
```
```
FIGURE 8.2(c)
```
```
Proof. Let b >0 and note that
```
```
X Ú a is equivalent to X + b Ú a + b
```
```
Hence,
```
```
P { X Ú a }= P { X + b Ú a + b }
... P {( X + b )^2 Ú( a + b )^2 }
```
```
where the inequality is obtained by noting that since a + b >0, X + b Ú a + b
implies that( X + b )^2 Ú ( a + b )^2. Upon applying Markov’s inequality, the
preceding yields that
```
```
P { X Ú a }...
```
```
E [( X + b )^2 ]
( a + b )^2
```
##### =

```
σ^2 + b^2
( a + b )^2
```
```
Letting b = σ^2 / a [which is easily seen to be the value of b that minimizes
(σ^2 + b^2 )/( a + b )^2 ] gives the desired result.
```

```
Section 8.5 Other Inequalities 405
```
**_EXAMPLE 5a_**

If the number of items produced in a factory during a week is a random variable with
mean 100 and variance 400, compute an upper bound on the probability that this
week’s production will be at least 120.

**_Solution._** It follows from the one-sided Chebyshev inequality that

##### P { X Ú 120 }= P { X − 100 Ú 20 }...

##### 400

##### 400 +( 20 )^2

##### =

##### 1

##### 2

Hence, the probability that this week’s production will be 120 or more is at most^12.
If we attempted to obtain a bound by applying Markov’s inequality, then we would
have obtained

```
P { X Ú 120 }...
```
##### E ( X )

##### 120

##### =

##### 5

##### 6

which is a far weaker bound than the preceding one..

Suppose now that _X_ has meanμand varianceσ^2. Since both _X_ −μandμ− _X_
have mean 0 and varianceσ^2 , it follows from the one-sided Chebyshev inequality
that, for _a_ >0,

```
P { X −μÚ a }...
```
```
σ^2
σ^2 + a^2
```
and

```
P {μ− X Ú a }...
```
```
σ^2
σ^2 + a^2
```
Thus, we have the following corollary.

**Corollary 5.1.** If _E_ [ _X_ ]=μand Var( _X_ )=σ^2 , then, for _a_ >0,

```
P { X Úμ+ a }...
```
```
σ^2
σ^2 + a^2
```
```
P { X ...μ− a }...
```
```
σ^2
σ^2 + a^2
```
**_EXAMPLE 5b_**

A set of 200 people consisting of 100 men and 100 women is randomly divided into
100 pairs of 2 each. Give an upper bound to the probability that at most 30 of these
pairs will consist of a man and a woman.

**_Solution._** Number the men arbitrarily from 1 to 100, and for _i_ =1, 2,...100, let

```
Xi =
```
##### {

```
1ifman i is paired with a woman
0 otherwise
```
Then _X_ , the number of man–woman pairs, can be expressed as

##### X =

##### ∑^100

```
i = 1
```
```
Xi
```

**406** Chapter 8 Limit Theorems

```
Because man i is equally likely to be paired with any of the other 199 people, of which
100 are women, we have
```
```
E [ Xi ]= P { Xi = 1 }=
```
##### 100

##### 199

```
Similarly, for i Z j ,
```
```
E [ XiXj ]= P { Xi =1, Xj = 1 }
```
```
= P { Xi = 1 } P { Xj = 1 | Xi = 1 }=
```
##### 100

##### 199

##### 99

##### 197

```
where P { Xj = 1 | Xi = 1 }= 99 /197, since, given that man i is paired with a woman,
man j is equally likely to be paired with any of the remaining 197 people, of which 99
are women. Hence, we obtain
```
##### E [ X ]=

##### ∑^100

```
i = 1
```
```
E [ Xi ]
```
##### =( 100 )

##### 100

##### 199

##### L 50. 25

```
Var( X )=
```
##### ∑^100

```
i = 1
```
```
Var( Xi )+ 2
```
##### ∑

```
i < j
```
##### ∑

```
Cov( Xi , Xj )
```
##### = 100

##### 100

##### 199

##### 99

##### 199

##### + 2

##### (

##### 100

##### 2

##### )[

##### 100

##### 199

##### 99

##### 197

##### −

##### (

##### 100

##### 199

##### ) 2 ]

##### L 25. 126

```
The Chebyshev inequality then yields
```
##### P { X ... 30 }... P {| X − 50. 25 |Ú 20. 25 }...

##### 25. 126

##### ( 20. 25 )^2

##### L. 061

```
Thus, there are fewer than 6 chances in a hundred that fewer than 30 men will be
paired with women. However, we can improve on this bound by using the one-sided
Chebyshev inequality, which yields
```
```
P { X ... 30 }= P { X ... 50. 25 − 20. 25 }
```
```
...
```
##### 25. 126

##### 25. 126 +( 20. 25 )^2

##### L. 058.

```
When the moment generating function of the random variable X is known, we can
obtain even more effective bounds on P { X Ú a }.Let
```
```
M ( t )= E [ etX ]
```
```
be the moment generating function of the random variable X. Then, for t >0,
```
```
P { X Ú a }= P { etX Ú eta }
... E [ etX ] e − ta by Markov’s inequality
```

```
Section 8.5 Other Inequalities 407
```
Similarly, for _t_ <0,

```
P { X ... a }= P { etX Ú eta }
... E [ etX ] e − ta
```
Thus, we have the following inequalities, known as _Chernoff bounds_.

**Proposition 5.2. Chernoff bounds**

```
P { X Ú a }... e − taM ( t ) for all t > 0
P { X ... a }... e − taM ( t ) for all t < 0
```
Since the Chernoff bounds hold for all _t_ in either the positive or negative quadrant,
we obtain the best bound on _P_ { _X_ Ú _a_ }by using the _t_ that minimizes _e_ − _taM_ ( _t_ ).

**_EXAMPLE 5c Chernoff bounds for the standard normal random variable_**

If _Z_ is a standard normal random variable, then its moment generating function is

_M_ ( _t_ )= _et_

(^2) / 2
, so the Chernoff bound on _P_ { _Z_ Ú _a_ }is given by
_P_ { _Z_ Ú _a_ }... _e_ − _taet_
(^2) / 2
for all _t_ > 0
Now the value of _t_ , _t_ >0, that minimizes _et_
(^2) / 2 − _ta_
is the value that minimizes _t_^2 / 2 − _ta_ ,
which is _t_ = _a_. Thus, for _a_ >0, we have
_P_ { _Z_ Ú _a_ }... _e_ − _a_
(^2) / 2
Similarly, we can show that, for _a_ <0,
_P_ { _Z_ ... _a_ }... _e_ − _a_
(^2) / 2
.
**_EXAMPLE 5d Chernoff bounds for the Poisson random variable_**
If _X_ is a Poisson random variable with parameterλ, then its moment generating func-
tion is _M_ ( _t_ )= _e_ λ( _e
t_ − 1 )

. Hence, the Chernoff bound on _P_ { _X_ Ú _i_ }is

```
P { X Ú i }... e λ( e
```
```
t − 1 )
e − it t > 0
```
Minimizing the right side of the preceding inequality is equivalent to minimizing
λ( _et_ − 1 )− _it_ , and calculus shows that the minimal value occurs when _et_ = _i_ /λ. Pro-
vided that _i_ /λ >1, this minimizing value of _t_ will be positive. Therefore, assuming
that _i_ >λand letting _et_ = _i_ /λin the Chernoff bound yields

```
P { X Ú i }... e λ( i /λ−^1 )
```
##### (

```
λ
i
```
```
) i
```
or, equivalently,

```
P { X Ú i }...
```
```
e −λ( e λ) i
ii
```
##### .

**_EXAMPLE 5e_**

Consider a gambler who is equally likely to either win or lose 1 unit on every play,
independently of his past results. That is, if _Xi_ is the gambler’s winnings on the _i_ th
play, then the _Xi_ are independent and


**408** Chapter 8 Limit Theorems

```
P { Xi = 1 }= P { Xi =− 1 }=
```
##### 1

##### 2

```
Let Sn =
```
```
∑ n
i = 1
```
```
Xi denote the gambler’s winnings after n plays. We will use the Chernoff
```
```
bound on P { Sn Ú a }. To start, note that the moment generating function of Xi is
```
```
E [ etX ]=
```
```
et + e − t
2
```
```
Now, using the McLaurin expansions of et and e − t , we see that
```
```
et + e − t = 1 + t +
```
```
t^2
2!
```
##### +

```
t^3
3!
```
##### + ··· +

##### (

```
1 − t +
```
```
t^2
2!
```
##### −

```
t^3
3!
```
##### + ···

##### )

##### = 2

##### {

##### 1 +

```
t^2
2!
```
##### +

```
t^4
4!
```
##### + ···

##### }

##### = 2

```
∑q
```
```
n = 0
```
```
t^2 n
( 2 n )!
```
##### ... 2

```
∑q
```
```
n = 0
```
```
( t^2 / 2 ) n
n!
```
```
since( 2 n )!Ú n !2 n
```
```
= 2 et
```
(^2) / 2
Therefore,
_E_ [ _etX_ ]Ú _et_
(^2) / 2
Since the moment generating function of the sum of independent random variables
is the product of their moment generating functions, we have
_E_ [ _etSn_ ]=( _E_ [ _etX_ ]) _n_
... _ent_
(^2) / 2
Using the preceding result along with the Chernoff bound gives
_P_ { _Sn_ Ú _a_ }... _e_ − _taent_
(^2) / 2
_t_ > 0
The value of _t_ that minimizes the right side of the preceding is the value that min-
imizes _nt_^2 / 2 − _ta_ , and this value is _t_ = _a_ / _n_. Supposing that _a_ > 0 (so that the
minimizing _t_ is positive) and letting _t_ = _a_ / _n_ in the preceding inequality yields
_P_ { _Sn_ Ú _a_ }... _e_ − _a_
(^2) / 2 _n
a_ > 0
This latter inequality yields, for example,
_P_ { _S_ 10 Ú 6 }... _e_ −^36 /^20 L. 1653


```
Section 8.5 Other Inequalities 409
```
whereas the exact probability is

```
P { S 10 Ú 6 }= P {gambler wins at least 8 of the first 10 games}
```
##### =

##### (

##### 10

##### 8

##### )

##### +

##### (

##### 10

##### 9

##### )

##### +

##### (

##### 10

##### 10

##### )

##### 210

##### =

##### 56

##### 1024

##### L. 0547.

The next inequality is one having to do with expectations rather than probabilities.
Before stating it, we need the following definition.

```
Definition
```
```
A twice-differentiable real-valued function f ( x )is said to be convex if f ′′( x )Ú0for
all x ; similarly, it is said to be concave if f ′′( x )...0.
```
Some examples of convex functions are _f_ ( _x_ )= _x_^2 , _f_ ( _x_ )= _eax_ ,and _f_ ( _x_ )=− _x_^1 / _n_ for
_x_ Ú0. If _f_ ( _x_ )is convex, then _g_ ( _x_ )=− _f_ ( _x_ )is concave, and vice versa.

**Proposition 5.3. Jensen’s inequality**
If _f_ ( _x_ )is a convex function, then

```
E [ f ( X )]Ú f ( E [ X ])
```
provided that the expectations exist and are finite.

```
Proof. Expanding f ( x )in a Taylor’s series expansion aboutμ= E [ X ] yields
```
```
f ( x )= f (μ)+ f ′(μ)( x −μ)+
```
```
f ′′(ξ )( x −μ)^2
2
whereξis some value between x andμ. Since f ′′(ξ )Ú0, we obtain
```
```
f ( x )Ú f (μ)+ f ′(μ)( x −μ)
```
```
Hence,
f ( X )Ú f (μ)+ f ′(μ)( X −μ)
```
```
Taking expectations yields
```
```
E [ f ( X )]Ú f (μ)+ f ′(μ) E [ X −μ]= f (μ)
```
```
and the inequality is established.
```
**_EXAMPLE 5f_**

An investor is faced with the following choices: Either she can invest all of her money
in a risky proposition that would lead to a random return _X_ that has mean _m_ ,or
she can put the money into a risk-free venture that will lead to a return of _m_ with
probability 1. Suppose that her decision will be made on the basis of maximizing the
expected value of _u_ ( _R_ ), where _R_ is her return and _u_ is her utility function. By Jensen’s
inequality, it follows that if _u_ is a concave function, then _E_ [ _u_ ( _X_ )]... _u_ ( _m_ ), so the risk-
free alternative is preferable, whereas if _u_ is convex, then _E_ [ _u_ ( _X_ )] Ú _u_ ( _m_ ),sothe
risky investment alternative would be preferred..


**410** Chapter 8 Limit Theorems

**8.6 BOUNDING THE ERROR PROBABILITY WHEN APPROXIMATING A SUM OF INDEPENDENT
BERNOULLI RANDOM VARIABLES BY A POISSON RANDOM VARIABLE**
In this section, we establish bounds on how closely a sum of independent Bernoulli
random variables is approximated by a Poisson random variable with the same mean.
Suppose that we want to approximate the sum of independent Bernoulli random
variables with respective means _p_ 1 , _p_ 2 ,..., _pn_. Starting with a sequence _Y_ 1 ,..., _Yn_
of independent Poisson random variables, with _Yi_ having mean _pi_ , we will construct
a sequence of independent Bernoulli random variables _X_ 1 ,..., _Xn_ with parameters
_p_ 1 ,..., _pn_ such that

```
P { Xi Z Yi }... p^2 i for each i
```
```
Letting X =
```
```
∑ n
i = 1
```
```
Xi and Y =
```
```
∑ n
i = 1
```
```
Yi , we will use the preceding inequality to con-
```
```
clude that
```
##### P { X Z Y }...

```
∑ n
```
```
i = 1
```
```
p^2 i
```
```
Finally, we will show that the preceding inequality implies that, for any set of real
numbers A ,
```
##### | P { X ∈ A }− P { Y ∈ A }|...

```
∑ n
```
```
i = 1
```
```
p^2 i
```
```
Since X is the sum of independent Bernoulli random variables and Y is a Poisson
random variable, the latter inequality will yield the desired bound.
To show how the task is accomplished, let Yi , i =1,..., n be independent Pois-
son random variables with respective means pi. Now let U 1 ,..., Un be independent
random variables that are also independent of the Yi ’s and which are such that
```
```
Ui =
```
##### {

```
0 with probability ( 1 − pi ) epi
1 with probability 1−( 1 − pi ) epi
```
```
This definition implicitly makes use of the inequality
```
```
e − p Ú 1 − p
```
```
in assuming that( 1 − pi ) epi ...1.
Next, define the random variables Xi , i =1,..., n ,by
```
```
Xi =
```
##### {

```
0if Yi = Ui = 0
1 otherwise
```
```
Note that
```
```
P { Xi = 0 }= P { Yi = 0 } P { Ui = 0 }= e − pi ( 1 − pi ) epi = 1 − pi
P { Xi = 1 }= 1 − P { Xi = 0 }= pi
```

```
Section 8.6 Bounding the Error Probability 411
```
Now, if _Xi_ is equal to 0, then so must _Yi_ equal 0 (by the definition of _Xi_ ). Therefore,

```
P { Xi Z Yi }= P { Xi =1, Yi Z 1 }
= P { Yi =0, Xi = 1 }+ P { Yi > 1 }
= P { Yi =0, Ui = 1 }+ P { Yi > 1 }
= e − pi [1−( 1 − pi ) epi ]+ 1 − e − pi − pie − pi
= pi − pie − pi
... p^2 i (since 1− e − p ... p )
```
Now let _X_ =

```
∑ n
i = 1
```
```
Xi and Y =
```
```
∑ n
i = 1
```
```
Yi , and note that X is the sum of independent
```
Bernoulli random variables and _Y_ is Poisson with the expected value _E_ [ _Y_ ]= _E_ [ _X_ ]=
∑ _n_

_i_ = 1

```
pi. Note also that the inequality X Z Y implies that Xi Z Yi for some i ,so
```
```
P { X Z Y }... P { Xi Z Yi for some i }
```
##### ...

```
∑ n
```
```
i = 1
```
```
P { Xi Z Yi } (Boole’s inequality)
```
##### ...

```
∑ n
```
```
i = 1
```
```
p^2 i
```
For any event _B_ , let _IB_ , the indicator variable for the event _B_ ,bedefinedby

##### IB =

##### {

```
1if B occurs
0 otherwise
```
Note that, for any set of real numbers _A_ ,

```
I { X ∈ A }− I { Y ∈ A }... I { X Z Y }
```
The preceding inequality follows from the fact that, since an indicator variable is
either 0 or 1, the left-hand side equals 1 only when _I_ { _X_ ∈ _A_ }=1and _I_ { _Y_ ∈ _A_ }=0. But
this would imply that _X_ ∈ _A_ and _Y_ ∈ _A_ , which means that _X_ Z _Y_ , so the right side
would also equal 1. Upon taking expectations of the preceding inequality, we obtain

```
P { X ∈ A }− P { Y ∈ A }... P { X Z Y }
```
By reversing _X_ and _Y_ , we obtain, in the same manner,

```
P { Y ∈ A }− P { X ∈ A }... P { X Z Y }
```
Thus, we can conclude that

```
| P { X ∈ A }− P { Y ∈ A }|... P { X Z Y }
```
Therefore, we have proven that withλ=

```
∑ n
i = 1
```
```
pi ,
```
```
∣ ∣ ∣ ∣ ∣ ∣ ∣
```
##### P

##### ⎧

##### ⎨

##### ⎩

```
∑ n
```
```
i = 1
```
```
Xi ∈ A
```
##### ⎫

##### ⎬

##### ⎭

##### −

##### ∑

```
i ∈ A
```
```
e −λλ i
i!
```
##### ∣ ∣ ∣ ∣ ∣ ∣ ∣

##### ...

```
∑ n
```
```
i = 1
```
```
p^2 i
```

**412** Chapter 8 Limit Theorems

```
Remark. When all the pi are equal to p , X is a binomial random variable. Hence,
the preceding inequality shows that, for any set of nonnegative integers A ,
∣ ∣ ∣ ∣ ∣ ∣
∑
```
```
i ∈ A
```
##### (

```
n
i
```
##### )

```
pi ( 1 − p ) n − i −
```
##### ∑

```
i ∈ A
```
```
e − np ( np ) i
i!
```
##### ∣ ∣ ∣ ∣ ∣ ∣

```
... np^2.
```
#### Summary

```
Two useful probability bounds are provided by the Markov and Chebyshev inequali-
ties. The Markov inequality is concerned with nonnegative random variables and says
that, for X of that type,
P { X Ú a }...
```
##### E [ X ]

```
a
for every positive value a. The Chebyshev inequality, which is a simple consequence
of the Markov inequality, states that if X has meanμand varianceσ^2 , then, for every
positive k ,
P {| X −μ|Ú k σ}...
```
##### 1

```
k^2
The two most important theoretical results in probability are the central limit theorem
and the strong law of large numbers. Both are concerned with a sequence of indepen-
dent and identically distributed random variables. The central limit theorem says that
if the random variables have a finite meanμand a finite varianceσ^2 , then the distri-
bution of the sum of the first n of them is, for large n , approximately that of a normal
random variable with mean n μand variance n σ^2. That is, if Xi , i Ú1, is the sequence,
then the central limit theorem states that, for every real number a ,
```
```
lim
n →q
```
##### P

##### {

```
X 1 + ··· + Xn − n μ
σ
```
##### √

```
n
```
```
... a
```
##### }

##### =

##### 1

##### √

```
2 π
```
```
∫ a
```
```
−q
```
```
e − x
```
(^2) / 2
_dx_
The _strong law of large numbers_ requires only that the random variables in the sequence
have a finite meanμ. It states that, with probability 1, the average of the first _n_ of them
will converge toμas _n_ goes to infinity. This implies that if _A_ is any specified event
of an experiment for which independent replications are performed, then the limit-
ing proportion of experiments whose outcomes are in _A_ will, with probability 1, equal
_P_ ( _A_ ). Therefore, if we accept the interpretation that “with probability 1” means “with
certainty,” we obtain the theoretical justification for the long-run relative frequency
interpretation of probabilities.

#### Problems...................................

```
8.1. Suppose that X is a random variable with mean
and variance both equal to 20. What can be said
about P { 0 < X < 40 }?
8.2. From past experience, a professor knows that the
test score of a student taking her final examination
is a random variable with mean 75.
(a) Give an upper bound for the probability that
a student’s test score will exceed 85. Sup-
pose, in addition, that the professor knows
```
```
that the variance of a student’s test score is
equal to 25.
(b) What can be said about the probability that a
student will score between 65 and 85?
(c) How many students would have to take the
examination to ensure, with probability at
least .9, that the class average would be
within 5 of 75? Do not use the central limit
theorem.
```

```
Problems 413
```
```
8.3. Use the central limit theorem to solve part (c) of
Problem 2.
8.4. Let X 1 ,..., X 20 be independent Poisson random
variables with mean 1.
(a) Use the Markov inequality to obtain a
bound on
```
```
P
```
```
⎧
⎨
⎩
```
```
∑^20
```
```
1
```
```
Xi > 15
```
```
⎫
⎬
⎭
(b) Use the central limit theorem to approximate
```
```
P
```
```
⎧
⎨
⎩
```
```
∑^20
```
```
1
```
```
Xi > 15
```
```
⎫
⎬
⎭
.
```
```
8.5. Fifty numbers are rounded off to the nearest inte-
ger and then summed. If the individual round-
off errors are uniformly distributed over(−.5,. 5 ),
approximate the probability that the resultant sum
differs from the exact sum by more than 3.
8.6. A die is continually rolled until the total sum of
all rolls exceeds 300. Approximate the probability
that at least 80 rolls are necessary.
8.7. A person has 100 light bulbs whose lifetimes are
independent exponentials with mean 5 hours. If
the bulbs are used one at a time, with a failed bulb
being replaced immediately by a new one, approx-
imate the probability that there is still a working
bulb after 525 hours.
8.8. In Problem 7, suppose that it takes a random time,
uniformly distributed over (0, .5), to replace a
failed bulb. Approximate the probability that all
bulbs have failed by time 550.
8.9. If X is a gamma random variable with parameters
( n , 1), approximately how large need n be so that
```
```
P
```
```
{∣
∣
∣∣ X
n
```
```
− 1
```
```
∣
∣
∣∣>. 01
```
```
}
<.01?
```
**8.10.** Civil engineers believe that _W_ , the amount of
weight (in units of 1000 pounds) that a certain span
of a bridge can withstand without structural dam-
age resulting, is normally distributed with mean
400 and standard deviation 40. Suppose that the
weight (again, in units of 1000 pounds) of a car
is a random variable with mean 3 and standard
deviation .3. Approximately how many cars would
have to be on the bridge span for the probability
of structural damage to exceed .1?
**8.11.** Many people believe that the daily change of price
of a company’s stock on the stock market is a ran-
dom variable with mean 0 and varianceσ^2 .That
is, if _Yn_ represents the price of the stock on the _n_ th
day, then
_Yn_ = _Yn_ − 1 + _Xn n_ Ú 1
where _X_ 1 , _X_ 2 ,...are independent and identically
distributed random variables with mean 0 and

```
varianceσ^2. Suppose that the stock’s price today
is 100. Ifσ^2 =1, what can you say about the prob-
ability that the stock’s price will exceed 105 after
10 days?
8.12. We have 100 components that we will put in use in
a sequential fashion. That is, component 1 is ini-
tially put in use, and upon failure, it is replaced
by component 2, which is itself replaced upon fail-
ure by component 3, and so on. If the lifetime
of component i is exponentially distributed with
mean 10+ i /10, i =1,..., 100, estimate the prob-
ability that the total life of all components will
exceed 1200. Now repeat when the life distribu-
tion of component i is uniformly distributed over
(0, 20+ i / 5 ), i =1,..., 100.
8.13. Student scores on exams given by a certain instruc-
tor have mean 74 and standard deviation 14. This
instructor is about to give two exams, one to a class
of size 25 and the other to a class of size 64.
(a) Approximate the probability that the average
test score in the class of size 25 exceeds 80.
(b) Repeat part (a) for the class of size 64.
(c) Approximate the probability that the average
test score in the larger class exceeds that of
the other class by over 2.2 points.
(d) Approximate the probability that the average
test score in the smaller class exceeds that of
the other class by over 2.2 points.
8.14. A certain component is critical to the operation of
an electrical system and must be replaced immedi-
ately upon failure. If the mean lifetime of this type
of component is 100 hours and its standard devi-
ation is 30 hours, how many of these components
must be in stock so that the probability that the
system is in continual operation for the next 2000
hours is at least .95?
8.15. An insurance company has 10,000 automobile pol-
icyholders. The expected yearly claim per policy-
holder is $240, with a standard deviation of $800.
Approximate the probability that the total yearly
claim exceeds $2.7 million.
8.16. A.J. has 20 jobs that she must do in sequence, with
the times required to do each of these jobs being
independent random variables with mean 50 min-
utes and standard deviation 10 minutes. M.J. has
20 jobs that he must do in sequence, with the times
required to do each of these jobs being indepen-
dent random variables with mean 52 minutes and
standard deviation 15 minutes.
(a) Find the probability that A.J. finishes in less
than 900 minutes.
(b) Find the probability that M.J. finishes in less
than 900 minutes.
(c) Find the probability that A.J. finishes
before M.J.
```

**414** Chapter 8 Limit Theorems

```
8.17. Redo Example 5b under the assumption that the
number of man–woman pairs is (approximately)
normally distributed. Does this seem like a reason-
able supposition?
8.18. Repeat part (a) of Problem 2 when it is known that
the variance of a student’s test score is equal to 25.
8.19. A lake contains 4 distinct types of fish. Suppose
that each fish caught is equally likely to be any
one of these types. Let Y denote the number of
fish that need be caught to obtain at least one of
each type.
(a) Give an interval ( a , b ) such that P { a ... Y ... b }
Ú.90.
(b) Using the one-sided Chebyshev inequality,
how many fish need we plan on catching so as
to be at least 90 percent certain of obtaining
at least one of each type.
8.20. If X is a nonnegative random variable with mean
25, what can be said about
(a) E [ X^3 ]?
(b) E [
```
```
√
X ]?
(c) E [log X ]?
(d) E [ e − X ]?
```
```
8.21. Let X be a nonnegative random variable.
Prove that
```
```
E [ X ]...( E [ X^2 ])^1 /^2 ...( E [ X^3 ])^1 /^3 ...···
```
```
8.22. Would the results of Example 5f change if the
investor were allowed to divide her money and
invest the fractionα,0<α<1, in the risky propo-
sition and invest the remainder in the risk-free
venture? Her return for such a split investment
would be R =α X +( 1 −α) m.
8.23. Let X be a Poisson random variable with mean 20.
(a) Use the Markov inequality to obtain an upper
bound on
p = P { X Ú 26 }
```
```
(b) Use the one-sided Chebyshev inequality to
obtain an upper bound on p.
(c) Use the Chernoff bound to obtain an upper
bound on p.
(d) Approximate p by making use of the central
limit theorem.
(e) Determine p by running an appropriate pro-
gram.
```
#### Theoretical Exercises

```
8.1. If X has varianceσ^2 ,thenσ, the positive square
root of the variance, is called the standard devia-
tion .If X has meanμand standard deviationσ,
show that
```
```
P {| X −μ|Ú k σ}...
1
k^2
```
```
8.2. If X has meanμand standard deviationσ,the
ratio r K|μ|/σis called the measurement signal-
to-noise ratio of X. The idea is that X can be
expressed as X =μ+( X −μ), withμrepresent-
ing the signal and X −μthe noise. If we define
|( X − μ)/μ|K D as the relative deviation of X
from its signal (or mean)μ, show that, forα>0,
```
```
P { D ...α}Ú 1 −
```
```
1
r^2 α^2
```
```
8.3. Compute the measurement signal-to-noise ratio—
that is,|μ|/σ,whereμ= E [ X ]andσ^2 =Var( X )—
of the following random variables:
(a) Poisson with meanλ;
(b) binomial with parameters n and p ;
(c) geometric with mean 1/ p ;
(d) uniform over( a , b );
(e) exponential with mean 1/λ;
(f) normal with parametersμ,σ^2.
```
```
8.4. Let Zn , n Ú1, be a sequence of random variables
and c a constant such that, for eachε>0, P {| Zn −
c |>ε}→0as n →q. Show that, for any bounded
continuous function g ,
```
```
E [ g ( Zn )]→ g ( c ) as n →q
```
```
8.5. Let f ( x )be a continuous function defined for 0...
x ...1. Consider the functions
```
```
Bn ( x )=
```
```
∑ n
```
```
k = 0
```
```
f
```
```
(
k
n
```
```
)(
n
k
```
```
)
xk ( 1 − x ) n − k
```
```
(called Bernstein polynomials ) and prove that
```
```
lim
n →q
Bn ( x )= f ( x )
```
```
Hint :Let X 1 , X 2 ,...be independent Bernoulli
random variables with mean x. Show that
```
```
Bn ( x )= E
```
```
[
f
```
```
(
X 1 + ··· + Xn
n
```
```
)]
```
```
and then use Theoretical Exercise 4.
Since it can be shown that the convergence of
Bn ( x )to f ( x )is uniform in x , the preceding rea-
soning provides a probabilistic proof of the famous
Weierstrass theorem of analysis, which states that
```

```
Self-Test Problems and Exercises 415
```
any continuous function on a closed interval can be
approximated arbitrarily closely by a polynomial.
**8.6. (a)** Let _X_ be a discrete random variable whose
possible values are 1, 2,....If _P_ { _X_ = _k_ }is
nonincreasing in _k_ =1, 2,..., prove that

```
P { X = k }... 2
```
```
E [ X ]
k^2
(b) Let X be a nonnegative continuous random
variable having a nonincreasing density func-
tion. Show that
```
```
f ( x )...
2 E [ X ]
x^2
```
```
for all x > 0
```
**8.7.** Suppose that a fair die is rolled 100 times. Let _Xi_
be the value obtained on the _i_ th roll. Compute an
approximation for

```
P
```
```
⎧
⎨
⎩
```
(^100) ∏
1
_Xi_ ... _a_^100
⎫
⎬
⎭
1 < _a_ < 6
**8.8.** Explain why a gamma random variable with
parameters( _t_ ,λ)has an approximately normal dis-
tribution when _t_ is large.
**8.9.** Suppose a fair coin is tossed 1000 times. If the first
100 tosses all result in heads, what proportion of
heads would you expect on the final 900 tosses?
Comment on the statement “The strong law of
large numbers swamps, but does not compensate.”
**8.10.** If _X_ is a Poisson random variable with meanλ,
show that for _i_ <λ,
_P_ { _X_ ... _i_ }...
_e_ −λ( _e_ λ) _i
ii_
**8.11.** Let _X_ be a binomial random variable with param-
eters _n_ and _p_. Show that, for _i_ > _np_ ,
**(a)** minimum
_t_ > 0
_e_ − _tiE_ [ _etX_ ] occurs when _t_ is such that
_et_ =( _niq_ − _i_ ) _p_ ,where _q_ = 1 − _p_.
**(b)** _P_ { _X_ Ú _i_ }... _n
n
ii_ ( _n_ − _i_ ) _n_ − _ip
i_ ( 1 − _p_ ) _n_ − _i_.
**8.12.** The Chernoff bound on a standard normal random
variable _Z_ gives _P_ { _Z_ > _a_ }... _e_ − _a_
(^2) / 2
, _a_ >0. Show,
by considering the density of _Z_ , that the right side
of the inequality can be reduced by the factor 2.
That is, show that
_P_ { _Z_ > _a_ }...
1
2
_e_ − _a_
(^2) / 2
_a_ > 0
**8.13.** Show that if _E_ [ _X_ ]< 0andθ Z0 is such that
_E_ [ _e_ θ _X_ ]=1, thenθ>0.

#### Self-Test Problems and Exercises

**8.1.** The number of automobiles sold weekly at a cer-
tain dealership is a random variable with expected
value 16. Give an upper bound to the probabil-
ity that
**(a)** next week’s sales exceed 18;
**(b)** next week’s sales exceed 25.
**8.2.** Suppose in Problem 1 that the variance of the
number of automobiles sold weekly is 9.
**(a)** Give a lower bound to the probability that
next week’s sales are between 10 and 22,
inclusively.
**(b)** Give an upper bound to the probability that
next week’s sales exceed 18.
**8.3.** If

```
E [ X ]= 75 E [ Y ]= 75 Var( X )= 10
Var( Y )=12 Cov( X , Y )=− 3
```
give an upper bound to
**(a)** _P_ {| _X_ − _Y_ |> 15 };
**(b)** _P_ { _X_ > _Y_ + 15 };
**(c)** _P_ { _Y_ > _X_ + 15 }.
**8.4.** Suppose that the number of units produced daily
at factory _A_ is a random variable with mean 20 and
standard deviation 3 and the number produced

```
at factory B is a random variable with mean
18 and standard deviation 6. Assuming indepen-
dence, derive an upper bound for the probability
that more units are produced today at factory B
than at factory A.
8.5. The amount of time that a certain type of compo-
nent functions before failing is a random variable
with probability density function
```
```
f ( x )= 2 x 0 < x < 1
```
```
Once the component fails, it is immediately
replaced by another one of the same type. If we
let Xi denote the lifetime of the i th component to
be put in use, then Sn =
```
```
∑ n
i = 1
```
```
Xi represents the time
of the n th failure. The long-term rate at which fail-
ures occur, call it r , is defined by
```
```
r = lim
n →q
```
```
n
Sn
Assuming that the random variables Xi , i Ú1, are
independent, determine r.
8.6. In Self-Test Problem 5, how many compo-
nents would one need to have on hand to be
```

**416** Chapter 8 Limit Theorems

```
approximately 90 percent certain that the stock
will last at least 35 days?
8.7. The servicing of a machine requires two separate
steps, with the time needed for the first step being
an exponential random variable with mean .2 hour
and the time for the second step being an inde-
pendent exponential random variable with mean
.3 hour. If a repair person has 20 machines to ser-
vice, approximate the probability that all the work
can be completed in 8 hours.
8.8. On each bet, a gambler loses 1 with probability .7,
loses 2 with probability .2, or wins 10 with prob-
ability .1. Approximate the probability that the
gambler will be losing after his first 100 bets.
8.9. Determine t so that the probability that the repair
person in Self-Test Problem 7 finishes the 20 jobs
within time t is approximately equal to .95.
8.10. A tobacco company claims that the amount of
nicotine in one of its cigarettes is a random
variable with mean 2.2 mg and standard devia-
tion .3 mg. However, the average nicotine con-
tent of 100 randomly chosen cigarettes was 3.1
mg. Approximate the probability that the average
would have been as high as or higher than 3.1 if the
company’s claims were true.
8.11. Each of the batteries in a collection of 40 batter-
ies is equally likely to be either a type A or a type
B battery. Type A batteries last for an amount of
time that has mean 50 and standard deviation 15;
```
```
type B batteries last for an amount of time that has
mean 30 and standard deviation 6.
(a) Approximate the probability that the total life
of all 40 batteries exceeds 1700.
(b) Suppose it is known that 20 of the batteries
are type A and 20 are type B. Now approx-
imate the probability that the total life of all
40 batteries exceeds 1700.
8.12. A clinic is equally likely to have 2, 3, or 4 doctors
volunteer for service on a given day. No matter
how may volunteer doctors there are on a given
day, the numbers of patients seen by these doctors
are independent Poisson random variables with
mean 30. Let X denote the number of patients
seen in the clinic on a given day.
(a) Find E [ X ].
(b) Find Var( X ).
(c) Use a table of the standard normal probability
distribution to approximate P { X > 65 }.
8.13. The strong law of large numbers states that, with
probability 1, the successive arithmetic averages
of a sequence of independent and identically dis-
tributed random variables converge to their com-
mon meanμ. What do the successive geometric
averages converge to? That is, what is
```
```
lim
n →q
(
```
```
∏ n
```
```
i = 1
```
```
Xi )^1 / n
```

## CHAPTER 9

# Additional Topics in Probability

### 9.1 The Poisson Process

**9.2 MARKOV CHAINS
9.3 SURPRISE, UNCERTAINTY, AND ENTROPY
9.4 CODING THEORY AND ENTROPY**

##### 9.1 THE POISSON PROCESS

```
Before we define a Poisson process, let us recall that a function f is said to be o ( h )if
```
```
lim
h → 0
```
```
f ( h )
h
```
##### = 0.

```
That is, f is o ( h )if, for small values of h , f ( h )is small even in relation to h. Sup-
pose now that “events” are occurring at random points at time, and let N ( t )denote
the number of events that occur in the time interval [0, t ]. The collection of random
variables{ N ( t ), t Ú 0 }is said to be a Poisson process having rate λ,λ>0, if
(i) N ( 0 )=0.
(ii) The numbers of events that occur in disjoint time intervals are independent.
(iii) The distribution of the number of events that occur in a given interval depends
only on the length of that interval and not on its location.
(iv) P { N ( h )= 1 }=λ h + o ( h ).
(v) P { N ( h )Ú 2 }= o ( h ).
Thus, condition (i) states that the process begins at time 0. Condition (ii), the inde-
pendent increment assumption, states, for instance, that the number of events that
occur by time t [that is, N ( t )] is independent of the number of events that occur
between t and t + s [that is, N ( t + s )− N ( t )]. Condition (iii), the stationary increment
assumption, states that the probability distribution of N ( t + s )− N ( t )is the same for
all values of t.
In Chapter 4, we presented an argument, based on the Poisson distribution being
a limiting version of the binomial distribution, that the foregoing conditions imply
that N ( t )has a Poisson distribution with meanλ t. We will now obtain this result by a
different method.
```
```
Lemma 1.1
For a Poisson process with rateλ,
```
```
P { N ( t )= 0 }= e −λ t
```
```
417
```

**418** Chapter 9 Additional Topics in Probability

```
Proof. Let P 0 ( t )= P { N ( t )= 0 }. We derive a differential equation for P 0 ( t )in the
following manner:
```
```
P 0 ( t + h )= P { N ( t + h )= 0 }
= P { N ( t )=0, N ( t + h )− N ( t )= 0 }
= P { N ( t )= 0 } P { N ( t + h )− N ( t )= 0 }
= P 0 ( t )[1−λ h + o ( h )]
```
```
where the final two equations follow from condition (ii) plus the fact that condi-
tions (iv) and (v) imply that P { N ( h )= 0 }= 1 −λ h + o ( h ). Hence,
```
```
P 0 ( t + h )− P 0 ( t )
h
```
```
=−λ P 0 ( t )+
```
```
o ( h )
h
Now, letting h →0, we obtain
```
```
P ′ 0 ( t )=−λ P 0 ( t )
```
```
or, equivalently,
P ′ 0 ( t )
P 0 ( t )
```
```
=−λ
```
```
which implies, by integration, that
```
```
log P 0 ( t )=−λ t + c
```
```
or
P 0 ( t )= Ke −λ t
```
```
Since P 0 ( 0 )= P { N ( 0 )= 0 }=1, we arrive at
```
```
P 0 ( t )= e −λ t
```
```
For a Poisson process, let T 1 denote the time the first event occurs. Further, for
n >1, let Tn denote the time elapsed between the( n − 1 )st and the n th event. The
sequence{ Tn , n =1, 2,...}is called the sequence of interarrival times. For instance, if
T 1 =5and T 2 =10, then the first event of the Poisson process would have occurred
at time 5 and the second at time 15.
We shall now determine the distribution of the Tn. To do so, we first note that the
event{ T 1 > t }takes place if and only if no events of the Poisson process occur in the
interval [0, t ]; thus,
P { T 1 > t }= P { N ( t )= 0 }= e −λ t
```
```
Hence, T 1 has an exponential distribution with mean 1/λ. Now,
```
```
P { T 2 > t }= E [ P { T 2 > t | T 1 }]
```
```
However,
```
```
P { T 2 > t | T 1 = s }= P {0 events in( s , s + t ]| T 1 = s }
= P {0 events in( s , s + t ]}
= e −λ t
```

```
Section 9.2 Markov Chains 419
```
```
where the last two equations followed from the assumptions about independent and
stationary increments. From the preceding, we conclude that T 2 is also an exponen-
tial random variable with mean 1/λand, furthermore, that T 2 is independent of T 1.
Repeating the same argument yields Proposition 1.1.
Proposition 1.1. T 1 , T 2 ,...are independent exponential random variables, each with
mean 1/λ.
```
```
Another quantity of interest is Sn , the arrival time of the n th event, also called the
waiting time until the n th event. It is easily seen that
```
```
Sn =
```
```
∑ n
```
```
i = 1
```
```
Ti n Ú 1
```
```
hence, from Proposition 1.1 and the results of Section 5.6.1, it follows that Sn has a
gamma distribution with parameters n andλ. That is, the probability density of Sn is
given by
```
```
fSn ( x )=λ e −λ x
```
```
(λ x ) n −^1
( n − 1 )!
```
```
x Ú 0
```
```
We are now ready to prove that N ( t )is a Poisson random variable with meanλ t.
```
```
Theorem 1.1. For a Poisson process with rate λ ,
```
```
P { N ( t )= n }=
```
```
e −λ t (λ t ) n
n!
Proof. Note that the n th event of the Poisson process will occur before or at time
t if and only if the number of events that occur by t is at least n. That is,
```
```
N ( t )Ú n 3 Sn ... t
```
```
so
```
```
P { N ( t )= n }= P { N ( t )Ú n }− P { N ( t )Ú n + 1 }
= P { Sn ... t }− P { Sn + 1 ... t }
```
```
=
```
```
∫ t
```
```
0
```
```
λ e −λ x
```
```
(λ x ) n −^1
( n − 1 )!
```
```
dx −
```
```
∫ t
```
```
0
```
```
λ e −λ x
```
```
(λ x ) n
n!
```
```
dx
```
```
But the integration-by-parts formula
```
##### ∫

```
udv = uv −
```
##### ∫

```
vdu with u = e −λ x and
dv =λ[(λ x ) n −^1 /( n − 1 )!] dx yields
∫ t
```
```
0
```
```
λ e −λ x
```
```
(λ x ) n −^1
( n − 1 )!
```
```
dx = e −λ t
```
```
(λ t ) n
n!
```
##### +

```
∫ t
```
```
0
```
```
λ e −λ x
```
```
(λ x ) n
n!
```
```
dx
```
```
which completes the proof.
```
### 9.2 MarkovChains................................

```
Consider a sequence of random variables X 0 , X 1 ,..., and suppose that the set of pos-
sible values of these random variables is{0, 1,..., M }. It will be helpful to interpret
Xn as being the state of some system at time n , and, in accordance with this interpre-
tation, we say that the system is in state i at time n if Xn = i. The sequence of random
variables is said to form a Markov chain if, each time the system is in state i , there is
```

**420** Chapter 9 Additional Topics in Probability

```
some fixed probability—call it Pij —that the system will next be in state j. That is, for
all i 0 ,..., in − 1 , i , j ,
```
```
P { Xn + 1 = j | Xn = i , Xn − 1 = in − 1 ,..., X 1 = i 1 , X 0 = i 0 }= Pij
```
```
The values Pij ,0... i ... M ,0... j ... N , are called the transition probabilities of the
Markov chain, and they satisfy
```
```
Pij Ú 0
```
##### ∑ M

```
j = 0
```
```
Pij = 1 i =0, 1,..., M
```
```
(Why?) It is convenient to arrange the transition probabilities Pij in a square array as
follows: ∥
∥ ∥ ∥ ∥ ∥ ∥ ∥ ∥ ∥ ∥ ∥
P 00 P 01 ··· P 0 M
P 10 P 11 ··· P 1 M
#
#
#
PM 0 PM 1 ··· PMM
```
##### ∥ ∥ ∥ ∥ ∥ ∥ ∥ ∥ ∥ ∥ ∥ ∥

```
Such an array is called a matrix.
Knowledge of the transition probability matrix and of the distribution of X 0 enables
us, in theory, to compute all probabilities of interest. For instance, the joint probabil-
ity mass function of X 0 ,..., Xn is given by
```
```
P { Xn = in , Xn − 1 = in − 1 ,..., X 1 = i 1 , X 0 = i 0 }
= P { Xn = in | Xn − 1 = in − 1 ,..., X 0 = i 0 } P { Xn − 1 = in − 1 ,..., X 0 = i 0 }
= Pin − 1 , inP { Xn − 1 = in − 1 ,..., X 0 = i 0 }
```
```
and continual repetition of this argument demonstrates that the preceding is equal to
```
```
Pin − 1 , inPin − 2 , in − 1 ··· Pi 1 , i 2 Pi 0 , i 1 P { X 0 = i 0 }
```
```
EXAMPLE 2a
Suppose that whether it rains tomorrow depends on previous weather conditions only
through whether it is raining today. Suppose further that if it is raining today, then it
will rain tomorrow with probabilityα, and if it is not raining today, then it will rain
tomorrow with probabilityβ.
If we say that the system is in state 0 when it rains and state 1 when it does not,
then the preceding system is a two-state Markov chain having transition probability
matrix ∥
∥
∥
∥
```
```
α 1 −α
β 1 −β
```
##### ∥

##### ∥

##### ∥

##### ∥

```
That is, P 00 =α= 1 − P 01 , P 10 =β= 1 − P 11..
```
```
EXAMPLE 2b
Consider a gambler who either wins 1 unit with probability p or loses 1 unit with
probability 1− p at each play of the game. If we suppose that the gambler will quit
```

```
Section 9.2 Markov Chains 421
```
playing when his fortune hits either 0 or _M_ , then the gambler’s sequence of fortunes
is a Markov chain having transition probabilities

```
Pi , i + 1 = p = 1 − Pi , i − 1 i =1,..., M − 1
P 00 = PMM = 1.
```
**_EXAMPLE 2c_**

The husband-and-wife physicists Paul and Tatyana Ehrenfest considered a concep-
tual model for the movement of molecules in which _M_ molecules are distributed
among 2 urns. At each time point one of the molecules is chosen at random and
is removed from its urn and placed in the other one. If we let _Xn_ denote the number
of molecules in the first urn immediately after the _n_ th exchange, then{ _X_ 0 , _X_ 1 ,...}is
a Markov chain with transition probabilities

```
Pi , i + 1 =
```
```
M − i
M
```
```
0 ... i ... M
```
```
Pi , i − 1 =
```
```
i
M
```
```
0 ... i ... M
```
```
Pij =0if| j − i |> 1.
```
Thus, for a Markov chain, _Pij_ represents the probability that a system in state _i_
will enter state _j_ at the next transition. We can also define the two-stage transition

probability _P_
( 2 )
_ij_ that a system presently in state _i_ will be in state _j_ after two additional
transitions. That is,
_P_ ( _ij_^2 )= _P_ { _Xm_ + 2 = _j_ | _Xm_ = _i_ }

The _P_ ( _ij_^2 )can be computed from the _Pij_ as follows:

```
P ( ij^2 )= P { X 2 = j | X 0 = i }
```
##### =

##### ∑ M

```
k = 0
```
```
P { X 2 = j , X 1 = k | X 0 = i }
```
##### =

##### ∑ M

```
k = 0
```
```
P { X 2 = j | X 1 = k , X 0 = i } P { X 1 = k | X 0 = i }
```
##### =

##### ∑ M

```
k = 0
```
```
PkjPik
```
```
In general, we define the n -stage transition probabilities, denoted as P ( ijn ),by
```
```
P
( n )
ij = P { Xn + m = j | Xm = i }
```
Proposition 2.1, known as the Chapman–Kolmogorov equations, shows how the _P_ ( _ijn_ )

can be computed.

**Proposition 2.1. The Chapman–Kolmogorov equations**

```
P ( ijn )=
```
##### ∑ M

```
k = 0
```
```
P ( ikr ) P ( kjn − r ) for all 0< r < n
```

**422** Chapter 9 Additional Topics in Probability

```
Proof.
```
```
P ( ijn )= P { Xn = j | X 0 = i }
```
```
=
```
##### ∑

```
k
```
```
P { Xn = j , Xr = k | X 0 = i }
```
##### =

##### ∑

```
k
```
```
P { Xn = j | Xr = k , X 0 = i } P { Xr = k | X 0 = i }
```
##### =

##### ∑

```
k
```
```
P ( kjn − r ) P ( ikr )
```
```
EXAMPLE 2d A random walk
An example of a Markov chain having a countably infinite state space is the random
walk , which tracks a particle as it moves along a one-dimensional axis. Suppose that
at each point in time the particle will move either one step to the right or one step to
the left with respective probabilities p and 1− p. That is, suppose the particle’s path
follows a Markov chain with transition probabilities
```
```
Pi , i + 1 = p = 1 − Pi , i − 1 i =0,;1,...
```
```
If the particle is at state i , then the probability that it will be at state j after n transitions
is the probability that( n − i + j )/2 of these steps are to the right and n −[( n − i +
j )/2]=( n + i − j )/2 are to the left. Since each step will be to the right, independently
of the other steps, with probability p , it follows that the above is just the binomial
probability
Pnij =
```
##### (

```
n
( n − i + j )/ 2
```
##### )

```
p ( n − i + j )/^2 ( 1 − p )( n + i − j )/^2
```
```
where
```
##### (

```
n
x
```
##### )

```
is taken to equal 0 when x is not a nonnegative integer less than or equal
to n. The preceding formula can be rewritten as
```
```
P^2 i , ni + 2 k =
```
##### (

```
2 n
n + k
```
##### )

```
pn + k ( 1 − p ) n − k k =0,;1,...,; n
```
```
P^2 i , ni ++ 21 k + 1 =
```
##### (

```
2 n + 1
n + k + 1
```
##### )

```
pn + k +^1 ( 1 − p ) n − k
```
```
k =0,;1,...,; n ,−( n + 1 ).
```
```
Although the P ( ijn )denote conditional probabilities, we can use them to derive
expressions for unconditional probabilities by conditioning on the initial state. For
instance,
```
```
P { Xn = j }=
```
##### ∑

```
i
```
```
P { Xn = j | X 0 = i } P { X 0 = i }
```
##### =

##### ∑

```
i
```
```
P ( ijn ) P { X 0 = i }
```
```
For a large number of Markov chains, it turns out that P ( ijn )converges, as n →q,toa
valueπ j that depends only on j. That is, for large values of n , the probability of being
```

```
Section 9.2 Markov Chains 423
```
in state _j_ after _n_ transitions is approximately equal toπ _j_ , no matter what the initial
state was. It can be shown that a sufficient condition for a Markov chain to possess
this property is that, for some _n_ >0,

```
P ( ijn )> 0 for all i , j =0, 1,..., M (2.1)
```
Markov chains that satisfy Equation (2.1) are said to be _ergodic_. Since Proposition 2.1
yields

```
Pij ( n +^1 )=
```
##### ∑ M

```
k = 0
```
```
P ( ikn ) Pkj
```
it follows, by letting _n_ →q, that, for ergodic chains,

```
π j =
```
##### ∑ M

```
k = 0
```
```
π kPkj (2.2)
```
Furthermore, since 1=

##### ∑ M

```
j = 0
```
```
P ( ijn ), we also obtain, by letting n →q,
```
##### ∑ M

```
j = 0
```
```
π j = 1 (2.3)
```
In fact, it can be shown that theπ _j_ ,0... _j_ ... _M_ , are the unique nonnegative solutions
of Equations (2.2) and (2.3). All this is summed up in Theorem 2.1, which we state
without proof.

**Theorem 2.1.** _For an ergodic Markov chain,_

```
π j = lim
n →q
```
##### P

```
( n )
ij
```
_exists, and the_ π _j_ ,0... _j_ ... _M, are the unique nonnegative solutions of_

```
π j =
```
##### ∑ M

```
k = 0
```
```
π kPkj
```
##### ∑ M

```
j = 0
```
```
π j = 1
```
**_EXAMPLE 2e_**

Consider Example 2a, in which we assume that if it rains today, then it will rain tomor-
row with probabilityα, and if it does not rain today, then it will rain tomorrow with
probabilityβ. From Theorem 2.1, it follows that the limiting probabilitiesπ 0 andπ 1
of rain and of no rain, respectively, are given by

```
π 0 =απ 0 +βπ 1
π 1 =( 1 −α)π 0 +( 1 −β)π 1
π 0 +π 1 = 1
```

**424** Chapter 9 Additional Topics in Probability

```
which yields
```
```
π 0 =
```
```
β
1 +β−α
```
```
π 1 =
```
```
1 −α
1 +β−α
```
```
For instance, ifα=.6andβ=.3, then the limiting probability of rain on the n th day
isπ 0 =^37..
```
```
The quantityπ j is also equal to the long-run proportion of time that the Markov
chain is in state j , j =0,..., M. To see intuitively why this might be so, let Pj denote
the long-run proportion of time the chain is in state j. (It can be proven using the
strong law of large numbers that, for an ergodic chain, such long-run proportions
exist and are constants.) Now, since the proportion of time the chain is in state k is
Pk , and since, when in state k , the chain goes to state j with probability Pkj , it follows
that the proportion of time the Markov chain is entering state j from state k is equal
to PkPkj. Summing over all k shows that Pj , the proportion of time the Markov chain
is entering state j , satisfies
Pj =
```
##### ∑

```
k
```
```
PkPkj
```
```
Since clearly it is also true that
∑
```
```
j
```
```
Pj = 1
```
```
it thus follows, since by Theorem 2.1 theπ j , j =0,..., M are the unique solution of
the preceding, that Pj =π j , j =0,..., M. The long-run proportion interpretation ofπ j
is generally valid even when the chain is not ergodic.
```
```
EXAMPLE 2f
Suppose in Example 2c that we are interested in the proportion of time that there are
j molecules in urn 1, j =0,..., M. By Theorem 2.1, these quantities will be the unique
solution of
```
```
π 0 =π 1 *
```
##### 1

##### M

```
π j =π j − 1 *
```
```
M − j + 1
M
```
```
+π j + 1 *
```
```
j + 1
M
```
```
j =1,..., M
```
```
π M =π M − 1 *
```
##### 1

##### M

##### ∑ M

```
j = 0
```
```
π j = 1
```
```
However, as it is easily checked that
```
```
π j =
```
##### (

##### M

```
j
```
##### )(

##### 1

##### 2

##### ) M

```
j =0,..., M
```
```
satisfy the preceding equations, it follows that these are the long-run proportions of
time that the Markov chain is in each of the states. (See Problem 11 for an explanation
of how one might have guessed at the foregoing solution.).
```

```
Section 9.3 Surprise, Uncertainty, and Entropy 425
```
### 9.3 Surprise, Uncertainty, and Entropy

```
Consider an event E that can occur when an experiment is performed. How surprised
would we be to hear that E does, in fact, occur? It seems reasonable to suppose that
the amount of surprise engendered by the information that E has occurred should
depend on the probability of E. For instance, if the experiment consists of rolling a
pair of dice, then we would not be too surprised to hear that E has occurred when
E represents the event that the sum of the dice is even (and thus has probability^12 ),
whereas we would certainly be more surprised to hear that E has occurred when E is
the event that the sum of the dice is 12 (and thus has probability 361 ).
In this section, we attempt to quantify the concept of surprise. To begin, let us
agree to suppose that the surprise one feels upon learning that an event E has occurred
depends only on the probability of E , and let us denote by S ( p )the surprise evoked
by the occurrence of an event having probability p. We determine the functional form
of S ( p )by first agreeing on a set of reasonable conditions that S ( p )should satisfy and
then proving that these axioms require that S ( p )have a specified form. We assume
throughout that S ( p )is defined for all 0< p ...1, but is not defined for events having
p =0.
Our first condition is just a statement of the intuitive fact that there is no surprise
in hearing that an event which is sure to occur has indeed occurred.
Axiom 1
S ( 1 )= 0
Our second condition states that the more unlikely an event is to occur, the greater
is the surprise evoked by its occurrence.
Axiom 2
S ( p )is a strictly decreasing function of p ; that is, if p < q ,then S ( p )> S ( q ).
The third condition is a mathematical statement of the fact that we would intu-
itively expect a small change in p to correspond to a small change in S ( p ).
Axiom 3
S ( p )is a continuous function of p.
To motivate the final condition, consider two independent events E and F having
respective probabilities P ( E )= p and P ( F )= q. Since P ( EF )= pq , the surprise
evoked by the information that both E and F have occurred is S ( pq ). Now, suppose
that we are told first that E has occurred and then, afterward, that F has also occurred.
Since S ( p )is the surprise evoked by the occurrence of E , it follows that S ( pq ) −
S ( p )represents the additional surprise evoked when we are informed that F has also
occurred. However, because F is independent of E , the knowledge that E occurred
does not change the probability of F ; hence, the additional surprise should just be
S ( q ). This reasoning suggests the final condition.
Axiom 4
S ( pq )= S ( p )+ S ( q ) 0 < p ...1, 0 < q ... 1
```
```
We are now ready for Theorem 3.1, which yields the structure of S ( p ).
Theorem 3.1. If S (·) satisfies Axioms 1 through 4, then
```
```
S ( p )=− C log 2 p
```
```
where C is an arbitrary positive integer.
```

**426** Chapter 9 Additional Topics in Probability

```
Proof. It follows from Axiom 4 that
```
```
S ( p^2 )= S ( p )+ S ( p )= 2 S ( p )
```
```
and by induction that
S ( pm )= mS ( p ) (3.1)
```
```
Also, since, for any integral n , S ( p )= S ( p^1 / n ··· p^1 / n )= nS ( p^1 / n ), it follows that
```
```
S ( p^1 / n )=
```
##### 1

```
n
```
```
S ( p ) (3.2)
```
```
Thus, from Equations (3.1) and (3.2), we obtain
```
```
S ( pm / n )= mS ( p^1 / n )
```
```
=
```
```
m
n
```
```
S ( p )
```
```
which is equivalent to
S ( px )= xS ( p ) (3.3)
```
```
whenever x is a positive rational number. But by the continuity of S (Axiom 3), it
follows that Equation (3.3) is valid for all nonnegative x. (Reason this out.)
```
```
Now, for any p ,0< p ...1, let x =−log 2 p. Then p =
```
##### (

```
1
2
```
```
) x
, and from Equa-
tion (3.3),
```
```
S ( p )= S
```
##### ((

##### 1

##### 2

```
) x )
= xS
```
##### (

##### 1

##### 2

##### )

```
=− C log 2 p
```
```
where C = S
```
##### (

```
1
2
```
##### )

```
> S ( 1 )=0byAxioms2and1.
```
```
It is usual to let C equal 1, in which case the surprise is said to be expressed in units
of bits (short for binary digits ).
Next, consider a random variable X that must take on one of the values x 1 ,..., xn
with respective probabilities p 1 ,..., pn. Since−log pi represents the surprise evoked
if X takes on the value xi ,†it follows that the expected amount of surprise we shall
receive upon learning the value of X is given by
```
##### H ( X )=−

```
∑ n
```
```
i = 1
```
```
pi log pi
```
```
The quantity H ( X )is known in information theory as the entropy of the random
variable X. (In case one of the pi =0, we take 0 log 0 to equal 0.) It can be shown
(and we leave it as an exercise) that H ( X )is maximized when all of the pi are equal.
(Is this intuitive?)
Since H ( X )represents the average amount of surprise one receives upon learning
the value of X , it can also be interpreted as representing the amount of uncertainty
that exists as to the value of X. In fact, in information theory, H ( X )is interpreted as
the average amount of information received when the value of X is observed. Thus,
the average surprise evoked by X , the uncertainty of X , or the average amount of
```
```
†For the remainder of this chapter, we write log x for log
2 x. Also, we use ln x for log ex.
```

```
Section 9.3 Surprise, Uncertainty, and Entropy 427
```
information yielded by _X_ all represent the same concept viewed from three slightly
different points of view.
Now consider two random variables _X_ and _Y_ that take on the respective values
_x_ 1 ,..., _xn_ and _y_ 1 ,..., _ym_ with joint mass function

```
p ( xi , yj )= P { X = xi , Y = yj }
```
It follows that the uncertainty as to the value of the random vector( _X_ , _Y_ ), denoted
by _H_ ( _X_ , _Y_ ), is given by

```
H ( X , Y )=−
```
##### ∑

```
i
```
##### ∑

```
j
```
```
p ( xi , yj )log p ( xi , yj )
```
Suppose now that _Y_ is observed to equal _yj_. In this situation, the amount of uncer-
tainty remaining in _X_ is given by

```
HY = yj ( X )=−
```
##### ∑

```
i
```
```
p ( xi | yj )log p ( xi | yj )
```
where
_p_ ( _xi_ | _yj_ )= _P_ { _X_ = _xi_ | _Y_ = _yj_ }

Hence, the average amount of uncertainty that will remain in _X_ after _Y_ is observed
is given by

```
HY ( X )=
```
##### ∑

```
j
```
```
HY = yj ( X ) pY ( yj )
```
where
_pY_ ( _yj_ )= _P_ { _Y_ = _yj_ }

Proposition 3.1 relates _H_ ( _X_ , _Y_ )to _H_ ( _Y_ )and _HY_ ( _X_ ). It states that the uncertainty as
to the value of _X_ and _Y_ is equal to the uncertainty of _Y_ plus the average uncertainty
remaining in _X_ when _Y_ is to be observed.

**Proposition 3.1.**
_H_ ( _X_ , _Y_ )= _H_ ( _Y_ )+ _HY_ ( _X_ )

```
Proof. Using the identity p ( xi , yj )= pY ( yj ) p ( xi | yj )yields
```
```
H ( X , Y )=−
```
##### ∑

```
i
```
##### ∑

```
j
```
```
p ( xi , yj )log p ( xi , yj )
```
##### =−

##### ∑

```
i
```
##### ∑

```
j
```
```
pY ( yj ) p ( xi | yj )[log pY ( yj )+log p ( xi | yj )]
```
##### =−

##### ∑

```
j
```
```
pY ( yj )log pY ( yj )
```
##### ∑

```
i
```
```
p ( xi | yj )
```
##### −

##### ∑

```
j
```
```
pY ( yj )
```
##### ∑

```
i
```
```
p ( xi | yj )log p ( xi | yj )
```
##### = H ( Y )+ HY ( X )

It is a fundamental result in information theory that the amount of uncertainty in
a random variable _X_ will, on the average, decrease when a second random variable
_Y_ is observed. Before proving this statement, we need the following lemma, whose
proof is left as an exercise.


**428** Chapter 9 Additional Topics in Probability

```
Lemma 3.1
ln x ... x − 1 x > 0
```
```
with equality only at x =1.
Theorem 3.2.
HY ( X )... H ( X )
```
```
with equality if and only if X and Y are independent.
Proof.
```
```
HY ( X )− H ( X )=−
```
##### ∑

```
i
```
##### ∑

```
j
```
```
p ( xi | yj )log[ p ( xi | yj )] p ( yj )
```
##### +

##### ∑

```
i
```
##### ∑

```
j
```
```
p ( xi , yj )log p ( xi )
```
##### =

##### ∑

```
i
```
##### ∑

```
j
```
```
p ( xi , yj )log
```
##### [

```
p ( xi )
p ( xi | yj )
```
##### ]

```
...log e
```
##### ∑

```
i
```
##### ∑

```
j
```
```
p ( xi , yj )
```
##### [

```
p ( xi )
p ( xi | yj )
```
##### − 1

##### ]

```
by Lemma 3.1
```
```
=log e
```
##### ⎡

##### ⎣

##### ∑

```
i
```
##### ∑

```
j
```
```
p ( xi ) p ( yj )−
```
##### ∑

```
i
```
##### ∑

```
j
```
```
p ( xi , yj )
```
##### ⎤

##### ⎦

```
=log e [1−1]
= 0
```
### 9.4 Coding Theory and Entropy

```
Suppose that the value of a discrete random vector X is to be observed at location
A and then transmitted to location B via a communication network that consists of
two signals, 0 and 1. In order to do this, it is first necessary to encode each possible
value of X in terms of a sequence of 0’s and 1’s. To avoid any ambiguity, it is usually
required that no encoded sequence can be obtained from a shorter encoded sequence
by adding more terms to the shorter.
For instance, if X can take on four possible values x 1 , x 2 , x 3 ,and x 4 , then one pos-
sible coding would be
x 1 % 00
x 2 % 01
x 3 % 10
x 4 % 11
```
##### (4.1)

```
That is, if X = x 1 , then the message 00 is sent to location B , whereas if X = x 2 ,then
01 is sent to B , and so on. A second possible coding is
x 1 % 0
x 2 % 10
x 3 % 110
x 4 % 111
```
##### (4.2)


```
Section 9.4 Coding Theory and Entropy 429
```
However, a coding such as

```
x 1 % 0
x 2 % 1
x 3 % 00
x 4 % 01
```
is not allowed because the coded sequences for _x_ 3 and _x_ 4 are both extensions of the
one for _x_ 1.
One of the objectives in devising a code is to minimize the expected number of
bits (that is, binary digits) that need to be sent from location _A_ to location _B_ .For
example, if

```
P { X = x 1 }=
```
##### 1

##### 2

```
P { X = x 2 }=
```
##### 1

##### 4

```
P { X = x 3 }=
```
##### 1

##### 8

```
P { X = x 4 }=
```
##### 1

##### 8

then the code given by Equation (4.2) would expect to send^12 ( 1 )+^14 ( 2 )+^18 ( 3 )+
1
8 (^3 )=^1 .75 bits, whereas the code given by Equation (4.1) would expect to send 2
bits. Hence, for the preceding set of probabilities, the encoding in Equation (4.2) is
more efficient than that in Equation (4.1).
The preceding discussion raises the following question: For a given random
vector _X_ , what is the maximum efficiency achievable by an encoding scheme? The
answer is that, for any coding, the average number of bits that will be sent is at least
as large as the entropy of _X_. To prove this result, known in information theory as the
_noiseless coding theorem_ , we shall need Lemma 4.1.

```
Lemma 4.1
Let X take on the possible values x 1 ,..., xN. Then, in order to be able to encode
the values of X in binary sequences (none of which is an extension of another) of
respective lengths n 1 ,..., nN , it is necessary and sufficient that
```
```
∑ N
```
```
i = 1
```
##### (

##### 1

##### 2

```
) ni
... 1
```
```
Proof. For a fixed set of N positive integers n 1 ,..., nN , let wj denote the number
of the ni that are equal to j , j =1,.... For there to be a coding that assigns ni
bits to the value xi , i =1,..., N , it is clearly necessary that w 1 ...2. Furthermore,
because no binary sequence is allowed to be an extension of any other, we must
have w 2 ... 22 − 2 w 1. (This follows because 2^2 is the number of binary sequences
of length 2, whereas 2 w 1 is the number of sequences that are extensions of the
w 1 binary sequence of length 1.) In general, the same reasoning shows that we
must have
```
```
wn ... 2 n − w 12 n −^1 − w 22 n −^2 − ··· − wn − 12 (4.3)
```

**430** Chapter 9 Additional Topics in Probability

```
for n =1,.... In fact, a little thought should convince the reader that these con-
ditions are not only necessary, but also sufficient for a code to exist that assigns ni
bits to xi , i =1,..., N.
Rewriting inequality (4.3) as
```
```
wn + wn − 12 + wn − 222 + ··· + w 12 n −^1 ... 2 n n =1,...
```
```
and dividing by 2 n yields the necessary and sufficient conditions, namely,
```
```
∑ n
```
```
j = 1
```
```
wj
```
##### (

##### 1

##### 2

```
) j
... 1 for all n (4.4)
```
```
However, because
```
```
∑ n
j = 1
```
```
wj
```
##### (

```
1
2
```
```
) j
is increasing in n , it follows that Equation (4.4) will
```
```
be true if and only if
∑q
```
```
j = 1
```
```
wj
```
##### (

##### 1

##### 2

```
) j
... 1
```
```
The result is now established, since, by the definition of wj as the number of ni that
equal j , it follows that
∑q
```
```
j = 1
```
```
wj
```
##### (

##### 1

##### 2

```
) j
=
```
##### ∑ N

```
i = 1
```
##### (

##### 1

##### 2

```
) ni
```
```
We are now ready to prove Theorem 4.1.
```
```
Theorem 4.1 The noiseless coding theorem
Let X take on the values x 1 ,..., xN with respective probabilities p ( x 1 ),..., p ( xN ).
Then, for any coding of X that assigns nibits to xi,
```
```
∑ N
```
```
i = 1
```
```
nip ( xi )Ú H ( X )=−
```
##### ∑ N

```
i = 1
```
```
p ( xi )log p ( xi )
```
```
Proof. Let Pi = p ( xi ), qi = 2 − ni
```
##### /∑ N

```
j = 1
```
```
2 − nj , i =1,..., N. Then
```
##### −

##### ∑ N

```
i = 1
```
```
Pi log
```
##### (

```
Pi
qi
```
##### )

```
=−log e
```
##### ∑ N

```
i = 1
```
```
Pi ln
```
##### (

```
Pi
qi
```
##### )

```
=log e
```
##### ∑ N

```
i = 1
```
```
Pi ln
```
##### (

```
qi
Pi
```
##### )

```
...log e
```
##### ∑ N

```
i = 1
```
```
Pi
```
##### (

```
qi
Pi
```
##### − 1

##### )

```
by Lemma 3.1
```
```
=0 since
```
##### ∑ N

```
i = 1
```
```
Pi =
```
##### ∑ N

```
i = 1
```
```
qi = 1
```

```
Section 9.4 Coding Theory and Entropy 431
```
```
Hence,
```
##### −

##### ∑ N

```
i = 1
```
```
Pi log Pi ...−
```
##### ∑ N

```
i = 1
```
```
Pi log qi
```
##### =

##### ∑ N

```
i = 1
```
```
niPi +log
```
##### ⎛

##### ⎜

##### ⎝

##### ∑ N

```
j = 1
```
```
2 − nj
```
##### ⎞

##### ⎟

##### ⎠

##### ...

##### ∑ N

```
i = 1
```
```
niPi by Lemma 4.1
```
**_EXAMPLE 4a_**

Consider a random variable _X_ with probability mass function

```
p ( x 1 )=
```
##### 1

##### 2

```
p ( x 2 )=
```
##### 1

##### 4

```
p ( x 3 )= p ( x 4 )=
```
##### 1

##### 8

Since

##### H ( X )=−

##### [

##### 1

##### 2

```
log
```
##### 1

##### 2

##### +

##### 1

##### 4

```
log
```
##### 1

##### 4

##### +

##### 1

##### 4

```
log
```
##### 1

##### 8

##### ]

##### =

##### 1

##### 2

##### +

##### 2

##### 4

##### +

##### 3

##### 4

##### = 1. 75

it follows from Theorem 4.1 that there is no more efficient coding scheme than

```
x 1 % 0
x 2 % 10
x 3 % 110
x 4 % 111.
```
For most random vectors, there does not exist a coding for which the average
number of bits sent attains the lower bound _H_ ( _X_ ). However, it is always possible
to devise a code such that the average number of bits is within 1 of _H_ ( _X_ ). To prove
this, define _ni_ to be the integer satisfying

```
−log p ( xi )... ni <−log p ( xi )+ 1
```
Now,

```
∑ N
```
```
i = 1
```
```
2 − ni ...
```
##### ∑ N

```
i = 1
```
```
2 log p ( xi )=
```
##### ∑ N

```
i = 1
```
```
p ( xi )= 1
```
so, by Lemma 4.1, we can associate sequences of bits having lengths _ni_ with the _xi_ , _i_ =
1,..., _N_. The average length of such a sequence,

##### L =

##### ∑ N

```
i = 1
```
```
nip ( xi )
```

**432** Chapter 9 Additional Topics in Probability

```
satisfies
```
```
−
```
##### ∑ N

```
i = 1
```
```
p ( xi )log p ( xi )... L <−
```
##### ∑ N

```
i = 1
```
```
p ( xi )log p ( xi )+ 1
```
```
or
H ( X )... L < H ( X )+ 1
```
```
EXAMPLE 4b
Suppose that 10 independent tosses of a coin having probability p of coming up heads
are made at location A and the result is to be transmitted to location B. The outcome
of this experiment is a random vector X =( X 1 ,..., X 10 ), where Xi is 1 or 0 according
to whether or not the outcome of the i th toss is heads. By the results of this section, it
follows that L , the average number of bits transmitted by any code, satisfies
```
```
H ( X )... L
```
```
with
L ... H ( X )+ 1
```
```
for at least one code. Now, since the Xi are independent, it follows from Proposi-
tion 3.1 and Theorem 3.2 that
```
```
H ( X )= H ( X 1 ,..., Xn )=
```
##### ∑ N

```
i = 1
```
```
H ( Xi )
```
```
=−10[ p log p +( 1 − p )log( 1 − p )]
```
```
If p =^12 ,then H ( X )=10, and it follows that we can do no better than just encoding
X by its actual value. For example, if the first 5 tosses come up heads and the last 5
tails, then the message 1111100000 is transmitted to location B.
However, if p Z^12 , we can often do better by using a different coding scheme. For
instance, if p =^14 ,then
```
##### H ( X )=− 10

##### (

##### 1

##### 4

```
log
```
##### 1

##### 4

##### +

##### 3

##### 4

```
log
```
##### 3

##### 4

##### )

##### = 8. 11

```
Thus, there is an encoding for which the average length of the encoded message is no
greater than 9.11.
One simple coding that is more efficient in this case than the identity code is to
break up( X 1 ,..., X 10 )into 5 pairs of 2 random variables each and then, for i =
1, 3, 5, 7, 9, code each of the pairs as follows:
```
```
Xi =0, Xi + 1 = 0 % 0
Xi =0, Xi + 1 = 1 % 10
Xi =1, Xi + 1 = 0 % 110
Xi =1, Xi + 1 = 1 % 111
```
```
The total message transmitted is the successive encodings of the preceding pairs.
For instance, if the outcome TTTHHTTTTH is observed, then the message 01011
0010 is sent. The average number of bits needed to transmit the message with this
code is
```

```
Section 9.4 Coding Theory and Entropy 433
```
##### 5

##### [

##### 1

##### (

##### 3

##### 4

##### ) 2

##### + 2

##### (

##### 1

##### 4

##### )(

##### 3

##### 4

##### )

##### + 3

##### (

##### 1

##### 4

##### )(

##### 3

##### 4

##### )

##### + 3

##### (

##### 1

##### 4

##### ) 2 ]

##### =

##### 135

##### 16

##### L 8. 44.

Up to this point, we have assumed that the message sent at location _A_ is received
without error at location _B_. However, there are always certain errors that can occur
because of random disturbances along the communications channel. Such random
disturbances might lead, for example, to the message 00101101, sent at _A_ , being
received at _B_ in the form 01101101.
Let us suppose that a bit transmitted at location _A_ will be correctly received at
location _B_ with probability _p_ , independently from bit to bit. Such a communications
system is called a _binary symmetric channel_. Suppose further that _p_ = .8 and we
want to transmit a message consisting of a large number of bits from _A_ to _B_. Thus,
direct transmission of the message will result in an error probability of .20 for each
bit, which is quite high. One way to reduce this probability of bit error would be to
transmit each bit 3 times and then decode by majority rule. That is, we could use the
following scheme:

```
Encode Decode Encode Decode
```
##### 0 → 000

##### 000

##### 001

##### 010

##### 100

##### ⎫

##### ⎪⎪

##### ⎬

##### ⎪⎪

##### ⎭

##### → 01 → 111

##### 111

##### 110

##### 101

##### 011

##### ⎫

##### ⎪⎪

##### ⎬

##### ⎪⎪

##### ⎭

##### → 1

Note that if no more than one error occurs in transmission, then the bit will be
correctly decoded. Hence, the probability of bit error is reduced to

```
(. 2 )^3 + 3 (. 2 )^2 (. 8 )=. 104
```
a considerable improvement. In fact, it is clear that we can make the probability of
bit error as small as we want by repeating the bit many times and then decoding by
majority rule. For instance, the scheme

```
Encode Decode
```
```
0 →string of 17 0’s By majority rule
1 →string of 17 1’s
```
will reduce the probability of bit error to below .01.
The problem with this type of encoding scheme is that, although it decreases the
probability of bit error, it does so at the cost of also decreasing the effective rate of
bits sent per signal. (See Table 9.1.)
In fact, at this point it may appear inevitable to the reader that decreasing the
probability of bit error to 0 _always_ results in also decreasing the effective rate at which
bits are transmitted per signal to 0. However, a remarkable result of information
theory known as the _noisy coding theorem_ and due to Claude Shannon demonstrates
that this is not the case. We now state this result as Theorem 4.2.


**434** Chapter 9 Additional Topics in Probability

```
TABLE 9.1: Repetition of Bits Encoding Scheme
Probability of error Rate
(per bit) (bits transmitted per signal)
```
```
.20 1
.10. 33
```
```
(
=^13
```
```
)
```
```
.01. 06
```
```
(
= 171
```
```
)
```
```
Theorem 4.2 The noisy coding theorem
There is a number C such that, for any value R which is less than C, and for any ε> 0 ,
there exists a coding–decoding scheme that transmits at an average rate of R bits sent
per signal and with an error (per bit) probability of less than ε. The largest such
value of C—call it C ∗† —is called the channel capacity, and for the binary symmetric
channel,
C ∗= 1 + p log p +( 1 − p )log( 1 − p )
```
#### Summary

```
The Poisson process having rateλis a collection of random variables{ N ( t ), t Ú 0 }that
relate to an underlying process of randomly occurring events. For instance, N ( t )rep-
resents the number of events that occur between times 0 and t. The defining features
of the Poisson process are as follows:
(i) The number of events that occur in disjoint time intervals are independent.
(ii) The distribution of the number of events that occur in an interval depends only
on the length of the interval.
(iii) Events occur one at a time.
(iv) Events occur at rateλ.
It can be shown that N ( t )is a Poisson random variable with meanλ t. In addition,
if Ti , i Ú1, are the times between the successive events, then they are independent
exponential random variables with rateλ.
A sequence of random variables Xn , n Ú 0, each of which takes on one of the
values 0,..., M , is said to be a Markov chain with transition probabilities Pi , j if, for
all n , i 0 ,..., in , i , j ,
P { Xn + 1 = j | Xn = i , Xn − 1 = in − 1 ,..., X 0 = i 0 }= Pi , j
If we interpret Xn as the state of some process at time n , then a Markov chain is a
sequence of successive states of a process which has the property that whenever it
enters state i , then, independently of all past states, the next state is j with probability
Pi , j , for all states i and j. For many Markov chains, the probability of being in state j at
time n converges to a limiting value that does not depend on the initial state. If we let
π j , j =0,..., M , denote these limiting probabilities, then they are the unique solution
of the equations
```
```
π j =
```
##### ∑ M

```
i = 0
```
```
π iPi , j j =0,..., M
```
##### ∑ M

```
j = 1
```
```
π j = 1
```
```
†For an entropy interpretation of C ∗, see Theoretical Exercise 9.18.
```

```
Problems and Theoretical Exercises 435
```
```
Moreover,π j is equal to the long-run proportion of time that the chain is in state j.
Let X be a random variable that takes on one of n possible values according to the
set of probabilities{ p 1 ,..., pn }. The quantity
```
##### H ( X )=−

```
∑ n
```
```
i = 1
```
```
pi log 2 ( pi )
```
```
is called the entropy of X. It can be interpreted as representing either the average
amount of uncertainty that exists regarding the value of X or the average information
received when X is observed. Entropy has important implications for binary codings
of X.
```
#### Problems and Theoretical Exercises

**9.1.** Customers arrive at a bank at a Poisson rateλ.
Suppose that two customers arrived during the first
hour. What is the probability that
**(a)** both arrived during the first 20 minutes?
**(b)** at least one arrived during the first 20 min-
utes?

**9.2.** Cars cross a certain point in the highway in accor-
dance with a Poisson process with rateλ=3per
minute. If Al runs blindly across the highway, what
is the probability that he will be uninjured if the
amount of time that it takes him to cross the road
is _s_ seconds? (Assume that if he is on the highway
when a car passes by, then he will be injured.) Do
this exercise for _s_ =2, 5, 10, 20.

**9.3.** Suppose that in Problem 9.2 Al is agile enough to
escape from a single car, but if he encounters two
or more cars while attempting to cross the road,
then he is injured. What is the probability that he
will be unhurt if it takes him _s_ seconds to cross? Do
this exercise for _s_ =5, 10, 20, 30.

**9.4.** Suppose that 3 white and 3 black balls are dis-
tributed in two urns in such a way that each urn
contains 3 balls. We say that the system is in state
_i_ if the first urn contains _i_ white balls, _i_ =0, 1, 2, 3.
At each stage, 1 ball is drawn from each urn and
the ball drawn from the first urn is placed in the
second, and conversely with the ball from the
second urn. Let _Xn_ denote the state of the sys-
tem after the _n_ th stage, and compute the transition
probabilities of the Markov chain{ _Xn_ , _n_ Ú 0 }.

**9.5.** Consider Example 2a. If there is a 50–50 chance of
rain today, compute the probability that it will rain
3 days from now ifα=.7andβ=.3.
**9.6.** Compute the limiting probabilities for the model
of Problem 9.4.
**9.7.** A transition probability matrix is said to be doubly
stochastic if
∑ _M_

```
i = 0
```
```
Pij = 1
```
```
for all states j = 0, 1,..., M. Show that such a
Markov chain is ergodic, then
```
```
∏
j =^1 /( M +^1 ), j =
0, 1,..., M.
9.8. On any given day, Buffy is either cheerful (c), so-so
(s), or gloomy (g). If she is cheerful today, then she
will be c, s, or g tomorrow with respective probabil-
ities .7, .2, and .1. If she is so-so today, then she will
be c, s, or g tomorrow with respective probabilities
.4, .3, and .3. If she is gloomy today, then Buffy will
be c, s, or g tomorrow with probabilities .2, .4, and
.4. What proportion of time is Buffy cheerful?
9.9. Suppose that whether it rains tomorrow depends
on past weather conditions only through the last
2 days. Specifically, suppose that if it has rained
yesterday and today, then it will rain tomorrow
with probability .8; if it rained yesterday but not
today, then it will rain tomorrow with probability
.3; if it rained today but not yesterday, then it will
rain tomorrow with probability .4; and if it has not
rained either yesterday or today, then it will rain
tomorrow with probability .2. What proportion of
days does it rain?
9.10. A certain person goes for a run each morning.
When he leaves his house for his run, he is equally
likely to go out either the front or the back door,
and similarly, when he returns, he is equally likely
to go to either the front or the back door. The run-
ner owns 5 pairs of running shoes, which he takes
off after the run at whichever door he happens to
be. If there are no shoes at the door from which he
leaves to go running, he runs barefooted. We are
interested in determining the proportion of time
that he runs barefooted.
(a) Set this problem up as a Markov chain. Give
the states and the transition probabilities.
(b) Determine the proportion of days that he runs
barefooted.
9.11. This problem refers to Example 2f.
(a) Verify that the proposed value of
```
```
∏
j satisfies
the necessary equations.
```

**436** Chapter 9 Additional Topics in Probability

```
(b) For any given molecule, what do you think is
the (limiting) probability that it is in urn 1?
(c) Do you think that the events that molecule j ,
j Ú1, is in urn 1 at a very large time would be
(in the limit) independent?
(d) Explain why the limiting probabilities are as
given.
9.12. Determine the entropy of the sum that is obtained
when a pair of fair dice is rolled.
9.13. Prove that if X cantakeonanyof n possible values
with respective probabilities P 1 ,..., Pn ,then H ( X )
is maximized when Pi = 1 / n , i =1,..., n. What is
H ( X )equal to in this case?
9.14. Apairoffairdiceisrolled.Let
```
```
X =
```
```
{
1 if the sum of the dice is 6
0 otherwise
and let Y equal the value of the first die. Compute
(a) H ( Y ),(b) HY ( X ),and(c) H ( X , Y ).
9.15. A coin having probability p =^23 of coming up
heads is flipped 6 times. Compute the entropy of
the outcome of this experiment.
9.16. A random variable can take on any of n possi-
ble values x 1 ,..., xn with respective probabilities
```
```
p ( xi ), i =1,..., n. We shall attempt to determine
the value of X by asking a series of questions,
each of which can be answered “yes” or “no.” For
instance, we may ask “Is X = x 1 ?” or “Is X equal
to either x 1 or x 2 or x 3 ?” and so on. What can you
say about the average number of such questions
that you will need to ask to determine the value
of X?
9.17. Show that, for any discrete random variable X and
function f ,
H ( f ( X ))... H ( X )
9.18. In transmitting a bit from location A to location
B ,ifwelet X denote the value of the bit sent at
location A and Y denote the value received at loca-
tion B ,then H ( X )− HY ( X )is called the rate of
transmission of information from A to B. The max-
imal rate of transmission, as a function of P { X =
1 }= 1 − P { X = 0 }, is called the channel capac-
ity. Show that, for a binary symmetric channel with
P { Y = 1 | X = 1 }= P { Y = 0 | X = 0 }= p ,thechan-
nel capacity is attained by the rate of transmission
of information when P { X = 1 }=^12 and its value is
1 + p log p +( 1 − p )log( 1 − p ).
```
#### Self-Test Problems and Exercises

```
9.1. Events occur according to a Poisson process with
rateλ=3 per hour.
(a) What is the probability that no events occur
between times 8 and 10 in the morning?
(b) What is the expected value of the number of
events that occur between times 8 and 10 in
the morning?
(c) What is the expected time of occurrence of
the fifth event after 2P.M.?
9.2. Customers arrive at a certain retail establishment
according to a Poisson process with rateλper
hour. Suppose that two customers arrive during
the first hour. Find the probability that
(a) both arrived in the first 20 minutes;
(b) at least one arrived in the first 30 minutes.
9.3. Four out of every five trucks on the road are fol-
lowed by a car, while one out of every six cars is
followed by a truck. What proportion of vehicles
on the road are trucks?
```
```
9.4. A certain town’s weather is classified each day as
being rainy, sunny, or overcast, but dry. If it is
rainy one day, then it is equally likely to be either
sunny or overcast the following day. If it is not
rainy, then there is one chance in three that the
weather will persist in whatever state it is in for
another day, and if it does change, then it is equally
likely to become either of the other two states. In
the long run, what proportion of days are sunny?
What proportion are rainy?
9.5. Let X be a random variable that takes on 5 pos-
sible values with respective probabilities .35, .2, .2,
.2, and .05. Also, let Y be a random variable that
takes on 5 possible values with respective proba-
bilities .05, .35, .1, .15, and .35.
(a) Show that H ( X )> H ( Y ).
(b) Using the result of Problem 9.13, give an intu-
itive explanation for the preceding inequality.
```
#### References

```
Sections 9.1 and 9.2
[1] KEMENY, J., L. SNELL,andA.KNAPP. Denumerable Markov Chains .NewYork:
D. Van Nostrand Company, 1966.
```
```
[2] PARZEN,E. Stochastic Processes. San Francisco: Holden-Day, Inc., 1962.
```

```
References 437
```
**[3]** ROSS,S.M. _Introduction to Probability Models_ , 9th ed. San Diego: Academic Press,
Inc., 2007.

**[4]** ROSS,S.M. _Stochastic Processes_ , 2d ed. New York: John Wiley & Sons, Inc., 1996.

```
Sections 9.3 and 9.4
```
**[5]** ABRAMSON,N. _Information Theory and Coding_. New York: McGraw-Hill Book
Company, 1963.

**[6]** MCELIECE,R. _Theory of Information and Coding_. Reading, MA: Addison-Wesley
Publishing Co., Inc., 1977.

**[7]** PETERSON,W.,andE.WELDON. _Error Correcting Codes_ , 2d ed. Cambridge, MA: The
MIT Press, 1972.


## CHAPTER 10

# Simulation

### 10.1 Introduction

**10.2 GENERAL TECHNIQUES FOR SIMULATING CONTINUOUS RANDOM VARIABLES
10.3 SIMULATING FROM DISCRETE DISTRIBUTIONS
10.4 VARIANCE REDUCTION TECHNIQUES**

##### 10.1 INTRODUCTION

```
How can we determine the probability of our winning a game of solitaire?
(By solitaire, we mean any one of the standard solitaire games played with an ordi-
nary deck of 52 playing cards and with some fixed playing strategy.) One possible
approach is to start with the reasonable hypothesis that all (52)! possible arrange-
ments of the deck of cards are equally likely to occur and then attempt to determine
how many of these lead to a win. Unfortunately, there does not appear to be any sys-
tematic method for determining the number of arrangements that lead to a win, and
as (52)! is a rather large number and the only way to determine whether a particular
arrangement leads to a win seems to be by playing the game out, it can be seen that
this approach will not work.
In fact, it might appear that the determination of the probability of winning at
solitaire is mathematically intractable. However, all is not lost, for probability falls
not only within the realm of mathematics, but also within the realm of applied sci-
ence; and, as in all applied sciences, experimentation is a valuable technique. For our
solitaire example, experimentation takes the form of playing a large number of such
games or, better yet, programming a computer to do so. After playing, say, n games,
if we let
```
```
Xi =
```
##### {

```
1ifthe i th game results in a win
0 otherwise
```
```
then Xi , i =1,..., n will be independent Bernoulli random variables for which
```
```
E [ Xi ]= P {win at solitaire}
```
```
Hence, by the strong law of large numbers, we know that
```
```
∑ n
```
```
i = 1
```
```
Xi
n
```
##### =

```
number of games won
number of games played
```
```
will, with probability 1, converge to P {win at solitaire}. That is, by playing a large
number of games, we can use the proportion of games won as an estimate of the prob-
ability of winning. This method of empirically determining probabilities by means of
experimentation is known as simulation.
```
**438**


```
Section 10.1 Introduction 439
```
In order to use a computer to initiate a simulation study, we must be able to gener-
ate the value of a uniform (0, 1) random variable; such variates are called _random
numbers_. To generate them, most computers have a built-in subroutine, called a
_random-number generator_ , whose output is a sequence of _pseudorandom numbers_ —
a sequence of numbers that is, for all practical purposes, indistinguishable from a sam-
ple from the uniform (0, 1) distribution. Most random-number generators start with
an initial value _X_ 0 , called the _seed_ , and then recursively compute values by specifying
positive integers _a_ , _c_ ,and _m_ , and then letting

```
Xn + 1 =( aXn + c )modulo mn Ú 0 (1.1)
```
where the foregoing means that _aXn_ + _c_ is divided by _m_ and the remainder is taken
as the value of _Xn_ + 1. Thus, each _Xn_ is either 0, 1,..., _m_ −1, and the quantity _Xn_ / _m_ is
taken as an approximation to a uniform (0, 1) random variable. It can be shown that,
subject to suitable choices for _a_ , _c_ ,and _m_ , Equation (1.1) gives rise to a sequence of
numbers that look as if they were generated from independent uniform (0, 1) random
variables.
As our starting point in simulation, we shall suppose that we can simulate from
the uniform (0, 1) distribution, and we shall use the term _random numbers_ to mean
independent random variables from this distribution.
In the solitaire example, we would need to program a computer to play out the
game starting with a given ordering of the cards. However, since the initial order-
ing is supposed to be equally likely to be any of the (52)! possible permutations, it
is also necessary to be able to generate a random permutation. Using only random
numbers, the following algorithm shows how this can be accomplished. The algorithm
begins by randomly choosing one of the elements and then putting it in position _n_ ;it
then randomly chooses among the remaining elements and puts the choice in position
_n_ −1, and so on. The algorithm efficiently makes a random choice among the remain-
ing elements by keeping these elements in an ordered list and then randomly choosing
a position on that list.

**_EXAMPLE 1a Generating a random permutation_**

Suppose we are interested in generating a permutation of the integers 1, 2,..., _n_ such
that all _n_! possible orderings are equally likely. Then, starting with any initial permu-
tation, we will accomplish this after _n_ −1 steps, where we interchange the positions
of two of the numbers of the permutation at each step. Throughout, we will keep
track of the permutation by letting _X_ ( _i_ ), _i_ =1,..., _n_ denote the number currently in
position _i_. The algorithm operates as follows:

1. Consider any arbitrary permutation, and let _X_ ( _i_ )denote the element in posi-
    tion _i_ , _i_ = 1 ..., _n_. [For instance, we could take _X_ ( _i_ )= _i_ , _i_ =1,..., _n_ .]
2. Generate a random variable _Nn_ that is equally likely to equal any of the values
    1, 2,..., _n_.
3. Interchange the values of _X_ ( _Nn_ )and _X_ ( _n_ ). The value of _X_ ( _n_ )will now remain
    fixed. [For instance, suppose that _n_ =4 and initially _X_ ( _i_ )= _i_ , _i_ =1, 2, 3, 4. If
    _N_ 4 =3, then the new permutation is _X_ ( 1 )=1, _X_ ( 2 )=2, _X_ ( 3 )=4, _X_ ( 4 )=3,
    and element 3 will remain in position 4 throughout.]
4. Generate a random variable _Nn_ − 1 that is equally likely to be either 1, 2,...,
    _n_ −1.
5. Interchange the values of _X_ ( _Nn_ − 1 )and _X_ ( _n_ − 1 ).[If _N_ 3 =1, then the new
    permutation is _X_ ( 1 )=4, _X_ ( 2 )=2, _X_ ( 3 )=1, _X_ ( 4 )=3.]


**440** Chapter 10 Simulation

6. Generate _Nn_ − 2 , which is equally likely to be either 1, 2,..., _n_ −2.
7. Interchange the values of _X_ ( _Nn_ − 2 )and _X_ ( _n_ − 2 ).[If _N_ 2 =1, then the new
    permutation is _X_ ( 1 )=2, _X_ ( 2 )=4, _X_ ( 3 )=1, _X_ ( 4 )=3, and this is the final
    permutation.]
8. Generate _Nn_ − 3 , and so on. The algorithm continues until _N_ 2 is generated, and
    after the next interchange the resulting permutation is the final one.
To implement this algorithm, it is necessary to be able to generate a random vari-
able that is equally likely to be any of the values 1, 2,..., _k_. To accomplish this, let
_U_ denote a random number—that is, _U_ is uniformly distributed on (0, 1)—and note
that _kU_ is uniform on(0, _k_ ). Hence,

```
P { i − 1 < kU < i }=
```
##### 1

```
k
```
```
i =1,..., k
```
```
so if we take Nk =[ kU ] +1, where [ x ] is the integer part of x (that is, the largest
integer less than or equal to x ), then Nk will have the desired distribution.
The algorithm can now be succinctly written as follows:
```
```
Step 1. Let X ( 1 ),..., X ( n )be any permutation of 1, 2,..., n. [For instance, we can
set X ( i )= i , i =1,..., n .]
Step 2. Let I = n.
Step 3. Generate a random number U and set N =[ IU ] +1.
Step 4. Interchange the values of X ( N )and X ( I ).
Step 5. Reduce the value of I by 1, and if I >1, go to step 3.
Step 6. X ( 1 ),..., X ( n )is the desired random generated permutation.
```
```
The foregoing algorithm for generating a random permutation is extremely useful.
For instance, suppose that a statistician is developing an experiment to compare the
effects of m different treatments on a set of n subjects. He decides to split the subjects
into m different groups of respective sizes n 1 , n 2 ,..., nm , where
```
```
∑ m
i = 1 ni = n ,with
the members of the i th group to receive treatment i. To eliminate any bias in the
assignment of subjects to treatments (for instance, it would cloud the meaning of the
experimental results if it turned out that all the “best” subjects had been put in the
same group), it is imperative that the assignment of a subject to a given group be done
“at random.” How is this to be accomplished?†
A simple and efficient procedure is to arbitrarily number the subjects 1 through
n and then generate a random permutation X ( 1 ),..., X ( n )of 1, 2,..., n. Now assign
subjects X ( 1 ), X ( 2 ),..., X ( n 1 )to be in group 1, X ( n 1 + 1 ),..., X ( n 1 + n 2 )to be in
group 2, and, in general, group j is to consist of subjects numbered X ( n 1 + n 2 +···+
nj − 1 + k ), k =1,..., nj..
```
### 10.2 General Techniques for Simulating Continuous Random Variables

```
In this section, we present two general methods for using random numbers to simulate
continuous random variables.
```
```
†Another technique for randomly dividing the subjects when m =2 was presented in Exam-
ple 2g of Chapter 6. The preceding procedure is faster, but requires more space than the one of
Example 2g.
```

```
Section 10.2 Simulating Continuous Random Variables 441
```
#### 10.2.1 The Inverse Transformation Method

A general method for simulating a random variable having a continuous distribution—
called the _inverse transformation method_ —is based on the following proposition.

**Proposition 2.1.** Let _U_ be a uniform (0, 1) random variable. For any continuous
distribution function _F_ , if we define the random variable _Y_ by

```
Y = F −^1 ( U )
```
then the random variable _Y_ has distribution function _F_ .[ _F_ −^1 ( _x_ )is defined to equal
that value _y_ for which _F_ ( _y_ )= _x_ .]

```
Proof.
```
```
FY ( a )= P { Y ... a }
= P { F −^1 ( U )... a } (2.1)
```
```
Now, since F ( x )is a monotone function, it follows that F −^1 ( U )... a if and only if
U ... F ( a ). Hence, from Equation (2.1), we have
```
```
FY ( a )= P { U ... F ( a )}
= F ( a )
```
It follows from Proposition 2.1 that we can simulate a random variable _X_ having
a continuous distribution function _F_ by generating a random number _U_ and then
setting _X_ = _F_ −^1 ( _U_ ).

**_EXAMPLE 2a Simulating an exponential random variable_**

If _F_ ( _x_ )= 1 − _e_ − _x_ ,then _F_ −^1 ( _u_ )is that value of _x_ such that

```
1 − e − x = u
```
or

```
x =−log( 1 − u )
```
Hence, if _U_ is a uniform (0, 1) variable, then

```
F −^1 ( U )=−log( 1 − U )
```
is exponentially distributed with mean 1. Since 1− _U_ is also uniformly distributed on
(0, 1), it follows that−log _U_ is exponential with mean 1. Since _cX_ is exponential with
mean _c_ when _X_ is exponential with mean 1, it follows that− _c_ log _U_ is exponential
with mean _c_..

The results of Example 2a can also be utilized to stimulate a gamma random
variable.

**_EXAMPLE 2b Simulating a gamma_** ( **_n_** **,** λ) **_random variable_**

To simulate from a gamma distribution with parameters( _n_ ,λ)when _n_ is an integer,
we use the fact that the sum of _n_ independent exponential random variables, each
having rateλ, has this distribution. Hence, if _U_ 1 ,..., _Un_ are independent uniform
(0, 1) random variables, then


**442** Chapter 10 Simulation

##### X =−

```
∑ n
```
```
i = 1
```
##### 1

```
λ
```
```
log Ui =−
```
##### 1

```
λ
```
```
log
```
##### ⎛

##### ⎝

```
∏ n
```
```
i = 1
```
```
Ui
```
##### ⎞

##### ⎠

```
has the desired distribution..
```
#### 10.2.2 The Rejection Method

```
Suppose that we have a method for simulating a random variable having density
function g ( x ). We can use this method as the basis for simulating from the contin-
uous distribution having density f ( x )by simulating Y from g and then accepting the
simulated value with a probability proportional to f ( Y )/ g ( Y ).
Specifically, let c be a constant such that
```
```
f ( y )
g ( y )
```
```
... c for all y
```
```
We then have the following technique for simulating a random variable having
density f.
```
```
Rejection Method
```
```
Step 1. Simulate Y having density g and simulate a random number U.
Step 2. If U ... f ( Y )/ cg ( Y ), set X = Y. Otherwise return to step 1.
```
```
The rejection method is expressed pictorially in Figure 10.1. We now prove that it
works.
```
```
Generate
Y  g
```
```
Start
Generate a
random number
U
```
```
Is
——–– f ( Y )
```
_U_ (^) _cg_ ( _Y_ )
Yes
Set _X_ = _Y_
No
**FIGURE 10.1:** Rejection method for simulating a random variable _X_ having density function _f_.
**Proposition 2.2.** The random variable _X_ generated by the rejection method has den-
sity function _f_.
**_Proof._** Let _X_ be the value obtained and let _N_ denote the number of necessary
iterations. Then
_P_ { _X_ ... _x_ }= _P_ { _YN_ ... _x_ }
= _P_

##### {

```
Y ... x | U ...
```
```
f ( Y )
cg ( Y )
```
##### }

##### =

##### P

##### {

```
Y ... x , U ...
```
```
f ( Y )
cg ( Y )
```
##### }

##### K

```
where K = P { U ... f ( Y )/ cg ( Y )}. Now, by independence, the joint density function
of Y and U is
f ( y , u )= g ( y ) 0 < u < 1
```

```
Section 10.2 Simulating Continuous Random Variables 443
```
```
so, using the foregoing, we have
```
```
P { X ... x }=
```
##### 1

##### K

##### ∫∫

```
y ... x
0 ... u ... f ( y )/ cg ( y )
```
```
g ( y ) du dy
```
##### =

##### 1

##### K

```
∫ x
```
```
−q
```
```
∫ f ( y )/ cg ( y )
```
```
0
```
```
du g ( y ) dy
```
##### =

##### 1

```
cK
```
```
∫ x
```
```
−q
```
```
f ( y ) dy
(2.2)
```
```
Letting X approachqand using the fact that f is a density gives
```
```
1 =
```
##### 1

```
cK
```
```
∫q
```
```
−q
```
```
f ( y ) dy =
```
##### 1

```
cK
```
```
Hence, from Equation (2.2), we obtain
```
```
P { X ... x }=
```
```
∫ x
```
```
−q
```
```
f ( y ) dy
```
```
which completes the proof.
```
**Remarks.** (a) Note that the way in which we “accept the value _Y_ with prob-
ability _f_ ( _Y_ )/ _cg_ ( _Y_ )” is by generating a random number _U_ and then accepting _Y_ if
_U_ ... _f_ ( _Y_ )/ _cg_ ( _Y_ ).
(b) Since each iteration will independently result in an accepted value with proba-
bility _P_ { _U_ ... _f_ ( _Y_ )/ _cg_ ( _Y_ )}= _K_ = 1 / _c_ , it follows that the number of iterations has a
geometric distribution with mean _c_..

**_EXAMPLE 2c Simulating a normal random variable_**

To simulate a unit normal random variable _Z_ (that is, one with mean 0 and variance
1), note first that the absolute value of _Z_ has probability density function

```
f ( x )=
```
##### 2

##### √

```
2 π
```
```
e − x
```
(^2) / 2
0 < _x_ <q (2.3)
We will start by simulating from the preceding density function by using the rejection
method, with _g_ being the exponential density function with mean 1—that is,
_g_ ( _x_ )= _e_ − _x_ 0 < _x_ <q
Now, note that
_f_ ( _x_ )
_g_ ( _x_ )

##### =

##### √

##### 2

```
π
```
```
exp
```
##### {

```
−( x^2 − 2 x )
2
```
##### }

##### =

##### √

##### 2

```
π
```
```
exp
```
##### {

```
−( x^2 − 2 x + 1 )
2
```
##### +

##### 1

##### 2

##### }

##### =

##### √

```
2 e
π
```
```
exp
```
##### {

```
−( x − 1 )^2
2
```
##### }

##### (2.4)

##### ...

##### √

```
2 e
π
```

**444** Chapter 10 Simulation

```
Hence, we can take c =
```
##### √

```
2 e /π; so, from Equation (2.4),
```
```
f ( x )
cg ( x )
```
```
=exp
```
##### {

```
−( x − 1 )^2
2
```
##### }

```
Therefore, using the rejection method, we can simulate the absolute value of a unit
normal random variable as follows:
(a) Generate independent random variables Y and U , Y being exponential with
rate 1 and U being uniform on (0, 1).
(b) If U ...exp{−( Y − 1 )^2 / 2 }, set X = Y. Otherwise, return to (a).
Once we have simulated a random variable X having Equation (2.3) as its density
function, we can then generate a unit normal random variable Z by letting Z be
equally likely to be either X or− X.
In step (b), the value Y is accepted if U ...exp{−( Y − 1 )^2 / 2 }, which is equiva-
lent to−log U Ú( Y − 1 )^2 /2. However, in Example 2a it was shown that−log U is
exponential with rate 1, so steps (a) and (b) are equivalent to
(a′) Generate independent exponentials Y 1 and Y 2 , each with rate 1.
(b′)If Y 2 Ú( Y 1 − 1 )^2 /2, set X = Y 1. Otherwise, return to (a’).
Suppose now that the foregoing results in Y 1 ’s being accepted—so we know that Y 2
is larger than( Y 1 − 1 )^2 /2. By how much does the one exceed the other? To answer
this question, recall that Y 2 is exponential with rate 1; hence, given that it exceeds
some value, the amount by which Y 2 exceeds( Y 1 − 1 )^2 /2 [that is, its “additional
life” beyond the time( Y 1 − 1 )^2 /2] is (by the memoryless property) also exponentially
distributed with rate 1. That is, when we accept step(b′), not only do we obtain X (the
absolute value of a unit normal), but, by computing Y 2 −( Y 1 − 1 )^2 /2, we also can
generate an exponential random variable (that is independent of X ) having rate 1.
Summing up, then, we have the following algorithm that generates an exponential
with rate 1 and an independent unit normal random variable:
```
```
Step 1. Generate Y 1 , an exponential random variable with rate 1.
Step 2. Generate Y 2 , an exponential random variable with rate 1.
Step 3. If Y 2 −( Y 1 − 1 )^2 / 2 > 0, set Y = Y 2 −( Y 1 − 1 )^2 /2 and go to step 4.
Otherwise, go to step 1.
Step 4. Generate a random number U , and set
```
##### Z =

##### {

```
Y 1 if U ...^12
− Y 1 if U >^12
```
```
The random variables Z and Y generated by the foregoing algorithm are indepen-
dent, with Z being normal with mean 0 and variance 1 and Y being exponential with
rate 1. (If we want the normal random variable to have meanμand varianceσ^2 ,we
just takeμ+σ Z .)
Remarks. (a) Since c =
```
##### √

```
2 e /π L 1 .32, the algorithm requires a geometrically
distributed number of iterations of step 2 with mean 1.32.
(b) If we want to generate a sequence of unit normal random variables, then we can
use the exponential random variable Y obtained in step 3 as the initial exponential
needed in step 1 for the next normal to be generated. Hence, on the average, we
can simulate a unit normal by generating 1. 64 (= 2 * 1. 32 − 1 )exponentials and
computing 1.32 squares..
```

```
Section 10.2 Simulating Continuous Random Variables 445
```
**_EXAMPLE 2d Simulating normal random variables: the polar method_**

It was shown in Example 7b of Chapter 6 that if _X_ and _Y_ are independent unit normal

random variables, then their polar coordinates _R_ =

##### √

_X_^2 + _Y_^2 , =tan−^1 ( _Y_ / _X_ )
are independent, with _R_^2 being exponentially distributed with mean 2 and being
uniformly distributed on(0, 2π). Hence, if _U_ 1 and _U_ 2 are random numbers, then,
using the result of Example 2a, we can set

```
R =(−2log U 1 )^1 /^2
Θ= 2 π U 2
```
from which it follows that

```
X = R cosΘ=(−2log U 1 )^1 /^2 cos( 2 π U 2 )
Y = R sinΘ=(−2log U 1 )^1 /^2 sin( 2 π U 2 ) (2.5)
```
are independent unit normals..

The preceding approach to generating unit normal random variables is called the
_Box–Muller approach_. Its efficiency suffers somewhat from its need to compute the
sine and cosine values. There is, however, a way to get around this potentially time-
consuming difficulty. To begin, note that if _U_ is uniform on (0, 1) then 2 _U_ is uniform
on (0, 2), so 2 _U_ −1 is uniform on(−1, 1). Thus, if we generate random numbers _U_ 1
and _U_ 2 and set

```
V 1 = 2 U 1 − 1
V 2 = 2 U 2 − 1
```
then( _V_ 1 , _V_ 2 )is uniformly distributed in the square of area 4 centered at (0, 0). (See
Figure 10.2.)
Suppose now that we continually generate such pairs( _V_ 1 , _V_ 2 )until we obtain one
that is contained in the disk of radius 1 centered at (0, 0)—that is, until _V_^21 + _V_ 22 ...1.
It then follows that such a pair( _V_ 1 , _V_ 2 )is uniformly distributed in the disk. Now, let

```
(1, 1)
```
```
(1, –1)
```
```
(–1, 1)
```
```
(–1, –1)
```
```
R V
2
```
```
V 1
```
```

V 12 += 1 V 22
```
```
= (0, 0)
= ( V 1 , V 2 )
```
```
FIGURE 10.2:
```

**446** Chapter 10 Simulation

```
R , denote the polar coordinates of this pair. Then it is easy to verify that R and
are independent, with R
2
being uniformly distributed on (0, 1) and being uniformly
distributed on(0, 2π). (See Problem 13.)
Since
```
```
sin =
```
##### V 2

##### R

##### =

##### V 2

##### √

##### V 12 + V^22

```
cos =
```
##### V 1

##### R

##### =

##### V 1

##### √

##### V 12 + V^22

```
it follows from Equation (2.5) that we can generate independent unit normals X and
Y by generating another random number U and setting
```
```
X =(−2log U )^1 /^2 V 1 / R
Y =(−2log U )^1 /^2 V 2 / R
```
```
In fact, because (conditional on V 12 + V 22 ...1) R
2
is uniform on (0, 1) and is inde-
pendent ofθ, we can use it instead of generating a new random number U , thus
showing that
```
```
X =(−2log R
```
```
2
)^1 /^2
```
##### V 1

##### R

##### =

##### √

```
−2log S
S
```
##### V 1

```
Y =(−2log R
```
```
2
)^1 /^2
```
##### V 2

##### R

##### =

##### √

```
−2log S
S
```
##### V 2

```
are independent unit normals, where
```
```
S = R
2
= V^21 + V 22
```
```
Summing up, we have the following approach to generating a pair of independent
unit normals:
```
```
Step 1. Generate random numbers U 1 and U 2.
Step 2. Set V 1 = 2 U 1 −1, V 2 = 2 U 2 −1, S = V^21 + V 22.
Step 3. If S >1, return to step 1.
Step 4. Return the independent unit normals
```
##### X =

##### √

```
−2log S
S
```
##### V 1 , Y =

##### √

```
−2log S
S
```
##### V 2

```
The preceding algorithm is called the polar method. Since the probability that a
random point in the square will fall within the circle is equal toπ/4 (the area of the
circle divided by the area of the square), it follows that, on average, the polar method
will require 4/π L 1 .273 iterations of step 1. Hence, it will, on average, require 2.546
random numbers, 1 logarithm, 1 square root, 1 division, and 4.546 multiplications to
generate 2 independent unit normals.
```
```
EXAMPLE 2e Simulating a chi-squared random variable
The chi-squared distribution with n degrees of freedom is the distribution ofχ n^2 =
Z^21 + ··· + Z^2 n , where Zi , i =1,..., n are independent unit normals. Now, it was
```

```
Section 10.3 Simulating from Discrete Distributions 447
```
```
shown in Section 6.3 of Chapter 6 that Z^21 + Z^22 has an exponential distribution with
rate^12. Hence, when n is even (say, n = 2 k ),χ 22 k has a gamma distribution with param-
eters
```
##### (

```
k ,^12
```
##### )

. Thus,−2log(

```
∏ k
i = 1 Ui )has a chi-squared distribution with 2 k degrees
of freedom. Accordingly, can simulate a chi-squared random variable with 2 k + 1
degrees of freedom by first simulating a unit normal random variable Z and then
adding Z^2 to the foregoing. That is,
```
```
χ 22 k + 1 = Z^2 −2log
```
##### ⎛

##### ⎝

```
∏ k
```
```
i = 1
```
```
Ui
```
##### ⎞

##### ⎠

```
where Z , U 1 ,..., Un are independent, Z is a unit normal, and U 1 ,..., Un are uniform
(0, 1) random variables.
```
### 10.3 Simulating from Discrete Distributions

```
All of the general methods for simulating random variables from continuous distribu-
tions have analogs in the discrete case. For instance, if we want to simulate a random
variable Z having probability mass function
```
```
P { X = xj }= Pj , j =0, 1,...,
```
##### ∑

```
j
```
```
Pj = 1
```
```
we can use the following discrete time analog of the inverse transform technique:
To simulate X for which P { X = xj }= Pj , let U be uniformly distributed over (0, 1)
and set
```
##### X =

##### ⎧

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎨

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎪⎪

##### ⎩

```
x 1 if U ... P 1
x 2 if P 1 < U ... P 1 + P 2
```
```
#
#
#
xj if
```
```
∑ j −^1
```
```
1
```
```
Pi < U ...
```
```
∑ j
```
```
i
```
```
Pi
```
##### #

##### #

##### #

```
Since
```
```
P { X = xj }= P
```
##### ⎧

##### ⎨

##### ⎩

```
∑ j −^1
```
```
1
```
```
Pi < U ...
```
```
∑ j
```
```
1
```
```
Pi
```
##### ⎫

##### ⎬

##### ⎭

```
= Pj
```
```
it follows that X has the desired distribution.
```
```
EXAMPLE 3a The geometric distribution
Suppose that independent trials, each of which results in a “success” with probability
p ,0< p <1, are continually performed until a success occurs. Letting X denote the
necessary number of trials; then
```
```
P { X = i }=( 1 − p ) i −^1 pi Ú 1
```

**448** Chapter 10 Simulation

```
which is seen by noting that X = i if the first i − 1 trials are all failures and the i th
trial is a success. The random variable X is said to be a geometric random variable
with parameter p. Since
```
```
∑ j −^1
```
```
i = 1
```
```
P { X = i }= 1 − P { X > j − 1 }
```
```
= 1 − P {first j −1 are all failures}
= 1 −( 1 − p ) j −^1 j Ú 1
```
```
we can simulate such a random variable by generating a random number U and then
setting X equal to that value j for which
```
```
1 −( 1 − p ) j −^1 < U ... 1 −( 1 − p ) j
```
```
or, equivalently, for which
```
```
( 1 − p ) j ... 1 − U <( 1 − p ) j −^1
```
```
Since 1− U has the same distribution as U , we can define X by
```
```
X =min{ j :( 1 − p ) j ... U }
=min{ j : j log( 1 − p )...log U }
```
```
=min
```
##### {

```
j : j Ú
```
```
log U
log( 1 − p )
```
##### }

```
where the inequality has changed sign because log( 1 − p )is negative [since log( 1 −
p )<log 1=0]. Using the notation [ x ] for the integer part of x (that is, [ x ]isthe
largest integer less than or equal to x ), we can write
```
##### X = 1 +

##### [

```
log U
log( 1 − p )
```
##### ]

##### .

```
As in the continuous case, special simulating techniques have been developed for
the more common discrete distributions. We now present two of these.
```
```
EXAMPLE 3b Simulating a binomial random variable
A binomial ( n , p ) random variable can easily be simulated by recalling that it can
be expressed as the sum of n independent Bernoulli random variables. That is, if
U 1 ,..., Un are independent uniform (0, 1) variables, then letting
```
```
Xi =
```
##### {

```
1if Ui < p
0 otherwise
```
```
it follows that X K
```
```
∑ n
i = 1
```
```
Xi is a binomial random variable with parameters n and p.
```

```
Section 10.4 Variance Reduction Techniques 449
```
```
EXAMPLE 3c Simulating a Poisson random variable
To simulate a Poisson random variable with meanλ, generate independent uniform
(0, 1) random variables U 1 , U 2 ,...stopping at
```
```
N =min
```
##### ⎧

##### ⎨

##### ⎩

```
n :
```
```
∏ n
```
```
i = 1
```
```
Ui < e −λ
```
##### ⎫

##### ⎬

##### ⎭

```
The random variable X K N −1 has the desired distribution. That is, if we continue
generating random numbers until their product falls below e −λ, then the number
required, minus 1, is Poisson with meanλ.
That X K N −1 is indeed a Poisson random variable having meanλcan perhaps
be most easily seen by noting that
```
```
X + 1 =min
```
##### ⎧

##### ⎨

##### ⎩

```
n :
```
```
∏ n
```
```
i = 1
```
```
Ui < e −λ
```
##### ⎫

##### ⎬

##### ⎭

```
is equivalent to
```
```
X =max
```
##### ⎧

##### ⎨

##### ⎩

```
n :
```
```
∏ n
```
```
i = 1
```
```
Ui Ú e −λ
```
##### ⎫

##### ⎬

##### ⎭

```
where
```
##### ∏^0

```
i = 1
```
```
Ui K 1
```
```
or, taking logarithms, to
```
```
X =max
```
##### ⎧

##### ⎨

##### ⎩

```
n :
```
```
∑ n
```
```
i = 1
```
```
log Ui Ú−λ
```
##### ⎫

##### ⎬

##### ⎭

```
or
```
```
X =max
```
##### ⎧

##### ⎨

##### ⎩

```
n :
```
```
∑ n
```
```
i = 1
```
```
−log Ui ...λ
```
##### ⎫

##### ⎬

##### ⎭

```
However,−log Ui is exponential with rate 1, so X can be thought of as being the
maximum number of exponentials having rate 1 that can be summed and still be less
thanλ. But by recalling that the times between successive events of a Poisson process
having rate 1 are independent exponentials with rate 1, it follows that X is equal to the
number of events by timeλof a Poisson process having rate 1; thus X has a Poisson
distribution with meanλ..
```
### 10.4 Variance Reduction Techniques

```
Let X 1 ,..., Xn have a given joint distribution, and suppose that we are interested in
computing
θ K E [ g ( X 1 ,..., Xn )]
```
```
where g is some specified function. It sometimes turns out that it is extremely difficult
to analytically computeθ, and when such is the case, we can attempt to use simulation
to estimateθ. This is done as follows: Generate X 1 (^1 ),..., X ( n^1 )having the same joint
distribution as X 1 ,..., Xn and set
```
```
Y 1 = g ( X
( 1 )
1 ,..., X
```
```
( 1 )
n )
```

**450** Chapter 10 Simulation

```
Now let X
( 2 )
1 ,..., X
```
```
( 2 )
n simulate a second set of random variables (independent of the
first set) having the distribution of X 1 ,..., Xn and set
```
```
Y 2 = g ( X 1 (^2 ),..., X ( n^2 ))
```
```
Continue this until you have generated k (some predetermined number) sets and so
have also computed Y 1 , Y 2 ,..., Yk. Now, Y 1 ,..., Yk are independent and identically
distributed random variables, each having the same distribution as g ( X 1 ,..., Xn ).
Thus, if we let Y denote the average of these k random variables—that is, if
```
##### Y =

```
∑ k
```
```
i = 1
```
```
Yi
k
```
```
then
```
```
E [ Y ]=θ
E [( Y −θ)^2 ]=Var( Y )
```
```
Hence, we can use Y as an estimate ofθ. Since the expected square of the difference
between Y andθis equal to the variance of Y , we would like this quantity to be as
small as possible. [In the preceding situation, Var( Y )=Var( Yi )/ k , which is usually
not known in advance, but must be estimated from the generated values Y 1 ,..., Yn .]
We now present three general techniques for reducing the variance of our estimator.
```
#### 10.4.1 Use of Antithetic Variables

```
In the foregoing situation, suppose that we have generated Y 1 and Y 2 , which are
identically distributed random variables having meanθ. Now,
```
```
Var
```
##### (

##### Y 1 + Y 2

##### 2

##### )

##### =

##### 1

##### 4

```
[Var( Y 1 )+Var( Y 2 )+2Cov( Y 1 , Y 2 )]
```
##### =

```
Var( Y 1 )
2
```
##### +

```
Cov( Y 1 , Y 2 )
2
Hence, it would be advantageous (in the sense that the variance would be reduced)
if Y 1 and Y 2 were negatively correlated rather than being independent. To see how
we could arrange this, let us suppose that the random variables X 1 ,..., Xn are inde-
pendent and, in addition, that each is simulated via the inverse transform technique.
That is, Xi is simulated from Fi −^1 ( Ui ), where Ui is a random number and Fi is the
distribution of Xi. Thus, Y 1 can be expressed as
```
```
Y 1 = g ( F 1 −^1 ( U 1 ),..., F − n^1 ( Un ))
```
```
Now, since 1− U is also uniform over (0, 1) whenever U is a random number (and
is negatively correlated with U ), it follows that Y 2 defined by
```
```
Y 2 = g ( F − 11 ( 1 − U 1 ),..., F − n^1 ( 1 − Un ))
```
```
will have the same distribution as Y 1. Hence, if Y 1 and Y 2 were negatively correlated,
then generating Y 2 by this means would lead to a smaller variance than if it were
generated by a new set of random numbers. (In addition, there is a computational
savings because, rather than having to generate n additional random numbers, we
need only subtract each of the previous n numbers from 1.) Although we cannot, in
```

```
Section 10.4 Variance Reduction Techniques 451
```
general, be certain that _Y_ 1 and _Y_ 2 will be negatively correlated, this often turns out to
be the case, and indeed it can be proven that it will be so whenever _g_ is a monotonic
function.

#### 10.4.2 Variance Reduction by Conditioning

Let us start by recalling the conditional variance formula (see Section 7.5.4)

```
Var( Y )= E [Var( Y | Z )]+Var( E [ Y | Z ])
```
Now, suppose that we are interested in estimating _E_ [ _g_ ( _X_ 1 ,..., _Xn_ )] by simulating
**X** =( _X_ 1 ,..., _Xn_ )and then computing _Y_ = _g_ ( **X** ). If, for some random variable _Z_
we can compute _E_ [ _Y_ | _Z_ ], then, since Var( _Y_ | _Z_ )Ú 0, it follows from the preceding
conditional variance formula that

```
Var( E [ Y | Z ])...Var( Y )
```
Thus, since _E_ [ _E_ [ _Y_ | _Z_ ]]= _E_ [ _Y_ ], it follows that _E_ [ _Y_ | _Z_ ] is a better estimator of _E_ [ _Y_ ]
than is _Y_.

**_EXAMPLE 4a Estimation of_** π

Let _U_ 1 and _U_ 2 be random numbers and set _Vi_ = 2 _Ui_ −1, _i_ = 1, 2. As noted in
Example 2d,( _V_ 1 , _V_ 2 )will be uniformly distributed in the square of area 4 centered at
(0, 0). The probability that this point will fall within the inscribed circle of radius 1
centered at (0, 0) (see Figure 10.2) is equal toπ/4 (the ratio of the area of the circle
to that of the square). Hence, upon simulating a large number _n_ of such pairs and
setting

```
Ij =
```
##### {

```
1ifthe j th pair falls within the circle
0 otherwise
```
it follows that _Ij_ , _j_ =1,..., _n_ , will be independent and identically distributed random
variables having _E_ [ _Ij_ ]=π/4. Thus, by the strong law of large numbers,

```
I 1 + ··· + In
n
```
##### →

```
π
4
```
```
as n →q
```
Therefore, by simulating a large number of pairs( _V_ 1 , _V_ 2 )and multiplying the propor-
tion of them that fall within the circle by 4, we can accurately approximateπ.
The preceding estimator can, however, be improved upon by using conditional
expectation. If we let _I_ be the indicator variable for the pair( _V_ 1 , _V_ 2 ), then, rather
than using the observed value of _I_ , it is better to condition on _V_ 1 and so utilize

```
E [ I | V 1 ]= P { V 12 + V 22 ... 1 | V 1 }
= P { V 22 ... 1 − V^21 | V 1 }
```
Now,

```
P { V 22 ... 1 − V 12 | V 1 =ν}= P { V^22 ... 1 −ν^2 }
```
```
= P {−
```
##### √

```
1 −ν^2 ... V 2 ...
```
##### √

```
1 −ν^2 }
```
```
=
```
##### √

```
1 −ν^2
```
so

```
E [ I | V 1 ]=
```
##### √

##### 1 − V^21


**452** Chapter 10 Simulation

```
Thus, an improvement on using the average value of I to estimateπ/4istousethe
average value of
```
##### √

```
1 − V 12. Indeed, since
```
##### E [

##### √

##### 1 − V^21 ]=

##### ∫ 1

```
− 1
```
##### 1

##### 2

##### √

```
1 −ν^2 d ν=
```
##### ∫ 1

```
0
```
##### √

```
1 − u^2 du = E [
```
##### √

##### 1 − U^2 ]

```
where U is uniform over (0, 1), we can generate n random numbers U and use the
average value of
```
##### √

```
1 − U^2 as our estimate ofπ/4. (Problem 14 shows that this esti-
mator has the same variance as the average of the n values,
```
##### √

##### 1 − V^2 .)

```
The preceding estimator ofπ can be improved even further by noting that the
function g ( u )=
```
##### √

```
1 − u^2 ,0... u ...1, is a monotonically decreasing function of u ,
and so the method of antithetic variables will reduce the variance of the estimator
of E [
```
##### √

```
1 − U^2 ]. That is, rather than generating n random numbers and using the
average value of
```
##### √

```
1 − U^2 as an estimator ofπ/4, we would obtain an improved
estimator by generating only n /2 random numbers U and then using one-half the
average of
```
##### √

##### 1 − U^2 +

##### √

```
1 −( 1 − U )^2 as the estimator ofπ/4.
The following table gives the estimates ofπresulting from simulations, using n =
10, 000, based on the three estimators.
```
```
Method Estimate ofπ
```
```
Proportion of the random points that fall in the circle 3. 1612
Average value of
```
##### √

##### 1 − U^23. 128448

```
Average value of
```
##### √

##### 1 − U^2 +

##### √

##### 1 −( 1 − U )^23. 139578

```
A further simulation using the final approach and n =64, 000 yielded the estimate
3.143288..
```
#### 10.4.3 Control Variates

```
Again, suppose that we want to use simulation to estimate E [ g ( X )], where X =
( X 1 ,..., Xn ). But suppose now that, for some function f , the expected value of f ( X )
is known—say, it is E [ f ( X )]=μ. Then, for any constant a , we can also use
```
```
W = g ( X )+ a [ f ( X )−μ]
```
```
as an estimator of E [ g ( X )]. Now,
```
```
Var( W )=Var[ g ( X )]+ a^2 Var[ f ( X )]+ 2 a Cov[ g ( X ), f ( X )] (4.1)
```
```
Simple calculus shows that the foregoing is minimized when
```
```
a =
```
```
−Cov[ f ( X ), g ( X )]
Var[ f ( X )]
```
##### (4.2)

```
and for this value of a ,
```
```
Var( W )=Var[ g ( X )]−
```
```
[Cov[ f ( X ), g ( X )]^2
Var[ f ( X )]
```
##### (4.3)


```
Problems 453
```
```
Unfortunately, neither Var[ f ( X )] nor Cov[ f ( X )], g ( X )] is usually known, so we can-
not in general obtain the foregoing reduction in variance. One approach in practice
is to use the simulated data to estimate these quantities. This approach usually yields
almost all of the theoretically possible reduction in variance.
```
#### Summary

```
Let F be a continuous distribution function and U a uniform (0, 1) random variable.
Then the random variable F −^1 ( U )has distribution function F , where F −^1 ( u )is that
value x such that F ( x )= u. Applying this result, we can use the values of uniform (0,
1) random variables, called random numbers , to generate the values of other random
variables. This technique is called the inverse transform method.
Another technique for generating random variables is based on the rejection method.
Suppose that we have an efficient procedure for generating a random variable from
the density function g and that we desire to generate a random variable having den-
sity function f. The rejection method for accomplishing this starts by determining a
constant c such that
max
```
```
f ( x )
g ( x )
```
```
... c
```
```
It then proceeds as follows:
```
1. Generate _Y_ having density _g_.
2. Generate a random number _U_.
3. If _U_ ... _f_ ( _Y_ )/ _cg_ ( _Y_ ), set _X_ = _Y_ and stop.
4. Return to step 1.
The number of passes through step 1 is a geometric random variable with mean _c_.
Standard normal random variables can be efficiently simulated by the rejection
method (with _g_ being exponential with mean 1) or by the technique known as the
_polar algorithm_.
To estimate a quantityθ, one often generates the values of a partial sequence
of random variables whose expected value isθ. The efficiency of this approach is
increased when these random variables have a small variance. Three techniques that
can often be used to specify random variables with meanθand relatively small vari-
ances are
1. the use of antithetic variables,
2. the use of conditional expectations, and
3. the use of control variates.

#### Problems...................................

**10.1.** The following algorithm will generate a random
permutation of the elements 1, 2,..., _n_ .Itissome-
what faster than the one presented in Example 1a
but is such that no position is fixed until the algo-
rithm ends. In this algorithm, _P_ ( _i_ )can be inter-
preted as the element in position _i_.
Step 1. Set _k_ =1.
Step 2. Set _P_ ( 1 )=1.
Step 3. If _k_ = _n_ , stop. Otherwise, let _k_ = _k_ +1.

```
Step 4. Generate a random number U and let
P ( k )= P ([ kU ]+ 1 )
P ([ kU ]+ 1 )= k
```
```
Go to step 3.
(a) Explain in words what the algorithm is doing.
(b) Show that at iteration k —that is, when the
value of P ( k )is initially set— P ( 1 ), P ( 2 ),...,
P ( k )is a random permutation of 1, 2,..., k.
```

**454** Chapter 10 Simulation

```
Hint : Use induction and argue that
Pk { i 1 , i 2 ,..., ij − 1 , k , ij ,..., ik − 2 , i }
```
```
= Pk − 1 { i 1 , i 2 ,..., ij − 1 , i , ij ,..., ik − 2 }
1
k
=
```
```
1
k!
```
```
by the induction hypothesis
```
```
10.2. Develop a technique for simulating a random vari-
able having density function
```
```
f ( x )=
```
```
{
e^2 x −q< x < 0
e −^2 x 0 < x <q
```
```
10.3. Give a technique for simulating a random variable
having the probability density function
```
```
f ( x )=
```
```
⎧
⎪⎪
⎪⎪
⎪⎪⎨
```
```
⎪⎪⎪
⎪⎪
⎪⎩
```
```
1
2
( x − 2 ) 2 ... x ... 3
```
```
1
2
```
```
(
2 −
```
```
x
3
```
```
)
3 < x ... 6
```
```
0 otherwise
```
```
10.4. Present a method for simulating a random variable
having distribution function
```
```
F ( x )=
```
```
⎧
⎪⎪
⎪⎪⎪
⎪⎪
⎪⎨
```
```
⎪⎪⎪
⎪⎪
⎪⎪
⎪⎩
```
```
0 x ...− 3
1
2
```
```
+
```
```
x
6
```
```
− 3 < x < 0
```
```
1
2
```
```
+
```
```
x^2
32
```
```
0 < x ... 4
1 x > 4
```
```
10.5. Use the inverse transformation method to present
an approach for generating a random variable
from the Weibull distribution
```
```
F ( t )= 1 − e − at
```
```
β
t Ú 0
```
```
10.6. Give a method for simulating a random variable
having failure rate function
(a) λ( t )= c ;
(b) λ( t )= ct ;
(c) λ( t )= ct^2 ;
(d) λ( t )= ct^3.
10.7. Let F be the distribution function
```
```
F ( x )= xn 0 < x < 1
```
```
(a) Give a method for simulating a random vari-
able having distribution F that uses only a sin-
gle random number.
(b) Let U 1 ,..., Un be independent random num-
bers. Show that
```
```
P {max( U 1 ,..., Un )... x }= xn
```
```
(c) Use part (b) to give a second method of sim-
ulating a random variable having distribu-
tion F.
10.8. Suppose it is relatively easy to simulate from Fi for
each i =1,..., n. How can we simulate from
(a) F ( x )=
```
```
∏ n
i = 1
```
```
Fi ( x )?
```
```
(b) F ( x )= 1 −
```
```
∏ n
i = 1
```
```
[1− Fi ( x )]?
```
```
10.9. Suppose we have a method for simulating random
variables from the distributions F 1 and F 2. Explain
how to simulate from the distribution
F ( x )= pF 1 ( x )+( 1 − p ) F 2 ( x ) 0 < p < 1
Give a method for simulating from
```
```
F ( x )=
```
```
⎧
⎨
⎩
```
```
1
3 (^1 − e
− 3 x )+^2
3 x^0 < x ...^1
1
3 (^1 − e
```
```
− 3 x )+ 2
3 x >^1
```
```
10.10. In Example 2c we simulated the absolute value
of a unit normal by using the rejection procedure
on exponential random variables with rate 1. This
raises the question of whether we could obtain a
more efficient algorithm by using a different expo-
nential density—that is, we could use the density
g ( x )=λ e −λ x. Show that the mean number of iter-
ations needed in the rejection scheme is minimized
whenλ=1.
10.11. Use the rejection method with g ( x )=1, 0< x <1,
to determine an algorithm for simulating a random
variable having density function
```
```
f ( x )=
```
```
{
60 x^3 ( 1 − x )^20 < x < 1
0 otherwise
```
```
10.12. Explain how you could use random numbers to
approximate
```
```
∫ 1
0 k ( x ) dx ,where k ( x )is an arbitrary
function.
Hint :If U is uniform on (0, 1), what is E [ k ( U )]?
10.13. Let( X , Y )be uniformly distributed in the circle
of radius 1 centered at the origin. Its joint density
is thus
```
```
f ( x , y )=
```
```
1
π
0 ... x^2 + y^2 ... 1
```
```
Let R =( X^2 + Y^2 )^1 /^2 andθ=tan−^1 ( Y / X )denote
the polar coordinates of ( X , Y ). Show that R and
θare independent, with R^2 being uniform on (0, 1)
andθbeing uniform on(0, 2π).
10.14. In Example 4a, we showed that
```
```
E [( 1 − V^2 )^1 /^2 ]= E [( 1 − U^2 )^1 /^2 ]=
π
4
```

```
Reference 455
```
```
when V is uniform(−1, 1)and U is uniform (0, 1).
Now show that
```
```
Var[( 1 − V^2 )^1 /^2 ]=Var[( 1 − U^2 )^1 /^2 ]
```
```
and find their common value.
```
**10.15. (a)** Verify that the minimum of (4.1) occurs when
_a_ is as given by (4.2).

```
(b) Verify that the minimum of (4.1) is given by
(4.3).
10.16. Let X be a random variable on (0, 1) whose den-
sity is f ( x ). Show that we can estimate
```
```
∫ 1
0 g ( x ) dx
by simulating X andthentaking g ( X )/ f ( X )as
our estimate. This method, called importance sam-
pling , tries to choose f similar in shape to g ,sothat
g ( X )/ f ( X )has a small variance.
```
#### Self-Test Problems and Exercises

```
10.1. The random variable X has probability density
function
f ( x )= Cex 0 < x < 1
(a) Find the value of the constant C.
(b) Give a method for simulating such a random
variable.
10.2. Give an approach for simulating a random variable
having probability density function
f ( x )= 30 ( x^2 − 2 x^3 + x^4 ) 0 < x < 1
10.3. Give an efficient algorithm to simulate the value of
a random variable with probability mass function
```
```
p 1 =. 15 p 2 =. 2 p 3 =. 35 p 4 =. 30
```
```
10.4. If X is a normal random variable with meanμ
and varianceσ^2 , define a random variable Y that
has the same distribution as X and is negatively
correlated with it.
10.5. Let X and Y be independent exponential random
variables with mean 1.
(a) Explain how we could use simulation to esti-
mate E [ eXY ].
(b) Show how to improve the estimation
approach in part (a) by using a control variate.
```
#### Reference

```
[1] ROSS,S.M. Simulation. 4th ed. San Diego: Academic Press, Inc., 2006.
```

_This page intentionally left blank_


### Answers to Selected Problems

##### CHAPTER 1

##### 1. 67,600,000; 19,656,000 2. 1296 4. 24; 4 5. 144; 18 6. 2401 7. 720; 72; 144;

##### 72 8. 120; 1260; 34,650 9. 27,720 10. 40,320; 10,080; 1152; 2880; 384 11. 720;

##### 72; 144 12. 24,300,000; 17,100,720 13. 190 14. 2,598,960 16. 42; 94

##### 17. 604,800 18. 600 19. 896; 1000; 910 20. 36; 26 21. 35 22. 18 23. 48

##### 25. 52!/(13!)^4 27. 27,720 28. 65,536; 2520 29. 12,600; 945 30. 564,480

##### 31. 165; 35 32. 1287; 14,112 33. 220; 572

##### CHAPTER 2

##### 9. 74 10. .4; .1 11. 70; 2 12. .5; .32; 149/198 13. 20,000; 12,000; 11,000; 68,000;

##### 10,000 14. 1.057 15. .0020; .4226; .0475; .0211; .00024 17. 9. 10947 * 10 −^6

**18.** .048 **19.** 5/18 **20.** .9052 **22.** ( _n_ + 1 )/ 2 _n_ **23.** 5/12 **25.** .4 **26.** .492929
**27.** .0888; .2477; .1243; .2099 **30.** 1/18; 1/6; 1/2 **31.** 2/9; 1/9 **33.** 70/323
**36.** .0045; .0588 **37.** .0833; .5 **38.** 4 **39.** .48 **40.** 1/64; 21/64; 36/64; 6/64
**41.** .5177 **44.** .3; .2; .1 **46.** 5 **48.** 1. 0604 * 10 −^3 **49.** .4329 **50.** 2. 6084 * 10 −^6
**52.** .09145; .4268 **53.** 12/35 **54.** .0511 **55.** .2198; .0343

##### CHAPTER 3

##### 1. 1/3

##### 2. 1/6; 1/5; 1/4; 1/3; 1/2; 1 3. .339 5. 6/91 6. 1/2 7. 2/3

##### 8. 1/2 9. 7/11 10. .22 11. 1/17; 1/33 12. .504; .3629 14. 35/768; 210/768

##### 15. .4848 16. .9835 17. .0792; .264 18. .331; .383; .286; 48.62 19. 44.29;

##### 41.18 20. .4; 1/26 21. .496; 3/14; 9/62 22. 5/9; 1/6; 5/54 23. 4/9; 1/2 24. 1/3;

##### 1/2 26. 20/21; 40/41 28. 3/128; 29/1536 29. .0893 30. 7/12; 3/5 33. .76,

##### 49/76 34. 27/31 35. .62, 10/19 36. 1/2 37. 1/3; 1/5; 1 38. 12/37 39. 46/185

##### 40. 3/13; 5/13; 5/52; 15/52 41. 43/459 42. 34.48 43. 4/9 45. 1/11 48. 2/3

##### 50. 17.5; 38/165; 17/33 51. .65; 56/65; 8/65; 1/65; 14/35; 12/35; 9/35 52. .11; 16/89;

```
12/27; 3/5; 9/25 55. 9 57. (c) 2/3 60. 2/3; 1/3; 3/4 61. 1/6; 3/20 65. 9/13;
1/2 69. 9; 9; 18; 110; 4; 4; 8; 120 all over 128 70. 1/9; 1/18 71. 38/64; 13/64; 13/64
```
**73.** 1/16; 1/32; 5/16; 1/4; 31/32 **74.** 9/19 **75.** 3/4, 7/12 **78.** _p_^2 /( 1 − 2 _p_ + 2 _p_^2 )
**79.** .5550 **81.** .9530 **83.** .5; .6; .8 **84.** 9/19; 6/19; 4/19; 7/15; 53/165; 7/33
**89.** 97/142; 15/26; 33/102

##### CHAPTER 4

**1.** _p_ ( 4 )= 6 /91; _p_ ( 2 )= 8 /91; _p_ ( 1 )= 32 /91; _p_ ( 0 )= 1 /91; _p_ (− 1 )= 16 /91;
_p_ (− 2 )= 28 / 91 **4.** (a) 1/2; 5/18; 5/36; 5/84; 5/252; 1/252; 0; 0; 0; 0 **5.** _n_ − 2 _i_ ;

```
457
```

**458** Answers to Selected Problems

```
i =0,..., n 6. p ( 3 )= p (− 3 )= 1 /8; p ( 1 )= p (− 1 )= 3 / 8 12. p ( 4 )= 1 /16;
p ( 3 )= 1 /8; p ( 2 )= 1 /16; p ( 0 )= 1 /2; p (− i )= p ( i ); p ( 0 )= 1 13. p ( 0 )=.28;
p ( 500 )=.27, p ( 1000 )=.315; p ( 1500 )=.09; p ( 2000 )=. 045 14. p ( 0 )= 1 /2;
p ( 1 )= 1 /6; p ( 2 )= 1 /12; p ( 3 )= 1 /20; p ( 4 )= 1 / 5 17. 1/4; 1/6; 1/12; 1/2 19. 1/2;
1/10; 1/5; 1/10; 1/10 20. .5918; no;−. 108 21. 39.28; 37 24. p = 11 /18;
maximum= 23 / 72 25. .46, 1.3 26. 11/2; 17/5 27. A ( p + 1 / 10 ) 28. 3/5
```
**31.** _p_ ∗ **32.** 11 − 10 (. 9 )^10 **33.** 3 **35.** −. 067 ; 1. 089 **37.** 82.2; 84.5 **39.** 3/8
**40.** 11/243 **42.** _p_ Ú 1 / 2 **45.** 3 **50.** 1/10; 1/10 **51.** _e_ −.^2 ;1− 1. 2 _e_ −.^2
**53.** 1 − _e_ −.^6 ;1− _e_ −^219.^18 **56.** 253 **57.** .5768; .6070 **59.** .3935; .3033; .0902
**60.** .8886 **61.** .4082 **63.** .0821; .2424 **65.** .3935; .2293; .3935 **66.** 2 /( 2 _n_ − 1 );
2 /( 2 _n_ − 2 ); _e_ −^1 **67.** 2 / _n_ ;( 2 _n_ − 3 )/( _n_ − 1 )^2 ; _e_ −^2 **68.** _e_ −^10 _e_

```
− 5
```
**70.** _p_ +( 1 − _p_ ) _e_ −λ _t_ **71.** .1500; .1012 **73.** 5.8125 **74.** 32/243; 4864/6561;
160/729; 160/729 **78.** 18 ( 17 ) _n_ −^1 /( 35 ) _n_ **81.** 3/10; 5/6; 75/138
**82.** .3439 **83.** 1.5

##### CHAPTER 5

**2.** 3. 5 _e_ −^5 /^2 **3.** no; no **4.** 1/2 **5.** 1 −(. 01 )^1 /^5 **6.** 4, 0,q **7.** 3/5; 6/5 **8.** 2
**10.** 2/3; 2/3 **11.** 2/5 **13.** 2/3; 1/3 **15.** .7977; .6827; .3695; .9522; .1587
**16.** (. 9938 )^10 **18.** 22.66 **19.** 14.56 **20.** .9994; .75; .977 **22.** 9.5; .0019
**23.** .9258; .1762 **26.** .0606; .0525 **28.** .8363 **29.** .9993 **32.** _e_ −^1 ; _e_ −^1 /^2
**34.** _e_ −^1 ; 1 / 3 **38.** 3/5 **40.** 1/ _y_

##### CHAPTER 6

**2.** (a) 14/39; 10/39; 10/39; 5/39 (b) 84; 70; 70; 70; 40; 40; 40; 15 all divided by 429
**3.** 15/26; 5/26; 5/26; 1/26 **4.** 25/169; 40/169; 40/169; 64/169 **7.** _p_ ( _i_ , _j_ )= _p_^2 ( 1 − _p_ ) _i_ + _j_
**8.** _c_ = 1 /8; _E_ [ _X_ ]= 0 **9.** ( 12 _x_^2 + 6 _x_ )/ 7 ; 15 / 56 ;. 8625 ; 5 / 7 ; 8 / 7 **10.** 1 / 2 ; 1 − _e_ − _a_
**11.** .1458 **12.** 39. 3 _e_ −^5 **13.** 1/6; 1/2 **15.** π/ 4 **16.** _n_ ( 1 / 2 ) _n_ −^1 **17.** 1/3 **18.** 7/9
**19.** 1/2 **21.** 2/5; 2/5 **22.** no; 1/3 **23.** 1/2; 2/3; 1/20; 1/18 **25.** _e_ −^1 / _i_! **28.**^12 _e_ − _t_ ;
1 − 3 _e_ −^2 **29.** .0326 **30.** .3772; .2061 **31.** .0829; .3766 **32.** e−^2 ;1− 3 _e_ −^2
**35.** 5/13; 8/13 **36.** 1/6; 5/6; 1/4; 3/4 **41.** ( _y_ + 1 )^2 _xe_ − _x_ ( _y_ +^1 ); _xe_ − _xy_ ; _e_ − _x_
**42.** 1 / 2 + 3 _y_ /( 4 _x_ )− _y_^3 /( 4 _x_^3 ) **46.** ( 1 − 2 _d_ / _L_ )^3 **47.** .79297 **48.** 1 − _e_ −^5 λ _a_ ;
( 1 − _e_ −λ _a_ )^5 **52.** _r_ /π **53.** _r_ **56.** (a) _u_ /(ν+ 1 )^2

##### CHAPTER 7

##### 1. 52.5/12 2. 324; 199.6 3. 1/2; 1/4; 0 4. 1/6; 1/4; 1/2 5. 3/2 6. 35 7. .9; 4.9;

```
4.2 8. ( 1 −( 1 − p ) N )/ p 10. .6; 0 11. 2 ( n − 1 ) p ( 1 − p )
```
**12.** ( 3 _n_^2 − _n_ )/( 4 _n_ − 2 ),3 _n_^2 /( 4 _n_ − 2 ) **14.** _m_ /( 1 − _p_ ) **15.** 1/2 **18.** 4
**21.** .9301; 87.5755 **22.** 14.7 **23.** 147/110 **26.** _n_ /( _n_ + 1 );1/( _n_ + 1 ) **29.**^43735 ; 12;
4;^12335 **31.** 175/6 **33.** 14 **34.** 20/19; 360/361 **35.** 21.2; 18.929; 49.214
**36.** − _n_ / 36 **37.** 0 **38.** 1/8 **41.** 6; 112/33 **42.** 100/19; 16,200/6137; 10/19;
3240/6137 **45.** 1/2; 0 **47.** 1 /( _n_ − 1 ) **48.** 6; 7; 5.8192 **49.** 6.06 **50.** 2 _y_^2
**51.** _y_^3 / 4 **53.** 12 **54.** 8 **56.** _N_ ( 1 − _e_ −^10 / _N_ ) **57.** 12.5 **63.** − 96 / 145 **65.** 5.16
**66.** 218 **67.** _x_ [1+( 2 _p_ − 1 )^2 ] _n_ **69.** 1/2; 1/16; 2/81 **70.** 1/2, 1/3
**72.** 1 / _i_ ;[ _i_ ( _i_ + 1 )]−^1 ;q **73.** μ; 1 +σ^2 ; yes;σ^2
**79.** .176; .141


```
Answers to Selected Problems 459
```
**CHAPTER 8**

**1.** Ú19/20 **2.** 15/17;Ú3/4;Ú 10 **3.** Ú 3 **4.** ...4/3; .8428 **5.** .1416 **6.** .9431
**7.** .3085 **8.** .6932 **9.** ( 327 )^2 **10.** 117 **11.** Ú.057 **13.** .0162; .0003;
.2514; .2514 **14.** _n_ Ú 23 **16.** .013; .018; .691 **18.** ....2 **23.** .769; .357;
.4267; .1093; .112184

##### CHAPTER 9

**1.** 1/9; 5/9 **3.** .9735; .9098; .7358; .5578 **10.** (b) 1/6 **14.** 2.585; .5417; 3.1267
**15.** 5.5098


_This page intentionally left blank_


### Solutions to Self-Test Problems and Exercises

##### CHAPTER 1

```
1.1. (a) There are 4! different orderings of the letters C, D, E, F. For each of these
orderings, we can obtain an ordering with A and B next to each other by
inserting A and B, either in the order A, B or in the order B, A, in any
of 5 places, namely, either before the first letter of the permutation of
C, D, E, F, or between the first and second, and so on. Hence, there are
2 · 5 ·4!=240 arrangements. Another way of solving this problem is
to imagine that B is glued to the back of A. Then there are 5! orderings
in which A is immediately before B. Since there are also 5! orderings in
which B is immediately before A, we again obtain a total of 2·5!= 240
different arrangements.
(b) There are 6!=720 possible arrangements, and since there are as many
with A before B as with B before A, there are 360 arrangements.
(c) Of the 720 possible arrangements, there are as many that have A before
B before C as have any of the 3! possible orderings of A, B, and C. Hence,
there are 720/ 6 =120 possible orderings.
(d) Of the 360 arrangements that have A before B, half will have C before D
and half D before C. Hence, there are 180 arrangements having A before
B and C before D.
(e) Gluing B to the back of A and D to the back of C yields 4!=24 different
orderings in which B immediately follows A and D immediately follows
C. Since the order of A and B and of C and D can be reversed, there are
4 · 24 =96 different arrangements.
(f) There are 5! orderings in which E is last. Hence, there are 6!−5!= 600
orderings in which E is not last.
1.2. 3! 4! 3! 3!, since there are 3! possible orderings of countries and then the coun-
trymen must be ordered.
1.3. (a) 10 · 9 · 8 = 720
(b) 8 · 7 · 6 + 2 · 3 · 8 · 7 =672. The result of part (b) follows because
there are 8· 7 ·6 choices not including A or B and there are 3· 8 · 7
choices in which a specified one of A and B, but not the other, serves. The
latter follows because the serving member of the pair can be assigned to
any of the 3 offices, the next position can then be filled by any of the other
8 people, and the final position by any of the remaining 7.
(c) 8 · 7 · 6 + 3 · 2 · 8 =384.
(d) 3 · 9 · 8 =216.
(e) 9 · 8 · 7 + 9 · 8 =576.
```
```
461
```

**462** Solutions to Self-Test Problems and Exercises

```
1.4. (a)
```
##### (

##### 10

##### 7

##### )

```
(b)
```
##### (

##### 5

##### 3

##### )(

##### 5

##### 4

##### )

##### +

##### (

##### 5

##### 4

##### )(

##### 5

##### 3

##### )

##### +

##### (

##### 5

##### 5

##### )(

##### 5

##### 2

##### )

##### 1.5.

##### (

##### 7

##### 3, 2, 2

##### )

##### = 210

```
1.6. There are
```
##### (

##### 7

##### 3

##### )

```
=35 choices of the three places for the letters. For each choice,
```
```
there are( 26 )^3 ( 10 )^4 different license plates. Hence, altogether there are 35·
( 26 )^3 ·( 10 )^4 different plates.
1.7. Any choice of r of the n items is equivalent to a choice of n − r , namely, those
items not selected.
1.8. (a) 10 · 9 · 9 ··· 9 = 10 · 9 n −^1
(b)
```
##### (

```
n
i
```
##### )

```
9 n − i , since there are
```
##### (

```
n
i
```
##### )

```
choices of the i places to put the zeroes and
then each of the other n − i positions can be any of the digits 1,...,9.
```
```
1.9. (a)
```
##### (

```
3 n
3
```
##### )

```
(b) 3
```
##### (

```
n
3
```
##### )

```
(c)
```
##### (

##### 3

##### 1

##### )(

##### 2

##### 1

##### )(

```
n
2
```
##### )(

```
n
1
```
##### )

```
= 3 n^2 ( n − 1 )
```
```
(d) n^3
(e)
```
##### (

```
3 n
3
```
##### )

##### = 3

##### (

```
n
3
```
##### )

```
+ 3 n^2 ( n − 1 )+ n^3
```
```
1.10. There are 9( · 8 · 7 · 6 ·5 numbers in which no digit is repeated. There are
5
2
```
##### )

```
· 8 · 7 ·6 numbers in which only one specified digit appears twice, so
```
```
there are 9
```
##### (

##### 5

##### 2

##### )

```
· 8 · 7 ·6 numbers in which only a single digit appears twice.
```
```
There are 7·2!2!5! numbers in which two specified digits appear twice, so there
```
```
are
```
##### (

##### 9

##### 2

##### )

```
7 ·2!2!5! numbers in which two digits appear twice. Thus, the answer is
```
##### 9 · 8 · 7 · 6 · 5 + 9

##### (

##### 5

##### 2

##### )

##### · 8 · 7 · 6 +

##### (

##### 9

##### 2

##### )

##### 7 ·

##### 5!

##### 2!2!

```
1.11. (a) We can regard this as a seven-stage experiment. First choose the 6 mar-
ried couples that have a representative in the group, and then select one of
the members of each of these couples. By the generalized basic principle
of counting, there are
```
##### ( 10

```
6
```
##### )

```
26 different choices.
(b) First select the 6 married couples that have a representative in the group,
and then select the 3 of those couples that are to contribute a man. Hence,
there are
```
##### ( 10

```
6
```
##### )( 6

```
3
```
##### )

```
=4!3!3!10! different choices. Another way to solve this is
to first select 3 men and then select 3 women not related to the selected
men. This shows that there are
```
##### ( 10

```
3
```
##### )( 7

```
3
```
##### )

```
=3!3!4!10! different choices.
```

```
Solutions to Self-Test Problems and Exercises 463
```
##### 1.12.

##### (

##### 8

##### 3

##### )(

##### 7

##### 3

##### )

##### +

##### (

##### 8

##### 4

##### )(

##### 7

##### 2

##### )

=3430. The first term gives the number of committees
that have 3 women and 3 men; the second gives the number that have 4 women
and 2 men.
**1.13.** (number of solutions of _x_ 1 + ··· + _x_ 5 = 4 )(number of solutions of _x_ 1 + ··· +

```
x 5 = 5 )(number of solutions of x 1 + ··· + x 5 = 6 )=
```
##### (

##### 8

##### 4

##### )(

##### 9

##### 4

##### )(

##### 10

##### 4

##### )

##### .

**1.14.** Since there are

##### (

```
j − 1
n − 1
```
##### )

```
positive vectors whose sum is j , there must be
```
```
∑ k
j = n
```
##### (

```
j − 1
n − 1
```
##### )

```
such vectors. But
```
##### (

```
j − 1
n − 1
```
##### )

```
is the number of subsets of size n
```
```
from the set of numbers{1,..., k }in which j is the largest element in the sub-
```
```
set. Consequently,
```
```
∑ k
j = n
```
##### (

```
j − 1
n − 1
```
##### )

```
is just the total number of subsets of size n
```
```
from a set of size k , showing that the preceding answer is equal to
```
##### (

```
k
n
```
##### )

##### .

**1.15.** Let us first determine the number of different results in which _k_ people pass.

```
Because there are
```
##### (

```
n
k
```
##### )

```
different groups of size k and k! possible orderings of
```
```
their scores, it follows that there are
```
##### (

```
n
k
```
##### )

```
k! possible results in which k people
```
```
pass. Consequently, there are
```
```
∑ n
k = 0
```
##### (

```
n
k
```
##### )

```
k! possible results.
```
**1.16.** The number of subsets of size 4 is

##### ( 20

```
4
```
##### )

```
=4845. Because the number of these
that contain none of the first five elements is
```
##### ( 15

```
4
```
##### )

```
=1365, the number that
contain at least one is 3480.Another way to solve this problem is to note that
there are
```
##### ( 5

```
i
```
##### )( 15

```
4 − i
```
##### )

that contain exactly _i_ of the first five elements and sum this
for _i_ =1, 2, 3, 4.
**1.17.** Multiplying both sides by 2, we must show that

```
n ( n − 1 )= k ( k − 1 )+ 2 k ( n − k )+( n − k )( n − k − 1 )
```
```
This follows because the right side is equal to
```
```
k^2 ( 1 − 2 + 1 )+ k (− 1 + 2 n − n − n + 1 )+ n ( n − 1 )
```
```
For a combinatorial argument, consider a group of n items and a subgroup
of k of the n items. Then
```
```
( k
2
```
##### )

```
is the number of subsets of size 2 that contain
2 items from the subgroup of size k , k ( n − k )is the number that contain 1
item from the subgroup, and
```
```
( n − k
2
```
##### )

```
is the number that contain 0 items from the
subgroup. Adding these terms gives the total number of subgroups of size 2,
namely,
```
```
( n
2
```
##### )

##### .

**1.18.** There are 3 choices that can be made from families consisting of a single parent
and 1 child; there are 3 · 1 · 2 =6 choices that can be made from families
consisting of a single parent and 2 children; there are 5· 2 · 1 =10 choices
that can be made from families consisting of 2 parents and a single child; there
are 7· 2 · 2 =28 choices that can be made from families consisting of 2 parents
and 2 children; there are 6· 2 · 3 =36 choices that can be made from families
consisting of 2 parents and 3 children. Hence, there are 80 possible choices.


**464** Solutions to Self-Test Problems and Exercises

```
1.19. First choose the 3 positions for the digits, and then put in the letters and digits.
Thus, there are
```
##### ( 8

```
3
```
##### )

```
· 26 · 25 · 24 · 23 · 22 · 10 · 9 ·8 different plates. If the
digits must be consecutive, then there are 6 possible positions for the digits,
showing that there are now 6· 26 · 25 · 24 · 23 · 22 · 10 · 9 ·8 different
plates.
```
##### CHAPTER 2

```
2.1. (a) 2 · 3 · 4 = 24
(b) 2 · 3 = 6
(c) 3 · 4 = 12
(d) AB ={( c , pasta, i ),( c , rice, i ),( c , potatoes, i )}
(e) 8
(f) ABC ={( c , rice, i )}
2.2. Let A be the event that a suit is purchased, B be the event that a shirt is pur-
chased, and C be the event that a tie is purchased. Then
```
```
P ( A ∪ B ∪ C )=. 22 +. 30 +. 28 −. 11 −. 14 −. 10 +. 06 =. 51
```
```
(a) 1 −. 51 =. 49
(b) The probability that two or more items are purchased is
```
```
P ( AB ∪ AC ∪ BC )=. 11 +. 14 +. 10 −. 06 −. 06 −. 06 +. 06 =. 23
```
```
Hence, the probability that exactly 1 item is purchased is. 51 −. 23 =.28.
2.3. By symmetry, the 14th card is equally likely to be any of the 52 cards; thus, the
probability is 4/52. A more formal argument is to count the number of the 52!
outcomes for which the 14th card is an ace. This yields
```
```
p =
```
##### 4 · 51 · 50 ··· 2 · 1

##### ( 52 )!

##### =

##### 4

##### 52

```
Letting A be the event that the first ace occurs on the 14th card, we have
```
##### P ( A )=

##### 48 · 47 ··· 36 · 4

##### 52 · 51 ··· 40 · 39

##### =. 0312

```
2.4. Let D denote the event that the minimum temperature is 70 degrees. Then
```
```
P ( A ∪ B )= P ( A )+ P ( B )− P ( AB )=. 7 − P ( AB )
P ( C ∪ D )= P ( C )+ P ( D )− P ( CD )=. 2 + P ( D )− P ( DC )
```
```
Since A ∪ B = C ∪ D and AB = CD , subtracting one of the preceding
equations from the other yields
```
```
0 =. 5 − P ( D )
```
```
or P ( D )=.5.
```
```
2.5. (a)
```
##### 52 · 48 · 44 · 40

##### 52 · 51 · 50 · 49

##### =. 6761

```
(b)
```
##### 52 · 39 · 26 · 13

##### 52 · 51 · 50 · 49

##### =. 1055


```
Solutions to Self-Test Problems and Exercises 465
```
```
2.6. Let R be the event that both balls are red, and let B be the event that both are
black. Then
```
##### P ( R ∪ B )= P ( R )+ P ( B )=

##### 3 · 4

##### 6 · 10

##### +

##### 3 · 6

##### 6 · 10

##### = 1 / 2

```
2.7. (a) ⎛^1
⎝^40
8
```
```
⎞
⎠
```
##### = 1. 3 * 10 −^8

```
(b)
```
```
⎛
⎝^8
7
```
```
⎞
⎠
```
```
⎛
⎝^32
1
```
```
⎞
⎠
⎛
⎝^40
8
```
```
⎞
⎠
```
##### = 3. 3 * 10 −^6

```
(c)
```
```
⎛
⎝^8
6
```
```
⎞
⎠
```
```
⎛
⎝^32
2
```
```
⎞
⎠
⎛
⎝^40
8
```
```
⎞
⎠
```
##### + 1. 3 * 10 −^8 + 3. 3 * 10 −^6 = 1. 8 * 10 −^4

```
2.8. (a)
```
##### 3 · 4 · 4 · 3

##### (

##### 14

##### 4

##### ) =. 1439

```
(b)
```
```
⎛
⎝^4
2
```
```
⎞
⎠
```
```
⎛
⎝^4
2
```
```
⎞
⎠
⎛
⎝^14
4
```
```
⎞
⎠
```
##### =. 0360

```
(c)
```
```
⎛
⎝^8
4
```
```
⎞
⎠
⎛
⎝^14
4
```
```
⎞
⎠
```
##### =. 0699

```
2.9. Let S =
```
```
⋃ n
i = 1
```
```
Ai , and consider the experiment of randomly choosing an element
```
```
of S. Then P ( A )= N ( A )/ N ( S ), and the results follow from Propositions 4.3
and 4.4.
```
**2.10.** Since there are 5!= 120 outcomes in which the position of horse number
1 is specified, it follows that _N_ ( _A_ ) = 360. Similarly, _N_ ( _B_ ) = 120, and
_N_ ( _AB_ ) = 2 · 4! = 48. Hence, from Self-Test Problem 9, we obtain
_N_ ( _A_ ∪ _B_ )=432.

**2.11.** One way to solve this problem is to start with the complementary probability
that at least one suit does not appear. Let _Ai_ , _i_ =1, 2, 3, 4, be the event that no
cards from suit _i_ appear. Then

##### P

##### ⎛

##### ⎝

##### ⋃^4

```
i = 1
```
```
Ai
```
##### ⎞

##### ⎠=

##### ∑

```
i
```
```
P ( Ai )−
```
##### ∑

```
j
```
##### ∑

```
i : i < j
```
```
P ( AiAj )+ ··· − P ( A 1 A 2 A 3 A 4 )
```

**466** Solutions to Self-Test Problems and Exercises

##### = 4

##### (

##### 39

##### 5

##### )

##### (

##### 52

##### 5

##### ) −

##### (

##### 4

##### 2

##### )

##### (

##### 26

##### 5

##### )

##### (

##### 52

##### 5

##### ) +

##### (

##### 4

##### 3

##### )

##### (

##### 13

##### 5

##### )

##### (

##### 52

##### 5

##### )

##### = 4

##### (

##### 39

##### 5

##### )

##### (

##### 52

##### 5

##### ) − 6

##### (

##### 26

##### 5

##### )

##### (

##### 52

##### 5

##### )+ 4

##### (

##### 13

##### 5

##### )

##### (

##### 52

##### 5

##### )

```
The desired probability is then 1 minus the preceding. Another way to solve is
to let A be the event that all 4 suits are represented, and then use
```
```
P ( A )= P ( n , n , n , n , o )+ P ( n , n , n , o , n )+ P ( n , n , o , n , n )+ P ( n , o , n , n , n )
```
```
where P ( n , n , n , o , n ), for instance, is the probability that the first card is from a
new suit, the second is from a new suit, the third is from a new suit, the fourth
is from an old suit (that is, one which has already appeared) and the fifth is
from a new suit. This gives
```
##### P ( A )=

##### 52 · 39 · 26 · 13 · 48 + 52 · 39 · 26 · 36 · 13

##### 52 · 51 · 50 · 49 · 48

##### +

##### 52 · 39 · 24 · 26 · 13 + 52 · 12 · 39 · 26 · 13

##### 52 · 51 · 50 · 49 · 48

##### =

##### 52 · 39 · 26 · 13 ( 48 + 36 + 24 + 12 )

##### 52 · 51 · 50 · 49 · 48

##### =. 2637

```
2.12. There are( 10 )!/ 25 different divisions of the 10 players into a first roommate
pair, a second roommate pair, and so on. Hence, there are( 10 )!/(5!2^5 )divi-
sions into 5 roommate pairs. There are
```
##### (

##### 6

##### 2

##### )(

##### 4

##### 2

##### )

```
ways of choosing the front-
court and backcourt players to be in the mixed roommate pairs and then
2 ways of pairing them up. As there is then 1 way to pair up the
remaining two backcourt players and 4!/(2!2^2 ) = 3 ways of making two
roommate pairs from the remaining four frontcourt players, the desired
probability is
```
```
P {2 mixed pairs}=
```
##### (

##### 6

##### 2

##### )(

##### 4

##### 2

##### )

##### ( 2 )( 3 )

##### ( 10 )!/(5!2^5 )

##### =. 5714

```
2.13. Let R denote the event that letter R is repeated; similarly, define the events E
and V. Then
```
```
P {same letter}= P ( R )+ P ( E )+ P ( V )=
```
##### 2

##### 7

##### 1

##### 8

##### +

##### 3

##### 7

##### 1

##### 8

##### +

##### 1

##### 7

##### 1

##### 8

##### =

##### 3

##### 28


```
Solutions to Self-Test Problems and Exercises 467
```
**2.14.** Let _B_ 1 = _A_ 1 , _Bi_ = _Ai_

##### ⎛

##### ⎝

```
i ⋃− 1
```
```
j = 1
```
```
Aj
```
##### ⎞

##### ⎠

```
c
```
```
, i >1. Then
```
##### P

##### ⎛

##### ⎝

```
⋃q
```
```
i = 1
```
```
Ai
```
##### ⎞

##### ⎠= P

##### ⎛

##### ⎝

```
⋃q
```
```
i = 1
```
```
Bi
```
##### ⎞

##### ⎠

##### =

```
∑q
```
```
i = 1
```
```
P ( Bi )
```
##### ...

```
∑q
```
```
i = 1
```
```
P ( Ai )
```
where the final equality uses the fact that the _Bi_ are mutually exclusive. The
inequality then follows, since _Bi_ ( _Ai_.
**2.15.**

##### P

##### ⎛

##### ⎝

```
⋂q
```
```
i = 1
```
```
Ai
```
##### ⎞

##### ⎠= 1 − P

##### ⎛

##### ⎜

##### ⎝

##### ⎛

##### ⎝

```
⋂q
```
```
i = 1
```
```
Ai
```
##### ⎞

##### ⎠

```
c
```
##### ⎞

##### ⎟

##### ⎠

##### = 1 − P

##### ⎛

##### ⎝

```
⋃q
```
```
i = 1
```
```
Aci
```
##### ⎞

##### ⎠

##### Ú 1 −

```
∑q
```
```
i = 1
```
```
P ( Aci )
```
##### = 1

**2.16.** The number of partitions for which{ 1 }is a subset is equal to the number of
partitions of the remaining _n_ − 1 elements into _k_ − 1 nonempty subsets,
namely, _Tk_ − 1 ( _n_ − 1 ). Because there are _Tk_ ( _n_ − 1 )partitions of{2,..., _n_ − 1 }
into _k_ nonempty subsets and then a choice of _k_ of them in which to place
element 1, it follows that there are _kTk_ ( _n_ − 1 )partitions for which{ 1 }is not a
subset. Hence, the result follows.
**2.17.** Let _R_ , _W_ , _B_ denote, respectively, the events that there are no red, no white,
and no blue balls chosen. Then
_P_ ( _R_ ∪ _W_ ∪ _B_ )= _P_ ( _R_ )+ _P_ ( _W_ )+ _P_ ( _B_ )− _P_ ( _RW_ )− _P_ ( _RB_ )
− _P_ ( _WB_ )+ _P_ ( _RWB_ )

##### =

##### (

##### 13

##### 5

##### )

##### (

##### 18

##### 5

##### ) +

##### (

##### 12

##### 5

##### )

##### (

##### 18

##### 5

##### ) +

##### (

##### 11

##### 5

##### )

##### (

##### 18

##### 5

##### ) −

##### (

##### 7

##### 5

##### )

##### (

##### 18

##### 5

##### ) −

##### (

##### 6

##### 5

##### )

##### (

##### 18

##### 5

##### )

##### −

##### (

##### 5

##### 5

##### )

##### (

##### 18

##### 5

##### )

##### L 0. 2933


**468** Solutions to Self-Test Problems and Exercises

```
Thus, the probability that all colors appear in the chosen subset is approxi-
mately 1− 0. 2933 = 0 .7067.
```
```
2.18. (a) 17 ·^816 ·^7 ·· 156 ··^514 ·^4 · 13 = 2212
```
```
(b) Because there are 9 nonblue balls, the probability is 17 ·^916 ·^8 ·· 157 ··^614 ·^5 · 13 = 4429.
(c) Because there are 3! possible orderings of the different colors and all pos-
sibilities for the final 3 balls are equally likely, the probability is
3!· 4 · 8 · 5
17 · 16 · 15 =
```
```
4
17.
(d) The probability that the red balls are in a specified 4 spots is 174 · 16 ·^3 ··^215 ·^1 · 14.
Because there are 14 possible locations of the red balls where they are all
together, the probability is 1714 ·· 164 ··^315 ·^2 ·· 141 = 1701.
```
```
2.19. (a) The probability that the 10 cards consist of 4 spades, 3 hearts, 2 diamonds,
```
```
and 1 club is
```
```
( 13
4
```
```
)( 13
3
```
```
)( 13
2
```
```
)( 13
1
```
```
)
( 52
10
```
```
). Because there are 4! possible choices
```
```
of the suits to have 4, 3, 2, and 1 cards, respectively, it follows that the
```
```
probability is
```
```
24
```
```
( 13
4
```
```
)( 13
3
```
```
)( 13
2
```
```
)( 13
1
```
```
)
( 52
10
```
##### ).

```
(b) Because there are
```
##### (

```
4
2
```
##### )

```
=6 choices of the two suits that are to have 3
cards and then 2 choices for the suit to have 4 cards, the probability is
12
```
```
( 13
3
```
```
)( 13
3
```
```
)( 13
4
```
```
)
(
52
10
```
##### ).

```
2.20. All the red balls are removed before all the blue ones if and only if the very
last ball removed is blue. Because all 30 balls are equally likely to be the last
ball removed, the probability is 10/ 30.
```
##### CHAPTER 3

```
3.1. (a) P (no aces)=
```
##### (

##### 35

##### 13

##### )/(

##### 39

##### 13

##### )

```
(b) 1 − P (no aces)−
```
##### 4

##### (

##### 35

##### 12

##### )

##### (

##### 39

##### 13

##### )

```
(c) P ( i aces)=
```
```
⎛
⎝^3
i
```
```
⎞
⎠
```
```
⎛
⎝^36
13 − i
```
```
⎞
⎠
⎛
⎝^39
13
```
```
⎞
⎠
```
```
3.2. Let Li denote the event that the life of the battery is greater than 10, 000*
i miles.
(a) P ( L 2 | L 1 )= P ( L 1 L 2 )/ P ( L 1 )= P ( L 2 )/ P ( L 1 )= 1 / 2
(b) P ( L 3 | L 1 )= P ( L 1 L 3 )/ P ( L 1 )= P ( L 3 )/ P ( L 1 )= 1 / 8
```
```
3.3. Put 1 white and 0 black balls in urn one, and the remaining 9 white and 10
black balls in urn two.
```

```
Solutions to Self-Test Problems and Exercises 469
```
**3.4.** Let _T_ be the event that the transferred ball is white, and let _W_ be the event
that a white ball is drawn from urn _B_. Then

##### P ( T | W )=

##### P ( W | T ) P ( T )

```
P ( W | T ) P ( T )+ P ( W | Tc ) P ( Tc )
```
```
=
```
##### ( 2 / 7 )( 2 / 3 )

##### ( 2 / 7 )( 2 / 3 )+( 1 / 7 )( 1 / 3 )

##### = 4 / 5

**3.5. (a)** _r_ + _rw_ , because each of the _r_ + _w_ balls is equally likely to be the _i_ th ball
removed.
**(b), (c)**

```
P ( Rj | Ri )=
```
```
P ( RiRj )
P ( Ri )
```
##### =

```
( r 2 )
( r + 2 w )
r
r + w
=
```
```
r − 1
r + w − 1
```
```
A simpler argument is to note that, for i Z j , given that the i th removal
is a red ball, the j th removal is equally likely to be any of the remaining
r + w −1 balls, of which r −1 are red.
```
**3.6.** Let _Bi_ denote the event that ball _i_ is black, and let _Ri_ = _Bci_. Then

##### P ( B 1 | R 2 )=

##### P ( R 2 | B 1 ) P ( B 1 )

##### P ( R 2 | B 1 ) P ( B 1 )+ P ( R 2 | R 1 ) P ( R 1 )

##### =

```
[ r /[( b + r + c )][ b /( b + r )]
[ r /( b + r + c )][ b /( b + r )]+[( r + c )/( b + r + c )][ r /( b + r )]
```
```
=
```
```
b
b + r + c
```
**3.7.** Let _B_ denote the event that both cards are aces.
**(a)**
_P_ { _B_ |yes to ace of spades}=

```
P { B , yes to ace of spades}
P {yes to ace of spades}
```
##### =

##### (

##### 1

##### 1

##### )(

##### 3

##### 1

##### )

##### (

##### 52

##### 2

##### )

##### /

##### (

##### 1

##### 1

##### )(

##### 51

##### 1

##### )

##### (

##### 52

##### 2

##### )

##### = 3 / 51

```
(b) Since the second card is equally likely to be any of the remaining 51, of
which 3 are aces, we see that the answer in this situation is also 3/51.
(c) Because we can always interchange which card is considered first and
which is considered second, the result should be the same as in part (b).
A more formal argument is as follows:
```

**470** Solutions to Self-Test Problems and Exercises

```
P { B |second is ace}=
```
```
P { B , second is ace}
P {second is ace}
```
```
=
```
##### P ( B )

```
P ( B )+ P {first is not ace, second is ace}
```
```
=
```
##### ( 4 / 52 )( 3 / 51 )

##### ( 4 / 52 )( 3 / 51 )+( 48 / 52 )( 4 / 51 )

##### = 3 / 51

```
(d)
P { B |at least one}=
```
##### P ( B )

```
P {at least one}
```
```
=
```
##### ( 4 / 52 )( 3 / 51 )

##### 1 −( 48 / 52 )( 47 / 51 )

##### = 1 / 33

##### 3.8.

##### P ( H | E )

##### P ( G | E )

##### =

##### P ( HE )

##### P ( GE )

##### =

##### P ( H ) P ( E | H )

##### P ( G ) P ( E | G )

```
Hypothesis H is 1.5 times as likely.
3.9. Let A denote the event that the plant is alive and let W be the event that it was
watered.
(a)
P ( A )= P ( A | W ) P ( W )+ P ( A | Wc ) P ( Wc )
=(. 85 )(. 9 )+(. 2 )(. 1 )=. 785
```
```
(b)
P ( Wc | Ac )=
```
```
P ( Ac | Wc ) P ( Wc )
P ( Ac )
```
```
=
```
##### (. 8 )(. 1 )

##### . 215

##### =

##### 16

##### 43

```
3.10. (a) 1 − P (no red balls)= 1 −
```
```
( 22
6
```
```
)
( 30
6
```
```
)
```
```
(b) Given that no red balls are chosen, the 6 chosen are equally likely to be
any of the 22 nonred balls. Thus,
```
```
P (2 green|no red)=
```
##### (

```
10
2
```
##### )(

```
12
4
```
##### )

##### (

```
22
6
```
##### )

```
3.11. Let W be the event that the battery works, and let C and D denote the events
that the battery is a type C andthatitisatype D battery, respectively.
(a) P ( W )= P ( W | C ) P ( C )+ P ( W | D ) P ( D )=. 7 ( 8 / 14 )+. 4 ( 6 / 14 )= 4 / 7
(b)
```
```
P ( C | Wc )=
```
```
P ( CWc )
P ( Wc )
```
##### =

```
P ( Wc | C ) P ( C )
3 / 7
```
##### =

##### . 3 ( 8 / 14 )

##### 3 / 7

##### =. 4


```
Solutions to Self-Test Problems and Exercises 471
```
**3.12.** Let _Li_ be the event that Maria likes book _i_ , _i_ =1, 2. Then

```
P ( L 2 | Lc 1 )=
```
```
P ( Lc 1 L 2 )
P ( Lc 1 )
```
##### =

```
P ( Lc 1 L 2 )
```
. 4

```
Using that L 2 is the union of the mutually exclusive events L 1 L 2 and Lc 1 L 2 ,we
see that
```
. 5 = _P_ ( _L_ 2 )= _P_ ( _L_ 1 _L_ 2 )+ _P_ ( _Lc_ 1 _L_ 2 )=. 4 + _P_ ( _Lc_ 1 _L_ 2 )

```
Thus,
```
```
P
```
##### (

```
L 2 | Lc 1
```
##### )

##### =

##### . 1

##### . 4

##### =. 25

**3.13. (a)** This is the probability that the last ball removed is blue. Because each of
the 30 balls is equally likely to be the last one removed, the probability is
1 /3.
**(b)** This is the probability that the last red or blue ball to be removed is a blue
ball. Because it is equally likely to be any of the 30 red or blue balls, the
probability that it is blue is 1/3.
**(c)** Let _B_ 1 , _R_ 2 , _G_ 3 denote, respectively, the events that the first color removed
is blue, the second is red, and the third is green. Then

##### P ( B 1 R 2 G 3 )= P ( G 3 ) P ( R 2 | G 3 ) P ( B 1 | R 2 G 3 )=

##### 8

##### 38

##### 20

##### 30

##### =

##### 8

##### 57

```
where P ( G 3 )is just the probability that the very last ball is green and
P ( R 2 | G 3 )is computed by noting that, given that the last ball is green,
each of the 20 red and 10 blue balls is equally likely to be the last of that
group to be removed, so the probability that it is one of the red balls is
20 /30. (Of course, P ( B 1 | R 2 G 3 )= 1 .)
(d) P ( B 1 )= P ( B 1 G 2 R 3 )+ P ( B 1 R 2 G 3 )=^2038188 + 578 = 17164
```
**3.14.** Let _H_ be the event that the coin lands heads, let _Th_ be the event that _B_ is told
that the coin landed heads, let _F_ be the event that _A_ forgets the result of the
toss, and let _C_ be the event that _B_ is told the correct result. Then
**(a)**

```
P ( Th )= P ( Th | F ) P ( F )+ P ( Th | Fc ) P ( Fc )
=(. 5 )(. 4 )+ P ( H )(. 6 )
=. 68
```
```
(b)
```
```
P ( C )= P ( C | F ) P ( F )+ P ( C | Fc ) P ( Fc )
=(. 5 )(. 4 )+ 1 (. 6 )=. 80
```
```
(c)
```
```
P ( H | Th )=
```
```
P ( HTh )
P ( Th )
```

**472** Solutions to Self-Test Problems and Exercises

```
Now,
```
```
P ( HTh )= P ( HTh | F ) P ( F )+ P ( HTh | Fc ) P ( Fc )
= P ( H | F ) P ( Th | HF ) P ( F )+ P ( H ) P ( Fc )
=(. 8 )(. 5 )(. 4 )+(. 8 )(. 6 )=. 64
```
```
giving the result P ( H | Th )=. 64 /. 68 = 16 / 17.
3.15. Since the black rat has a brown sibling, we can conclude that both of its parents
have one black and one brown gene.
(a)
P (2 black|at least one)=
```
##### P ( 2 )

```
P (at least one)
```
##### =

##### 1 / 4

##### 3 / 4

##### =

##### 1

##### 3

```
(b) Let F be the event that all 5 offspring are black, let B 2 be the event that
the black rat has 2 black genes, and let B 1 be the event that it has 1 black
and 1 brown gene. Then
```
##### P ( B 2 | F )=

##### P ( F | B 2 ) P ( B 2 )

##### P ( F | B 2 ) P ( B 2 )+ P ( F | B 1 ) P ( B 1 )

##### =

##### ( 1 )( 1 / 3 )

##### ( 1 )( 1 / 3 )+( 1 / 2 )^5 ( 2 / 3 )

##### =

##### 16

##### 17

```
3.16. Let F be the event that a current flows from A to B , and let Ci be the event
that relay i closes. Then
```
```
P ( F )= P ( F | C 1 ) p 1 + P ( F | Cc 1 )( 1 − p 1 )
```
```
Now,
```
```
P ( F | C 1 )= P ( C 4 ∪ C 2 C 5 )
= P ( C 4 )+ P ( C 2 C 5 )− P ( C 4 C 2 C 5 )
= p 4 + p 2 p 5 − p 4 p 2 p 5
```
```
Also,
```
```
P ( F | Cc 1 )= P ( C 2 C 5 ∪ C 2 C 3 C 4 )
= p 2 p 5 + p 2 p 3 p 4 − p 2 p 3 p 4 p 5
```
```
Hence, for part (a), we obtain
```
```
P ( F )= p 1 ( p 4 + p 2 p 5 − p 4 p 2 p 5 )+( 1 − p 1 ) p 2 ( p 5 + p 3 p 4 − p 3 p 4 p 5 )
```
```
For part (b), let qi = 1 − pi. Then
```
```
P ( C 3 | F )= P ( F | C 3 ) P ( C 3 )/ P ( F )
= p 3 [1− P ( C 1 cC 2 c ∪ Cc 4 Cc 5 )]/ P ( F )
= p 3 ( 1 − q 1 q 2 − q 4 q 5 + q 1 q 2 q 4 q 5 )/ P ( F )
```
```
3.17. Let A be the event that component 1 is working, and let F be the event that
the system functions.
(a)
P ( A | F )=
```
##### P ( AF )

##### P ( F )

##### =

##### P ( A )

##### P ( F )

##### =

##### 1 / 2

##### 1 −( 1 / 2 )^2

##### =

##### 2

##### 3


```
Solutions to Self-Test Problems and Exercises 473
```
```
where P ( F )was computed by noting that it is equal to 1 minus the prob-
ability that components 1 and 2 are both failed.
(b)
```
```
P ( A | F )=
```
##### P ( AF )

##### P ( F )

##### =

##### P ( F | A ) P ( A )

##### P ( F )

##### =

##### ( 3 / 4 )( 1 / 2 )

##### ( 1 / 2 )^3 + 3 ( 1 / 2 )^3

##### =

##### 3

##### 4

where _P_ ( _F_ )was computed by noting that it is equal to the probability that
all 3 components work plus the three probabilities relating to exactly 2 of
the components working.
**3.18.** If we assume that the outcomes of the successive spins are independent, then
the conditional probability of the next outcome is unchanged by the result that
the previous 10 spins landed on black.
**3.19.** Condition on the outcome of the initial tosses:

```
P ( A odd)= P 1 ( 1 − P 2 )( 1 − P 3 )+( 1 − P 1 ) P 2 P 3 + P 1 P 2 P 3 ( A odd)
+( 1 − P 1 )( 1 − P 2 )( 1 − P 3 ) P ( A odd)
```
```
so,
P ( A odd)=
```
##### P 1 ( 1 − P 2 )( 1 − P 3 )+( 1 − P 1 ) P 2 P 3

##### P 1 + P 2 + P 3 − P 1 P 2 − P 1 P 3 − P 2 P 3

**3.20.** Let _A_ and _B_ be the events that the first trial is larger and that the second is
larger, respectively. Also, let _E_ be the event that the results of the trials are
equal. Then
1 = _P_ ( _A_ )+ _P_ ( _B_ )+ _P_ ( _E_ )

```
But, by symmetry, P ( A )= P ( B ): thus,
```
##### P ( B )=

##### 1 − P ( E )

##### 2

##### =

##### 1 −

```
∑ n
```
```
i = 1
```
```
p^2 i
```
##### 2

```
Another way of solving the problem is to note that
```
```
P ( B )=
```
##### ∑

```
i
```
##### ∑

```
j > i
```
```
P {first trial results in i , second trial results in j }
```
##### =

##### ∑

```
i
```
##### ∑

```
j > i
```
```
pipj
```
```
To see that the two expressions derived for P ( B )are equal, observe that
```
##### 1 =

```
∑ n
```
```
i = 1
```
```
pi
```
```
∑ n
```
```
j = 1
```
```
pj
```
##### =

##### ∑

```
i
```
##### ∑

```
j
```
```
pipj
```
##### =

##### ∑

```
i
```
```
p^2 i +
```
##### ∑

```
i
```
##### ∑

```
j Z i
```
```
pipj
```
##### =

##### ∑

```
i
```
```
p^2 i + 2
```
##### ∑

```
i
```
##### ∑

```
j > i
```
```
pipj
```

**474** Solutions to Self-Test Problems and Exercises

```
3.21. Let E ={ A gets more heads than B };then
```
```
P ( E )= P ( E | A leads after both flip n ) P ( A leads after both flip n )
+ P ( E |even after both flip n ) P (even after both flip n )
+ P ( E | B leads after both flip n ) P ( B leads after both flip n )
```
```
= P ( A leads)+
```
##### 1

##### 2

```
P (even)
```
```
Now, by symmetry,
```
```
P ( A leads)= P ( B leads)
```
```
=
```
```
1 − P (even)
2
Hence,
P ( E )=
```
##### 1

##### 2

```
3.22. (a) Not true: In rolling 2 dice, let E ={sumis7}, F ={1st die does not land on 4},
and G ={2nd die does not land on 3}. Then
```
##### P ( E | F ∪ G )=

```
P {7, not(4, 3)}
P {not(4, 3)}
```
##### =

##### 5 / 36

##### 35 / 36

##### = 5 / 35 Z P ( E )

```
(b)
```
```
P ( E ( F ∪ G ))= P ( EF ∪ EG )
= P ( EF )+ P ( EG ) since EFG =∅
= P ( E )[ P ( F )+ P ( G )]
= P ( E ) P ( F ∪ G ) since FG =∅
```
```
(c)
```
##### P ( G | EF )=

##### P ( EFG )

##### P ( EF )

##### =

##### P ( E ) P ( FG )

##### P ( EF )

```
since E is independent of FG
```
##### =

##### P ( E ) P ( F ) P ( G )

##### P ( E ) P ( F )

```
by independence
```
```
= P ( G ).
```
```
3.23. (a) necessarily false; if they were mutually exclusive, then we would have
```
```
0 = P ( AB )Z P ( A ) P ( B )
```
```
(b) necessarily false; if they were independent, then we would have
```
```
P ( AB )= P ( A ) P ( B )> 0
```
```
(c) necessarily false; if they were mutually exclusive, then we would have
```
```
P ( A ∪ B )= P ( A )+ P ( B )= 1. 2
```
```
(d) possibly true
```

```
Solutions to Self-Test Problems and Exercises 475
```
**3.24.** The probabilities in parts (a), (b), and (c) are.5,(. 8 )^3 =.512, and(. 9 )^7 L.4783,
respectively.

**3.25.** Let _Di_ , _i_ =1, 2, denote the event that radio _i_ is defective. Also, let _A_ and _B_
be the events that the radios were produced at factory _A_ and at factory _B_ ,
respectively. Then

##### P ( D 2 | D 1 )=

##### P ( D 1 D 2 )

##### P ( D 1 )

##### =

##### P ( D 1 D 2 | A ) P ( A )+ P ( D 1 D 2 | B ) P ( B )

##### P ( D 1 | A ) P ( A )+ P ( D 1 | B ) P ( B )

##### =

##### (. 05 )^2 ( 1 / 2 )+(. 01 )^2 ( 1 / 2 )

##### (. 05 )( 1 / 2 )+(. 01 )( 1 / 2 )

##### = 13 / 300

**3.26.** We are given that _P_ ( _AB_ )= _P_ ( _B_ )and must show that this implies that _P_ ( _BcAc_ )=
_P_ ( _Ac_ ). One way is as follows:

```
P ( BcAc )= P (( A ∪ B ) c )
= 1 − P ( A ∪ B )
= 1 − P ( A )− P ( B )+ P ( AB )
= 1 − P ( A )
= P ( Ac )
```
**3.27.** The result is true for _n_ =0. With _Ai_ denoting the event that there are _i_ red
balls in the urn after stage _n_ , assume that

```
P ( Ai )=
```
##### 1

```
n + 1
```
```
, i =1,..., n + 1
```
```
Now let Bj , j =1,..., n +2, denote the event that there are j red balls in the
urnafterstage n +1. Then
```
```
P ( Bj )=
```
```
n ∑+ 1
```
```
i = 1
```
```
P ( Bj | Ai ) P ( Ai )
```
##### =

##### 1

```
n + 1
```
```
n ∑+ 1
```
```
i = 1
```
```
P ( Bj | Ai )
```
##### =

##### 1

```
n + 1
```
```
[ P ( Bj | Aj − 1 )+ P ( Bj | Aj )]
```
```
Because there are n +2 balls in the urn after stage n , it follows that P ( Bj | Aj − 1 )
is the probability that a red ball is chosen when j −1ofthe n +2 balls in the
urn are red and P ( Bj | Aj )is the probability that a red ball is not chosen when j
of the n +2 balls in the urn are red. Consequently,
```
```
P ( Bj | Aj − 1 )=
```
```
j − 1
n + 2
```
```
, P ( Bj | Aj )=
```
```
n + 2 − j
n + 2
```

**476** Solutions to Self-Test Problems and Exercises

```
Substituting these results into the equation for P ( Bj )gives
```
```
P ( Bj )=
```
##### 1

```
n + 1
```
##### [

```
j − 1
n + 2
```
##### +

```
n + 2 − j
n + 2
```
##### ]

##### =

##### 1

```
n + 2
```
```
This completes the induction proof.
```
```
3.28. If Ai is the event that player i receives an ace, then
```
```
P ( Ai )= 1 −
```
##### (

```
2 n − 2
n
```
##### )

##### (

```
2 n
n
```
##### ) = 1 −

##### 1

##### 2

```
n − 1
2 n − 1
```
##### =

```
3 n − 1
4 n − 2
```
```
By arbitrarily numbering the aces and noting that the player who does not
receive ace number one will receive n of the remaining 2 n − 1 cards, we
see that
```
```
P ( A 1 A 2 )=
```
```
n
2 n − 1
```
```
Therefore,
```
```
P ( Ac 2 | A 1 )= 1 − P ( A 2 | A 1 )= 1 −
```
##### P ( A 1 A 2 )

##### P ( A 1 )

##### =

```
n − 1
3 n − 1
```
```
We may regard the card division outcome as the result of two trials, where trial
i , i =1, 2, is said to be a success if ace number i goes to the first player. Because
the locations of the two aces become independent as n goes to infinity, with
each one being equally likely to be given to either player, it follows that the
trials become independent, each being a success with probability 1/2. Hence,
in the limiting case where n →q, the problem becomes one of determining
the conditional probability that two heads result, given that at least one does,
when two fair coins are flipped. Because 3 nn −−^11 converges to 1/3, the answer
agrees with that of Example 2b.
```
```
3.29. (a) For any permutation i 1 ,..., in of 1, 2,..., n , the probability that the suc-
cessive types collected is i 1 ,..., in is pi 1 ··· pin =
```
```
∏ n
i = 1 pi. Consequently,
the desired probability is n!
```
```
∏ n
i = 1 pi.
(b) For i 1 ,..., ik all distinct,
```
```
P ( Ei 1 ··· Eik )=
```
##### (

```
n − k
n
```
```
) n
```
```
which follows because there are no coupons of types i 1 ,..., ik when each
of the n independent selections is one of the other n − k types. It now
follows by the inclusion–exclusion identity that
```
```
P (∪ ni = 1 Ei )=
```
```
∑ n
```
```
k = 1
```
```
(− 1 ) k +^1
```
##### (

```
n
k
```
##### )(

```
n − k
n
```
```
) n
```

```
Solutions to Self-Test Problems and Exercises 477
```
```
Because 1− P (∪ ni = 1 Ei )is the probability that one of each type is obtained,
by part (a) it is equal to nnn !. Substituting this into the preceding equation
gives
```
##### 1 −

```
n!
nn
```
##### =

```
∑ n
```
```
k = 1
```
```
(− 1 ) k +^1
```
##### (

```
n
k
```
##### )(

```
n − k
n
```
```
) n
```
```
or
```
```
n != nn −
```
```
∑ n
```
```
k = 1
```
```
(− 1 ) k +^1
```
##### (

```
n
k
```
##### )

```
( n − k ) n
```
```
or
```
```
n !=
```
```
∑ n
```
```
k = 0
```
```
(− 1 ) k
```
##### (

```
n
k
```
##### )

```
( n − k ) n
```
##### 3.30.

```
P ( E | E ∪ F )= P ( E | F ( E ∪ F )) P ( F | E ∪ F )+ P ( E | Fc ( E ∪ F )) P ( Fc | E ∪ F )
```
```
Using
F ( E ∪ F )= F and Fc ( E ∪ F )= FcE
```
```
gives
```
```
P ( E | E ∪ F )= P ( E | F ) P ( F | E ∪ F )+ P ( E | EFc ) P ( Fc | E ∪ F )
= P ( E | F ) P ( F | E ∪ F )+ P ( Fc | E ∪ F )
Ú P ( E | F ) P ( F | E ∪ F )+ P ( E | F ) P ( Fc | E ∪ F )
= P ( E | F )
```
##### CHAPTER 4

```
4.1. Since the probabilities sum to 1, we must have 4 P { X = 3 }+. 5 =1, implying
that P { X = 0 }=.375, P { X = 3 }=.125. Hence, E [ X ]= 1 (. 3 ) + 2 (. 2 )+
3 (. 125 )= 1 .075.
4.2. The relationship implies that pi = cip 0 , i =1, 2, where pi = P { X = i }. Because
these probabilities sum to 1, it follows that
```
```
p 0 ( 1 + c + c^2 )= 1 * p 0 =
```
##### 1

```
1 + c + c^2
```
```
Hence,
```
```
E [ X ]= p 1 + 2 p 2 =
```
```
c + 2 c^2
1 + c + c^2
```
```
4.3. Let X be the number of flips. Then the probability mass function of X is
```
```
p 2 = p^2 +( 1 − p )^2 , p 3 = 1 − p 2 = 2 p ( 1 − p )
```

**478** Solutions to Self-Test Problems and Exercises

```
Hence,
```
```
E [ X ]= 2 p 2 + 3 p 3 = 2 p 2 + 3 ( 1 − p 2 )= 3 − p^2 −( 1 − p )^2
```
```
4.4. The probability that a randomly chosen family will have i children is ni / m.
Thus,
```
```
E [ X ]=
```
```
∑ r
```
```
i = 1
```
```
ini / m
```
```
Also, since there are ini children in families having i children, it follows that
the probability that a randomly chosen child is from a family with i children is
ini /
```
```
∑ r
i = 1
```
```
ini. Therefore,
```
##### E [ Y ]=

```
∑ r
```
```
i = 1
```
```
i^2 ni
```
```
∑ r
```
```
i = 1
```
```
ini
```
```
Thus, we must show that
∑ r
```
```
i = 1
```
```
i^2 ni
```
```
∑ r
```
```
i = 1
```
```
ini
```
##### Ú

```
∑ r
```
```
i = 1
```
```
ini
```
```
∑ r
```
```
i = 1
```
```
ni
```
```
or, equivalently, that
```
```
∑ r
```
```
j = 1
```
```
nj
```
```
∑ r
```
```
i = 1
```
```
i^2 ni Ú
```
```
∑ r
```
```
i = 1
```
```
ini
```
```
∑ r
```
```
j = 1
```
```
jnj
```
```
or, equivalently, that
```
```
∑ r
```
```
i = 1
```
```
∑ r
```
```
j = 1
```
```
i^2 ninj Ú
```
```
∑ r
```
```
i = 1
```
```
∑ r
```
```
j = 1
```
```
ijninj
```
```
But, for a fixed pair i , j , the coefficient of ninj in the left-side summation of
the preceding inequality is i^2 + j^2 , whereas its coefficient in the right-hand
summation is 2 ij. Hence, it suffices to show that
```
```
i^2 + j^2 Ú 2 ij
```
```
which follows because( i − j )^2 Ú0.
4.5. Let p = P { X = 1 }. Then E [ X ]= p and Var( X )= p ( 1 − p ),so
```
```
p = 3 p ( 1 − p )
```
```
implying that p = 2 /3. Hence, P { X = 0 }= 1 /3.
```

```
Solutions to Self-Test Problems and Exercises 479
```
**4.6.** If you wager _x_ on a bet that wins the amount wagered with probability _p_ and
loses that amount with probability 1− _p_ , then your expected winnings are

```
xp − x ( 1 − p )=( 2 p − 1 ) x
```
```
which is positive (and increasing in x ) if and only if p > 1 /2. Thus, if p ... 1 /2,
one maximizes one’s expected return by wagering 0, and if p > 1 /2, one maxi-
mizes one’s expected return by wagering the maximal possible bet. Therefore,
if the information is that the .6 coin was chosen, then you should bet 10, and if
the information is that the .3 coin was chosen, then you should bet 0. Hence,
your expected payoff is
```
```
1
2
```
##### ( 1. 2 − 1 ) 10 +

##### 1

##### 2

##### 0 − C = 1 − C

```
Since your expected payoff is 0 without the information (because in this case
the probability of winning is^12 (. 6 )+^12 (. 3 )< 1 /2), it follows that if the infor-
mation costs less than 1, then it pays to purchase it.
```
**4.7. (a)** If you turn over the red paper and observe the value _x_ , then your expected
return if you switch to the blue paper is

```
2 x ( 1 / 2 )+ x / 2 ( 1 / 2 )= 5 x / 4 > x
```
```
Thus, it would always be better to switch.
(b) Suppose the philanthropist writes the amount x on the red paper. Then
the amount on the blue paper is either 2 x or x /2. Note that if x / 2 Ú y ,then
the amount on the blue paper will be at least y and will thus be accepted.
Hence, in this case, the reward is equally likely to be either 2 x or x /2, so
```
```
E [ Ry ( x )]= 5 x /4, if x / 2 Ú y
```
```
If x / 2 < y ... 2 x , then the blue paper will be accepted if its value is 2 x and
rejected if it is x /2. Therefore,
```
```
E [ Ry ( x )]= 2 x ( 1 / 2 )+ x ( 1 / 2 )= 3 x /2, if x / 2 < y ... 2 x
```
```
Finally, if 2 x < y , then the blue paper will be rejected. Hence, in this case,
the reward is x ,so
Ry ( x )= x ,if2 x < y
```
```
That is, we have shown that when the amount x is written on the red
paper, the expected return under the y -policy is
```
```
E [ Ry ( x )]=
```
##### ⎧

##### ⎨

##### ⎩

```
x if x < y / 2
3 x /2if y / 2 ... x < 2 y
5 x /4if x Ú 2 y
```
**4.8.** Suppose that _n_ independent trials, each of which results in a success with prob-
ability _p_ , are performed. Then the number of successes will be less than or
equal to _i_ if and only if the number of failures is greater than or equal to _n_ − _i_.
But since each trial is a failure with probability 1− _p_ , it follows that the num-
ber of failures is a binomial random variable with parameters _n_ and 1− _p_.
Hence,


**480** Solutions to Self-Test Problems and Exercises

```
P {Bin( n , p )... i }= P {Bin( n ,1− p )Ú n − i }
= 1 − P {Bin( n ,1− p )... n − i − 1 }
```
```
The final equality follows from the fact that the probability that the number
of failures is greater than or equal to n − i is 1 minus the probability that it is
less than n − i.
```
```
4.9. Since E [ X ]= np ,Var( X )= np ( 1 − p ), we are given that np =6, np ( 1 − p )=
2 .4. Thus, 1− p =.4, or p =.6, n =10. Hence,
```
##### P { X = 5 }=

##### (

##### 10

##### 5

##### )

##### (. 6 )^5 (. 4 )^5

```
4.10. Let Xi , i =1,..., m , denote the number on the i th ball drawn. Then
```
```
P { X ... k }= P { X 1 ... k , X 2 ... k ,..., Xm ... k }
= P { X 1 ... k } P { X 2 ... k }··· P { Xm ... k }
```
```
=
```
##### (

```
k
n
```
```
) m
```
```
Therefore,
```
```
P { X = k }= P { X ... k }− P { X ... k − 1 }=
```
##### (

```
k
n
```
```
) m
−
```
##### (

```
k − 1
n
```
```
) m
```
```
4.11. (a) Given that A wins the first game, it will win the series if, from then on, it
wins 2 games before team B wins 3 games. Thus,
```
```
P { A wins| A wins first}=
```
##### ∑^4

```
i = 2
```
##### (

##### 4

```
i
```
##### )

```
pi ( 1 − p )^4 − i
```
```
(b)
```
```
P { A wins first| A wins}=
```
```
P { A wins| A wins first} P { A wins first}
P { A wins}
```
##### =

##### ∑^4

```
i = 2
```
##### (

##### 4

```
i
```
##### )

```
pi +^1 ( 1 − p )^4 − i
```
##### ∑^5

```
i = 3
```
##### (

##### 5

```
i
```
##### )

```
pi ( 1 − p )^5 − i
```
```
4.12. To obtain the solution, condition on whether the team wins this weekend:
```
##### . 5

##### ∑^4

```
i = 3
```
##### (

##### 4

```
i
```
##### )

```
(. 4 ) i (. 6 )^4 − i +. 5
```
##### ∑^4

```
i = 3
```
##### (

##### 4

```
i
```
##### )

```
(. 7 ) i (. 3 )^4 − i
```

```
Solutions to Self-Test Problems and Exercises 481
```
**4.13.** Let _C_ be the event that the jury makes the correct decision, and let _F_ be the
event that four of the judges agreed. Then

##### P ( C )=

##### ∑^7

```
i = 4
```
##### (

##### 7

```
i
```
##### )

```
(. 7 ) i (. 3 )^7 − i
```
```
Also,
```
##### P ( C | F )=

##### P ( CF )

##### P ( F )

##### =

##### (

```
7
4
```
##### )

##### (. 7 )^4 (. 3 )^3

##### (

```
7
4
```
##### )

##### (. 7 )^4 (. 3 )^3 +

##### (

```
7
3
```
##### )

##### (. 7 )^3 (. 3 )^4

##### =. 7

**4.14.** Assuming that the number of hurricanes can be approximated by a Poisson
random variable, we obtain the solution

```
∑^3
```
```
i = 0
```
```
e −^5.^2 ( 5. 2 ) i / i!
```
##### 4.15.

##### E [ Y ]=

```
∑q
```
```
i = 1
```
```
iP { X = i }/ P { X > 0 }
```
##### = E [ X ]/ P { X > 0 }

##### =

```
λ
1 − e −λ
```
**4.16. (a)** 1 / _n_
**(b)** Let _D_ be the event that girl _i_ and girl _j_ choose different boys. Then

```
P ( GiGj )= P ( GiGj | D ) P ( D )+ P ( GiGj | Dc ) P ( Dc )
=( 1 / n )^2 ( 1 − 1 / n )
```
```
=
```
```
n − 1
n^3
```
```
Therefore,
```
```
P ( Gi | Gj )=
```
```
n − 1
n^2
```
```
(c), (d) Because, when n is large, P ( Gi | Gj )is small and nearly equal to P ( Gi ),
it follows from the Poisson paradigm that the number of couples is
approximately Poisson distributed with mean
```
```
∑ n
i = 1 P ( Gi )= 1. Hence,
P 0 L e −^1 and Pk L e −^1 / k!
(e) To determine the probability that a given set of k girls all are coupled,
condition on whether or not D occurs, where D is the event that they all
choose different boys. This gives
```

**482** Solutions to Self-Test Problems and Exercises

```
P ( Gi 1 ··· Gik )= P ( Gi 1 ··· Gik | D ) P ( D )+ P ( Gi 1 ··· Gik | Dc ) P ( Dc )
= P ( Gi 1 ··· Gik | D ) P ( D )
```
```
=( 1 / n ) k
```
```
n ( n − 1 )···( n − k + 1 )
nk
```
```
=
```
```
n!
( n − k )! n^2 k
```
```
Therefore,
```
```
∑
```
```
i 1 <...< ik
```
```
P ( Gi 1 ··· Gik )=
```
##### (

```
n
k
```
##### )

```
P ( Gi 1 ··· Gik )=
```
```
n! n!
( n − k )!( n − k )! k! n^2 k
```
```
and the inclusion–exclusion identity yields
```
```
1 − P 0 = P (∪ ni = 1 Gi )=
```
```
∑ n
```
```
k = 1
```
```
(− 1 ) k +^1
```
```
n! n!
( n − k )!( n − k )! k! n^2 k
```
```
4.17. (a) Because woman i is equally likely to be paired with any of the remaining
2 n −1 people, P ( Wi )= 2 n^1 − 1
(b) Because, conditional on Wj , woman i is equally likely to be paired with
any of 2 n −3 people, P ( Wi | Wj )= 2 n^1 − 3
(c) When n is large, the number of wives paired with their husbands will
approximately be Poisson with mean
```
```
∑ n
i = 1 P ( Wi )=
```
```
n
2 n − 1 L^1 /2. There-
fore, the probability that there is no such pairing is approximately e −^1 /^2.
(d) It reduces to the match problem.
```
```
4.18. (a)
```
##### (

##### 8

##### 3

##### )

##### ( 9 / 19 )^3 ( 10 / 19 )^5 ( 9 / 19 )=

##### (

##### 8

##### 3

##### )

##### ( 9 / 19 )^4 ( 10 / 19 )^5

```
(b) If W is her final winnings and X is the number of bets she makes, then,
since she would have won 4 bets and lost X −4 bets, it follows that
```
##### W = 20 − 5 ( X − 4 )= 40 − 5 X

```
Hence,
```
##### E [ W ]= 40 − 5 E [ X ]= 40 −5[4/( 9 / 19 )]=− 20 / 9

```
4.19. The probability that a round does not result in an “odd person” is equal to 1/4,
the probability that all three coins land on the same side.
(a) ( 1 / 4 )^2 ( 3 / 4 )= 3 / 64
(b) ( 1 / 4 )^4 = 1 / 256
```

```
Solutions to Self-Test Problems and Exercises 483
```
**4.20.** Let _q_ = 1 − _p_. Then

##### E [1/ X ]=

```
∑q
```
```
i = 1
```
##### 1

```
i
```
```
qi −^1 p
```
##### =

```
p
q
```
```
∑q
```
```
i = 1
```
```
qi / i
```
##### =

```
p
q
```
```
∑q
```
```
i = 1
```
```
∫ q
```
```
0
```
```
xi −^1 dx
```
##### =

```
p
q
```
```
∫ q
```
```
0
```
```
∑q
```
```
i = 1
```
```
xi −^1 dx
```
##### =

```
p
q
```
```
∫ q
```
```
0
```
##### 1

```
1 − x
```
```
dx
```
##### =

```
p
q
```
##### ∫ 1

```
p
```
##### 1

```
y
```
```
dy
```
##### =−

```
p
q
```
```
log( p )
```
**4.21.** Since _Xa_ −− _bb_ will equal 1 with probability _p_ or 0 with probability 1− _p_ , it follows
that it is a Bernoulli random variable with parameter _p_. Because the variance
of such a Bernoulli random variable is _p_ ( 1 − _p_ ), we have

```
p ( 1 − p )=Var
```
##### (

```
X − b
a − b
```
##### )

##### =

##### 1

```
( a − b )^2
```
```
Var( X − b )=
```
##### 1

```
( a − b )^2
```
```
Var( X )
```
```
Hence,
Var( X )=( a − b )^2 p ( 1 − p )
```
**4.22.** Let _X_ denote the number of games that you play and _Y_ the number of games
that you lose.
**(a)** After your fourth game, you will continue to play until you lose. There-
fore, _X_ −4 is a geometric random variable with parameter 1− _p_ ,so

##### E [ X ]= E [4+( X − 4 )]= 4 + E [ X −4]= 4 +

##### 1

```
1 − p
```
```
(b) If we let Z denote the number of losses you have in the first 4 games, then
Z is a binomial random variable with parameters 4 and 1− p. Because
Y = Z +1, we have
```
```
E [ Y ]= E [ Z +1]= E [ Z ]+ 1 = 4 ( 1 − p )+ 1
```
**4.23.** A total of _n_ white balls will be withdrawn before a total of _m_ black balls if
and only if there are at least _n_ white balls in the first _n_ + _m_ −1 withdrawals.
(Compare with _the problem of the points_ , Example 4j of Chapter 3.) With _X_
equal to the number of white balls among the first _n_ + _m_ −1 balls withdrawn,
_X_ is a hypergeometric random variable, and it follows that


**484** Solutions to Self-Test Problems and Exercises

```
P { X Ú n }=
```
```
n +∑ m − 1
```
```
i = n
```
```
P { X = i }=
```
```
n +∑ m − 1
```
```
i = n
```
##### (

##### N

```
i
```
##### )(

##### M

```
n + m − 1 − i
```
##### )

##### (

##### N + M

```
n + m − 1
```
##### )

```
4.24. Because each ball independently goes into urn i with the same probability pi ,it
follows that Xi is a binomial random variable with parameters n =10, p = pi.
First note that Xi + Xj is the number of balls that go into either urn i or
urn j. Then, because each of the 10 balls independently goes into one of these
urns with probability pi + pj , it follows that Xi + Xj is a binomial random
variable with parameters 10 and pi + pj.
By the same logic, X 1 + X 2 + X 3 is a binomial random variable with param-
eters 10 and p 1 + p 2 + p 3. Therefore,
```
##### P { X 1 + X 2 + X 3 = 7 }=

##### (

##### 10

##### 7

##### )

```
( p 1 + p 2 + p 3 )^7 ( p 4 + p 5 )^3
```
```
4.25. Let Xi equal 1 if person i has a match, and let it equal 0 otherwise. Then
```
##### X =

```
∑ n
```
```
i = 1
```
```
Xi
```
```
is the number of matches. Taking expectations gives
```
##### E [ X ]= E [

```
∑ n
```
```
i = 1
```
```
Xi ]=
```
```
∑ n
```
```
i = 1
```
```
E [ Xi ]=
```
```
∑ n
```
```
i = 1
```
```
P { Xi = 1 }=
```
```
∑ n
```
```
i = 1
```
```
1 / n = 1
```
```
where the final equality follows because person i is equally likely to end up
with any of the n hats.
To compute Var( X ), we use Equation (9.1), which states that
```
##### E [ X^2 ]=

```
∑ n
```
```
i = 1
```
```
E [ Xi ] +
```
```
∑ n
```
```
i = 1
```
##### ∑

```
j Z i
```
```
E [ XiXj ]
```
```
Now, for i Z j ,
```
```
E [ XiXj ]= P { Xi =1, Xj = 1 }= P { Xi = 1 } P { Xj = 1 | Xi = 1 }=
```
##### 1

```
n
```
##### 1

```
n − 1
```
```
Hence,
```
##### E [ X^2 ]= 1 +

```
∑ n
```
```
i = 1
```
##### ∑

```
j Z i
```
##### 1

```
n ( n − 1 )
```
```
= 1 + n ( n − 1 )
```
##### 1

```
n ( n − 1 )
```
##### = 2

```
which yields
```
```
Var( X )= 2 − 12 = 1
```

```
Solutions to Self-Test Problems and Exercises 485
```
```
4.26. With q = 1 − p , we have, on the one hand,
```
##### P ( E )=

```
∑q
```
```
i = 1
```
```
P { X = 2 i }
```
##### =

```
∑q
```
```
i = 1
```
```
pq^2 i −^1
```
```
= pq
```
```
∑q
```
```
i = 1
```
```
( q^2 ) i −^1
```
```
= pq
```
##### 1

```
1 − q^2
=
```
```
pq
( 1 − q )( 1 + q )
```
##### =

```
q
1 + q
```
```
On the other hand,
```
```
P ( E )= P ( E | X = 1 ) p + P ( E | X > 1 ) q = qP ( E | X > 1 )
```
```
However, given that the first trial is not a success, the number of trials needed
for a success is 1 plus the geometrically distributed number of additional trials
required. Therefore,
```
```
P ( E | X > 1 )= P ( X +1 is even)= P ( Ec )= 1 − P ( E )
```
```
which yields P ( E )= q /( 1 + q ).
```
##### CHAPTER 5

```
5.1. Let X be the number of minutes played.
(a) P { X > 15 }= 1 − P { X ... 15 }= 1 − 5 (. 025 )=. 875
(b) P { 20 < X < 35 }= 10 (. 05 )+ 5 (. 025 )=. 625
(c) P { X < 30 }= 10 (. 025 )+ 10 (. 05 )=. 75
(d) P { X > 36 }= 4 (. 025 )=. 1
5.2. (a) 1 =
```
##### ∫ 1

```
0 cx
```
```
ndx = c /( n + 1 )* c = n + 1
```
```
(b) P { X > x }=( n + 1 )
```
##### ∫ 1

```
xx
```
```
ndx = xn + 1
```
##### ∣

##### ∣

##### ∣

```
1
x
```
```
= 1 − xn +^1
5.3. First, let us find c by using
```
##### 1 =

##### ∫ 2

```
0
```
```
cx^4 dx = 32 c / 5 * c = 5 / 32
```
```
(a) E [ X ]= 325
```
##### ∫ 2

```
0 x
```
(^5) _dx_ = 5
32
64
6 =^5 /^3
**(b)** _E_ [ _X_^2 ]= 325

##### ∫ 2

```
0 x
```
(^6) _dx_ =^5
32
128
7 =^20 /^7 *Var( _X_ )=^20 /^7 −(^5 /^3 )
(^2) = 5 / 63
**5.4.** Since

##### 1 =

##### ∫ 1

```
0
```
```
( ax + bx^2 ) dx = a / 2 + b / 3
```
##### . 6 =

##### ∫ 1

```
0
```
```
( ax^2 + bx^3 ) dx = a / 3 + b / 4
```

**486** Solutions to Self-Test Problems and Exercises

```
we obtain a = 3 .6, b =− 2 .4. Hence,
(a) P { X < 1 / 2 }=
```
##### ∫ 1 / 2

```
0 (^3.^6 x −^2.^4 x
```
(^2) ) _dx_ =( 1. 8 _x_ (^2) −. 8 _x_ (^3) )

##### ∣

##### ∣

##### ∣

```
1 / 2
0
```
##### =. 35

```
(b) E [ X^2 ]=
```
##### ∫ 1

```
0 (^3.^6 x
```
(^3) − 2. 4 _x_ (^4) ) _dx_ =. 42 *Var( _X_ )=. 06
**5.5.** For _i_ =1,..., _n_ ,
_P_ { _X_ = _i_ }= _P_ {Int( _nU_ )= _i_ − 1 }
= _P_ { _i_ − 1 ... _nU_ < _i_ }
= _P_

##### {

```
i − 1
n
```
##### ... U <

```
i
n
```
##### }

```
= 1 / n
```
```
5.6. If you bid x ,70... x ...140, then you will either win the bid and make a profit
of x −100 with probability( 140 − x )/70 or lose the bid and make a profit of
0 otherwise. Therefore, your expected profit if you bid x is
```
```
1
70
```
```
( x − 100 )( 140 − x )=
```
##### 1

##### 70

```
( 240 x − x^2 − 14000 )
```
```
Differentiating and setting the preceding equal to 0 gives
```
```
240 − 2 x = 0
```
```
Therefore, you should bid 120 thousand dollars. Your expected profit will be
40/7 thousand dollars.
5.7. (a) P { U >. 1 }= 9 / 10
(b) P { U >. 2 | U >. 1 }= P { U >. 2 }/ P { U >. 1 }= 8 / 9
(c) P { U >. 3 | U >.2, U >. 1 }= P { U >. 3 }/ P { U >. 2 }= 7 / 8
(d) P { U >. 3 }= 7 / 10
The answer to part (d) could also have been obtained by multiplying the prob-
abilities in parts (a), (b), and (c).
5.8. Let X be the test score, and let Z =( X − 100 )/15. Note that Z is a standard
normal random variable.
(a) P { X > 125 }= P { Z > 25 / 15 }L. 0478
(b)
```
```
P { 90 < X < 110 }= P {− 10 / 15 < Z < 10 / 15 }
= P { Z < 2 / 3 }− P { Z <− 2 / 3 }
= P { Z < 2 / 3 }−[1− P { Z < 2 / 3 }]
L. 4950
```
```
5.9. Let X be the travel time. We want to find x such that
```
```
P { X > x }=. 05
```
```
which is equivalent to
```
##### P

##### {

##### X − 40

##### 7

##### >

```
x − 40
7
```
##### }

##### =. 05

```
That is, we need to find x such that
```
##### P

##### {

##### Z >

```
x − 40
7
```
##### }

##### =. 05


```
Solutions to Self-Test Problems and Exercises 487
```
```
where Z is a standard normal random variable. But
```
##### P { Z > 1. 645 }=. 05

```
Thus,
```
```
x − 40
7
```
```
= 1 .645 or x = 51. 515
```
```
Therefore, you should leave no later than 8.485 minutes after 12P.M.
```
**5.10.** Let _X_ be the tire life in units of one thousand, and let _Z_ =( _X_ − 34 )/4. Note
that _Z_ is a standard normal random variable.
**(a)** _P_ { _X_ > 40 }= _P_ { _Z_ > 1. 5 }L. 0668
**(b)** _P_ { 30 < _X_ < 35 }= _P_ {− 1 < _Z_ <. 25 }= _P_ { _Z_ <. 25 }− _P_ { _Z_ > 1 }L. 44
**(c)**

##### P { X > 40 | X > 30 }= P { X > 40 }/ P { X > 30 }

##### = P { Z > 1. 5 }/ P { Z >− 1 }L. 079

**5.11.** Let _X_ be next year’s rainfall and let _Z_ =( _X_ − 40. 2 )/ 8 .4.
**(a)** _P_ { _X_ > 44 }= _P_ { _Z_ > 3. 8 / 8. 4 }L _P_ { _Z_ >. 4524 }L. 3255

```
(b)
```
##### (

##### 7

##### 3

##### )

##### (. 3255 )^3 (. 6745 )^4

**5.12.** Let _Mi_ and _Wi_ denote, respectively, the numbers of men and women in the
samples that earn, in units of one thousand dollars, at least _i_ per year. Also, let
_Z_ be a standard normal random variable.
**(a)**

##### P { W 25 Ú 70 }= P { W 25 Ú 69. 5 }

##### = P

##### {

##### W 25 − 200 (. 34 )

##### √

##### 200 (. 34 )(. 66 )

##### Ú

##### 69. 5 − 200 (. 34 )

##### √

##### 200 (. 34 )(. 66 )

##### }

##### L P { Z Ú. 2239 }

##### L. 4114

```
(b)
```
##### P { M 25 ... 120 }= P { M 25 ... 120. 5 }

##### = P

##### {

##### M 25 −( 200 )(. 587 )

##### √

##### ( 200 )(. 587 )(. 413 )

##### ...

##### 120. 5 −( 200 )(. 587 )

##### √

##### ( 200 )(. 587 )(. 413 )

##### }

##### L P { Z .... 4452 }

##### L. 6719


**488** Solutions to Self-Test Problems and Exercises

```
(c)
```
```
P { M 20 Ú 150 }= P { M 20 Ú 149. 5 }
```
##### = P

##### {

##### M 20 −( 200 )(. 745 )

##### √

##### ( 200 )(. 745 )(. 255 )

##### Ú

##### 149. 5 −( 200 )(. 745 )

##### √

##### ( 200 )(. 745 )(. 255 )

##### }

##### L P { Z Ú. 0811 }

##### L. 4677

##### P { W 20 Ú 100 }= P { W 20 Ú 99. 5 }

##### = P

##### {

##### W 20 −( 200 )(. 534 )

##### √

##### ( 200 )(. 534 )(. 466 )

##### Ú

##### 99. 5 −( 200 )(. 534 )

##### √

##### ( 200 )(. 534 )(. 466 )

##### }

##### L P { Z Ú− 1. 0348 }

##### =L. 8496

```
Hence, P { M
20 Ú^150 } P { W 20 Ú^100 }L.^3974
5.13. The lack of memory property of the exponential gives the result e −^4 /^5.
5.14. (a) e −^2
2
= e −^4
(b) F ( 3 )− F ( 1 )= e −^1 − e −^9
(c) λ( t )= 2 te − t
```
```
2
/ e − t
```
```
2
= 2 t
(d) Let∫ Z be a standard normal random variable. Use the identity E [ X ]=
q
0 P { X > x } dx to obtain
```
```
E [ X ]=
```
```
∫q
```
```
0
```
```
e − x
```
```
2
dx
```
##### = 2 −^1 /^2

```
∫q
```
```
0
```
```
e − y
```
(^2) / 2
_dy_
= 2 −^1 /^2

##### √

```
2 π P { Z > 0 }
=
```
##### √

```
π/ 2
```
```
(e) Use the result of Theoretical Exercise 5 to obtain
```
##### E [ X^2 ]=

```
∫q
```
```
0
```
```
2 xe − x
```
```
2
dx =− e − x
```
```
2
```
##### ∣

##### ∣

##### ∣

##### ∣

```
q
```
```
0
```
##### = 1

```
Hence, Var( X )= 1 −π/4.
5.15. (a) P { X > 6 }=exp{−
```
##### ∫ 6

```
0 λ( t ) dt }= e
```
```
− 3. 45
(b)
```
```
P { X < 8 | X > 6 }= 1 − P { X > 8 | X > 6 }
= 1 − P { X > 8 }/ P { X > 6 }
= 1 − e −^5.^65 / e −^3.^45
L. 8892
```
```
5.16. For x Ú0,
```
```
F 1 / X ( x )= P { 1 / X ... x }
= P { X ... 0 }+ P { X Ú 1 / x }
= 1 / 2 + 1 − FX ( 1 / x )
```

```
Solutions to Self-Test Problems and Exercises 489
```
```
Differentiation yields
```
```
f 1 / X ( x )= x −^2 fX ( 1 / x )
```
```
=
```
##### 1

```
x^2 π( 1 +( 1 / x )^2 )
= fX ( x )
```
```
The proof when x <0 is similar.
```
**5.17.** If _X_ denotes the number of the first _n_ bets that you win, then the amount that
you will be winning after _n_ bets is

```
35 X −( n − X )= 36 X − n
```
```
Thus, we want to determine
```
```
p = P { 36 X − n > 0 }= P { X > n / 36 }
```
```
when X is a binomial random variable with parameters n and p = 1 /38.
(a) When n =34,
```
```
p = P { X Ú 1 }
= P { X >. 5 } (the continuity correction)
```
##### = P

##### {

##### X − 34 / 38

##### √

##### 34 ( 1 / 38 )( 37 / 38 )

##### >

##### . 5 − 34 / 38

##### √

##### 34 ( 1 / 38 )( 37 / 38 )

##### }

##### = P

##### {

##### X − 34 / 38

##### √

##### 34 ( 1 / 38 )( 37 / 38 )

##### >−. 4229

##### }

##### L
(. 4229 )

##### L. 6638

```
(Because you will be ahead after 34 bets if you win at least 1 bet, the exact
probability in this case is 1−( 37 / 38 )^34 =.5961.)
(b) When n =1000,
```
```
p = P { X > 27. 5 }
```
##### = P

##### {

##### X − 1000 / 38

##### √

##### 1000 ( 1 / 38 )( 37 / 38 )

##### >

##### 27. 5 − 1000 / 38

##### √

##### 1000 ( 1 / 38 )( 37 / 38 )

##### }

##### L 1 −
(. 2339 )

##### L. 4075

```
The exact probability—namely, the probability that a binomial n =1000,
p = 1 /38 random variable is greater than 27—is .3961.
```

**490** Solutions to Self-Test Problems and Exercises

```
(c) When n =100, 000,
```
```
p = P { X > 2777. 5 }
```
##### = P

##### {

##### X − 100000 / 38

##### √

##### 100000 ( 1 / 38 )( 37 / 38 )

##### >

##### 2777. 5 − 100000 / 38

##### √

##### 100000 ( 1 / 38 )( 37 / 38 )

##### }

##### L 1 −
( 2. 883 )

##### L. 0020

```
The exact probability in this case is .0021.
5.18. If X denotes the lifetime of the battery, then the desired probability,
P { X > s + t | X > t }, can be determined as follows:
```
```
P { X > s + t | X > t }=
```
```
P { X > s + t , X > t }
P { X > t }
```
```
=
```
```
P { X > s + t }
P { X > t }
```
##### =

```
P { X > s + t |battery is type 1} p 1
+ P { X > s + t |battery is type 2} p 2
P { X > t |battery is type 1} p 1
+ P { X > t |battery is type 2} p 2
```
```
=
```
```
e −λ^1 ( s + t ) p 1 + e −λ^2 ( s + t ) p 2
e −λ^1 tp 1 + e −λ^2 tp 2
Another approach is to directly condition on the type of battery and then
use the lack-of-memory property of exponential random variables. That is,
we could do the following:
```
```
P { X > s + t | X > t }= P { X > s + t | X > t ,type 1} P {type 1| X > t }
+ P { X > s + t | X > t ,type 2} P {type 2| X > t }
= e −λ^1 sP {type 1| X > t }+ e −λ^2 sP {type 2| X > t }
```
```
Now for i =1, 2, use
```
```
P {type i | X > t }=
```
```
P {type i , X > t }
P { X > t }
```
##### =

```
P { X > t |type i } pi
P { X > t |type 1} p 1 + P { X > t |type 2} p 2
```
```
=
```
```
e −λ itpi
e −λ^1 tp 1 + e −λ^2 tp 2
5.19. Let Xi be an exponential random variable with mean i , i =1, 2.
(a) The value c should be such that P { X 1 > c }=.05. Therefore,
```
```
e − c =. 05 = 1 / 20
```
```
or c =log( 20 )= 2 .996.
(b)
P { X 2 > c }= e − c /^2 =
```
##### 1

##### √

##### 20

##### =. 2236


```
Solutions to Self-Test Problems and Exercises 491
```
```
5.20. (a)
```
```
E [( Z − c )+]=
```
##### 1

##### √

```
2 π
```
```
∫q
```
```
−q
```
```
( x − c )+ e − x
```
(^2) / 2
_dx_

##### =

##### 1

##### √

```
2 π
```
```
∫q
```
```
c
```
```
( x − c ) e − x
```
(^2) / 2
_dx_

##### =

##### 1

##### √

```
2 π
```
```
∫q
```
```
c
```
```
xe − x
```
(^2) / 2
_dx_ −

##### 1

##### √

```
2 π
```
```
∫q
```
```
c
```
```
ce − x
```
(^2) / 2
_dx_

##### =−

##### 1

##### √

```
2 π
```
```
e − x
```
(^2) / 2
|q _c_ − _c_ ( 1 −
( _c_ ))

##### =

##### 1

##### √

```
2 π
```
```
e − c
```
(^2) / 2
− _c_ ( 1 −
( _c_ ))
**(b)** Using the fact that _X_ has the same distribution asμ+σ _Z_ , where _Z_ is a
standard normal random variable, yields
_E_ [( _X_ − _c_ )+]= _E_ [(μ+σ _Z_ − _c_ )+]

##### = E

##### ⎡

##### ⎣

##### (

```
σ
```
##### (

##### Z −

```
c −μ
σ
```
##### ))+

##### ⎤

##### ⎦

##### = E

##### [

```
σ( Z −
```
```
c −μ
σ
```
##### )+

##### ]

```
=σ E
```
##### [(

##### Z −

```
c −μ
σ
```
##### )+]

```
=σ
```
##### [

##### 1

##### √

```
2 π
```
```
e − a
```
(^2) / 2
− _a_ ( 1 −
( _a_ ))

##### ]

```
where a = c −σμ.
```
##### CHAPTER 6

```
6.1. (a) 3 C + 6 C = 1 * C = 1 / 9
(b) Let p ( i , j )= P { X = i , Y = j }. Then
```
```
p (1, 1)= 4 /9, p (1, 0)= 2 /9, P (0, 1)= 1 /9, p (0, 0)= 2 / 9
```
```
(c)
```
##### ( 12 )!

##### 26

##### ( 1 / 9 )^6 ( 2 / 9 )^6

```
(d)
```
##### ( 12 )!

##### (4!)^3

##### ( 1 / 3 )^12

```
(e)
```
##### ∑^12

```
i = 8
```
##### (

##### 12

```
i
```
##### )

```
( 2 / 3 ) i ( 1 / 3 )^12 − i
```
```
6.2. (a) With pj = P { XYZ = j }, we have
```
```
p 6 = p 2 = p 4 = p 12 = 1 / 4
```
```
Hence,
E [ XYZ ]=( 6 + 2 + 4 + 12 )/ 4 = 6
```

**492** Solutions to Self-Test Problems and Exercises

```
(b) With qj = P { XY + XZ + YZ = j }, we have
```
```
q 11 = q 5 = q 8 = q 16 = 1 / 4
```
```
Hence,
```
```
E [ XY + XZ + YZ ]=( 11 + 5 + 8 + 16 )/ 4 = 10
```
```
6.3. In this solution, we will make use of the identity
∫q
```
```
0
```
```
e − xxndx = n!
```
```
which follows because e − xxn / n !, x > 0, is the density function of a gamma
random variable with parameters n +1andλand must thus integrate to 1.
(a)
```
##### 1 = C

```
∫q
```
```
0
```
```
e − y
```
```
∫ y
```
```
− y
```
```
( y − x ) dx dy
```
##### = C

```
∫q
```
```
0
```
```
e − y 2 y^2 dy = 4 C
```
```
Hence, C = 1 /4.
(b) Since the joint density is nonzero only when y > x and y >− x , we have,
for x >0,
```
```
fX ( x )=
```
##### 1

##### 4

```
∫q
```
```
x
```
```
( y − x ) e − ydy
```
##### =

##### 1

##### 4

```
∫q
```
```
0
```
```
ue −( x + u ) du
```
##### =

##### 1

##### 4

```
e − x
```
```
For x <0,
```
```
fX ( x )=
```
##### 1

##### 4

```
∫q
```
```
− x
```
```
( y − x ) e − ydy
```
##### =

##### 1

##### 4

```
[− ye − y − e − y + xe − y ]q− x
```
```
=(− 2 xex + ex )/ 4
```
```
(c) fY ( y )=^14 e − y
```
```
∫ y
− y ( y − x ) dx =
```
```
1
2 y
```
(^2) _e_ − _y_
**(d)**

##### E [ X ]=

##### 1

##### 4

##### [∫

```
q
```
```
0
```
```
xe − xdx +
```
##### ∫ 0

```
−q
```
```
(− 2 x^2 ex + xex ) dx
```
##### ]

##### =

##### 1

##### 4

##### [

##### 1 −

```
∫q
```
```
0
```
```
( 2 y^2 e − y + ye − y ) dy
```
##### ]

##### =

##### 1

##### 4

##### [1− 4 −1]=− 1

```
(e) E [ Y ]=^12
```
```
∫q
0 y
```
(^3) _e_ − _ydy_ = 3


```
Solutions to Self-Test Problems and Exercises 493
```
**6.4.** The multinomial random variables _Xi_ , _i_ =1,..., _r_ , represent the numbers of
each of the types of outcomes 1,..., _r_ that occur in _n_ independent trials when
each trial results in one of the outcomes 1,..., _r_ with respective probabili-
ties _p_ 1 ,..., _pr_. Now, say that a trial results in a category 1 outcome if that
trial resulted in any of the outcome types 1,..., _r_ 1 ; say that a trial results
in a category 2 outcome if that trial resulted in any of the outcome types
_r_ 1 + 1,..., _r_ 1 + _r_ 2 ; and so on. With these definitions, _Y_ 1 ,..., _Yk_ represent
the numbers of category 1 outcomes, category 2 outcomes, up to category _k_
outcomes when _n_ independent trials that each result in one of the categories
1,..., _k_ with respective probabilities

```
∑ ri − 1 + ri
j = ri − 1 + 1 pj , i =1,..., k , are performed.
But by definition, such a vector has a multinomial distribution.
```
**6.5. (a)** Letting _pj_ = _P_ { _XYZ_ = _j_ }, we have

```
p 1 = 1 /8, p 2 = 3 /8, p 4 = 3 /8, p 8 = 1 / 8
```
```
(b) Letting pj = P { XY + XZ + YZ = j }, we have
```
```
p 3 = 1 /8, p 5 = 3 /8, p 8 = 3 /8, p 12 = 1 / 8
```
```
(c) Letting pj = P { X^2 + YZ = j }, we have
```
```
p 2 = 1 /8, p 3 = 1 /4, p 5 = 1 /4, p 6 = 1 /4, p 8 = 1 / 8
```
**6.6. (a)**

##### 1 =

##### ∫ 1

```
0
```
##### ∫ 5

```
1
```
```
( x / 5 + cy ) dy dx
```
##### =

##### ∫ 1

```
0
```
```
( 4 x / 5 + 12 c ) dx
```
```
= 12 c + 2 / 5
```
```
Hence, c = 1 /20.
(b) No, the density does not factor.
(c)
```
##### P { X + Y > 3 }=

##### ∫ 1

```
0
```
##### ∫ 5

```
3 − x
```
```
( x / 5 + y / 20 ) dy dx
```
##### =

##### ∫ 1

```
0
```
```
[( 2 + x ) x / 5 + 25 / 40 −( 3 − x )^2 /40] dx
```
```
= 1 / 5 + 1 / 15 + 5 / 8 − 19 / 120 = 11 / 15
```
**6.7. (a)** Yes, the joint density function factors.

```
(b) fX ( x )= x
```
##### ∫ 2

```
0 ydy =^2 x ,0< x <^1
(c) fY ( y )= y
```
##### ∫ 1

```
0 xdx = y /2,^0 < y <^2
(d)
```
```
P { X < x , Y < y }= P { X < x } P { Y < y }
=min(1, x^2 )min(1, y^2 / 4 ), x >0, y > 0
```
```
(e) E [ Y ]=
```
##### ∫ 2

```
0 y
```
(^2) / 2 _dy_ = 4 / 3


**494** Solutions to Self-Test Problems and Exercises

```
(f)
```
##### P { X + Y < 1 }=

##### ∫ 1

```
0
```
```
x
```
```
∫ 1 − x
```
```
0
```
```
ydydx
```
##### =

##### 1

##### 2

##### ∫ 1

```
0
```
```
x ( 1 − x )^2 dx = 1 / 24
```
```
6.8. Let Ti denote the time at which a shock type i ,of i = 1, 2, 3, occurs. For
s >0, t >0,
```
```
P { X 1 > s , X 2 > t }= P { T 1 > s , T 2 > t , T 3 >max( s , t )}
= P { T 1 > s } P { T 2 > t } P { T 3 >max( s , t )}
=exp{−λ 1 s }exp{−λ 2 t }exp{−λ 3 max( s , t )}
=exp{−(λ 1 s +λ 2 t +λ 3 max( s , t ))}
```
```
6.9. (a) No, advertisements on pages having many ads are less likely to be chosen
than are ones on pages with few ads.
(b) m^1 n ( ni )
```
```
(c)
```
```
∑ m
```
```
i = 1
```
```
n ( i )
```
```
nm = n / n , where n =
```
```
∑ m
```
```
i = 1
```
```
n ( i )/ m
```
```
(d) ( 1 − n / n ) k −^1
```
##### 1

```
m
```
```
n ( i )
n
```
##### 1

```
n ( i )
```
```
=( 1 − n / n ) k −^1 /( nm )
```
```
(e)
```
```
∑q
```
```
k = 1
```
##### 1

```
nm
```
```
( 1 − n / n ) k −^1 =
```
##### 1

```
nm
```
##### .

```
(f) The number of iterations is geometric with mean n
```
##### √

```
n
6.10. (a) P { X = i }= 1 / m , i =1,..., m.
(b) Step 2. Generate a uniform (0, 1) random variable U .If U < n ( X )/ n ,
go to step 3. Otherwise return to step 1.
Step 3. Generate a uniform (0, 1) random variable U , and select the
element on page X in position [ n ( X ) U ]+1.
6.11. Yes, they are independent. This can be easily seen by considering the equiva-
lent question of whether XN is independent of N. But this is indeed so, since
knowing when the first random variable greater than c occurs does not affect
the probability distribution of its value, which is the uniform distribution
on ( c , 1).
6.12. Let pi denote the probability of obtaining i points on a single throw of the dart.
Then
```
```
p 30 =π/ 36
p 20 = 4 π/ 36 − p 30 =π/ 12
p 10 = 9 π/ 36 − p 20 − p 30 = 5 π/ 36
p 0 = 1 − p 10 − p 20 − p 30 = 1 −π/ 4
```
```
(a) π/ 12
(b) π/ 9
(c) 1 −π/ 4
```

```
Solutions to Self-Test Problems and Exercises 495
```
**(d)** π( 30 / 36 + 20 / 12 + 50 / 36 )= 35 π/ 9
**(e)** (π/ 4 )^2
**(f)** 2 (π/ 36 )( 1 −π/ 4 )+ 2 (π/ 12 )( 5 π/ 36 )
**6.13.** Let _Z_ be a standard normal random variable.
**(a)**

##### P

##### ⎧

##### ⎨

##### ⎩

##### ∑^4

```
i = 1
```
```
Xi > 0
```
##### ⎫

##### ⎬

##### ⎭

##### = P

##### ⎧

##### ⎪⎪

##### ⎨

##### ⎪⎪

##### ⎩

##### ∑^4

```
i = 1
```
```
Xi − 6
```
```
√
24
```
##### >

##### − 6

##### √

##### 24

##### ⎫

##### ⎪⎪

##### ⎬

##### ⎪⎪

##### ⎭

##### L P { Z >− 1. 2247 }L. 8897

```
(b)
```
##### P

##### ⎧

##### ⎨

##### ⎩

##### ∑^4

```
i = 1
```
```
Xi > 0
```
##### ∣

##### ∣

##### ∣

##### ∑^2

```
i = 1
```
```
Xi =− 5
```
##### ⎫

##### ⎬

##### ⎭

##### = P { X 3 + X 4 > 5 }

##### = P

##### {

##### X 3 + X 4 − 3

##### √

##### 12

##### > 2 /

##### √

##### 12

##### }

##### L P { Z >. 5774 }L. 2818

```
(c)
```
```
p
```
##### ⎧

##### ⎨

##### ⎩

##### ∑^4

```
i = 1
```
```
Xi > 0 | X 1 = 5
```
##### ⎫

##### ⎬

##### ⎭

##### = P { X 2 + X 3 + X 4 >− 5 }

##### = P

##### {

##### X 2 + X 3 + X 4 − 4. 5

##### √

##### 18

##### >− 9. 5 /

##### √

##### 18

##### }

##### L P { Z >− 2. 239 }L. 9874

**6.14.** In the following, _C_ does not depend on _n_.

```
P { N = n | X = x }= fX | N ( x | n ) P { N = n }/ fX ( x )
```
```
= C
```
##### 1

```
( n − 1 )!
```
```
(λ x ) n −^1 ( 1 − p ) n −^1
```
```
= C (λ( 1 − p ) x ) n −^1 /( n − 1 )!
```
```
which shows that, conditional on X = x , N −1 is a Poisson random variable
with meanλ( 1 − p ) x. That is,
```
```
P { N = n | X = x }= P { N − 1 = n − 1 | X = x }
= e −λ(^1 − p ) x (λ( 1 − p ) x ) n −^1 /( n − 1 )!, n Ú 1.
```
**6.15. (a)** The Jacobian of the transformation is

##### J =

##### ∣

##### ∣

##### ∣

##### ∣

##### 10

##### 11

##### ∣

##### ∣

##### ∣

##### ∣=^1

```
As the equations u = x , v = x + y imply that x = u , y = v − u , we obtain
```
```
fU , V ( u , v )= fX , Y ( u , v − u )=1, 0 < u <1, 0 < v − u < 1
```

**496** Solutions to Self-Test Problems and Exercises

```
or, equivalently,
```
```
fU , V ( u , v )=1, max( v −1, 0)< u <min( v ,1)
```
```
(b) For 0< v <1,
fV ( v )=
```
```
∫ v
```
```
0
```
```
du = v
```
```
For 1... v ...2,
```
```
fV ( v )=
```
##### ∫ 1

```
v − 1
```
```
du = 2 − v
```
```
6.16. Let U be a uniform random variable on (7, 11). If you bid x ,7... x ...10, you
will be the high bidder with probability
```
```
( P { U < x })^3 =
```
##### (

##### P

##### {

##### U − 7

##### 4

##### <

```
x − 7
4
```
##### })^3

##### =

##### (

```
x − 7
4
```
##### ) 3

```
Hence, your expected gain—call it E [ G ( x )]—if you bid x is
```
```
E [ G ( x )]=
```
##### 1

##### 4

```
( x − 7 )^3 ( 10 − x )
```
```
Calculus shows this is maximized when x = 37 /4.
6.17. Let i 1 , i 2 ,..., in , be a permutation of 1, 2,..., n. Then
```
```
P { X 1 = i 1 , X 2 = i 2 ,..., Xn = in }= P { X 1 = i 1 } P { X 2 = i 2 }··· P { Xn = in }
= pi 1 pi 2 ··· pin
= p 1 p 2 ··· pn
```
```
Therefore, the desired probability is n! p 1 p 2 ··· pn , which reduces to nnn !when
all pi = 1 / n.
6.18. (a) Because
```
```
∑ n
i = 1
```
```
Xi =
```
```
∑ n
i = 1
```
```
Yi , it follows that N = 2 M.
```
```
(b) Consider the n − k coordinates whose Y -values are equal to 0, and call
them the red coordinates. Because the k coordinates whose X -values are
equal to 1 are equally likely to be any of the
```
##### (

```
n
k
```
##### )

```
sets of k coordinates,
it follows that the number of red coordinates among these k coordinates
has the same distribution as the number of red balls chosen when one
randomly chooses k of a set of n balls of which n − k are red. Therefore,
M is a hypergeometric random variable.
(c) E [ N ]= E [2 M ]= 2 E [ M ]=^2 k ( nn − k )
(d) Using the formula for the variance of a hypergeometric given in
Example 8j of Chapter 4, we obtain
```
```
Var( N )=4Var( M )= 4
```
```
n − k
n − 1
```
```
k ( 1 − k / n )( k / n )
```
```
6.19. (a) First note that Sn − Sk =
```
```
∑ n
i = k + 1
```
```
Zi is a normal random variable with mean
```
```
0 and variance n − k that is independent of Sk. Consequently, given that
Sk = y , Sn is a normal random variable with mean y and variance n − k.
```

```
Solutions to Self-Test Problems and Exercises 497
```
```
(b) Because the conditional density function of Sk given that Sn = x is a
density function whose argument is y , anything that does not depend on
y can be regarded as a constant. (For instance, x is regarded as a fixed
constant.) In the following, the quantities Ci , i =1, 2, 3, 4 are all constants
that do not depend on y :
```
```
fSk | Sn ( y | x )=
```
```
fSk , Sn ( y , x )
fSn ( x )
```
```
= C 1 fSn | Sk ( x | y ) fSk ( y )
```
##### (

```
where C 1 =
```
##### 1

```
fSn ( x )
```
##### )

##### = C 1

##### 1

##### √

```
2 π
```
##### √

```
n − k
```
```
e −( x − y )
```
(^2) / 2 ( _n_ − _k_ ) 1
√
2 π

##### √

```
k
```
```
e − y
```
(^2) / 2 _k_
= _C_ 2 exp

##### {

##### −

```
( x − y )^2
2 ( n − k )
```
##### −

```
y^2
2 k
```
##### }

```
= C 3 exp
```
##### {

```
2 xy
2 ( n − k )
```
##### −

```
y^2
2 ( n − k )
```
##### −

```
y^2
2 k
```
##### }

```
= C 3 exp
```
##### {

##### −

```
n
2 k ( n − k )
```
##### (

```
y^2 − 2
```
```
k
n
```
```
xy
```
##### )}

```
= C 3 exp
```
##### ⎧

##### ⎨

##### ⎩

##### −

```
n
2 k ( n − k )
```
##### [(

```
y −
```
```
k
n
```
```
x
```
##### ) 2

##### −

##### (

```
k
n
```
```
x
```
##### ) 2 ]

##### ⎫

##### ⎬

##### ⎭

```
= C 4 exp
```
##### {

##### −

```
n
2 k ( n − k )
```
##### (

```
y −
```
```
k
n
```
```
x
```
##### ) 2 }

```
But we recognize the preceding as the density function of a normal ran-
dom variable with mean
```
```
k
n
```
```
x and variance
```
```
k ( n − k )
n
```
##### .

**6.20. (a)**

```
P { X 6 > X 1 | X 1 =max( X 1 ,..., X 5 )}
```
```
=
```
```
P { X 6 > X 1 , X 1 =max( X 1 ,..., X 5 )}
P { X 1 =max( X 1 ,..., X 5 )}
```
##### =

```
P { X 6 =max( X 1 ,..., X 6 ), X 1 =max( X 1 ,..., X 5 )}
1 / 5
```
```
= 5
```
##### 1

##### 6

##### 1

##### 5

##### =

##### 1

##### 6

```
Thus, the probability that X 6 is the largest value is independent of which
is the largest of the other five values. (Of course, this would not be true if
the Xi had different distributions.)
(b) One way to solve this problem is to condition on whether X 6 > X 1. Now,
```
```
P { X 6 > X 2 | X 1 =max( X 1 ,..., X 5 ), X 6 > X 1 }= 1
```

**498** Solutions to Self-Test Problems and Exercises

```
Also, by symmetry,
```
```
P { X 6 > X 2 | X 1 =max( X 1 ,..., X 5 ), X 6 < X 1 }=
```
##### 1

##### 2

```
From part (a),
```
```
P { X 6 > X 1 | X 1 =max( X 1 ,..., X 5 )}=
```
##### 1

##### 6

```
Thus, conditioning on whether X 6 > X 1 yields the result
```
```
P { X 6 > X 2 | X 1 =max( X 1 ,..., X 5 )}=
```
##### 1

##### 6

##### +

##### 1

##### 2

##### 5

##### 6

##### =

##### 7

##### 12

##### CHAPTER 7

```
7.1. (a) d =
```
```
∑ m
i = 1
```
```
1 / n ( i )
```
```
(b) P { X = i }= P {[ mU ]= i − 1 }= P { i − 1 ... mU < i }= 1 / m , i =1,..., m
```
```
(c) E
```
##### [

```
m
n ( X )
```
##### ]

##### =

```
∑ m
i = 1
```
```
m
n ( i )
```
```
P { X = i }=
```
```
∑ m
```
```
i = 1
```
```
m
n ( i )
```
##### 1

```
m
```
```
= d
```
```
7.2. Let Ij equal 1 if the j th ball withdrawn is white and the( j + 1 )st is black, and
let Ij equal 0 otherwise. If X is the number of instances in which a white ball is
immediately followed by a black one, then we may express X as
```
##### X =

```
n +∑ m − 1
```
```
j = 1
```
```
Ij
```
```
Thus,
```
##### E [ X ]=

```
n +∑ m − 1
```
```
j = 1
```
```
E [ Ij ]
```
##### =

```
n +∑ m − 1
```
```
j = 1
```
```
P { jth selection is white,( j + 1 ) st is black}
```
##### =

```
n +∑ m − 1
```
```
j = 1
```
```
P { jth selection is white} P { j + 1 ) st is black| jth is white}
```
##### =

```
n +∑ m − 1
```
```
j = 1
```
```
n
n + m
```
```
m
n + m − 1
```
##### =

```
nm
n + m
```
```
The preceding used the fact that each of the n + m balls is equally likely to
be the j th one selected and, given that that selection is a white ball, each of the
other n + m −1 balls is equally likely to be the next ball chosen.
```

```
Solutions to Self-Test Problems and Exercises 499
```
**7.3.** Arbitrarily number the couples, and then let _Ij_ equal 1 if married couple num-
ber _j_ , _j_ = 1,..., 10, is seated at the same table. Then, if _X_ represents the
number of married couples that are seated at the same table, we have

##### X =

##### ∑^10

```
j = 1
```
```
Ij
```
```
so
```
```
E [ X ]=
```
##### ∑^10

```
j = 1
```
```
E [ Ij ]
```
```
(a) To compute( E [ Ij ] in this case, consider wife number j. Since each of the
19
3
```
##### )

```
groups of size 3 not including her is equally likely to be the remain-
ing members of her table, it follows that the probability that her husband
is at her table is (
1
1
```
##### )(

##### 18

##### 2

##### )

##### (

##### 19

##### 3

##### ) =

##### 3

##### 19

```
Hence, E [ Ij ]= 3 /19 and so
```
```
E [ X ]= 30 / 19
```
```
(b) In this case, since the 2 men at the table of wife j are equally likely to be
any of the 10 men, it follows that the probability that one of them is her
husband is 2/10, so
```
```
E [ Ij ]= 2 / 10 and E [ X ]= 2
```
**7.4.** From Example 2i, we know that the expected number of times that the die
need be rolled until all sides have appeared at least once is 6( 1 + 1 / 2 + 1 / 3 +
1 / 4 + 1 / 5 + 1 / 6 )= 14 .7. Now, if we let _Xi_ denote the total number of times

```
that side i appears, then, since
```
##### ∑^6

```
i = 1
```
```
Xi is equal to the total number of rolls, we
```
```
have
```
```
14. 7 = E
```
##### ⎡

##### ⎣

##### ∑^6

```
i = 1
```
```
Xi
```
##### ⎤

##### ⎦=

##### ∑^6

```
i = 1
```
```
E [ Xi ]
```
```
But, by symmetry, E [ Xi ] will be the same for all i , and thus it follows from the
preceding that E [ X 1 ]= 14. 7 / 6 = 2 .45.
```
**7.5.** Let _Ij_ equal 1 if we win 1 when the _j_ th red card to show is turned over, and let
_Ij_ equal 0 otherwise. (For instance, _I_ 1 will equal 1 if the first card turned over
is red.) Hence, if _X_ is our total winnings, then

##### E [ X ]= E

##### ⎡

##### ⎢

##### ⎣

```
∑ n
```
```
j = 1
```
```
Ij
```
##### ⎤

##### ⎥

##### ⎦=

```
∑ n
```
```
j = 1
```
```
E [ Ij ]
```

**500** Solutions to Self-Test Problems and Exercises

```
Now, Ij will equal 1 if j red cards appear before j black cards. By symmetry, the
probability of this event is equal to 1/2; therefore, E [ Ij ]= 1 /2and E [ X ]= n /2.
7.6. To see that N ... n − 1 + I , note that if all events occur, then both sides of
the preceding inequality are equal to n , whereas if they do not all occur, then
the inequality reduces to N ... n −1, which is clearly true in this case. Taking
expectations yields
E [ N ]... n − 1 + E [ I ]
```
```
However, if we let Ii equal 1 if Ai occurs and 0 otherwise, then
```
##### E [ N ]= E

##### ⎡

##### ⎣

```
∑ n
```
```
i = 1
```
```
Ii
```
##### ⎤

##### ⎦=

```
∑ n
```
```
i = 1
```
```
E [ Ii ]=
```
```
∑ n
```
```
i = 1
```
```
P ( Ai )
```
```
Since E [ I ]= P ( A 1 ··· An ), the result follows.
7.7. Imagine that the values 1, 2,..., n are lined up in their numerical order and that
the k values selected are considered special. From Example 3e, the position
of the first special value, equal to the smallest value chosen, has mean 1+
n − k
k + 1
```
##### =

```
n + 1
k + 1
```
##### .

```
For a more formal argument, note that X Ú j if none of the j −1 smallest
values are chosen. Hence,
```
```
P { X Ú j }=
```
##### (

```
n − j + 1
k
```
##### )

##### (

```
n
k
```
##### ) =

##### (

```
n − k
j − 1
```
##### )

##### (

```
n
j − 1
```
##### )

```
which shows that X has the same distribution as the random variable of Exam-
ple 3e (with the notational change that the total number of balls is now n and
the number of special balls is k ).
7.8. Let X denote the number of families that depart after the Sanchez family
leaves. Arbitrarily number all the N − 1 non-Sanchez families, and let Ir ,
1 ... r ... N −1, equal 1 if family r departs after the Sanchez family does. Then
```
##### X =

##### N ∑− 1

```
r = 1
```
```
Ir
```
```
Taking expectations gives
```
##### E [ X ]=

##### N ∑− 1

```
r = 1
```
```
P {family r departs after the Sanchez family}
```
```
Now consider any non-Sanchez family that checked in k pieces of luggage.
Because each of the k + j pieces of luggage checked in either by this family or
by the Sanchez family is equally likely to be the last of these k + j to appear,
the probability that this family departs after the Sanchez family is kk + j. Because
the number of non-Sanchez families who checked in k pieces of luggage is nk
when k Z j ,or nj −1 when k = j , we obtain
```
##### E [ X ]=

##### ∑

```
k
```
```
knk
k + j
```
##### −

##### 1

##### 2


```
Solutions to Self-Test Problems and Exercises 501
```
```
7.9. Let the neighborhood of any point on the rim be the arc starting at that point
and extending for a length 1. Consider a uniformly chosen point on the rim
of the circle—that is, the probability that this point lies on a specified arc of
length x is
```
```
x
2 π
```
```
—and let X denote the number of points that lie in its neighbor-
hood. With Ij defined to equal 1 if item number j is in the neighborhood of the
random point and to equal 0 otherwise, we have
```
##### X =

##### ∑^19

```
j = 1
```
```
Ij
```
```
Taking expectations gives
```
##### E [ X ]=

##### ∑^19

```
j = 1
```
```
P {item j lies in the neighborhood of the random point}
```
```
But because item j will lie in its neighborhood if the random point is located
on the arc of length 1 going from item j in the counterclockwise direction, it
follows that
```
```
P {item j lies in the neighborhood of the random point}=
```
##### 1

```
2 π
```
```
Hence,
```
##### E [ X ]=

##### 19

```
2 π
```
##### > 3

```
Because E [ X ] > 3, at least one of the possible values of X must exceed 3,
proving the result.
```
**7.10.** If _g_ ( _x_ )= _x_^1 /^2 ,then

```
g ′( x )=
```
##### 1

##### 2

```
x −^1 /^2 , g ′′( x )=−
```
##### 1

##### 4

```
x −^3 /^2
```
```
so the Taylor series expansion of
```
##### √

```
x aboutλgives
```
```
√
X L
```
##### √

```
λ+
```
##### 1

##### 2

```
λ−^1 /^2 ( X −λ)−
```
##### 1

##### 8

```
λ−^3 /^2 ( X −λ)^2
```
```
Taking expectations yields
```
##### E [

##### √

##### X ]L

##### √

```
λ+
```
##### 1

##### 2

```
λ−^1 /^2 E [ X −λ]−
```
##### 1

##### 8

```
λ−^3 /^2 E [( X −λ)^2 ]
```
##### =

##### √

```
λ−
```
##### 1

##### 8

```
λ−^3 /^2 λ
```
##### =

##### √

```
λ−
```
##### 1

##### 8

```
λ−^1 /^2
```

**502** Solutions to Self-Test Problems and Exercises

```
Hence,
```
```
Var(
```
##### √

##### X )= E [ X ]−( E [

##### √

##### X ])^2

```
Lλ−
```
##### (√

```
λ−
```
##### 1

##### 8

```
λ−^1 /^2
```
##### ) 2

##### = 1 / 4 −

##### 1

```
64 λ
L 1 / 4
```
```
7.11. Number the tables so that tables 1, 2, and 3 are the ones with four seats and
tables 4, 5, 6, and 7 are the ones with two seats. Also, number the women, and
let Xi , j equal 1 if woman i is seated with her husband at table j. Note that
```
```
E [ Xi , j ]=
```
##### (

##### 2

##### 2

##### )(

##### 18

##### 2

##### )

##### (

##### 20

##### 4

##### ) =

##### 3

##### 95

```
, j =1, 2, 3
```
```
and
```
```
E [ Xi , j ]=
```
##### 1

##### (

##### 20

##### 2

##### )=

##### 1

##### 190

```
, j =4, 5, 6, 7
```
```
Now, X denotes the number of married couples that are seated at the same
table, we have
```
##### E [ X ]= E

##### ⎡

##### ⎢

##### ⎣

##### ∑^10

```
i = 1
```
##### ∑^7

```
j = 1
```
```
Xi , j
```
##### ⎤

##### ⎥

##### ⎦

##### =

##### ∑^22

```
i = 1
```
##### ∑^3

```
j = 1
```
```
E [ Xi , j ]+
```
##### ∑^19

```
i = 1
```
##### ∑^7

```
j = 4
```
```
E [ Xi , j ]
```
```
7.12. Let Xi equal 1 if individual i does not recruit anyone, and let Xi equal 0 other-
wise. Then
```
```
E [ Xi ]= P { i does not recruit any of i +1, i +2,..., n }
```
```
=
```
```
i − 1
i
```
```
i
i + 1
```
##### ···

```
n − 2
n − 1
```
```
=
```
```
i − 1
n − 1
```
```
Hence,
```
##### E

##### ⎡

##### ⎣

```
∑ n
```
```
i = 1
```
```
Xi
```
##### ⎤

##### ⎦=

```
∑ n
```
```
i = 1
```
```
i − 1
n − 1
```
##### =

```
n
2
```

```
Solutions to Self-Test Problems and Exercises 503
```
```
From the preceding we also obtain
```
```
Var( Xi )=
```
```
i − 1
n − 1
```
##### (

##### 1 −

```
i − 1
n − 1
```
##### )

##### =

```
( i − 1 )( n − i )
( n − 1 )^2
```
```
Now, for i < j ,
```
```
E [ XiXj ]=
```
```
i − 1
i
```
##### ···

```
j − 2
j − 1
```
```
j − 2
j
```
```
j − 1
j + 1
```
##### ···

```
n − 3
n − 1
```
```
=
```
```
( i − 1 )( j − 2 )
( n − 2 )( n − 1 )
```
```
Thus,
```
```
Cov( Xi , Xj )=
```
```
( i − 1 )( j − 2 )
( n − 2 )( n − 1 )
```
##### −

```
i − 1
n − 1
```
```
j − 1
n − 1
```
```
=
```
```
( i − 1 )( j − n )
( n − 2 )( n − 1 )^2
```
```
Therefore,
```
```
Var
```
##### ⎛

##### ⎝

```
∑ n
```
```
i = 1
```
```
Xi
```
##### ⎞

##### ⎠=

```
∑ n
```
```
i = 1
```
```
Var( Xi )+ 2
```
```
∑ n −^1
```
```
i = 1
```
```
∑ n
```
```
j = i + 1
```
```
Cov( Xi , Xj )
```
##### =

```
∑ n
```
```
i = 1
```
```
( i − 1 )( n − i )
( n − 1 )^2
```
##### + 2

```
n ∑− 1
```
```
i = 1
```
```
∑ n
```
```
j = i + 1
```
```
( i − 1 )( j − n )
( n − 2 )( n − 1 )^2
```
##### =

##### 1

```
( n − 1 )^2
```
```
∑ n
```
```
i = 1
```
```
( i − 1 )( n − i )
```
##### −

##### 1

```
( n − 2 )( n − 1 )^2
```
```
n ∑− 1
```
```
i = 1
```
```
( i − 1 )( n − i )( n − i − 1 )
```
**7.13.** Let _Xi_ equal 1 if the _i_ th triple consists of one of each type of player. Then

```
E [ Xi ]=
```
##### (

##### 2

##### 1

##### )(

##### 3

##### 1

##### )(

##### 4

##### 1

##### )

##### (

##### 9

##### 3

##### ) =

##### 2

##### 7

```
Hence, for part (a), we obtain
```
##### E

##### ⎡

##### ⎣

##### ∑^3

```
i = 1
```
```
Xi
```
##### ⎤

##### ⎦= 6 / 7

```
It follows from the preceding that
```
```
Var( Xi )=( 2 / 7 )( 1 − 2 / 7 )= 10 / 49
```

**504** Solutions to Self-Test Problems and Exercises

```
Also, for i Z j ,
```
```
E [ XiXj ]= P { Xi =1, Xj = 1 }
= P { Xi = 1 } P { Xj = 1 | Xi = 1 }
```
##### =

##### (

##### 2

##### 1

##### )(

##### 3

##### 1

##### )(

##### 4

##### 1

##### )

##### (

##### 9

##### 3

##### )

##### (

##### 1

##### 1

##### )(

##### 2

##### 1

##### )(

##### 3

##### 1

##### )

##### (

##### 6

##### 3

##### )

##### = 6 / 70

```
Hence, for part (b), we obtain
```
```
Var
```
##### ⎛

##### ⎝

##### ∑^3

```
i = 1
```
```
Xi
```
##### ⎞

##### ⎠=

##### ∑^3

```
i = 1
```
```
Var( Xi )+ 2
```
##### ∑∑

```
j > 1
```
```
Cov( Xi , Xj )
```
##### = 30 / 49 + 2

##### (

##### 3

##### 2

##### )(

##### 6

##### 70

##### −

##### 4

##### 49

##### )

##### =

##### 312

##### 490

```
7.14. Let Xi , i =1,..., 13, equal 1 if the i th card is an ace and let Xi be 0 otherwise.
Let Yj equal 1 if the j th card is a spade and let i , j =1,..., 13, be 0 otherwise.
Now,
```
```
Cov( X , Y )=Cov
```
##### ⎛

##### ⎜

##### ⎝

```
∑ n
```
```
i = 1
```
```
Xi ,
```
```
∑ n
```
```
j = 1
```
```
Yj
```
##### ⎞

##### ⎟

##### ⎠

##### =

```
∑ n
```
```
i = 1
```
```
∑ n
```
```
j = 1
```
```
Cov( Xi , Yj )
```
```
However, Xi is clearly independent of Yj because knowing the suit of a par-
ticular card gives no information about whether it is an ace and thus cannot
affect the probability that another specified card is an ace. More formally, let
Ai , s , Ai , h , Ai , d , Ai , c be the events, respectively, that card i is a spade, a heart, a
diamond, and a club. Then
```
```
P { Yj = 1 }=
```
##### 1

##### 4

```
( P { Yj = 1 | Ai , s }+ P { Yj = 1 | Ai , h }
```
```
+ P { Yj = 1 | Ai , d }+ P { Yj = 1 | Ai , c })
```
```
But, by symmetry, we have
```
```
P { Yj = 1 | Ai , s }= P { Yj = 1 | Ai , h }= P { Yj = 1 | Ai , d }= P { Yj = 1 | Ai , c }
```
```
Therefore,
P { Yj = 1 }= P { Yj = 1 | Ai , s }
```
```
As the preceding implies that
```
```
P { Yj = 1 }= P { Yj = 1 | Aci , s }
```

```
Solutions to Self-Test Problems and Exercises 505
```
```
we see that Yj and Xi are independent. Hence, Cov( Xi , Yj ) = 0, and thus
Cov( X , Y )=0.
The random variables X and Y , although uncorrelated, are not indepen-
dent. This follows, for instance, from the fact that
```
```
P { Y = 13 | X = 4 }= 0 Z P { Y = 13 }
```
**7.15. (a)** Your expected gain without any information is 0.
**(b)** You should predict heads if _p_ > 1 /2 and tails otherwise.
**(c)** Conditioning on _V_ , the value of the coin, gives

```
E [Gain]=
```
##### ∫ 1

```
0
```
```
E [Gain| V = p ] dp
```
##### =

##### ∫ 1 / 2

```
0
```
```
[1( 1 − p )− 1 ( p )] dp +
```
##### ∫ 1

```
1 / 2
```
```
[1( p )− 1 ( 1 − p )] dp
```
```
= 1 / 2
```
**7.16.** Given that the name chosen appears in _n_ ( _X_ )different positions on the list,
since each of these positions is equally likely to be the one chosen, it fol-
lows that
_E_ [ _I_ | _n_ ( _X_ )]= _P_ { _I_ = 1 | _n_ ( _X_ )}= 1 / _n_ ( _X_ )

```
Hence,
E [ I ]= E [1/ n ( X )]
```
Thus, _E_ [ _mI_ ]= _E_ [ _m_ / _n_ ( _X_ )]= _d_.
**7.17.** Letting _Xi_ equal 1 if a collision occurs when the _i_ th item is placed, and letting
it equal 0 otherwise, we can express the total number of collisions _X_ as

##### X =

```
∑ m
```
```
i = 1
```
```
Xi
```
```
Therefore,
```
```
E [ X ]=
```
```
∑ m
```
```
i = 1
```
```
E [ Xi ]
```
```
To determine E [ Xi ], condition on the cell in which it is placed.
```
```
E [ Xi ]=
```
##### ∑

```
j
```
```
E [ Xi |placed in cell j ] pj
```
##### =

##### ∑

```
j
```
```
P { i causes collision|placed in cell j ] pj
```
##### =

##### ∑

```
j
```
```
[1−( 1 − pj ) i −^1 ] pj
```
##### = 1 −

##### ∑

```
j
```
```
( 1 − pj ) i −^1 pj
```
```
The next to last equality used the fact that, conditional on item i being placed
in cell j , item i will cause a collision if any of the preceding i −1 items were
put in cell j. Thus,
```

**506** Solutions to Self-Test Problems and Exercises

```
E [ X ]= m −
```
```
∑ m
```
```
i = 1
```
```
∑ n
```
```
j = 1
```
```
( 1 − pj ) i −^1 pj
```
```
Interchanging the order of the summations gives
```
```
E [ X ]= m − n +
```
```
∑ n
```
```
j = 1
```
```
( 1 − pj ) m
```
```
Looking at the result shows that we could have derived it more easily by taking
expectations of both sides of the identity
```
```
number of nonempty cells= m − X
```
```
The expected number of nonempty cells is then found by defining an indicator
variable for each cell, equal to 1 if that cell is nonempty and to 0 otherwise,
and then taking the expectation of the sum of these indicator variables.
7.18. Let L denote the length of the initial run. Conditioning on the first value gives
```
```
E [ L ]= E [ L |first value is one]
```
```
n
n + m
```
```
+ E [ L |first value is zero]
```
```
m
n + m
```
```
Now, if the first value is one, then the length of the run will be the position of
the first zero when considering the remaining n + m −1 values, of which n − 1
are ones and m are zeroes. (For instance, if the initial value of the remaining
n + m − 1 is zero, then L =1.) As a similar result is true given that the
first value is a zero, we obtain from the preceding, upon using the result from
Example 3e, that
```
##### E [ L ]=

```
n + m
m + 1
```
```
n
n + m
```
##### +

```
n + m
n + 1
```
```
m
n + m
=
```
```
n
m + 1
```
##### +

```
m
n + 1
```
```
7.19. Let X be the number of flips needed for both boxes to become empty, and let
Y denote the number of heads in the first n + m flips. Then
```
##### E [ X ]=

```
n ∑+ m
```
```
i = 0
```
```
E [ X | Y = i ] P { Y = i }
```
##### =

```
n ∑+ m
```
```
i = 0
```
```
E [ X | Y = i ]
```
##### (

```
n + m
i
```
##### )

```
pi ( 1 − p ) n + m − i
```
```
Now, if the number of heads in the first n + m flips is i , i ... n , then the number
of additional flips is the number of flips needed to obtain an additional n − i
heads. Similarly, if the number of heads in the first n + m flips is i , i > n ,
then, because there would have been a total of n + m − i < m tails, the
number of additional flips is the number needed to obtain an additional i − n
heads. Since the number of flips needed for j outcomes of a particular type is a
negative binomial random variable whose mean is j divided by the probability
of that outcome, we obtain
```

```
Solutions to Self-Test Problems and Exercises 507
```
##### E [ X ]=

```
∑ n
```
```
i = 0
```
```
n − i
p
```
##### (

```
n + m
i
```
##### )

```
pi ( 1 − p ) n + m − i
```
##### +

```
n ∑+ m
```
```
i = n + 1
```
```
i − n
1 − p
```
##### (

```
n + m
i
```
##### )

```
pi ( 1 − p ) n + m − i
```
**7.20.** Taking expectations of both sides of the identity given in the hint yields

```
E [ Xn ]= E
```
##### [

```
n
```
```
∫q
```
```
0
```
```
xn −^1 IX ( x ) dx
```
##### ]

```
= n
```
```
∫q
```
```
0
```
```
E [ xn −^1 IX ( x )] dx
```
```
= n
```
```
∫q
```
```
0
```
```
xn −^1 E [ IX ( x )] dx
```
```
= n
```
```
∫q
```
```
0
```
```
xn −^1 F ( x ) dx
```
Taking the expectation inside the integral sign is justified because all the ran-
dom variables _IX_ ( _x_ ),0< _x_ <q, are nonnegative.
**7.21.** Consider a random permutation _I_ 1 ,..., _In_ that is equally likely to be any of the
_n_! permutations. Then

```
E [ aIjaIj + 1 ]=
```
##### ∑

```
k
```
```
E [ aIjaIj + 1 | Ij = k ] P { Ij = k }
```
##### =

##### 1

```
n
```
##### ∑

```
k
```
```
akE [ aIj + 1 | Ij = k ]
```
##### =

##### 1

```
n
```
##### ∑

```
k
```
```
ak
```
##### ∑

```
i
```
```
aiP { Ij + 1 = i | Ij = k }
```
##### =

##### 1

```
n ( n − 1 )
```
##### ∑

```
k
```
```
ak
```
##### ∑

```
i Z k
```
```
ai
```
##### =

##### 1

```
n ( n − 1 )
```
##### ∑

```
k
```
```
ak (− ak )
```
##### < 0

```
where the final equality followed from the assumption that
```
```
∑ n
i = 1 ai =^0 .Since
the preceding shows that
```
##### E

##### ⎡

##### ⎢

##### ⎣

```
∑ n
```
```
j = 1
```
```
aIjaIj + 1
```
##### ⎤

##### ⎥

##### ⎦<^0

```
it follows that there must be some permutation i 1 ,..., in for which
```
```
∑ n
```
```
j = 1
```
```
aijaij + 1 < 0
```

**508** Solutions to Self-Test Problems and Exercises

```
7.22. (a) E [ X ]=λ 1 +λ 2 , E [ X ]=λ 2 +λ 3
(b)
```
```
Cov( X , Y )=Cov( X 1 + X 2 , X 2 + X 3 )
=Cov( X 1 , X 2 + X 3 )+Cov( X 2 , X 2 + X 3 )
=Cov( X 2 , X 2 )
=Var( X 2 )
=λ 2
```
```
(c) Conditioning on X 2 gives
```
```
P { X = i , Y = j }=
```
##### ∑

```
k
```
```
P { X = i , Y = j | X 2 = k } P { X 2 = k }
```
##### =

##### ∑

```
k
```
```
P { X 1 = i − k , X 3 = j − k | X 2 = k } e −λ^2 λ k 2 / k!
```
##### =

##### ∑

```
k
```
```
P { X 1 = i − k , X 3 = j − k } e −λ^2 λ k 2 / k!
```
##### =

##### ∑

```
k
```
```
P { X 1 = i − k } P { X 3 = j − k } e −λ^2 λ k 2 / k!
```
##### =

```
min∑( i , j )
```
```
k = 0
```
```
e −λ^1
```
```
λ i 1 − k
( i − k )!
```
```
e −λ^3
```
```
λ j 3 − k
( j − k )!
```
```
e −λ^2
```
```
λ k 2
k!
```
##### 7.23.

```
Corr
```
##### ⎛

##### ⎝

##### ∑

```
i
```
```
Xi ,
```
##### ∑

```
j
```
```
Yj
```
##### ⎞

##### ⎠=

```
Cov(
```
##### ∑

```
iXi ,
```
##### ∑

```
jYj )
√
Var(
```
##### ∑

```
iXi )Var(
```
##### ∑

```
jYj )
```
##### =

##### ∑

```
i
```
##### ∑

```
j Cov( Xi , Yj )
√
n σ x^2 n σ y^2
```
##### =

##### ∑

```
i Cov( Xi , Yi )+
```
##### ∑

```
i
```
##### ∑

```
j Z i Cov( Xi , Yj )
n σ x σ y
```
```
=
```
```
n ρσ x σ y
n σ x σ y
=ρ
```
```
where the next to last equality used the fact that Cov( Xi , Yi )=ρσ x σ y
```
```
7.24. Let Xi equal 1 if the i th card chosen is an ace, and let it equal 0 otherwise.
Because
```
##### X =

##### ∑^3

```
i = 1
```
```
Xi
```
```
and E [ Xi ]= P { Xi = 1 }= 1 /13, it follows that E [ X ]= 3 /13. But, with A being
the event that the ace of spades is chosen, we have
```

```
Solutions to Self-Test Problems and Exercises 509
```
```
E [ X ]= E [ X | A ] P ( A )+ E [ X | Ac ] P ( Ac )
```
```
= E [ X | A ]
```
##### 3

##### 52

```
+ E [ X | Ac ]
```
##### 49

##### 52

##### = E [ X | A ]

##### 3

##### 52

##### +

##### 49

##### 52

##### E

##### ⎡

##### ⎣

##### ∑^3

```
i = 1
```
```
Xi | Ac
```
##### ⎤

##### ⎦

##### = E [ X | A ]

##### 3

##### 52

##### +

##### 49

##### 52

##### ∑^3

```
i = 1
```
```
E [ Xi | Ac ]
```
##### = E [ X | A ]

##### 3

##### 52

##### +

##### 49

##### 52

##### 3

##### 3

##### 51

Using that _E_ [ _X_ ]= 3 /13 gives the result

##### E [ X | A ]=

##### 52

##### 3

##### (

##### 3

##### 13

##### −

##### 49

##### 52

##### 3

##### 17

##### )

##### =

##### 19

##### 17

##### = 1. 1176

Similarly, letting _L_ be the event that at least one ace is chosen, we have

```
E [ X ]= E [ X | L ] P ( L )+ E [ X | Lc ] P ( Lc )
= E [ X | L ] P ( L )
```
```
= E [ X | L ]
```
##### (

##### 1 −

##### 48 · 47 · 46

##### 52 · 51 · 50

##### )

Thus,

```
E [ X | L ]=
```
##### 3 / 13

##### 1 −^4852 ··^4751 ··^4650

##### L 1. 0616

Another way to solve this problem is to number the four aces, with the ace of
spades having number 1, and then let _Yi_ equal 1 if ace number _i_ is chosen and
0 otherwise. Then

##### E [ X | A ]= E

##### ⎡

##### ⎣

##### ∑^4

```
i = 1
```
```
Yi | Y 1 = 1
```
##### ⎤

##### ⎦

##### = 1 +

##### ∑^4

```
i = 2
```
```
E [ Yi | Y 1 =1]
```
##### = 1 + 3 ·

##### 2

##### 51

##### = 19 / 17

where we used that the fact given that the ace of spades is chosen the other
two cards are equally likely to be any pair of the remaining 51 cards; so the
conditional probability that any specified card (not equal to the ace of spades)
is chosen is 2/51. Also,

##### E [ X | L ]= E

##### ⎡

##### ⎣

##### ∑^4

```
i = 1
```
```
Yi | L
```
##### ⎤

##### ⎦=

##### ∑^4

```
i = 1
```
```
E [ Yi | L ]= 4 P { Y 1 = 1 | L }
```
Because

```
P { Y 1 = 1 | L }= P ( A | L )=
```
##### P ( AL )

##### P ( L )

##### =

##### P ( A )

##### P ( L )

##### =

##### 3 / 52

##### 1 −^4852 ··^4751 ··^4650

we obtain the same answer as before.


**510** Solutions to Self-Test Problems and Exercises

```
7.25. (a) E [ I | X = x ]= P { Z < X | X = x }= P { Z < x | X = x }= P { Z < x }=
( x )
(b) It follows from part (a) that E [ I | X ]=
( X ). Therefore,
```
```
E [ I ]= E [ E [ I | X ]]= E [
( X )]
```
```
The result now follows because E [ I ]= P { I = 1 }= P { Z < X }.
(c) Since X − Z is normal with meanμand variance 2, we have
```
```
P { X > Z }= P { X − Z > 0 }
```
```
= P
```
##### {

```
X − Z −μ
2
```
##### >

```
−μ
2
```
##### }

##### = 1 −

##### (

```
−μ
2
```
##### )

##### =

##### (

```
μ
2
```
##### )

```
7.26. Let N be the number of heads in the first n + m −1 flips. Let M =max( X , Y )
be the number of flips needed to amass at least n heads and at least m tails.
Conditioning on N gives
```
```
E [ M ]=
```
##### ∑

```
i
```
```
E [ M | N = i ] P { N = i }
```
##### =

```
n ∑− 1
```
```
i = 0
```
```
E [ M | N = i ] P { N = i }+
```
```
n +∑ m − 1
```
```
i = n
```
```
E [ M | N = i ] P { N = i }
```
```
Now, suppose we are given that there are a total of i heads in the first n + m − 1
trials. If i < n , then we have already obtained at least m tails, so the additional
number of flips needed is equal to the number needed for an additional n − i
heads; similarly, if i Ú n , then we have already obtained at least n heads, so
the additional number of flips needed is equal to the number needed for an
additional m −( n + m − 1 − i )tails. Consequently, we have
```
##### E [ M ]=

```
n ∑− 1
```
```
i = 0
```
##### (

```
n + m − 1 +
```
```
n − i
p
```
##### )

```
P { N = i }
```
##### +

```
n +∑ m − 1
```
```
i = n
```
##### (

```
n + m − 1 +
```
```
i + 1 − n
1 − p
```
##### )

```
P { N = i }
```
```
= n + m − 1 +
```
```
n ∑− 1
```
```
i = 0
```
```
n − i
p
```
##### (

```
n + m − 1
i
```
##### )

```
pi ( 1 − p ) n + m −^1 − i
```
##### +

```
n +∑ m − 1
```
```
i = n
```
```
i + 1 − n
1 − p
```
##### (

```
n + m − 1
i
```
##### )

```
pi ( 1 − p ) n + m −^1 − i
```
```
The expected number of flips to obtain either n heads or m tails, E [min( X , Y )],
is now given by
```
```
E [min( X , Y )]= E [ X + Y − M ]=
```
```
n
p
```
##### +

```
m
1 − p
```
##### − E [ M ]


```
Solutions to Self-Test Problems and Exercises 511
```
```
7.27. This is just the expected time to collect n −1ofthe n types of coupons in
Example 2 i. By the results of that example the solution is
```
##### 1 +

```
n
n − 1
```
##### +

```
n
n − 2
```
##### +...+

```
n
2
```
```
7.28. With q = 1 − p ,
```
##### E [ X ]=

```
∑q
```
```
i = 1
```
```
P { X Ú i }=
```
```
∑ n
```
```
i = 1
```
```
P { X Ú i }=
```
```
∑ n
```
```
i = 1
```
```
qi −^1 =
```
```
1 − qn
p
```
##### 7.29.

```
Cov( X , Y )= E [ XY ]− E [ X ] E [ Y ]= P ( X =1, Y = 1 )− P ( X = 1 ) P ( Y = 1 )
```
```
Hence,
```
```
Cov( X , Y )= 0 3 P ( X =1, Y = 1 )= P ( X = 1 ) P ( Y = 1 )
```
```
Because
```
```
Cov( X , Y )=Cov( 1 − X ,1− Y )=−Cov( 1 − X , Y )=−Cov( X ,1− Y )
```
```
the preceding shows that all of the following are equivalent when X and Y are
Bernoulli:
```
1. Cov( _X_ , _Y_ )= 0
2. _P_ ( _X_ =1, _Y_ = 1 )= _P_ ( _X_ = 1 ) _P_ ( _Y_ = 1 )
3. _P_ ( 1 − _X_ =1, 1− _Y_ = 1 )= _P_ ( 1 − _X_ = 1 ) _P_ ( 1 − _Y_ = 1 )
4. _P_ ( 1 − _X_ =1, _Y_ = 1 )= _P_ ( 1 − _X_ = 1 ) _P_ ( _Y_ = 1 )
5. _P_ ( _X_ =1, 1− _Y_ = 1 )= _P_ ( _X_ = 1 ) _P_ ( 1 − _Y_ = 1 )

```
7.30. Number the individuals, and let Xi , j equal 1 if the j th individual who has hat
size i chooses a hat of that size, and let Xi , j equal 0 otherwise. Then the number
of individuals who choose a hat of their size is
```
##### X =

```
∑ r
```
```
i = 1
```
```
∑ ni
```
```
j = 1
```
```
Xi , j
```
```
Hence,
```
```
E [ X ]=
```
```
∑ r
```
```
i = 1
```
```
∑ ni
```
```
j = 1
```
```
E [ Xi , j ]=
```
```
∑ r
```
```
i = 1
```
```
∑ ni
```
```
j = 1
```
```
hi
n
```
##### =

##### 1

```
n
```
```
∑ r
```
```
i = 1
```
```
hini
```
##### CHAPTER 8

```
8.1. Let X denote the number of sales made next week, and note that X is integral.
From Markov’s inequality, we obtain the following:
(a) P { X > 18 }= P { X Ú 19 }...
```
##### E [ X ]

##### 19

##### = 16 / 19

```
(b) P { X > 25 }= P { X Ú 26 }...
```
##### E [ X ]

##### 26

##### = 16 / 26


**512** Solutions to Self-Test Problems and Exercises

```
8.2. (a)
```
```
P { 10 ... X ... 22 }= P {| X − 16 |... 6 }
= P {| X −μ|... 6 }
= 1 − P {| X −μ|> 6 }
Ú 1 − 9 / 36 = 3 / 4
```
```
(b) P { X Ú 19 }= P { X − 16 Ú 3 }...
```
##### 9

##### 9 + 9

##### = 1 / 2

```
In part (a), we used Chebyshev’s inequality; in part (b), we used its
one-sided version. (See Proposition 5.1.)
```
```
8.3. First note that E [ X − Y ]=0and
```
```
Var( X − Y )=Var( X )+Var( Y )−2Cov( X , Y )= 28
```
```
Using Chebyshev’s inequality in part (a) and the one-sided version in parts (b)
and (c) gives the following results:
(a) P {| X − Y |> 15 }... 28 / 225
(b) P { X − Y > 15 }...
```
##### 28

##### 28 + 225

##### = 28 / 253

```
(c) P { Y − X > 15 }...
```
##### 28

##### 28 + 225

##### = 28 / 253

```
8.4. If X is the number produced at factory A and Y the number produced at fac-
tory B ,then
```
```
E [ Y − X ]=−2, Var( Y − X )= 36 + 9 = 45
```
```
P { Y − X > 0 }= P { Y − X Ú 1 }= P { Y − X + 2 Ú 3 }...
```
##### 45

##### 45 + 9

##### = 45 / 54

```
8.5. Note first that
```
```
E [ Xi ]=
```
##### ∫ 1

```
0
```
```
2 x^2 dx = 2 / 3
```
```
Now use the strong law of large numbers to obtain
```
```
r = lim
n →q
```
```
n
Sn
```
```
= lim
n →q
```
##### 1

```
Sn / n
```
```
=
```
##### 1

```
lim
n →q
```
```
Sn / n
```
```
= 1 /( 2 / 3 )= 3 / 2
```
```
8.6. Because E [ Xi ]= 2 /3and
```
```
E [ Xi^2 ]=
```
##### ∫ 1

```
0
```
```
2 x^3 dx = 1 / 2
```

```
Solutions to Self-Test Problems and Exercises 513
```
```
we have Var( Xi )= 1 / 2 −( 2 / 3 )^2 = 1 /18. Thus, if there are n components on
hand, then
```
```
P { Sn Ú 35 }= P { Sn Ú 34. 5 } (the continuity correction)
```
##### = P

##### {

```
Sn − 2 n / 3
√
n / 18
```
##### ...

```
34. 5 − 2 n / 3
√
n / 18
```
##### }

##### L P

##### {

##### Z Ú

```
34. 5 − 2 n / 3
√
n / 18
```
##### }

```
where Z is a standard normal random variable. Since
```
```
P { Z >− 1. 284 }= P { Z < 1. 284 }L. 90
```
```
we see that n should be chosen so that
```
```
( 34. 5 − 2 n / 3 )L− 1. 284
```
##### √

```
n / 18
```
```
A numerical computation gives the result n =55.
```
**8.7.** If _X_ is the time required to service a machine, then

```
E [ X ]=. 2 +. 3 =. 5
```
```
Also, since the variance of an exponential random variable is equal to the
square of its mean, we have
```
```
Var( X )=(. 2 )^2 +(. 3 )^2 =. 13
```
```
Therefore, with Xi being the time required to service job i , i =1,..., 20, and Z
being a standard normal random variable, it follows that
```
##### P { X 1 + ··· + X 20 < 8 }= P

##### {

##### X 1 + ··· + X 20 − 10

##### √

##### 2. 6

##### <

##### 8 − 10

##### √

##### 2. 6

##### }

##### L P { Z <− 1. 24035 }

##### L. 1074

**8.8.** Note first that if _X_ is the gambler’s winnings on a single bet, then

```
E [ X ]=−. 7 −. 4 + 1 =−.1, E [ X^2 ]=. 7 +. 8 + 10 = 11. 5
→Var( X )= 11. 49
```
```
Therefore, with Z having a standard normal distribution,
```
##### P { X 1 + ··· + X 100 ...−. 5 }= P

##### {

##### X 1 + ··· + X 100 + 10

##### √

##### 1149

##### ...

##### −. 5 + 10

##### √

##### 1149

##### }

##### L P { Z .... 2803 }

##### L. 6104


**514** Solutions to Self-Test Problems and Exercises

```
8.9. Using the notation of Problem 7, we have
```
```
P { X 1 + ··· + X 20 < t }= P
```
##### {

##### X 1 + ··· + X 20 − 10

##### √

##### 2. 6

##### <

```
t − 10
√
2. 6
```
##### }

##### L P

##### {

##### Z <

```
t − 10
√
2. 6
```
##### }

```
Now, P { Z < 1. 645 }L.95, so t should be such that
```
```
t − 10
√
2. 6
```
##### L 1. 645

```
which yields t L 12 .65.
```
```
8.10. If the claim were true, then, by the central limit theorem, the average nicotine
content (call it X ) would approximately have a normal distribution with mean
2.2 and standard deviation .03. Thus, the probability that it would be as high
as 3.1 is
```
##### P { X > 3. 1 }= P

##### {

##### X − 2. 2

##### √

##### . 03

##### >

##### 3. 1 − 2. 2

##### √

##### . 03

##### }

##### L P { Z > 5. 196 }

##### L 0

```
where Z is a standard normal random variable.
8.11. (a) If we arbitrarily number the batteries and let Xi denote the life of battery
i , i =1,..., 40, then the Xi are independent and identically distributed
random variables. To compute the mean and variance of the life of, say,
battery 1, we condition on its type. Letting I equal 1 if battery 1 is type A
and letting it equal 0 if it is type B , we have
```
```
E [ X 1 | I =1]=50 , E [ X 1 | I =0]= 30
```
```
yielding
```
```
E [ X 1 ]= 50 P { I = 1 }+ 30 P { I = 0 }= 50 ( 1 / 2 )+ 30 ( 1 / 2 )= 40
```
```
In addition, using the fact that E [ W^2 ]=( E [ W ])^2 +Var( W ), we have
```
```
E [ X 12 | I =1]=( 50 )^2 +( 15 )^2 =2725 , E [ X 12 | I =0]=( 30 )^2 + 62 = 936
```
```
yielding
```
```
E [ X^21 ]=( 2725 )( 1 / 2 )+( 936 )( 1 / 2 )= 1830. 5
```
```
Thus, X 1 ,..., X 40 are independent and identically distributed random
variables having mean 40 and variance 1830. 5 − 1600 = 230 .5. Hence,
with S =
```
##### ∑ 40

```
i = 1 Xi , we have
```
```
E [ S ]= 40 ( 40 )=1600 , Var( S )= 40 ( 230. 5 )= 9220
```

```
Solutions to Self-Test Problems and Exercises 515
```
```
and the central limit theorem yields
```
##### P { S > 1700 }= P

##### {

##### S − 1600

##### √

##### 9220

##### >

##### 1700 − 1600

##### √

##### 9220

##### }

##### L P { Z > 1. 041 }

##### = 1 −
( 1. 041 )=. 149

```
(b) For this part, let SA be the total life of all the type A batteries and let SB be
the total life of all the type B batteries. Then, by the central limit theorem,
SA has approximately a normal distribution with mean 20( 50 )=1000 and
variance 20( 225 )=4500, and SB has approximately a normal distribution
with mean 20( 30 )=600 and variance 20( 36 )= 720 .Because the sum of
independent normal random variables is also a normal random variable,
it follows that SA + SB is approximately normal with mean 1600 and
variance 5220. Consequently, with S = SA + SB ,
```
##### P { S > 1700 }= P

##### {

##### S − 1600

##### √

##### 5220

##### >

##### 1700 − 1600

##### √

##### 5220

##### }

##### L P { Z > 1. 384 }

##### = 1 −
( 1. 384 )=. 084

**8.12.** Let _N_ denote the number of doctors who volunteer. Conditional on the event
_N_ = _i_ , the number of patients seen is distributed as the sum of _i_ indepen-
dent Poisson random variables with common mean 30. Because the sum of
independent Poisson random variables is also a Poisson random variable, it
follows that the conditional distribution of _X_ given that _N_ = _i_ is Poisson with
mean 30 _i_. Therefore,

```
E [ X | N ]= 30 N Var( X | N )= 30 N
```
```
As a result,
E [ X ]= E [ E [ X | N ]]= 30 E [ N ]= 90
```
```
Also, by the conditional variance formula,
```
```
Var( X )= E [Var( X | N )] +Var( E [ X | N ])= 30 E [ N ]+( 30 )^2 Var( N )
```
```
Because
```
```
Var( N )=
```
##### 1

##### 3

##### ( 22 + 32 + 42 )− 9 = 2 / 3

```
we obtain Var( X )=690.
To approximate P { X > 65 }, we would not be justified in assuming that the
distribution of X is approximately that of a normal random variable with mean
90 and variance 690. What we do know, however, is that
```
##### P { X > 65 }=

##### ∑^4

```
i = 2
```
```
P { X > 65 | N = i } P { N = i }=
```
##### 1

##### 3

##### ∑^4

```
i = 2
```
```
Pi ( 65 )
```

**516** Solutions to Self-Test Problems and Exercises

```
where Pi ( 65 )is the probability that a Poisson random variable with mean 30 i
is greater than 65. That is,
```
```
Pi ( 65 )= 1 −
```
##### ∑^65

```
j = 0
```
```
e −^30 i ( 30 i ) j / j!
```
```
Because a Poisson random variable with mean 30 i has the same distribution
as does the sum of 30 i independent Poisson random variables with mean 1,
it follows from the central limit theorem that its distribution is approximately
normal with mean and variance equal to 30 i. Consequently, with Xi being a
Poisson random variable with mean 30 i and Z being a standard normal ran-
dom variable, we can approximate Pi ( 65 )as follows:
```
```
Pi ( 65 )= P { X > 65 }
= P { X Ú 65. 5 }
```
##### = P

##### {

```
X − 30 i
√
30 i
```
##### Ú

```
65. 5 − 30 i
√
30 i
```
##### }

##### L P

##### {

##### Z Ú

```
65. 5 − 30 i
√
30 i
```
##### }

```
Therefore,
P 2 ( 65 )L P { Z Ú. 7100 }L. 2389
P 3 ( 65 )L P { Z Ú− 2. 583 }L. 9951
P 4 ( 65 )L P { Z Ú− 4. 975 }L 1
```
```
leading to the result
P { X > 65 }L. 7447
```
```
If we would have mistakenly assumed that X was approximately normal, we
would have obtained the approximate answer .8244. (The exact probability is
.7440.)
8.13. Take logarithms and then apply the strong law of large numbers to obtain
```
```
log
```
##### ⎡

##### ⎢

##### ⎣

##### ⎛

##### ⎝

```
∏ n
```
```
i = 1
```
```
Xi
```
##### ⎞

##### ⎠

```
1 / n
```
##### ⎤

##### ⎥

##### ⎦=

##### 1

```
n
```
```
∑ n
```
```
i = 1
```
```
log( Xi )→ E [log( Xi )]
```
```
Therefore, ⎛
```
```
⎝
```
```
∏ n
```
```
i = 1
```
```
Xi
```
##### ⎞

##### ⎠

```
1 / n
→ eE [log( Xi )]
```
##### CHAPTER 9

```
9.1. From axiom (iii), it follows that the number of events that occur between times
8 and 10 has the same distribution as the number of events that occur by time
2 and thus is a Poisson random variable with mean 6. Hence, we obtain the
following solutions for parts (a) and (b):
(a) P { N ( 10 )− N ( 8 )= 0 }= e −^6
(b) E [ N ( 10 )− N ( 8 )]= 6
```

```
Solutions to Self-Test Problems and Exercises 517
```
**(c)** It follows from axioms (ii) and (iii) that, from any point in time onward,
the process of events occurring is a Poisson process with rateλ. Hence,
the expected time of the fifth event after 2P.M.is 2+ _E_ [ _S_ 5 ]= 2 + 5 /3.
That is, the expected time of this event is 3:40P.M.
**9.2. (a)**

```
P { N ( 1 / 3 )= 2 | N ( 1 )= 2 }
```
```
=
```
##### P { N ( 1 / 3 )=2, N ( 1 )= 2 }

##### P { N ( 1 )= 2 }

##### =

##### P { N ( 1 / 3 )=2, N ( 1 )− N ( 1 / 3 )= 0 }

##### P { N ( 1 )= 2 }

##### =

##### P { N ( 1 / 3 )= 2 } P { N ( 1 )− N ( 1 / 3 )= 0 }

##### P { N ( 1 )= 2 }

```
(by axiom( ii ))
```
##### =

##### P { N ( 1 / 3 )= 2 } P { N ( 2 / 3 )= 0 }

##### P { N ( 1 )= 2 }

```
(by axiom( iii ))
```
##### =

```
e −λ/^3 (λ/ 3 )^2 /2! e −^2 λ/^3
e −λλ^2 /2!
= 1 / 9
(b)
```
```
P { N ( 1 / 2 )Ú 1 | N ( 1 )= 2 }= 1 − P { N ( 1 / 2 )= 0 | N ( 1 )= 2 }
```
```
= 1 −
```
##### P { N ( 1 / 2 )=0, N ( 1 )= 2 }

##### P { N ( 1 )= 2 }

##### = 1 −

##### P { N ( 1 / 2 )=0, N ( 1 )− N ( 1 / 2 )= 2 }

##### P { N ( 1 )= 2 }

##### = 1 −

##### P { N ( 1 / 2 )= 0 } P { N ( 1 )− N ( 1 / 2 )= 2 }

##### P { N ( 1 )= 2 }

##### = 1 −

##### P { N ( 1 / 2 )= 0 } P { N ( 1 / 2 )= 2 }

##### P { N ( 1 )= 2 }

##### = 1 −

```
e −λ/^2 e −λ/^2 (λ/ 2 )^2 /2!
e −λλ^2 /2!
= 1 − 1 / 4 = 3 / 4
```
**9.3.** Fix a point on the road and let _Xn_ equal 0 if the _n_ th vehicle to pass is a car
and let it equal 1 if it is a truck, _n_ Ú 1. We now suppose that the sequence
_Xn_ , _n_ Ú1, is a Markov chain with transition probabilities

```
P 0,0= 5 /6, P 0,1= 1 /6, P 1,0= 4 /5, P 1,1= 1 / 5
```
```
Then the long-run proportion of times is the solution of
π 0 =π 0 ( 5 / 6 )+π 1 ( 4 / 5 )
π 1 =π 0 ( 1 / 6 )+π 1 ( 1 / 5 )
π 0 +π 1 = 1
```
```
Solving the preceding equations gives
```
```
π 0 = 24 / 29 π 1 = 5 / 29
```
```
Thus, 2400/ 29 L83 percent of the vehicles on the road are cars.
```

**518** Solutions to Self-Test Problems and Exercises

```
9.4. The successive weather classifications constitute a Markov chain. If the states
are 0 for rainy, 1 for sunny, and 2 for overcast, then the transition probability
matrix is as follows:
```
##### P =

##### 01 / 21 / 2

##### 1 / 31 / 31 / 3

##### 1 / 31 / 31 / 3

```
The long-run proportions satisfy
```
```
π 0 =π 1 ( 1 / 3 )+π 2 ( 1 / 3 )
π 1 =π 0 ( 1 / 2 )+π 1 ( 1 / 3 )+π 2 ( 1 / 3 )
π 2 =π 0 ( 1 / 2 )+π 1 ( 1 / 3 )+π 2 ( 1 / 3 )
1 =π 0 +π 1 +π 2
```
```
The solution of the preceding system of equations is
```
```
π 0 = 1 /4, π 1 = 3 /8, π 2 = 3 / 8
```
```
Hence, three-eighths of the days are sunny and one-fourth are rainy.
9.5. (a) A direct computation yields
```
```
H ( X )/ H ( Y )L 1. 06
```
```
(b) Both random variables take on two of their values with the same prob-
abilities .35 and .05. The difference is that if they do not take on either
of those values, then X , but not Y , is equally likely to take on any of its
three remaining possible values. Hence, from Theoretical Exercise 13, we
would expect the result of part (a).
```
##### CHAPTER 10

```
10.1. (a)
```
```
1 = C
```
##### ∫ 1

```
0
```
```
exdx * C = 1 /( e − 1 )
```
```
(b)
F ( x )= C
```
```
∫ x
```
```
0
```
```
eydy =
```
```
ex − 1
e − 1
```
```
,0... x ... 1
```
```
Hence, if we let X = F −^1 ( U ),then
```
##### U =

```
eX − 1
e − 1
or
X =log( U ( e − 1 )+ 1 )
```
```
Thus, we can simulate the random variable X by generating a random
number U and then setting X =log( U ( e − 1 )+ 1 ).
10.2. Use the acceptance–rejection method with g ( x )=1, 0< x <1. Calculus shows
that the maximum value of f ( x )/ g ( x )occurs at a value of x ,0< x <1, such that
```
```
2 x − 6 x^2 + 4 x^3 = 0
```

```
Solutions to Self-Test Problems and Exercises 519
```
```
or, equivalently, when
```
```
4 x^2 − 6 x + 2 =( 4 x − 2 )( x − 1 )= 0
```
```
The maximum thus occurs when x = 1 /2, and it follows that
```
```
C =max f ( x )/ g ( x )= 30 ( 1 / 4 − 2 / 8 + 1 / 16 )= 15 / 8
```
```
Hence, the algorithm is as follows:
Step 1. Generate a random number U 1.
Step 2. Generate a random number U 2.
Step 3. If U 2 ... 16 ( U 12 − 2 U 13 + U^41 ), set X = U 1 ; else return to Step 1.
```
**10.3.** It is most efficient to check the higher probability values first, as in the follow-
ing algorithm:
**Step 1.** Generate a random number _U_.
**Step 2.** If _U_ ....35, set _X_ =3 and stop.
**Step 3.** If _U_ ....65, set _X_ =4 and stop.
**Step 4.** If _U_ ....85, set _X_ =2 and stop.
**Step 5.** _X_ =1.

**10.4.** 2 μ− _X_
**10.5. (a)** Generate 2 _n_ independent exponential random variables with mean 1, _Xi_ , _Yi_ , _i_ =

```
1,..., n , and then use the estimator
```
```
∑ n
i = 1
```
```
eXiYi / n.
```
```
(b) We can use XY as a control variate to obtain an estimator of the type
```
```
∑ n
```
```
i = 1
```
```
( eXiYi + cXiYi )/ n
```
```
Another possibility would be to use XY + X^2 Y^2 /2 as the control variate
and so obtain an estimator of the type
```
```
∑ n
```
```
i = 1
```
```
( eXiYi + c [ XiYi + X^2 iYi^2 / 2 − 1 /2])/ n
```
```
The motivation behind the preceding formula is based on the fact that the
first three terms of the MacLaurin series expansion of exy are 1+ xy +
( x^2 y^2 )/2.
```

_This page intentionally left blank_


### Index

```
A
Absolutely continuous random
variables, See Continuous
random variables
Algorithm, polar, 453
Analytical Theory of Probability
(Laplace), 399
Answers to selected problems,
456–457
Antithetic variables, variance
reduction, 450–451
Archimedes, 208
Ars Conjectandi (The Art of
Conjecturing), 142, 391
Associative laws, 25
Axiom, defined, 27
Axioms of probability, 26–29
```
```
B
Banach match problem, 158–159
Basic principle of counting, 1–3
proof of, 2
Bayes, Thomas, 74
Bayes’s formula, 65–79, 101
Bell, E. T., 208
Bernoulli, Jacques, 142–143
Bernoulli, James, 134, 143, 391
Bernoulli, Nicholas, 391
Bernoulli random variables,
134–139, 403
Bernoulli trials, 112
Bernstein polynomials, 414
Bertrand, Joseph L. F., 197
Bertrand’s paradox, 197
Best-prize problem, 344–346
Beta distribution, 218–219
Binary symmetric channel, 433
Binomial coefficients, 7, 15
Binomial distribution, normal
approximation to, 204–207
Binomial random variables,
134–139, 259–260
```
```
binomial distribution function,
computing, 142–143
moments of, 316–317
properties of, 139–141
simulating, 448
variance of, 325–331
Binomial theorem, 7
combinatorial proof of, 8–9
proof by mathematical
induction, 8
Bits, 426
Bivariate normal distribution,
268–269
Boole’s inequality, 300–301
Borel,E., 403 ́
Box–Muller approach, 445
Branching process, 383
Buffon’s needle problem,
243–246
```
```
C
Cantor distribution, 381
Cauchy distribution, 217–218
Center of gravity, 128
Central limit theorem, 198, 412
Channel capacity, 434, 436
Chapman–Kolmogorov equations,
421–423
Chebyshev’s inequality:
defined, 389
one-sided, 403–407
and weak law of large numbers,
388–391
Chernoff bounds, 407–409
Chi-squared distribution, 216, 255
Chi-squared random variable,
simulating, 446–447
Coding theory:
binary symmetric channel, 433
and entropy, 428–434
noiseless coding theorem,
429–431, 433–434
```
```
521
```

**522** Index

```
Combinatorial analysis, 1–21
combinations, 5–9
integer solutions of equations,
number of, 12–15
multinomial coefficients, 9–12
permutations, 3–5
principle of counting, 1–3
Combinatorial identity, 7
Commutative laws, 25
Complement, 24, 49
Conditional covariance formula,
372, 381
Conditional distributions:
continuous case, 266–274
bivariate normal distribution,
268–269
discrete case, 263–266
Conditional expectation, 331–349,
371
computing expectations by
conditioning, 333–343
computing probabilities by
conditioning, 344–347
best-prize problem, 344–346
conditional variance, 347–349
definitions, 331–333
and prediction, 349–353
Conditional independence, 98
Conditional probability, 58–65
Bayes’s formula, 65–79
independent events, 79–93
Conditional probability density
function, 286
Conditional probability mass
function, 286
Conditional variance, 347–349
variance of a sum of a random
number of random
variables, 349
Conditional variance formula, 372
Conditioning:
computing expectations by,
333–343
computing probabilities by,
344–347
best-prize problem, 344–346
variance reduction by, 451–452
```
```
Continuity correction, 205
Continuous random variables,
186–231
beta distribution, 218–219
Cauchy distribution, 217–218
expectation of, 190–194
gamma distribution, 215–216
simulation of:
general techniques for,
440–447
inverse transformation
method, 441–442, 453
rejection method, 442–444,
453–454
Weibull distribution, 216–217
Control variates, variance reduction,
452–453
Convolution, 252
Correlation, 371
Correlation coefficient, 322–331
Counting, basic principle of, 1–3
proof of, 2
Coupon-collecting problem,
318–319
singletons in, 321–322
Coupon collecting with unequal
probabilities, 314–315
Covariance, 322–323, 371
defined, 322
Cumulative distribution function
(distribution function),
123–125
properties, 168–170
```
```
D
DeMoivre, Abraham, 198, 207–208,
393
DeMoivre–Laplace limit theorem,
204
DeMorgan’s laws, 26
Dependent random variables, 241
Deviations, 324
Discrete distributions:
simulation from, 447–449
binomial random variable,
448
```

```
Index 523
```
geometric distribution,
447–448
Poisson random variable, 449
Discrete probability distribution,
358
Discrete random variables, 123–125,
171
Distribution function (distribution
function), 123, 170
Distributions:
beta, 218-219
binomial, normal
approximation to, 204-207
bivariate normal, 268-269
Cantor, 381
Cauchy, 217-218
chi-squared, 216, 255
conditional, 263-274
continuous probability, 359
discreet, 447-449
discrete probability, 358
gamma, 215-216
Gaussian, 207
geometric, 447-448
Laplace, 211
marginal, 233
mulltinomial, 240
multivariate, 372
multivariate normal, 365-367
n-Erlang, 216
negative hypergeometric, 319
normal, 356-357
Weibull, 216-217
zeta (Zipf), 163–164
Distributive laws, 25
Double exponential random
variable, 211fn
Duration of play, problem of, 89–90

**E**
Edges, 91
Ehrenfest, Paul and Tatyana, 421
Entropy, 426–428, 435
and coding theory, 428–434
Equations, number of integer
solutions of, 12–15

Ergodic Markov chain, 423–424

```
Events, 23–26
independent, 79–93, 101
mutually exclusive, 24, 49
odds of, 101
pairwise independent, 147
Exchangeable random variables,
282–285
Expectation, See Continuous
random variables
conditional, 331–349, 371
and prediction, 349–353
correlations, 322–331
covariance, 322–323
general definition of, 369–370
moment generating functions,
354–365
binomial distribution with
parameters n and p , 355
continuous probability
distribution, 359
determination of the
distribution, 358
discrete probability
distribution, 358
exponential distribution with
parameterλ, 356
independent binomial random
variables, sums of, 360
independent normal random
variables, sums of, 360
independent Poisson random
variables, sums of, 360
joint, 363–365
normal distribution, 356–357
Poisson distribution with
meanλ, 355–356
of the sum of a random
number of random
variables, 361–363
moments of the number of
events that occur, 315–322,
319
binomial random variables,
moments of, 316–317
coupon-collecting problem,
318–319, 321–322
```

**524** Index

```
Expectation, See Continuous
random variables
( Continued )
hypergeometric random
variables, moments of,
317–318
moments in the match
problem, 318
negative hypergeometric
random variables, 319–321
probabilistic method, obtaining
bounds from expectations
via, 311–312
properties of, 297–387
of sums of random variables,
298–315
Boole’s inequality, 300–301
coupon-collecting problems,
303
coupon collecting with
unequal probabilities,
314–315
expectation of a binomial
random variable, 301
expected number of matches,
303
expected number of runs,
304–305
hypergeometric random
variable, mean of, 302
maximum–minimums
identity, 313–314
negative binomial random
variable, mean of, 301–302
probability of a union of
events, 308–310
quick-sort algorithm,
analyzing, 306–308
random walk in a plane,
305–306
sample mean, 300
variance of sums, 322–331
Expected value (expectation),
125–128, 171
Exponential random variables,
208–214, 223
hazard rate functions, 212–214
```
```
F
Failure rate function, 212, 223
Fermat, Pierre de, 85–86, 89
Fermat’s combinatorial identity, 18
Finite population, sampling from,
326–331
First of moment of X , 132
Functional system, 1
```
```
G
Galton, Francis, 399
Gambler’s ruin problem, 87–88
Gamma distribution, 215–216
Gamma function, 215, 223
Gamma random variables,
254–255
Gauss, Karl Friedrich, 207–208
Gaussian curve, 207
Gaussian distribution, 207
Generalized basic principle of
counting, 2
Geometric distribution, 447–448
variance of, 340
Geometric random variable with
parameter p , 448
Geometric random variables,
155–157, 260–263
Geometrical probability, 197
Goodwill cost, defined, 176
```
```
H
Half-life, probabilistic interpretation
of (example), 249–251
Hamiltonian path:
defined, 311
maximum number of, in a
tournament, 311–312
Hazard rate functions, 212–214, 223
Huygens, Christiaan, 86, 89
Hypergeometric random variables,
160–163
moments of, 317–318
```
```
I
Identically distributed uniform
random variables, 252–254
Importance sampling, 455
```

```
Index 525
```
Independent Bernoulli random
variables, bounding error
probability when
approximating a sum of,
410–412

Independent binomial random
variables, sums of, 260, 360
Independent events, 79–93, 101
Independent increment assumption,
417
Independent normal random
variables, sums of, 360
Independent Poisson random
variables, sums of, 259–260,
360
Independent random variables,
240–251, 286
binomial random variables,
259–260
Buffon’s needle problem,
243–246
conditional distributions:
continuous case, 266–274
discrete case, 263–266
gamma random variables,
254–255
geometric random variables,
260–263
half-life, probabilistic
interpretation of (example),
249–251
identically distributed uniform
random variables, 252–254
normal random variables,
256–259
Poisson random variables,
259–260
random subsets, 246–249
sums of, 252–263

Independent uniform random
variables, sum of two,
252–253
Inequality:
Boole’s, 300–301
Chebyshev’s, 388–391
Jensen’s, 409
Markov’s, 388

```
Initial probabilities, 99
Integer solutions of equations,
number of, 12–15
Interarrival times, sequence of,
418
Intersection, 23–24, 49
Inverse transformation method,
441–442, 453
exponential random variable,
simulating, 441
gamma random variable,
simulating, 441–442
```
```
J
Jacobian determinant, 280
Jensen’s inequality, 409
Joint cumulative probability
distribution function,
232–240, 282–285
Joint density function of order
statistics, 270
Joint distribution functions,
232–240
joint cumulative probability
distribution function,
232–240, 282–285
joint probability mass function,
233–234
marginal distributions, 233
multinomial distribution, 240
Joint moment generating functions,
363–365
Joint probability density function,
235–239, 285
Joint probability mass function,
233–234
Jointly continuous random
variables, 235, 239, 285
Jointly distributed random
variables, 232–297
joint distribution functions,
232–240
joint probability density
function, 235–239, 285
marginal probability mass
functions, 234
```

**526** Index

```
K
Kelley strategy, 378
Khinchine, A. Y., 391
Kolmogorov, A. N., 403
```
```
L
Laplace distribution, 211
Laplace, Pierre-Simon, 399
Laplace’s rule of succession, 98–99
Law of frequency of errors, 399
Laws of large numbers, 388
Legendre theorem, 229
Length of the longest run
(example), 148–154
L’Hopital’s rule, 392ˆ
Liapounoff, A., 393
Limit theorems, 388–417
central limit theorem, 391–399,
412
Chebyshev’s inequality, 388–391
strong law of large numbers,
400–403, 412
weak law of large numbers,
388–391
Lognormal random variable, 258
```
```
M
Marginal distributions, 233
Marginal probability mass functions,
234
Markov chain, 419–424, 434
Chapman–Kolmogorov
equations, 421–422
ergodic, 423–424
matrix, 420
random walk, 422
transition probabilities, 420
Markov’s inequality, 388
Matching problem (example),
41–42, 63
Matrix, 420
Maximum likelihood estimate, 160
Maximum–minimums identity,
313–314
Mean, 132, 171
Measureable events, 29
Measurement signalto-noise ratio,
414
```
```
Memoryless, use of term, 223
Men of Mathematics (Bell), 208
Method of maximum likelihood
estimation, 180
Midrange of a sequence, 293
Minimax theorem, 175
Moment generating functions,
354–365, 372
binomial distribution with
parameters n and p , 355
continuous probability
distribution, 359
determination of the
distribution, 358
discrete probability distribution,
358
exponential distribution with
parameterλ, 356
independent binomial random
variables, sums of, 360
independent normal random
variables, sums of, 360
independent Poisson random
variables, sums of, 360
joint, 363–365
normal distribution, 356–357
Poisson distribution with mean
λ, 355–356
of the sum of a random number
of random variables,
361–363
Multinomial coefficients, 9–12
defined, 11
Multinomial distribution, 240
Multinomial theorem, 11
Multiplication rule, 62–63, 101
Multivariate distributions, 372
Mutually exclusive events, 24, 49
```
```
N
n-Erlang distribution, 216
Natural Inheritance (Galton), 399
Negative binomial random
variables, 157–160
Negative hypergeometric
distribution, 319
```

```
Index 527
```
Negative hypergeometric random
variables, 319–321
Newton, Isaac, 208
Noiseless coding theorem, 429–431,
433–434
Normal curve, 207
Normal random variables,
256–259
joint distribution of the sample
mean and sample variance,
367–369
multivariate normal
distribution, 365–367
simulating, 443–444
polar method, 445–446

Notation/terminology, 6, 10
_n_ th moment of X, 132
Null event, 24
Null set, 49

**O**
Odds, of an event, 101
One-sided Chebyshev’s inequality,
403–407
Order statistics, 270–274, 286

distribution of the range of a
random sample, 273–274
joint density function of, 270
Overlook probabilities, 74

**P**
Pairwise independent events, 147
Pareto, V., 164
Pascal, Blaise, 85–86
Pearson, Karl, 207–208

Permutations, 3–5
Personal view of probability, 48
Pierre-Simon, Marquis de Laplace,
399
Points, problem of, 86
Poisson distribution function,
computing, 154–155
Poisson paradigm, 148
Poisson process, 417–419
defined, 417, 434
independent increment
assumption, 417

```
sequence of interarrival times,
418
stationary increment
assumption, 417
waiting time, 419
Poisson random variables, 143–145,
171, 259–260
simulating, 449
Poisson, Simeon Denis, 143 ́
Polar algorithm, 453
Polar method, 445–446
Polya’s urn model, 284
Posterior probability, 99–100
Principle of counting, 1–3
Prior probabilities, 99
Probabilistic method, 93
obtaining bounds from
expectations via, 311–312
maximum number of
Hamiltonian paths in a
tournament, 311–312
Probabilistic Method, The
(Alon/Spencer/Erdos), 93 fn
Probability:
axioms of, 26–29
as a continuous set function,
44–48
defining, 26
of an event, 27
geometrical, 197
as a measure of belief, 48–49
multiplication rule, 62–63, 101
personal view of, 48
sample space and events, 22–26
simple propositions, 29–33
subjective view of, 48
Probability density function, 222
defined, 186
Probability mass function, 123, 171,
233
Probability, personal view of, 48
Problem of duration of play, 89–90
Pseudorandom numbers, 439
```
```
Q
Quick-sort algorithm, analyzing,
306–308
```

**528** Index

```
R
Random-number generator, 439
seed, 439
Random numbers, 385, 439, 453
Random permutation, generating,
439–440
Random samples, distribution of the
range of, 273–274
Random variables, 117–186, 134–139
Bernoulli, 134–139
binomial, 134–139, 259–260
continuous, 186–231
cumulative distribution
function, 123–125
properties of, 168–170
defined, 117, 170
dependent, 241
discrete, 123–125, 171
distribution of a function of,
219–221
exchangeable, 282–285
expectation of a function of,
128–132
expectation of a sum of a
random number of, 335
expectation of sums of, 298–315
expected value (expectation),
125–128
sums of, 164–168
exponential, 208
gamma, 254–255
geometric, 155–157, 260–263
hypergeometric, 160–163
Identically distributed uniform,
252–254
independent, 240–251
joint probability distribution of
functions of, 274–282
jointly continuous, 239
moment generating functions,
354–365
of the sum of a random
number of, 361–363
negative binomial, 157–160
normal, 198–204, 256–259
order statistics, 270–274, 286
Poisson, 143–145, 171, 259–260
```
```
uniform, 194–198
variance, 171
variance of a sum of a random
number of, 349
Weibull, 217
zeta (Zipf) distribution, 163–164
Random walk, 422
Rate of transmission of information,
436
Rayleigh density function, 229
Recherches sur la probabilil ́edes
jugements en matiere`
criminelle et en matiere`
civile (Investigations into the
Probability of Verdicts in
Criminal and Civil Matters) ,
143
Rejection method, 442–444, 453–454
simulating a chi-squared
random variable, 446–447
simulating a normal random
variable, 443–444
polar method, 445–446
Riemann, G. F. B., 164
```
```
S
Sample mean, 300, 372
joint distribution of, 367–369
joint distribution of sample
variance and, 367–369
Sample median, 272
Sample spaces:
and events, 22–26, 49
having equally likely outcomes,
33–44
Sample variance, 324, 372
joint distribution of sample
mean and, 367–369
Seed, 439
Selected problems, answers to,
456–457
Self-text problems/exercises,
458–516
Sequence of interarrival times, 418
Sequential updating of information,
99–101
Shannon, Claude, 433
```

```
Index 529
```
Simulation, 438–456
of continuous random variables:
general techniques for,
440–447
inverse transformation
method, 441–442, 453
rejection method, 442–444,
453–454
defined, 438
from discrete distributions,
447–449
pseudorandom numbers, 439
random-number generator, 439
random numbers, 439, 453
random permutation,
generating (example),
439–440
seed, 439
variance reduction techniques,
449–453
Simulation, defined, 246

Singletons, in coupon-collecting
problem, 321–322

Size of the zeroth generation, 383
St. Petersburg paradox, 175
Standard deviation of _X_ , 134, 171
Standard deviations, 414
Stationary increment assumption,
417
Stieltjes integrals, 369–370

Strong law of large numbers,
400–403, 412

Subjective view of probability, 48
Sums of random variables:
expectation of, 298–315
binomial random variable,
300–301
Boole’s inequality, 300–301
coupon-collecting problems,
303
coupon collecting with
unequal probabilities,
314–315
expectation of a binomial
random variable, 301
expected number of matches,
303

```
expected number of runs,
304–305
hypergeometric random
variable, mean of, 302
maximum–minimums
identity, 313–314
negative binomial random
variable, mean of, 301–302
probability of a union of
events, 308–310
quick-sort algorithm,
analyzing, 306–308
random walk in a plane,
305–306
sample mean, 300
Superset, 24
Surprise concept, 425–426
```
```
T
Theory of games, 175
Transition probabilities, Markov
chains, 420
Trials, 82
```
```
U
Uncertainty, 426–427
Uniform random variables, 194–198
Union, 23–24, 49
Updated probability, 99–100
Updating information sequentially,
99–101
Utility, 130–131
```
```
V
Variables, 163–164, See also
Random variables
antithetic, 450–451
Variance, 171
conditional, 347–349
covariance, 322–323
of geometric distribution, 340
sample, 324, 372
Variance reduction:
antithetic variables, use of,
450–451
by conditioning, 451–452
control variates, 452–453
techniques, 449–453
```

**530** Index

```
Venn diagram, 24–25
Vertices, 91
```
```
W
Waiting time, 419
Weak law of large numbers, 388–391
Weibull distribution, 216–217
Weibull random variables, 217
```
```
Wheel of fortune game
(chuck-a-luck) (example),
136
Wilcoxon sum-of ranks test, 376
```
```
Z
Zeroth generation, size of, 383
Zeta (Zipf) distribution, 163–164
Zipf, G. K., 164
```

